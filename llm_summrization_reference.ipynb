{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBAT6pEGiMnd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, PromptTemplate, LLMChain\n",
        "\n",
        "# Define the prompt template\n",
        "summary_prompt = \"\"\"\n",
        "Summarize the following paragraph. Here is an example of a summary:\n",
        "\n",
        "Paragraph: Keyword extraction is one of the core tasks in natural language processing. Classic extraction models are notorious for having a short attention span which make it hard for them to conclude relational connections among the words and sentences that are far from each other. This, in turn, makes their usage prohibitive for generating keywords that are inferred from the context of the whole text. In this paper, we explore using Large Language Models (LLMs) in generating keywords for items that are inferred from the items textual metadata. Our modeling framework includes several stages to fine grain the results by avoiding outputting keywords that are non informative or sensitive and reduce hallucinations common in LLM. We call our LLM-based framework Theme-Aware Keyword Extraction (LLM TAKE). We propose two variations of framework for generating extractive and abstractive themes for products in an E commerce setting. We perform an extensive set of experiments on three real data sets and show that our modeling framework can enhance accuracy based and diversity based metrics when compared with benchmark models.\n",
        "Summary: The paper introduces Theme-Aware Keyword Extraction (LLM TAKE), a framework using Large Language Models (LLMs) for improved keyword extraction from e-commerce textual metadata. Traditional models often miss relational connections in text, but LLM TAKE refines results to avoid non-informative, sensitive, or hallucinated keywords. It offers two variations for extractive and abstractive theme generation. Experiments on three real datasets show that LLM TAKE enhances accuracy and diversity metrics compared to benchmark models, proving its effectiveness in e-commerce keyword extraction.\n",
        "Now, summarize the following paragraph:\n",
        "\n",
        "Paragraph: {paragraph}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Create the prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"paragraph\"],\n",
        "    template=summary_prompt\n",
        ")\n",
        "\n",
        "# Initialize the OpenAI LLM\n",
        "llm = OpenAI(model=\"gpt-4\", api_key=openai.api_key)\n",
        "\n",
        "# Create the LLM Chain\n",
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt_template\n",
        ")\n"
      ],
      "metadata": {
        "id": "BEsfeZDtiYAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_summary(paragraph):\n",
        "    # Generate the summary using the LLM Chain\n",
        "    summary = chain.run(paragraph=paragraph)\n",
        "    return summary.strip()\n",
        "\n",
        "# Example usage\n",
        "paragraph = \"\"\"\n",
        "text...........................................................something................\n",
        "\"\"\"\n",
        "\n",
        "summary = extract_summary(paragraph)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "1CKnORlyieko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}