{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "predicted =str([\"management fee\", \"Fund\", \"Primary Investment\", \"Revenue\",\"www\", \"efeg\", \"sfsegeg\",\"erw\"])\n",
    "\n",
    "predicted = ast.literal_eval(predicted)\n",
    "\n",
    "actual = ['finance ','management fee', 'Fund', 'Primary Investment', 'Revenue', \"Banking\",\"default\",'logo']\n",
    "\n",
    "#You need to pass input file object here\n",
    "input_excel_file_name = \"sample.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade numpy openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venum\\Downloads/sample.csv Metrics file saved \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input file name</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample.xlsx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>erw</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>logo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>management fee</td>\n",
       "      <td>management fee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sfsegeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>default</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>finance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Revenue</td>\n",
       "      <td>Revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Primary Investment</td>\n",
       "      <td>Primary Investment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>efeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Banking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Fund</td>\n",
       "      <td>Fund</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input file name              actual           predicted  Accuracy  \\\n",
       "0      sample.xlsx                 NaN                 erw  0.333333   \n",
       "1              NaN                logo                 NaN       NaN   \n",
       "2              NaN      management fee      management fee       NaN   \n",
       "3              NaN                 NaN             sfsegeg       NaN   \n",
       "4              NaN             default                 NaN       NaN   \n",
       "5              NaN            finance                  NaN       NaN   \n",
       "6              NaN             Revenue             Revenue       NaN   \n",
       "7              NaN  Primary Investment  Primary Investment       NaN   \n",
       "8              NaN                 NaN                 www       NaN   \n",
       "9              NaN                 NaN                efeg       NaN   \n",
       "10             NaN             Banking                 NaN       NaN   \n",
       "11             NaN                Fund                Fund       NaN   \n",
       "\n",
       "    Precision  Recall  F1 Score  \n",
       "0         0.5     0.5       0.5  \n",
       "1         NaN     NaN       NaN  \n",
       "2         NaN     NaN       NaN  \n",
       "3         NaN     NaN       NaN  \n",
       "4         NaN     NaN       NaN  \n",
       "5         NaN     NaN       NaN  \n",
       "6         NaN     NaN       NaN  \n",
       "7         NaN     NaN       NaN  \n",
       "8         NaN     NaN       NaN  \n",
       "9         NaN     NaN       NaN  \n",
       "10        NaN     NaN       NaN  \n",
       "11        NaN     NaN       NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def export_evaluation_metrics_as_csv(input_excel_file_name, output_location, actual, predicted ,file_type):\n",
    "    \n",
    "    file_name = input_excel_file_name\n",
    "    output_filename = output_location + \"/\" + file_name.split(\"/\")[-1].split(\".\")[0] + \".csv\"\n",
    "    \n",
    "    #Def equalize_lengths\n",
    "    def equalize_lengths(actual, predicted):\n",
    "        # Determine the lengths of the lists\n",
    "        len_actual = len(actual)\n",
    "        len_predicted = len(predicted)\n",
    "\n",
    "        # Append None to the shorter list until both lists are the same length\n",
    "        if len_actual > len_predicted:\n",
    "            predicted.extend([None] * (len_actual - len_predicted))\n",
    "        elif len_predicted > len_actual:\n",
    "            actual.extend([None] * (len_predicted - len_actual))\n",
    "\n",
    "        return actual, predicted\n",
    "    \n",
    "    actual, predicted = equalize_lengths(actual, predicted)\n",
    "    \n",
    "    actual_set = set(actual)\n",
    "    predicted_set = set(predicted)\n",
    "\n",
    "    # Combine sets to get all unique items\n",
    "    all_items = list(actual_set.union(predicted_set))\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(index=all_items, columns=['actual', 'predicted'])\n",
    "\n",
    "    # Populate the DataFrame\n",
    "    df['actual'] = [item if item in actual_set else np.nan for item in all_items]\n",
    "    df['predicted'] = [item if item in predicted_set else np.nan for item in all_items]\n",
    "\n",
    "    # Reset index to get the items as columns instead of index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    all_terms = list(set(predicted + actual))\n",
    "    y_true = [1 if term in actual else 0 for term in all_terms]\n",
    "    y_pred = [1 if term in predicted else 0 for term in all_terms]\n",
    "\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    df[\"input file name\"] = input_excel_file_name\n",
    "    df['Accuracy'] = accuracy\n",
    "    df['Precision'] = precision\n",
    "    df['Recall'] = recall\n",
    "    df['F1 Score'] = f1\n",
    "    \n",
    "    df = df[[ 'input file name','actual', 'predicted', 'Accuracy', 'Precision','Recall', 'F1 Score']]\n",
    "    \n",
    "    df.loc[1:, 'input file name'] = np.nan\n",
    "    df.loc[1:, 'Accuracy'] = np.nan\n",
    "    df.loc[1:, 'Precision'] = np.nan\n",
    "    df.loc[1:, 'Recall'] = np.nan\n",
    "    df.loc[1:, 'F1 Score'] = np.nan\n",
    "    \n",
    "    \n",
    "    if file_type == \"excel\":\n",
    "        output_filename = output_filename.replace(\".csv\",\".xlsx\")\n",
    "        df.to_excel(output_filename, index=False)\n",
    "    else:\n",
    "        df.to_csv(output_filename)\n",
    "        \n",
    "    print(f\"{output_filename} Metrics file saved \")\n",
    "    return df\n",
    "\n",
    "# Print the DataFrame\n",
    "\n",
    "output_location = r\"C:\\Users\\venum\\Downloads\"\n",
    "file_type = \"csv\" #\"excel\" or \"csv\"\n",
    "scores_df = export_evaluation_metrics_as_csv(input_excel_file_name, output_location, actual, predicted,file_type )\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
