{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc8203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1414dec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\llm\\llm_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754faf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BART model and tokenizer\n",
    "model = BartForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1ace15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>troubled marsh under sec scrutiny the us stock...</td>\n",
       "      <td>paydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us insurer marsh cuts 2 500 jobs up to 2 500 j...</td>\n",
       "      <td>paydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>japan bank shares up on link talk shares of su...</td>\n",
       "      <td>paydown_intrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ge sees  excellent  world economy us behemoth ...</td>\n",
       "      <td>paydown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news corp eyes video games market news corp  t...</td>\n",
       "      <td>paydown_intrest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document         category\n",
       "0  troubled marsh under sec scrutiny the us stock...          paydown\n",
       "1  us insurer marsh cuts 2 500 jobs up to 2 500 j...          paydown\n",
       "2  japan bank shares up on link talk shares of su...  paydown_intrest\n",
       "3  ge sees  excellent  world economy us behemoth ...          paydown\n",
       "4  news corp eyes video games market news corp  t...  paydown_intrest"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sample_docs.csv\")\n",
    "df =df[[\"document\",\"category\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e13ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6d146c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>troubled marsh under sec scrutiny the us stock...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us insurer marsh cuts 2 500 jobs up to 2 500 j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>japan bank shares up on link talk shares of su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ge sees  excellent  world economy us behemoth ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news corp eyes video games market news corp  t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  category\n",
       "0  troubled marsh under sec scrutiny the us stock...         0\n",
       "1  us insurer marsh cuts 2 500 jobs up to 2 500 j...         0\n",
       "2  japan bank shares up on link talk shares of su...         1\n",
       "3  ge sees  excellent  world economy us behemoth ...         0\n",
       "4  news corp eyes video games market news corp  t...         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['category'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77fb240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'paydown', 1: 'paydown_intrest', 2: 'paydown_only'}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map encoded numerical values to categories\n",
    "encoded_to_category = {index: category for index, category in enumerate(label_encoder.classes_)}\n",
    "\n",
    "print(encoded_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef7ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ddaacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"document\"].to_list()\n",
    "y = df[\"category\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4b34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare your dataset\n",
    "# Assuming you have your data in X (text) and y (labels) format\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "num_labels = len(set(y_train))\n",
    "\n",
    "# Prepare your dataset\n",
    "# Assuming you have your data in X (text) and y (labels) format\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "num_labels = len(set(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94675e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Tokenize and encode your training and validation data\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f611c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tokenized encodings into PyTorch tensors\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    torch.tensor(y_train)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(val_encodings['input_ids']),\n",
    "    torch.tensor(val_encodings['attention_mask']),\n",
    "    torch.tensor(y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6328179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\llm\\llm_env\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Create DataLoader for training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f3a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    for batch in val_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8cb24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbedb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b3760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f38a7526",
   "metadata": {},
   "source": [
    "# Type2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f402d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1d092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2eb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f866b432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "E:\\llm\\llm_env\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader  # Import DataLoader from PyTorch\n",
    "\n",
    "# Load dataset from CSV\n",
    "df = pd.read_csv(\"sample_docs.csv\")  # Adjust the file path accordingly\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset format\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 8\n",
    "num_epochs = 4\n",
    "\n",
    "# Load zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "\n",
    "labels = dataset.unique(\"category\")\n",
    "\n",
    "# Fine-tune zero-shot model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define data loader\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        inputs = tokenizer(batch[\"document\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        labels_ids = torch.tensor([labels.index(label) for label in batch[\"category\"]])  # Convert labels to indices\n",
    "        outputs = model(**inputs, labels=labels_ids)  # Use label indices instead of tokenized labels\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "# Fine-tuned model\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model, tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5db68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text = \"sample text\"\n",
    "candidate_labels = labels\n",
    "result = classifier(text, candidate_labels)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
