{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ae861cf7a844cd7b685592058af2df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d3ab8f6c14042f9b90a12c9f90e34b1",
              "IPY_MODEL_0955fda0bf164a82ad43af078892a9ca",
              "IPY_MODEL_aed4b13353fe4283ba9532942c36a9e5"
            ],
            "layout": "IPY_MODEL_a5015f6308504604b5e40744248fd339"
          }
        },
        "6d3ab8f6c14042f9b90a12c9f90e34b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f79a9aae91d6415ca4b10bbf8c4b4c8e",
            "placeholder": "​",
            "style": "IPY_MODEL_9846fc9bd82c4da28d127d9b24485b99",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0955fda0bf164a82ad43af078892a9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fad1bdeb28c54d7cafc9b17e6839c569",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72581da74ebd4bbdaa8cf5a93915c442",
            "value": 48
          }
        },
        "aed4b13353fe4283ba9532942c36a9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dab9ff59ff94b48b656b7b835add042",
            "placeholder": "​",
            "style": "IPY_MODEL_a3bf467317d341f7821e58d40e9595d0",
            "value": " 48.0/48.0 [00:00&lt;00:00, 806B/s]"
          }
        },
        "a5015f6308504604b5e40744248fd339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f79a9aae91d6415ca4b10bbf8c4b4c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9846fc9bd82c4da28d127d9b24485b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fad1bdeb28c54d7cafc9b17e6839c569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72581da74ebd4bbdaa8cf5a93915c442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dab9ff59ff94b48b656b7b835add042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3bf467317d341f7821e58d40e9595d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1066d70bce0a4f79ae9ba822d42bb52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34a10475a1344790abadf7ff6283f827",
              "IPY_MODEL_94a5c1133379459cbeb8519a71d2b11b",
              "IPY_MODEL_7071d7376965474483a1818a894a185d"
            ],
            "layout": "IPY_MODEL_2bf1840f2ef34c7e9768f59790e13db9"
          }
        },
        "34a10475a1344790abadf7ff6283f827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80002f6222b0441799edb2efde0c1350",
            "placeholder": "​",
            "style": "IPY_MODEL_78615bbe2634433e884e5adec33868da",
            "value": "vocab.txt: 100%"
          }
        },
        "94a5c1133379459cbeb8519a71d2b11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9303deba06f9454885edcbff08cc6601",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b182fa3c143466fb504b51e724eb6bb",
            "value": 231508
          }
        },
        "7071d7376965474483a1818a894a185d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c84ff0fb44b141488e052298b7b8c2da",
            "placeholder": "​",
            "style": "IPY_MODEL_4c2e6d6a9cb64bc3b60a1612350e285a",
            "value": " 232k/232k [00:00&lt;00:00, 2.35MB/s]"
          }
        },
        "2bf1840f2ef34c7e9768f59790e13db9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80002f6222b0441799edb2efde0c1350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78615bbe2634433e884e5adec33868da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9303deba06f9454885edcbff08cc6601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b182fa3c143466fb504b51e724eb6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c84ff0fb44b141488e052298b7b8c2da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c2e6d6a9cb64bc3b60a1612350e285a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45503582a56240aa865686c382485a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e94bd1a2b524b189906a5475c69c05b",
              "IPY_MODEL_73d218c99d704df684940ec15ef747fc",
              "IPY_MODEL_6dc3b671588d4117baa02c54e73cfed2"
            ],
            "layout": "IPY_MODEL_fc35c0ad4ff04b64be2f747739da1d7c"
          }
        },
        "8e94bd1a2b524b189906a5475c69c05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a27b3565b4b49bd99bc24b34e5af636",
            "placeholder": "​",
            "style": "IPY_MODEL_adf2c8c6c1fd4e0caebe04bf09f3860f",
            "value": "tokenizer.json: 100%"
          }
        },
        "73d218c99d704df684940ec15ef747fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9252d3e883479486dc219b5fc08958",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_126da52849e7415a888d03e38904ecf3",
            "value": 466062
          }
        },
        "6dc3b671588d4117baa02c54e73cfed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90b93d6dd124253b00b6c098e33b56e",
            "placeholder": "​",
            "style": "IPY_MODEL_d3356ef12f1f4d58bb697fb45e05a2bc",
            "value": " 466k/466k [00:00&lt;00:00, 5.07MB/s]"
          }
        },
        "fc35c0ad4ff04b64be2f747739da1d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a27b3565b4b49bd99bc24b34e5af636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf2c8c6c1fd4e0caebe04bf09f3860f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af9252d3e883479486dc219b5fc08958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "126da52849e7415a888d03e38904ecf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c90b93d6dd124253b00b6c098e33b56e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3356ef12f1f4d58bb697fb45e05a2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5157b318f2e4bfd8edee6d4265de13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fb3bf251f2d473dae15377fcfab3956",
              "IPY_MODEL_5228e28c524847e18f8e55f4843cde45",
              "IPY_MODEL_3a91d6e728eb4349851aa5841ee76986"
            ],
            "layout": "IPY_MODEL_d00a6475a3e14f1786f26c9a0e6c3845"
          }
        },
        "9fb3bf251f2d473dae15377fcfab3956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57de7e129c584d3cb5b7c1c8e224033b",
            "placeholder": "​",
            "style": "IPY_MODEL_91e9310d68514d278465d38d07b7052d",
            "value": "config.json: 100%"
          }
        },
        "5228e28c524847e18f8e55f4843cde45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa803a0320e74bdcb7548f96bd5d8fc3",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab0e3f450a9444beb7a4e4543dcd24fd",
            "value": 570
          }
        },
        "3a91d6e728eb4349851aa5841ee76986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_301bbbbbeb704706ae858a1efbff0e79",
            "placeholder": "​",
            "style": "IPY_MODEL_e3bf6958320c49d0a409b1c05a6a7168",
            "value": " 570/570 [00:00&lt;00:00, 17.9kB/s]"
          }
        },
        "d00a6475a3e14f1786f26c9a0e6c3845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57de7e129c584d3cb5b7c1c8e224033b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e9310d68514d278465d38d07b7052d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa803a0320e74bdcb7548f96bd5d8fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab0e3f450a9444beb7a4e4543dcd24fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "301bbbbbeb704706ae858a1efbff0e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3bf6958320c49d0a409b1c05a6a7168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07761961ae994ab2a1b7660901f65541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_008a085867b842788fc95e6d783b575a",
              "IPY_MODEL_1ee4a5d7569049ac817ae4264a0e549a",
              "IPY_MODEL_1f54d71b849d41ff8810d690d1f95ff7"
            ],
            "layout": "IPY_MODEL_ca44bc423d844dd7a1045d629ef1668c"
          }
        },
        "008a085867b842788fc95e6d783b575a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b7f55c653dc4566b8fdf69216731b6a",
            "placeholder": "​",
            "style": "IPY_MODEL_60cecea8d26849348b88bf24b4deaad0",
            "value": "model.safetensors: 100%"
          }
        },
        "1ee4a5d7569049ac817ae4264a0e549a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78251ebb013843d4873e45c0cea022dd",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e5712598e694bbabf31e63799c4c35a",
            "value": 440449768
          }
        },
        "1f54d71b849d41ff8810d690d1f95ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce5d0893059c49d58e0ef719fba3858b",
            "placeholder": "​",
            "style": "IPY_MODEL_bcd1861e67454738800d837e065017c5",
            "value": " 440M/440M [00:05&lt;00:00, 77.7MB/s]"
          }
        },
        "ca44bc423d844dd7a1045d629ef1668c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b7f55c653dc4566b8fdf69216731b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60cecea8d26849348b88bf24b4deaad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78251ebb013843d4873e45c0cea022dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5712598e694bbabf31e63799c4c35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce5d0893059c49d58e0ef719fba3858b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd1861e67454738800d837e065017c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d63a56aff40d415cabf70bfe39327c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfe320eafe644ebd86048d391e3fdc98",
              "IPY_MODEL_d0f7990cb1ea4d7485ec0f81b124d4f9",
              "IPY_MODEL_6435fcf4df6943b2bf132a1fb3aa6d74"
            ],
            "layout": "IPY_MODEL_a64dc30335ff4fec9d3c7317286033ad"
          }
        },
        "bfe320eafe644ebd86048d391e3fdc98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bcb8e2668d64bdea4c713d600c79ea7",
            "placeholder": "​",
            "style": "IPY_MODEL_64714ca2dc6c43da917dab06c2355bdd",
            "value": "Fetching 5 files: 100%"
          }
        },
        "d0f7990cb1ea4d7485ec0f81b124d4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9b1f532e974d7f9fb104e398a670bc",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c23169b0a70431096209ff47090d214",
            "value": 5
          }
        },
        "6435fcf4df6943b2bf132a1fb3aa6d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c9c4abc0466440c934cc4c4b81a874c",
            "placeholder": "​",
            "style": "IPY_MODEL_465fc92f17c64e03bc14cb558d8a6b8f",
            "value": " 5/5 [00:03&lt;00:00,  1.93s/it]"
          }
        },
        "a64dc30335ff4fec9d3c7317286033ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bcb8e2668d64bdea4c713d600c79ea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64714ca2dc6c43da917dab06c2355bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec9b1f532e974d7f9fb104e398a670bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c23169b0a70431096209ff47090d214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c9c4abc0466440c934cc4c4b81a874c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465fc92f17c64e03bc14cb558d8a6b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dfa0da36ea7428daaffeb84b094332e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_873628da40644b239e187bd38850a656",
              "IPY_MODEL_9c43415c539349cea2e3bb95efc3cb29",
              "IPY_MODEL_ea01b6402d2549dda5c11da39e92dd7f"
            ],
            "layout": "IPY_MODEL_db38017b87134738933cb4dfe5678b6a"
          }
        },
        "873628da40644b239e187bd38850a656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60d6e95b2b874977a14febccfe3e3790",
            "placeholder": "​",
            "style": "IPY_MODEL_67be254d06ef4cf28b8e1be6eb0da867",
            "value": "config.json: 100%"
          }
        },
        "9c43415c539349cea2e3bb95efc3cb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e36fbef8e84476d99414bb6e55eaa8a",
            "max": 740,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_619a768b2cbc42efaf58db3a413f32d4",
            "value": 740
          }
        },
        "ea01b6402d2549dda5c11da39e92dd7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5058e118fe3b4dcda6fabad76e90313f",
            "placeholder": "​",
            "style": "IPY_MODEL_e87b7726d54a40d0b49988c409465ec2",
            "value": " 740/740 [00:00&lt;00:00, 7.49kB/s]"
          }
        },
        "db38017b87134738933cb4dfe5678b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60d6e95b2b874977a14febccfe3e3790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67be254d06ef4cf28b8e1be6eb0da867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e36fbef8e84476d99414bb6e55eaa8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "619a768b2cbc42efaf58db3a413f32d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5058e118fe3b4dcda6fabad76e90313f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e87b7726d54a40d0b49988c409465ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15bf7ff98a154d5698df381acaad9fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dceca8549b14b4380ebb20941145f65",
              "IPY_MODEL_65c41a9548a84c699f4594f0cd904407",
              "IPY_MODEL_b2d2bf9004e44e47924a891e38e2fbf6"
            ],
            "layout": "IPY_MODEL_c94ff76f475143569c2f030e24409d97"
          }
        },
        "7dceca8549b14b4380ebb20941145f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b50fa45be6514f1d9410da47cc5bad85",
            "placeholder": "​",
            "style": "IPY_MODEL_2bf7429fe09c47e69af4ac4c967eb6b1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "65c41a9548a84c699f4594f0cd904407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76b9469949c5486c97c29a72ff812fb9",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a1158f8a9c740d19c8922c4e5c64294",
            "value": 695
          }
        },
        "b2d2bf9004e44e47924a891e38e2fbf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f644b5e8d0d471c83d94dcd332226a1",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0658f11a9b4e4282c7c6b0530d8ea6",
            "value": " 695/695 [00:00&lt;00:00, 6.70kB/s]"
          }
        },
        "c94ff76f475143569c2f030e24409d97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b50fa45be6514f1d9410da47cc5bad85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bf7429fe09c47e69af4ac4c967eb6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76b9469949c5486c97c29a72ff812fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1158f8a9c740d19c8922c4e5c64294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f644b5e8d0d471c83d94dcd332226a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0658f11a9b4e4282c7c6b0530d8ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4582b810ba044f8aa22f93cbd4fc360a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d323e0c82f645848dcd838d00bf07af",
              "IPY_MODEL_750e22e57a204aff9b92f796972864b1",
              "IPY_MODEL_8d2350230ca74a15be5c87b0a6c11c7e"
            ],
            "layout": "IPY_MODEL_70626758351e4835801b9b3c1c0b3b0f"
          }
        },
        "3d323e0c82f645848dcd838d00bf07af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01020158deaf44688ebca211eda3ee89",
            "placeholder": "​",
            "style": "IPY_MODEL_7d5b2d3f5be04e8fa5707213180fd5dd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "750e22e57a204aff9b92f796972864b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fb61b21c70d4ea9a24cbbe1dd179d8e",
            "max": 1242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_225c351a384347079968cf30a6d6ec5d",
            "value": 1242
          }
        },
        "8d2350230ca74a15be5c87b0a6c11c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e3827b36f747c49f7f99c4b49cbdd0",
            "placeholder": "​",
            "style": "IPY_MODEL_87060c8538b24d598cd76b7822e6d5fc",
            "value": " 1.24k/1.24k [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "70626758351e4835801b9b3c1c0b3b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01020158deaf44688ebca211eda3ee89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5b2d3f5be04e8fa5707213180fd5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fb61b21c70d4ea9a24cbbe1dd179d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225c351a384347079968cf30a6d6ec5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2e3827b36f747c49f7f99c4b49cbdd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87060c8538b24d598cd76b7822e6d5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a6ea0ecd2ac4632aaec256aab3afd7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec7642e78fb94617ae5ce940b8105822",
              "IPY_MODEL_7034641ae6fa43bd90b8a83ec1a8c650",
              "IPY_MODEL_13b020570df24caca282a5c37535050d"
            ],
            "layout": "IPY_MODEL_9576f6bfe5fe46c8b6a8bfa2529d28d9"
          }
        },
        "ec7642e78fb94617ae5ce940b8105822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd0efc59d5746ed8eae1800400a41ff",
            "placeholder": "​",
            "style": "IPY_MODEL_6fd60ba72216474d961d6c11ae7f572a",
            "value": "tokenizer.json: 100%"
          }
        },
        "7034641ae6fa43bd90b8a83ec1a8c650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfde163b3d2d4b1db66fb1c925e06206",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e1b25ce3de14fd78629472271092b31",
            "value": 711396
          }
        },
        "13b020570df24caca282a5c37535050d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8324208d1267497583204f7ed9845900",
            "placeholder": "​",
            "style": "IPY_MODEL_4f04dded6f1b4bddbdcd89fe3653a80c",
            "value": " 711k/711k [00:00&lt;00:00, 3.48MB/s]"
          }
        },
        "9576f6bfe5fe46c8b6a8bfa2529d28d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd0efc59d5746ed8eae1800400a41ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd60ba72216474d961d6c11ae7f572a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfde163b3d2d4b1db66fb1c925e06206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e1b25ce3de14fd78629472271092b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8324208d1267497583204f7ed9845900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f04dded6f1b4bddbdcd89fe3653a80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9cbf5aacb9d4560b4f5d9856be1e4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cc8a522a7ff4fceb970dffad782723b",
              "IPY_MODEL_592c05f603a74216ac09bfc1cab77440",
              "IPY_MODEL_b4d0b374665e4b63bf5e82ceac00ce83"
            ],
            "layout": "IPY_MODEL_541ddd80ecb74179ad5b7eeadef478cd"
          }
        },
        "3cc8a522a7ff4fceb970dffad782723b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_474f5b8711fc47639ec8015910a08e20",
            "placeholder": "​",
            "style": "IPY_MODEL_d68c7c56a52646a182e5adaa2cf2808a",
            "value": "model_optimized.onnx: 100%"
          }
        },
        "592c05f603a74216ac09bfc1cab77440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d26f02dce9434b2084ef216cd70a5eab",
            "max": 217824172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a41114e234ee4483b9b18eae51537162",
            "value": 217824172
          }
        },
        "b4d0b374665e4b63bf5e82ceac00ce83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07c160df6f5949fcb7715292a99d8d1c",
            "placeholder": "​",
            "style": "IPY_MODEL_c795ba9a9b064f2e8710b616f1005e3e",
            "value": " 218M/218M [00:02&lt;00:00, 110MB/s]"
          }
        },
        "541ddd80ecb74179ad5b7eeadef478cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474f5b8711fc47639ec8015910a08e20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68c7c56a52646a182e5adaa2cf2808a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d26f02dce9434b2084ef216cd70a5eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41114e234ee4483b9b18eae51537162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07c160df6f5949fcb7715292a99d8d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c795ba9a9b064f2e8710b616f1005e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dee259618ffe43d1acf3949149c6e492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6321e86cb6804a16916b633427e6a25e",
              "IPY_MODEL_d9f821ba2aa2430d9962e63488fd61b2",
              "IPY_MODEL_b8e588e83d674ee09908f498121c6374"
            ],
            "layout": "IPY_MODEL_981d9feed1d74bd8952f4edaff57ec88"
          }
        },
        "6321e86cb6804a16916b633427e6a25e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92bc4a6d26b4aacb01edc225626a421",
            "placeholder": "​",
            "style": "IPY_MODEL_6768b442e5344e43886e9a416bfad8ca",
            "value": "Fetching 5 files: 100%"
          }
        },
        "d9f821ba2aa2430d9962e63488fd61b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_211e36f151ea48a9877a7fdd470540ce",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70e17f4b00764257ab8ad6a4869325f0",
            "value": 5
          }
        },
        "b8e588e83d674ee09908f498121c6374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25ef21bc55e243c6b6721f2e1efbdd35",
            "placeholder": "​",
            "style": "IPY_MODEL_58bdd3d989774c8a9da647ecc6146886",
            "value": " 5/5 [00:02&lt;00:00,  1.25s/it]"
          }
        },
        "981d9feed1d74bd8952f4edaff57ec88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92bc4a6d26b4aacb01edc225626a421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6768b442e5344e43886e9a416bfad8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "211e36f151ea48a9877a7fdd470540ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e17f4b00764257ab8ad6a4869325f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25ef21bc55e243c6b6721f2e1efbdd35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58bdd3d989774c8a9da647ecc6146886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86c7aaba772a4ec0ac1a3427dc659c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7da84b07b4e474dbb620eafab1dbdef",
              "IPY_MODEL_7c9e245124644079a96891b7e497ef33",
              "IPY_MODEL_9a3fa06798064967b39a69ec6c345696"
            ],
            "layout": "IPY_MODEL_6ff33ed73bb64c5794f12c1d5ecb1d0a"
          }
        },
        "d7da84b07b4e474dbb620eafab1dbdef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8afec28431d48ef8d06863083a82595",
            "placeholder": "​",
            "style": "IPY_MODEL_49a7a126152f47349d804570e51a70ad",
            "value": "config.json: 100%"
          }
        },
        "7c9e245124644079a96891b7e497ef33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49cd4bc555443b5b3550e9fa4b5d849",
            "max": 650,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02c871c02ce14f61ba29a4ceb972907d",
            "value": 650
          }
        },
        "9a3fa06798064967b39a69ec6c345696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b53f8916e3485f96881f487e180725",
            "placeholder": "​",
            "style": "IPY_MODEL_9628fe2c9b854276b28914e23034ed41",
            "value": " 650/650 [00:00&lt;00:00, 5.15kB/s]"
          }
        },
        "6ff33ed73bb64c5794f12c1d5ecb1d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8afec28431d48ef8d06863083a82595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a7a126152f47349d804570e51a70ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f49cd4bc555443b5b3550e9fa4b5d849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c871c02ce14f61ba29a4ceb972907d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3b53f8916e3485f96881f487e180725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9628fe2c9b854276b28914e23034ed41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e20376da74f41c5a95eef582655a634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_280ade5062aa47f1a8d0a700ea1c1cba",
              "IPY_MODEL_7acf8c9ca0f64d488ef0c901decc9790",
              "IPY_MODEL_01a2ec5e014c413893a8f8e2b71368ff"
            ],
            "layout": "IPY_MODEL_4e53628c6f834f4081efc0cb1269c848"
          }
        },
        "280ade5062aa47f1a8d0a700ea1c1cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a344ed1057c48a28da77f3003b17f7e",
            "placeholder": "​",
            "style": "IPY_MODEL_db3b1500b992420f89c55b2204039746",
            "value": "tokenizer.json: 100%"
          }
        },
        "7acf8c9ca0f64d488ef0c901decc9790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_891faf33ee5b4d428db3f53a11063e08",
            "max": 711661,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc8c635f20ae4ce7831fbaa6edc40990",
            "value": 711661
          }
        },
        "01a2ec5e014c413893a8f8e2b71368ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f088389cebd14005b473996e48d0244d",
            "placeholder": "​",
            "style": "IPY_MODEL_5e80296abab34f56989912e24137582a",
            "value": " 712k/712k [00:00&lt;00:00, 2.94MB/s]"
          }
        },
        "4e53628c6f834f4081efc0cb1269c848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a344ed1057c48a28da77f3003b17f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db3b1500b992420f89c55b2204039746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "891faf33ee5b4d428db3f53a11063e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8c635f20ae4ce7831fbaa6edc40990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f088389cebd14005b473996e48d0244d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e80296abab34f56989912e24137582a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5475a06e87544618a330042a2a0a22d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f6c56ae5c0b4f4e9454c94e74a2ed2d",
              "IPY_MODEL_f9feda69895a4322af34591b132c7c2f",
              "IPY_MODEL_d8d72c016091433a8ae80d6267bcc4b2"
            ],
            "layout": "IPY_MODEL_a25bf3284c454535b35708b9277e5525"
          }
        },
        "9f6c56ae5c0b4f4e9454c94e74a2ed2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad7a62d36c23460fa98502789f381422",
            "placeholder": "​",
            "style": "IPY_MODEL_cf460b361d9846838a35e0dd1d716cd2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f9feda69895a4322af34591b132c7c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec4e2eb6953407e947ea3d4731055d5",
            "max": 1433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_434cd666947c4ce380387b5666929c8c",
            "value": 1433
          }
        },
        "d8d72c016091433a8ae80d6267bcc4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2817add739c4b2c85ec862d3d3c5da1",
            "placeholder": "​",
            "style": "IPY_MODEL_f2ea564d380e4d028953a157ba33702a",
            "value": " 1.43k/1.43k [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "a25bf3284c454535b35708b9277e5525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad7a62d36c23460fa98502789f381422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf460b361d9846838a35e0dd1d716cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dec4e2eb6953407e947ea3d4731055d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "434cd666947c4ce380387b5666929c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2817add739c4b2c85ec862d3d3c5da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ea564d380e4d028953a157ba33702a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "138d475989394f379615556ac017baeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e319f70791af4f108d8bad78eb85b972",
              "IPY_MODEL_cf8432a417c94f059ef72d1ab1a03f0d",
              "IPY_MODEL_634117d3179d489fa3e4504d3ac1f332"
            ],
            "layout": "IPY_MODEL_053bce7a21304a2fbb33302a598a7438"
          }
        },
        "e319f70791af4f108d8bad78eb85b972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_598934192e2b4564b73c4349c887a0cf",
            "placeholder": "​",
            "style": "IPY_MODEL_4a9e6509652c4c7c9dd69327ba3ff00a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "cf8432a417c94f059ef72d1ab1a03f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fad778dcec9f4c4da3eaa66307e7117f",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44ceba2fcbd54692a0867dbd68d25286",
            "value": 695
          }
        },
        "634117d3179d489fa3e4504d3ac1f332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc5003a2e5e44e0828477e6e35a4255",
            "placeholder": "​",
            "style": "IPY_MODEL_94282be1b70f4a56835bf474e0647446",
            "value": " 695/695 [00:00&lt;00:00, 6.56kB/s]"
          }
        },
        "053bce7a21304a2fbb33302a598a7438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "598934192e2b4564b73c4349c887a0cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a9e6509652c4c7c9dd69327ba3ff00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fad778dcec9f4c4da3eaa66307e7117f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ceba2fcbd54692a0867dbd68d25286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfc5003a2e5e44e0828477e6e35a4255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94282be1b70f4a56835bf474e0647446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43c60008c42d49aea133ef70f28215f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f9d5475bb9c4020adec22265d560e58",
              "IPY_MODEL_3a64664a75ec422988eb6c6b4c2d56b8",
              "IPY_MODEL_dde39c2cd84d4be6b1f968a1155b6c11"
            ],
            "layout": "IPY_MODEL_853d46996b6147b8b04929823aee5bfb"
          }
        },
        "8f9d5475bb9c4020adec22265d560e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5b098316f942e9a91b36b3513ccda6",
            "placeholder": "​",
            "style": "IPY_MODEL_4c05615ba7994b01a8bd891276f52997",
            "value": "model.onnx: 100%"
          }
        },
        "3a64664a75ec422988eb6c6b4c2d56b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd7ce91f61e64dfdaf0e09c7ea485967",
            "max": 90387630,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64243f6d232a4f42840ae6e4bfee680d",
            "value": 90387630
          }
        },
        "dde39c2cd84d4be6b1f968a1155b6c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a9396d4671e4214b5424901e0d7539c",
            "placeholder": "​",
            "style": "IPY_MODEL_867030196ad24fa98f3fbdd5a0da6d86",
            "value": " 90.4M/90.4M [00:01&lt;00:00, 77.8MB/s]"
          }
        },
        "853d46996b6147b8b04929823aee5bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5b098316f942e9a91b36b3513ccda6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c05615ba7994b01a8bd891276f52997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7ce91f61e64dfdaf0e09c7ea485967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64243f6d232a4f42840ae6e4bfee680d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a9396d4671e4214b5424901e0d7539c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "867030196ad24fa98f3fbdd5a0da6d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pEwRBfKmJbCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -qU langchain_experimental langchain_openai langchain_community langchain ragas chromadb langchain-groq fastembed pypdf openai"
      ],
      "metadata": {
        "id": "UPB0BfOruyFU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "z1Pl8xfBy69M",
        "outputId": "1607d446-862a-43b5-8ee8-221469cecc23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.2\n",
            "    Uninstalling transformers-4.40.2:\n",
            "      Successfully uninstalled transformers-4.40.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastembed 0.2.7 requires huggingface-hub<0.21,>=0.20, but you have huggingface-hub 0.23.0 which is incompatible.\n",
            "fastembed 0.2.7 requires tokenizers<0.16,>=0.15, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.23.0 tokenizers-0.19.1 transformers-4.41.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub"
                ]
              },
              "id": "6c4ca8cab04245ae83f1314d016537dc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "class TextChunker:\n",
        "    def __init__(self, model_name=\"\", tokenizer = \"\", model = \"\"):\n",
        "        # Load pre-trained GPT-2 model and tokenizer\n",
        "        self.tokenizer = tokenizer #GPT2Tokenizer.from_pretrained(model_name)\n",
        "        self.model = model #GPT2Model.from_pretrained(model_name)\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def extract_text_from_pdf(self, path = \"/\"):\n",
        "        text = \"\"\n",
        "        loader = PyPDFLoader(path)\n",
        "        documents = loader.load()\n",
        "        for doc in documents:\n",
        "            text = text + \"\\n\" + str(doc.page_content)\n",
        "        return text,documents\n",
        "\n",
        "    def char_count_chunking(self, text, chunk_size=200, chunk_overlap=50):\n",
        "        # Instantiate the RecursiveCharacterTextSplitter class\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "        # Create documents using the text splitter\n",
        "        docs = text_splitter.create_documents([text])\n",
        "        chunks = [doc.page_content for doc in docs]\n",
        "        return chunks\n",
        "\n",
        "    def char_count_chunking_with_custom_delimiter(self, text, chunk_size=200, chunk_overlap=50, delimiter=\"\\n\\n\"):\n",
        "        # Instantiate the CharacterTextSplitter class\n",
        "        text_splitter = CharacterTextSplitter(separator=delimiter, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "        # Create documents using the text splitter\n",
        "        docs = text_splitter.create_documents([text])\n",
        "        chunks = [doc.page_content for doc in docs]\n",
        "        return chunks\n",
        "\n",
        "    def semantic_section_chunking(self, text, max_chunk_size=200, overlap_size=50):\n",
        "        # Tokenize the text\n",
        "        input_ids = self.tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=False)\n",
        "        # Define the chunking parameters\n",
        "        chunk_size = max_chunk_size - overlap_size\n",
        "        stride = chunk_size\n",
        "        # Perform chunking\n",
        "        chunks = []\n",
        "        for i in range(0, input_ids.size(1), stride):\n",
        "            # Slice the input_ids to form a chunk\n",
        "            chunk_input_ids = input_ids[:, i:i+chunk_size]\n",
        "            # Decode the chunk\n",
        "            chunk_text = self.tokenizer.decode(chunk_input_ids[0], skip_special_tokens=True)\n",
        "            # Add the chunk to the list\n",
        "            chunks.append(chunk_text)\n",
        "        return chunks\n",
        "\n",
        "    def semantic_section_chunking_with_TextEmbedding(self, text , text_embedding_model_name,  breakpoint_threshold_type = \"percentile\"):\n",
        "        embed_model = FastEmbedEmbeddings(model_name = text_embedding_model_name)\n",
        "        semantic_chunker = SemanticChunker(embed_model, breakpoint_threshold_type=breakpoint_threshold_type)\n",
        "        semantic_chunks = semantic_chunker.create_documents([d.page_content for d in documents])\n",
        "        return semantic_chunks\n",
        "\n"
      ],
      "metadata": {
        "id": "ZkWN_un9Jbpi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pc_BrhY7LdXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path =r\"/content/drive/MyDrive/chunking/ds (1).pdf\"\n"
      ],
      "metadata": {
        "id": "ptmB6tMG2UQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using gpt2\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model  = GPT2Model.from_pretrained(model_name)\n",
        "text_chunker = TextChunker(model_name= model_name, tokenizer = tokenizer, model = model)\n",
        "text, documents  = text_chunker.extract_text_from_pdf(path = pdf_path )\n",
        "\n",
        "chunks_char_count = text_chunker.char_count_chunking(text, chunk_size=50, chunk_overlap=40)\n",
        "print(\"Char count chunking:\")\n",
        "for i, chunk in enumerate(chunks_char_count):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")\n",
        "\n",
        "chunks_char_count = text_chunker.char_count_chunking(text, chunk_size=50, chunk_overlap=0)\n",
        "print(\"Char count chunking non overlap:\")\n",
        "for i, chunk in enumerate(chunks_char_count):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")\n",
        "\n",
        "chunks_custom_delimiter = text_chunker.char_count_chunking_with_custom_delimiter(text, chunk_size=200, chunk_overlap=50, delimiter=\"@\")\n",
        "print(\"\\nChar count chunking with custom delimiter:\")\n",
        "for i, chunk in enumerate(chunks_custom_delimiter):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")\n",
        "\n",
        "\n",
        "chunks_semantic = text_chunker.semantic_section_chunking(text, max_chunk_size=200, overlap_size=50)\n",
        "print(\"\\nSemantic section chunking:\")\n",
        "for i, chunk in enumerate(chunks_semantic):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6MkGNzBzK2S",
        "outputId": "9b4c80d4-ca16-4238-b33a-02f4b31bd2e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Chunk 2836: lar (??)). Using these notations, Sinkhorn’s\n",
            "Chunk 2837: Using these notations, Sinkhorn’s iterates read\n",
            "Chunk 2838: f(ℓ+1)= Minrow\n",
            "ε(C−1ng(ℓ)T) +εloga, (1.65)\n",
            "Chunk 2839: ε(C−1ng(ℓ)T) +εloga, (1.65)\n",
            "g(ℓ+1)= Mincol\n",
            "Chunk 2840: g(ℓ+1)= Mincol\n",
            "ε(C−f(ℓ)1mT) +εlogb. (1.66)\n",
            "Chunk 2841: Note that as ε→0, minεconverges to min, but the\n",
            "Chunk 2842: as ε→0, minεconverges to min, but the iterations\n",
            "Chunk 2843: to min, but the iterations do not converge\n",
            "Chunk 2844: min, but the iterations do not converge anymore\n",
            "Chunk 2845: the iterations do not converge anymore in the\n",
            "Chunk 2846: do not converge anymore in the limit ε= 0,\n",
            "Chunk 2847: because alternate minimization does not converge\n",
            "Chunk 2848: minimization does not converge for constrained\n",
            "Chunk 2849: does not converge for constrained problems (which\n",
            "Chunk 2850: for constrained problems (which is the case for\n",
            "Chunk 2851: problems (which is the case for the un-\n",
            "Chunk 2852: regularized dual (1.17)).\n",
            "Chunk 2853: Remark 17 (Log-domain Sinkhorn) .While\n",
            "Chunk 2854: 17 (Log-domain Sinkhorn) .While mathematically\n",
            "Chunk 2855: Sinkhorn) .While mathematically equivalent to the\n",
            "Chunk 2856: .While mathematically equivalent to the Sinkhorn\n",
            "Chunk 2857: equivalent to the Sinkhorn updates (1.51), itera-\n",
            "Chunk 2858: tions (1.63) and (1.64) suggest to use the\n",
            "Chunk 2859: (1.63) and (1.64) suggest to use the log-sum-exp\n",
            "Chunk 2860: suggest to use the log-sum-exp stabilization\n",
            "Chunk 2861: to use the log-sum-exp stabilization trick to\n",
            "Chunk 2862: the log-sum-exp stabilization trick to avoid\n",
            "Chunk 2863: stabilization trick to avoid underﬂow for small\n",
            "Chunk 2864: trick to avoid underﬂow for small values\n",
            "Chunk 2865: ofε. Writing z = min z, that trick suggests to\n",
            "Chunk 2866: z = min z, that trick suggests to evaluate min\n",
            "Chunk 2867: z, that trick suggests to evaluate min εzas\n",
            "Chunk 2868: minεz= z−εlog∑\n",
            "ie−(zi−z)/ε. (1.67)\n",
            "Chunk 2869: Instead of substracting z to stabilize the log\n",
            "Chunk 2870: of substracting z to stabilize the log domain\n",
            "Chunk 2871: z to stabilize the log domain iterations as in\n",
            "Chunk 2872: the log domain iterations as in (1.67), one can\n",
            "Chunk 2873: domain iterations as in (1.67), one can actually\n",
            "Chunk 2874: as in (1.67), one can actually substract the\n",
            "Chunk 2875: previously computed scalings. This leads to the\n",
            "Chunk 2876: computed scalings. This leads to the following\n",
            "Chunk 2877: scalings. This leads to the following stabilized\n",
            "Chunk 2878: This leads to the following stabilized iteration\n",
            "Chunk 2879: f(ℓ+1)= Minrow\n",
            "Chunk 2880: ε(S(f(ℓ),g(ℓ)))−f(ℓ)+εlog(a) (1.68)\n",
            "Chunk 2881: g(ℓ+1)= Mincol\n",
            "Chunk 2882: ε(S(f(ℓ+1),g(ℓ)))−g(ℓ)+εlog(b), (1.69)\n",
            "Chunk 2883: where we deﬁned\n",
            "S(f,g) =(\n",
            "Ci,j−fi−gj)\n",
            "i,j.\n",
            "Chunk 2884: In contrast to the original iterations (1.51),\n",
            "Chunk 2885: to the original iterations (1.51), these\n",
            "Chunk 2886: the original iterations (1.51), these log-domain\n",
            "Chunk 2887: iterations (1.51), these log-domain iterations\n",
            "Chunk 2888: (1.51), these log-domain iterations (1.68) and\n",
            "Chunk 2889: these log-domain iterations (1.68) and (1.69) are\n",
            "Chunk 2890: iterations (1.68) and (1.69) are stable for\n",
            "Chunk 2891: arbitraryε >0, because the quantity S(f,g) stays\n",
            "Chunk 2892: >0, because the quantity S(f,g) stays bounded\n",
            "Chunk 2893: the quantity S(f,g) stays bounded during the\n",
            "Chunk 2894: S(f,g) stays bounded during the iterations. The\n",
            "Chunk 2895: bounded during the iterations. The downside is\n",
            "Chunk 2896: during the iterations. The downside is that it\n",
            "Chunk 2897: requiresnmcomputations of exp at each step.\n",
            "Chunk 2898: of exp at each step. Computing a Minrow\n",
            "Chunk 2899: εor Mincol\n",
            "εis typically substantially\n",
            "Chunk 2900: slower than matrix multiplications, and requires\n",
            "Chunk 2901: matrix multiplications, and requires computing\n",
            "Chunk 2902: multiplications, and requires computing line by\n",
            "Chunk 2903: and requires computing line by line soft-minima\n",
            "Chunk 2904: computing line by line soft-minima of matrices S.\n",
            "Chunk 2905: line by line soft-minima of matrices S. There is\n",
            "Chunk 2906: therefore no eﬃcient way to parallelize the\n",
            "Chunk 2907: no eﬃcient way to parallelize the application of\n",
            "Chunk 2908: way to parallelize the application of Sinkhorn\n",
            "Chunk 2909: parallelize the application of Sinkhorn maps for\n",
            "Chunk 2910: the application of Sinkhorn maps for several\n",
            "Chunk 2911: of Sinkhorn maps for several marginals\n",
            "Chunk 2912: maps for several marginals simultaneously.\n",
            "Chunk 2913: In Euclidean domain of small dimension, it is\n",
            "Chunk 2914: domain of small dimension, it is possible to\n",
            "Chunk 2915: of small dimension, it is possible to develop\n",
            "Chunk 2916: dimension, it is possible to develop eﬃcient\n",
            "Chunk 2917: it is possible to develop eﬃcient multiscale\n",
            "Chunk 2918: possible to develop eﬃcient multiscale solvers\n",
            "Chunk 2919: to develop eﬃcient multiscale solvers with a\n",
            "Chunk 2920: eﬃcient multiscale solvers with a decaying\n",
            "Chunk 2921: εstrategy to signiﬁcantly speed up the\n",
            "Chunk 2922: to signiﬁcantly speed up the computation using\n",
            "Chunk 2923: speed up the computation using sparse grids [ ?].\n",
            "Chunk 2924: 24\n",
            "1.6 Extensions\n",
            "Chunk 2925: Wasserstein Barycenters. Given input histogram\n",
            "Chunk 2926: Barycenters. Given input histogram {bs}S\n",
            "Chunk 2927: s=1, wherebs∈Σns, and weights λ∈ΣS, a\n",
            "Chunk 2928: Wasserstein barycenter is computed by minimizing\n",
            "Chunk 2929: min\n",
            "a∈ΣnS∑\n",
            "s=1λsLCs(a,bs) (1.70)\n",
            "Chunk 2930: where the cost matrices Cs∈Rn×nsneed to be\n",
            "Chunk 2931: the cost matrices Cs∈Rn×nsneed to be speciﬁed. A\n",
            "Chunk 2932: matrices Cs∈Rn×nsneed to be speciﬁed. A typical\n",
            "Chunk 2933: Cs∈Rn×nsneed to be speciﬁed. A typical setup is\n",
            "Chunk 2934: to be speciﬁed. A typical setup is “Eulerian”, so\n",
            "Chunk 2935: A typical setup is “Eulerian”, so that all the\n",
            "Chunk 2936: barycenters are deﬁned on the same grid,\n",
            "Chunk 2937: are deﬁned on the same grid, ns=n,Cs=C=Dpis set\n",
            "Chunk 2938: on the same grid, ns=n,Cs=C=Dpis set to be a\n",
            "Chunk 2939: same grid, ns=n,Cs=C=Dpis set to be a distance\n",
            "Chunk 2940: ns=n,Cs=C=Dpis set to be a distance matrix, so\n",
            "Chunk 2941: set to be a distance matrix, so that one\n",
            "Chunk 2942: solves\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsWp\n",
            "p(a,bs).\n",
            "Chunk 2943: This barycenter problem (1.70) was originally\n",
            "Chunk 2944: problem (1.70) was originally introduced by [ ?]\n",
            "Chunk 2945: was originally introduced by [ ?] following\n",
            "Chunk 2946: originally introduced by [ ?] following earlier\n",
            "Chunk 2947: introduced by [ ?] following earlier ideas of [\n",
            "Chunk 2948: by [ ?] following earlier ideas of [ ?]. They\n",
            "Chunk 2949: following earlier ideas of [ ?]. They proved\n",
            "Chunk 2950: in particular uniqueness of the barycenter for\n",
            "Chunk 2951: uniqueness of the barycenter for c(x,y)\n",
            "Chunk 2952: of the barycenter for c(x,y) =||x−y||2overX=Rd,\n",
            "Chunk 2953: for c(x,y) =||x−y||2overX=Rd, if one of the input\n",
            "Chunk 2954: =||x−y||2overX=Rd, if one of the input measure\n",
            "Chunk 2955: has a density with respect to the Lebesgue\n",
            "Chunk 2956: a density with respect to the Lebesgue measure\n",
            "Chunk 2957: with respect to the Lebesgue measure (and more\n",
            "Chunk 2958: to the Lebesgue measure (and more generally under\n",
            "Chunk 2959: measure (and more generally under the same\n",
            "Chunk 2960: (and more generally under the same hypothesis as\n",
            "Chunk 2961: generally under the same hypothesis as the\n",
            "Chunk 2962: one guaranteeing the existence of a Monge map,\n",
            "Chunk 2963: the existence of a Monge map, see Remark ??).\n",
            "Chunk 2964: The barycenter problem for histograms (1.70) is\n",
            "Chunk 2965: problem for histograms (1.70) is in fact a linear\n",
            "Chunk 2966: histograms (1.70) is in fact a linear program,\n",
            "Chunk 2967: (1.70) is in fact a linear program, since one can\n",
            "Chunk 2968: in fact a linear program, since one can look for\n",
            "Chunk 2969: linear program, since one can look for the S\n",
            "Chunk 2970: couplings ( Ps)sbetween each input and the\n",
            "Chunk 2971: ( Ps)sbetween each input and the barycenter\n",
            "Chunk 2972: each input and the barycenter itself\n",
            "Chunk 2973: min\n",
            "a∈Σn,(Ps∈Rn×ns)s{S∑\n",
            "s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "Chunk 2974: a∈Σn,(Ps∈Rn×ns)s{S∑\n",
            "s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "s1ns=a,P⊤\n",
            "Chunk 2975: s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "s1ns=a,P⊤\n",
            "s1n=bs}\n",
            ".\n",
            "Chunk 2976: Although this problem is an LP, its scale forbids\n",
            "Chunk 2977: problem is an LP, its scale forbids the use\n",
            "Chunk 2978: is an LP, its scale forbids the use generic\n",
            "Chunk 2979: LP, its scale forbids the use generic solvers for\n",
            "Chunk 2980: forbids the use generic solvers for medium scale\n",
            "Chunk 2981: use generic solvers for medium scale problems.\n",
            "Chunk 2982: solvers for medium scale problems. One\n",
            "Chunk 2983: can therefore resort to using ﬁrst order methods\n",
            "Chunk 2984: resort to using ﬁrst order methods such as\n",
            "Chunk 2985: to using ﬁrst order methods such as subgradient\n",
            "Chunk 2986: ﬁrst order methods such as subgradient descent on\n",
            "Chunk 2987: methods such as subgradient descent on the dual [\n",
            "Chunk 2988: as subgradient descent on the dual [ ?].\n",
            "Chunk 2989: Remark 18.Barycenter of arbitrary measures Given\n",
            "Chunk 2990: of arbitrary measures Given a set of input\n",
            "Chunk 2991: arbitrary measures Given a set of input measure (\n",
            "Chunk 2992: Given a set of input measure ( βs)sdeﬁned on some\n",
            "Chunk 2993: of input measure ( βs)sdeﬁned on some space X,\n",
            "Chunk 2994: the barycenter problem becomes\n",
            "min\n",
            "α∈M1\n",
            "+(X)S∑\n",
            "Chunk 2995: min\n",
            "α∈M1\n",
            "+(X)S∑\n",
            "s=1λsLc(α,βs). (1.71)\n",
            "Chunk 2996: In the case where X=Rdandc(x,y) =||x−y||2, [?]\n",
            "Chunk 2997: case where X=Rdandc(x,y) =||x−y||2, [?] shows\n",
            "Chunk 2998: X=Rdandc(x,y) =||x−y||2, [?] shows that if one of\n",
            "Chunk 2999: =||x−y||2, [?] shows that if one of the input\n",
            "Chunk 3000: [?] shows that if one of the input measures has a\n",
            "Chunk 3001: that if one of the input measures has a density,\n",
            "Chunk 3002: then this barycenter is unique. Problem (1.71)\n",
            "Chunk 3003: barycenter is unique. Problem (1.71) can be\n",
            "Chunk 3004: is unique. Problem (1.71) can be viewed as a\n",
            "Chunk 3005: Problem (1.71) can be viewed as a generalization\n",
            "Chunk 3006: can be viewed as a generalization of the problem\n",
            "Chunk 3007: as a generalization of the problem of computing\n",
            "Chunk 3008: barycenters of points ( xs)S\n",
            "Chunk 3009: s=1∈XSto arbitrary measures. Indeed, if βs=δxsis\n",
            "Chunk 3010: arbitrary measures. Indeed, if βs=δxsis a single\n",
            "Chunk 3011: measures. Indeed, if βs=δxsis a single Dirac\n",
            "Chunk 3012: Indeed, if βs=δxsis a single Dirac mass, then a\n",
            "Chunk 3013: solution to (1.71) is δx⋆wherex⋆is a Fr´ echet\n",
            "Chunk 3014: to (1.71) is δx⋆wherex⋆is a Fr´ echet mean\n",
            "Chunk 3015: (1.71) is δx⋆wherex⋆is a Fr´ echet mean solving (\n",
            "Chunk 3016: δx⋆wherex⋆is a Fr´ echet mean solving ( ??). Note\n",
            "Chunk 3017: a Fr´ echet mean solving ( ??). Note that for\n",
            "Chunk 3018: echet mean solving ( ??). Note that for c(x,y)\n",
            "Chunk 3019: solving ( ??). Note that for c(x,y) =||x−y||2,\n",
            "Chunk 3020: ( ??). Note that for c(x,y) =||x−y||2, the mean\n",
            "Chunk 3021: of the barycenter α⋆is necessarily the barycenter\n",
            "Chunk 3022: α⋆is necessarily the barycenter of the mean, i.e.\n",
            "Chunk 3023: ∫\n",
            "Xxdα⋆(x) =∑\n",
            "sλs∫\n",
            "Xxdαs(x),\n",
            "Chunk 3024: and the support of α⋆is located in the convex\n",
            "Chunk 3025: support of α⋆is located in the convex hull of the\n",
            "Chunk 3026: α⋆is located in the convex hull of the supports\n",
            "Chunk 3027: in the convex hull of the supports of the ( αs)s.\n",
            "Chunk 3028: hull of the supports of the ( αs)s. The\n",
            "Chunk 3029: of the supports of the ( αs)s. The consistency of\n",
            "Chunk 3030: of the ( αs)s. The consistency of the\n",
            "Chunk 3031: approximation of the inﬁnite dimensional\n",
            "Chunk 3032: of the inﬁnite dimensional optimization (1.71)\n",
            "Chunk 3033: inﬁnite dimensional optimization (1.71) when\n",
            "Chunk 3034: optimization (1.71) when approximating the input\n",
            "Chunk 3035: (1.71) when approximating the input distribution\n",
            "Chunk 3036: using discrete ones (and thus solving (1.70) in\n",
            "Chunk 3037: ones (and thus solving (1.70) in place) is\n",
            "Chunk 3038: (and thus solving (1.70) in place) is studied in\n",
            "Chunk 3039: solving (1.70) in place) is studied in [ ?]. Let\n",
            "Chunk 3040: in place) is studied in [ ?]. Let us also note\n",
            "Chunk 3041: is studied in [ ?]. Let us also note that it is\n",
            "Chunk 3042: in [ ?]. Let us also note that it is possible to\n",
            "Chunk 3043: re-cast (1.71) as a multi-marginal OT problem,\n",
            "Chunk 3044: (1.71) as a multi-marginal OT problem, see Remark\n",
            "Chunk 3045: a multi-marginal OT problem, see Remark ??.\n",
            "Chunk 3046: One can use entropic smoothing and approximate\n",
            "Chunk 3047: use entropic smoothing and approximate the\n",
            "Chunk 3048: entropic smoothing and approximate the solution\n",
            "Chunk 3049: smoothing and approximate the solution of (1.70)\n",
            "Chunk 3050: and approximate the solution of (1.70) using\n",
            "Chunk 3051: min\n",
            "a∈ΣnS∑\n",
            "s=1λsLε\n",
            "Cs(a,bs) (1.72)\n",
            "Chunk 3052: for someε > 0. This is a smooth convex\n",
            "Chunk 3053: someε > 0. This is a smooth convex minimization\n",
            "Chunk 3054: 0. This is a smooth convex minimization problem,\n",
            "Chunk 3055: a smooth convex minimization problem, which can\n",
            "Chunk 3056: convex minimization problem, which can be tackled\n",
            "Chunk 3057: problem, which can be tackled using gradient\n",
            "Chunk 3058: descent [ ?]. An alternative is to use descent\n",
            "Chunk 3059: [ ?]. An alternative is to use descent method\n",
            "Chunk 3060: alternative is to use descent method (typically\n",
            "Chunk 3061: is to use descent method (typically quasi-Newton)\n",
            "Chunk 3062: descent method (typically quasi-Newton) on the\n",
            "Chunk 3063: method (typically quasi-Newton) on the semi-dual\n",
            "Chunk 3064: quasi-Newton) on the semi-dual [ ?], which is\n",
            "Chunk 3065: 25\n",
            "Chunk 3066: useful to integrate additional regularizations on\n",
            "Chunk 3067: integrate additional regularizations on the\n",
            "Chunk 3068: additional regularizations on the barycenter\n",
            "Chunk 3069: regularizations on the barycenter (e.g. to impose\n",
            "Chunk 3070: on the barycenter (e.g. to impose some\n",
            "Chunk 3071: the barycenter (e.g. to impose some smoothness).\n",
            "Chunk 3072: (e.g. to impose some smoothness). A simple\n",
            "Chunk 3073: but eﬀective approach, as remarked in [ ?] is to\n",
            "Chunk 3074: approach, as remarked in [ ?] is to rewrite\n",
            "Chunk 3075: as remarked in [ ?] is to rewrite (1.72) as a\n",
            "Chunk 3076: in [ ?] is to rewrite (1.72) as a (weighted) KL\n",
            "Chunk 3077: to rewrite (1.72) as a (weighted) KL projection\n",
            "Chunk 3078: (1.72) as a (weighted) KL projection problem\n",
            "Chunk 3079: min\n",
            "(Ps)s{∑\n",
            "Chunk 3080: (Ps)s{∑\n",
            "sλsKL(Ps|Ks) ;∀s,PsT1m=bs,P111=...=PS1S}\n",
            "Chunk 3081: (1.73)\n",
            "Chunk 3082: where we denoted Ksdef.=e−Cs/ε. Here, the\n",
            "Chunk 3083: we denoted Ksdef.=e−Cs/ε. Here, the barycenter\n",
            "Chunk 3084: Ksdef.=e−Cs/ε. Here, the barycenter ais\n",
            "Chunk 3085: Here, the barycenter ais implicitly encoded in\n",
            "Chunk 3086: barycenter ais implicitly encoded in the row\n",
            "Chunk 3087: ais implicitly encoded in the row marginals of\n",
            "Chunk 3088: encoded in the row marginals of all\n",
            "Chunk 3089: the couplings Ps∈Rn×nsasa=P111=...=PS1S. As\n",
            "Chunk 3090: couplings Ps∈Rn×nsasa=P111=...=PS1S. As detailed\n",
            "Chunk 3091: Ps∈Rn×nsasa=P111=...=PS1S. As detailed in [ ?],\n",
            "Chunk 3092: As detailed in [ ?], one can generalize Sinkhorn\n",
            "Chunk 3093: in [ ?], one can generalize Sinkhorn to\n",
            "Chunk 3094: this problem, which also corresponds to iterative\n",
            "Chunk 3095: which also corresponds to iterative projection.\n",
            "Chunk 3096: corresponds to iterative projection. This can\n",
            "Chunk 3097: to iterative projection. This can also be seen as\n",
            "Chunk 3098: projection. This can also be seen as a special\n",
            "Chunk 3099: This can also be seen as a special case of the\n",
            "Chunk 3100: generalized Sinkhorn detailed in §??. The optimal\n",
            "Chunk 3101: Sinkhorn detailed in §??. The optimal couplings (\n",
            "Chunk 3102: in §??. The optimal couplings ( Ps)ssolving\n",
            "Chunk 3103: The optimal couplings ( Ps)ssolving (1.73) are\n",
            "Chunk 3104: couplings ( Ps)ssolving (1.73) are computed in\n",
            "Chunk 3105: ( Ps)ssolving (1.73) are computed in scaling\n",
            "Chunk 3106: form as\n",
            "Ps= diag( us)Kdiag(vs), (1.74)\n",
            "Chunk 3107: and the scalings are sequentially updated as\n",
            "Chunk 3108: ∀s∈J1,SK,v(ℓ+1)\n",
            "sdef.=bs\n",
            "KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "Chunk 3109: sdef.=bs\n",
            "KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "∀s∈J1,SK,u(ℓ+1)\n",
            "Chunk 3110: KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Chunk 3111: s, (1.75)\n",
            "∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Ksv(ℓ+1)\n",
            "Chunk 3112: ∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Ksv(ℓ+1)\n",
            "s, (1.76)\n",
            "Chunk 3113: Ksv(ℓ+1)\n",
            "s, (1.76)\n",
            "where a(ℓ+1)def.=∏\n",
            "s(Ksv(ℓ+1)\n",
            "Chunk 3114: where a(ℓ+1)def.=∏\n",
            "s(Ksv(ℓ+1)\n",
            "s)λs. (1.77)\n",
            "Chunk 3115: An alternative way to derive these iterations is\n",
            "Chunk 3116: way to derive these iterations is to perform\n",
            "Chunk 3117: derive these iterations is to perform alternate\n",
            "Chunk 3118: iterations is to perform alternate minimization\n",
            "Chunk 3119: is to perform alternate minimization on the\n",
            "Chunk 3120: perform alternate minimization on the variables\n",
            "Chunk 3121: alternate minimization on the variables of a dual\n",
            "Chunk 3122: problem, which detailed in the following\n",
            "Chunk 3123: which detailed in the following proposition.\n",
            "Chunk 3124: Proposition 9. The optimal (us,vs)appearing in\n",
            "Chunk 3125: 9. The optimal (us,vs)appearing in (1.74) can be\n",
            "Chunk 3126: (us,vs)appearing in (1.74) can be written as\n",
            "Chunk 3127: in (1.74) can be written as (us,vs) =\n",
            "Chunk 3128: can be written as (us,vs) = (efs/ε,egs/ε)where\n",
            "Chunk 3129: (fs,gs)sare the solutions of the following\n",
            "Chunk 3130: the solutions of the following program (whose\n",
            "Chunk 3131: of the following program (whose value matches the\n",
            "Chunk 3132: program (whose value matches the one of (1.72) )\n",
            "Chunk 3133: max\n",
            "(fs,gs)s{∑\n",
            "sλs(\n",
            "⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "Chunk 3134: sλs(\n",
            "⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "sλsfs= 0}\n",
            "Chunk 3135: ⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "sλsfs= 0}\n",
            ". (1.78)\n",
            "Chunk 3136: Proof. Introducing Lagrange multipliers in (1.73)\n",
            "Chunk 3137: Lagrange multipliers in (1.73) leads to\n",
            "Chunk 3138: min\n",
            "(Ps)s,amax\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "Chunk 3139: (Ps)s,amax\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "εKL(Ps|Ks) +⟨a−Ps1m,fs⟩\n",
            "Chunk 3140: sλs(\n",
            "εKL(Ps|Ks) +⟨a−Ps1m,fs⟩\n",
            "+⟨bs−PsT1m,gs⟩)\n",
            ".\n",
            "Chunk 3141: Strong duality holds, so that one can exchange\n",
            "Chunk 3142: duality holds, so that one can exchange the min\n",
            "Chunk 3143: holds, so that one can exchange the min and the\n",
            "Chunk 3144: that one can exchange the min and the max, and\n",
            "Chunk 3145: can exchange the min and the max, and gets\n",
            "Chunk 3146: max\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "⟨gs,bs⟩+ min\n",
            "Chunk 3147: sλs(\n",
            "⟨gs,bs⟩+ min\n",
            "PsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\n",
            "+ min\n",
            "Chunk 3148: PsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\n",
            "+ min\n",
            "a⟨∑\n",
            "sλsfs,a⟩.\n",
            "Chunk 3149: The explicit minimization on agives the\n",
            "Chunk 3150: explicit minimization on agives the constraint∑\n",
            "Chunk 3151: sλsfs= 0 together with\n",
            "max\n",
            "(fs,gs)s∑\n",
            "Chunk 3152: max\n",
            "(fs,gs)s∑\n",
            "sλs⟨gs,bs⟩−εKL∗(fs⊕gs\n",
            "ε|Ks)\n",
            "Chunk 3153: where KL∗(·|Ks) is the Legendre transform ( ??)\n",
            "Chunk 3154: is the Legendre transform ( ??) of the function\n",
            "Chunk 3155: transform ( ??) of the function KL∗(·|Ks). This\n",
            "Chunk 3156: ( ??) of the function KL∗(·|Ks). This Legendre\n",
            "Chunk 3157: the function KL∗(·|Ks). This Legendre transform\n",
            "Chunk 3158: KL∗(·|Ks). This Legendre transform reads\n",
            "Chunk 3159: KL∗(U|K) =∑\n",
            "i,jKi,j(eUi,j−1), (1.79)\n",
            "26\n",
            "Chunk 3160: Figure 1.15: Barycenters between 4 input 3-D\n",
            "Chunk 3161: 1.15: Barycenters between 4 input 3-D shapes\n",
            "Chunk 3162: Barycenters between 4 input 3-D shapes using\n",
            "Chunk 3163: between 4 input 3-D shapes using entropic\n",
            "Chunk 3164: 4 input 3-D shapes using entropic regularization\n",
            "Chunk 3165: shapes using entropic regularization (1.72). The\n",
            "Chunk 3166: entropic regularization (1.72). The weights\n",
            "Chunk 3167: (λs)sare bilinear with respect to the four\n",
            "Chunk 3168: bilinear with respect to the four corners of the\n",
            "Chunk 3169: with respect to the four corners of the square.\n",
            "Chunk 3170: to the four corners of the square. Shapes are\n",
            "Chunk 3171: corners of the square. Shapes are represented as\n",
            "Chunk 3172: the square. Shapes are represented as measures\n",
            "Chunk 3173: Shapes are represented as measures that\n",
            "Chunk 3174: are uniform within the boundaries of the shape\n",
            "Chunk 3175: within the boundaries of the shape and null\n",
            "Chunk 3176: the boundaries of the shape and null outside.\n",
            "Chunk 3177: which shows the desired formula. To show (1.79),\n",
            "Chunk 3178: the desired formula. To show (1.79), since this\n",
            "Chunk 3179: formula. To show (1.79), since this function is\n",
            "Chunk 3180: To show (1.79), since this function is separable,\n",
            "Chunk 3181: since this function is separable, one needs to\n",
            "Chunk 3182: function is separable, one needs to compute\n",
            "Chunk 3183: ∀(u,k)∈R2\n",
            "+,KL∗(u|k)def.= max\n",
            "rur−(rlog(r/k)−r+k)\n",
            "Chunk 3184: whose optimality condition reads u= log(r/k),\n",
            "Chunk 3185: condition reads u= log(r/k), i.e.r=keu, hence the\n",
            "Chunk 3186: reads u= log(r/k), i.e.r=keu, hence the result.\n",
            "Chunk 3187: Minimizing (1.78) with respect to each gs, while\n",
            "Chunk 3188: (1.78) with respect to each gs, while keeping all\n",
            "Chunk 3189: respect to each gs, while keeping all the other\n",
            "Chunk 3190: to each gs, while keeping all the other variable\n",
            "Chunk 3191: while keeping all the other variable ﬁxed, is\n",
            "Chunk 3192: keeping all the other variable ﬁxed, is obtained\n",
            "Chunk 3193: the other variable ﬁxed, is obtained in closed\n",
            "Chunk 3194: form by (1.75). Minimizing (1.78) with respect to\n",
            "Chunk 3195: Minimizing (1.78) with respect to all the (\n",
            "Chunk 3196: (1.78) with respect to all the ( fs)srequires to\n",
            "Chunk 3197: respect to all the ( fs)srequires to solve for\n",
            "Chunk 3198: to all the ( fs)srequires to solve for ausing\n",
            "Chunk 3199: the ( fs)srequires to solve for ausing (1.77) and\n",
            "Chunk 3200: to solve for ausing (1.77) and leads\n",
            "Chunk 3201: to the expression (1.76).\n",
            "Chunk 3202: Figures ??and??show applications to 2-D and 3-D\n",
            "Chunk 3203: ??and??show applications to 2-D and 3-D shapes\n",
            "Chunk 3204: applications to 2-D and 3-D shapes interpolation.\n",
            "Chunk 3205: to 2-D and 3-D shapes interpolation. Figure\n",
            "Chunk 3206: and 3-D shapes interpolation. Figure ??shows a\n",
            "Chunk 3207: interpolation. Figure ??shows a computation\n",
            "Chunk 3208: of barycenters on a surface, where the ground\n",
            "Chunk 3209: on a surface, where the ground cost is the square\n",
            "Chunk 3210: where the ground cost is the square of the\n",
            "Chunk 3211: the ground cost is the square of the geodesic\n",
            "Chunk 3212: cost is the square of the geodesic distance. For\n",
            "Chunk 3213: square of the geodesic distance. For this ﬁgure,\n",
            "Chunk 3214: the computations are performed using the geodesic\n",
            "Chunk 3215: are performed using the geodesic in heat\n",
            "Chunk 3216: using the geodesic in heat approximation detailed\n",
            "Chunk 3217: geodesic in heat approximation detailed in Remark\n",
            "Chunk 3218: heat approximation detailed in Remark ??. We\n",
            "Chunk 3219: approximation detailed in Remark ??. We refer\n",
            "Chunk 3220: to [?] for more details and other applications to\n",
            "Chunk 3221: more details and other applications to computer\n",
            "Chunk 3222: and other applications to computer graphics and\n",
            "Chunk 3223: applications to computer graphics and imaging\n",
            "Chunk 3224: to computer graphics and imaging sciences.\n",
            "Chunk 3225: Wasserstein Loss. In statistics, text processing\n",
            "Chunk 3226: Loss. In statistics, text processing or imaging,\n",
            "Chunk 3227: statistics, text processing or imaging, one must\n",
            "Chunk 3228: text processing or imaging, one must usually\n",
            "Chunk 3229: processing or imaging, one must usually compare a\n",
            "Chunk 3230: imaging, one must usually compare a probability\n",
            "Chunk 3231: distribution βarising from measurements to a\n",
            "Chunk 3232: βarising from measurements to a model, namely a\n",
            "Chunk 3233: measurements to a model, namely a parameterized\n",
            "Chunk 3234: to a model, namely a parameterized family of\n",
            "Chunk 3235: namely a parameterized family of distributions\n",
            "Chunk 3236: a parameterized family of distributions {αθ,θ∈\n",
            "Chunk 3237: Θ}where Θ is a subset of an Euclidean space. Such\n",
            "Chunk 3238: is a subset of an Euclidean space. Such a\n",
            "Chunk 3239: a subset of an Euclidean space. Such a comparison\n",
            "Chunk 3240: an Euclidean space. Such a comparison is done\n",
            "Chunk 3241: space. Such a comparison is done through a “loss”\n",
            "Chunk 3242: a comparison is done through a “loss” or a\n",
            "Chunk 3243: is done through a “loss” or a “ﬁdelity”\n",
            "Chunk 3244: term, which, in this section, is the Wasserstein\n",
            "Chunk 3245: in this section, is the Wasserstein distance. In\n",
            "Chunk 3246: is the Wasserstein distance. In the simplest\n",
            "Chunk 3247: Wasserstein distance. In the simplest scenario,\n",
            "Chunk 3248: distance. In the simplest scenario, the\n",
            "Chunk 3249: In the simplest scenario, the computation of a\n",
            "Chunk 3250: suitable parameter θis obtained by minimizing\n",
            "Chunk 3251: parameter θis obtained by minimizing directly\n",
            "Chunk 3252: min\n",
            "θ∈ΘE(θ)def.=Lc(αθ,β). (1.80)\n",
            "Chunk 3253: Of course, one can consider more complicated\n",
            "Chunk 3254: one can consider more complicated problems: for\n",
            "Chunk 3255: consider more complicated problems: for instance,\n",
            "Chunk 3256: complicated problems: for instance, the\n",
            "Chunk 3257: problems: for instance, the barycenter problem\n",
            "Chunk 3258: for instance, the barycenter problem described\n",
            "Chunk 3259: in§??consists in a sum of such terms. However,\n",
            "Chunk 3260: in a sum of such terms. However, most of these\n",
            "Chunk 3261: of such terms. However, most of these more\n",
            "Chunk 3262: such terms. However, most of these more advanced\n",
            "Chunk 3263: However, most of these more advanced problems can\n",
            "Chunk 3264: of these more advanced problems can be usually\n",
            "Chunk 3265: solved by adapting tools deﬁned for basic case:\n",
            "Chunk 3266: adapting tools deﬁned for basic case: either\n",
            "Chunk 3267: tools deﬁned for basic case: either using the\n",
            "Chunk 3268: deﬁned for basic case: either using the chain\n",
            "Chunk 3269: for basic case: either using the chain rule to\n",
            "Chunk 3270: case: either using the chain rule to compute\n",
            "Chunk 3271: either using the chain rule to compute explicitly\n",
            "Chunk 3272: the chain rule to compute explicitly derivatives,\n",
            "Chunk 3273: or using automatic diﬀerentiation.\n",
            "Chunk 3274: The Wasserstein distance between two histograms\n",
            "Chunk 3275: distance between two histograms or two densities\n",
            "Chunk 3276: between two histograms or two densities is convex\n",
            "Chunk 3277: histograms or two densities is convex with\n",
            "Chunk 3278: or two densities is convex with respect to these\n",
            "Chunk 3279: is convex with respect to these inputs,\n",
            "Chunk 3280: as shown by (1.17) and (1.21) respectively.\n",
            "Chunk 3281: by (1.17) and (1.21) respectively. Therefore,\n",
            "Chunk 3282: and (1.21) respectively. Therefore, when the\n",
            "Chunk 3283: respectively. Therefore, when the parameter θis\n",
            "Chunk 3284: Therefore, when the parameter θis itself a\n",
            "Chunk 3285: when the parameter θis itself a histogram, namely\n",
            "Chunk 3286: θis itself a histogram, namely Θ =\n",
            "Chunk 3287: Σnandαθ=θ, or more generally when\n",
            "Chunk 3288: or more generally when θdescribesKweights in the\n",
            "Chunk 3289: when θdescribesKweights in the simplex, Θ = Σ K,\n",
            "Chunk 3290: in the simplex, Θ = Σ K, andαθ=∑K\n",
            "Chunk 3291: i=1θiαi\n",
            "Chunk 3292: is a convex combination of known atoms\n",
            "Chunk 3293: a convex combination of known atoms α1,...,αKin\n",
            "Chunk 3294: combination of known atoms α1,...,αKin ΣN,\n",
            "Chunk 3295: of known atoms α1,...,αKin ΣN, Problem (1.80)\n",
            "Chunk 3296: atoms α1,...,αKin ΣN, Problem (1.80) remains\n",
            "Chunk 3297: α1,...,αKin ΣN, Problem (1.80) remains convex\n",
            "Chunk 3298: ΣN, Problem (1.80) remains convex (the ﬁrst case\n",
            "Chunk 3299: corresponds to the barycenter problem, the second\n",
            "Chunk 3300: to the barycenter problem, the second to one\n",
            "Chunk 3301: barycenter problem, the second to one iteration\n",
            "Chunk 3302: problem, the second to one iteration of the\n",
            "Chunk 3303: the second to one iteration of the dictionary\n",
            "Chunk 3304: to one iteration of the dictionary learning\n",
            "Chunk 3305: iteration of the dictionary learning problem with\n",
            "Chunk 3306: a Wasserstein loss [ ?]). However, for more\n",
            "Chunk 3307: loss [ ?]). However, for more general\n",
            "Chunk 3308: ?]). However, for more general parameterizations\n",
            "Chunk 3309: for more general parameterizations θ↦→αθ, Problem\n",
            "Chunk 3310: parameterizations θ↦→αθ, Problem (1.80) is in\n",
            "Chunk 3311: θ↦→αθ, Problem (1.80) is in general\n",
            "Chunk 3312: not convex.\n",
            "27\n",
            "Chunk 3313: g✓XZ⇣xz\u0000↵✓Figure 1.16: Schematic display of the\n",
            "Chunk 3314: 1.16: Schematic display of the density ﬁtting\n",
            "Chunk 3315: Schematic display of the density ﬁtting problem\n",
            "Chunk 3316: display of the density ﬁtting problem 1.81.\n",
            "Chunk 3317: A practical problem of paramount importance in\n",
            "Chunk 3318: problem of paramount importance in statistic and\n",
            "Chunk 3319: paramount importance in statistic and machine\n",
            "Chunk 3320: importance in statistic and machine learning is\n",
            "Chunk 3321: in statistic and machine learning is density\n",
            "Chunk 3322: and machine learning is density ﬁtting. Given\n",
            "Chunk 3323: some discrete samples ( xi)n\n",
            "Chunk 3324: i=1⊂X from some unknown distribution, the goal is\n",
            "Chunk 3325: some unknown distribution, the goal is to ﬁt a\n",
            "Chunk 3326: distribution, the goal is to ﬁt a parametric\n",
            "Chunk 3327: the goal is to ﬁt a parametric model\n",
            "Chunk 3328: θ↦→αθ∈M (X) to the observed empirical input\n",
            "Chunk 3329: (X) to the observed empirical input measure β\n",
            "Chunk 3330: min\n",
            "θ∈ΘL(αθ,β) where β=1\n",
            "n∑\n",
            "iδxi, (1.81)\n",
            "Chunk 3331: whereLis some “loss” function between a discrete\n",
            "Chunk 3332: some “loss” function between a discrete and a\n",
            "Chunk 3333: function between a discrete and a “continuous”\n",
            "Chunk 3334: between a discrete and a “continuous” (arbitrary)\n",
            "Chunk 3335: and a “continuous” (arbitrary) distribution (see\n",
            "Chunk 3336: (arbitrary) distribution (see Fig-\n",
            "Chunk 3337: ure 1.16).\n",
            "Chunk 3338: In the case where αθas a densify ρθdef.=ραθwith\n",
            "Chunk 3339: where αθas a densify ρθdef.=ραθwith respect to\n",
            "Chunk 3340: a densify ρθdef.=ραθwith respect to the Lebesgue\n",
            "Chunk 3341: ρθdef.=ραθwith respect to the Lebesgue measure\n",
            "Chunk 3342: respect to the Lebesgue measure (or any other\n",
            "Chunk 3343: to the Lebesgue measure (or any other ﬁxed\n",
            "Chunk 3344: reference measure), the maximum likelihood\n",
            "Chunk 3345: measure), the maximum likelihood estimator (MLE)\n",
            "Chunk 3346: the maximum likelihood estimator (MLE) is\n",
            "Chunk 3347: maximum likelihood estimator (MLE) is obtained by\n",
            "Chunk 3348: estimator (MLE) is obtained by solving\n",
            "Chunk 3349: min\n",
            "θLMLE(αθ,β)def.=−∑\n",
            "ilog(ρθ(xi)).\n",
            "Chunk 3350: This corresponds to using an empirical\n",
            "Chunk 3351: corresponds to using an empirical counterpart of\n",
            "Chunk 3352: to using an empirical counterpart of a\n",
            "Chunk 3353: an empirical counterpart of a Kullback-Leibler\n",
            "Chunk 3354: counterpart of a Kullback-Leibler loss since,\n",
            "Chunk 3355: of a Kullback-Leibler loss since, assuming the\n",
            "Chunk 3356: loss since, assuming the xiare i.i.d.\n",
            "Chunk 3357: samples of some ¯β, then\n",
            "LMLE(α,β)n→+∞−→ KL(α|¯β)\n",
            "Chunk 3358: This MLE approach is known to lead to optimal\n",
            "Chunk 3359: approach is known to lead to optimal estimation\n",
            "Chunk 3360: is known to lead to optimal estimation procedures\n",
            "Chunk 3361: lead to optimal estimation procedures in many\n",
            "Chunk 3362: optimal estimation procedures in many cases (see\n",
            "Chunk 3363: procedures in many cases (see for instance [ ?]).\n",
            "Chunk 3364: However, it fails to work when estimating\n",
            "Chunk 3365: it fails to work when estimating singular\n",
            "Chunk 3366: to work when estimating singular distributions,\n",
            "Chunk 3367: when estimating singular distributions, typically\n",
            "Chunk 3368: singular distributions, typically when the αθdoes\n",
            "Chunk 3369: typically when the αθdoes not has a density\n",
            "Chunk 3370: (so thatLMLE(αθ,β) = +∞) or when ( xi)iare\n",
            "Chunk 3371: thatLMLE(αθ,β) = +∞) or when ( xi)iare samples\n",
            "Chunk 3372: = +∞) or when ( xi)iare samples from some\n",
            "Chunk 3373: +∞) or when ( xi)iare samples from some singular\n",
            "Chunk 3374: ( xi)iare samples from some singular ¯β(so that\n",
            "Chunk 3375: samples from some singular ¯β(so that the\n",
            "Chunk 3376: from some singular ¯β(so that the αθshould share\n",
            "Chunk 3377: the same support as βfor KL(α|¯β) to be ﬁnite,\n",
            "Chunk 3378: support as βfor KL(α|¯β) to be ﬁnite, but this\n",
            "Chunk 3379: as βfor KL(α|¯β) to be ﬁnite, but this support is\n",
            "Chunk 3380: to be ﬁnite, but this support is usually\n",
            "Chunk 3381: be ﬁnite, but this support is usually unknown).\n",
            "Chunk 3382: but this support is usually unknown). Another\n",
            "Chunk 3383: support is usually unknown). Another issue is\n",
            "Chunk 3384: is usually unknown). Another issue is that\n",
            "Chunk 3385: in several cases of practical interest, the\n",
            "Chunk 3386: cases of practical interest, the density ρθis\n",
            "Chunk 3387: practical interest, the density ρθis inaccessible\n",
            "Chunk 3388: interest, the density ρθis inaccessible (or too\n",
            "Chunk 3389: the density ρθis inaccessible (or too hard to\n",
            "Chunk 3390: ρθis inaccessible (or too hard to compute).\n",
            "Chunk 3391: A typical setup where both problems (singular and\n",
            "Chunk 3392: setup where both problems (singular and unknown\n",
            "Chunk 3393: both problems (singular and unknown densities)\n",
            "Chunk 3394: (singular and unknown densities) occur is for\n",
            "Chunk 3395: and unknown densities) occur is for so-called\n",
            "Chunk 3396: densities) occur is for so-called generative\n",
            "Chunk 3397: models, where the parametric measure is written\n",
            "Chunk 3398: where the parametric measure is written as a\n",
            "Chunk 3399: parametric measure is written as a push-forward\n",
            "Chunk 3400: measure is written as a push-forward of a ﬁxed\n",
            "Chunk 3401: is written as a push-forward of a ﬁxed reference\n",
            "Chunk 3402: as a push-forward of a ﬁxed reference measure ζ∈M\n",
            "Chunk 3403: of a ﬁxed reference measure ζ∈M (Z)\n",
            "Chunk 3404: αθ=hθ,♯ζwherehθ:Z→X\n",
            "Chunk 3405: where the push-forward operator is introduced in\n",
            "Chunk 3406: push-forward operator is introduced in Deﬁnition\n",
            "Chunk 3407: operator is introduced in Deﬁnition 1. The space\n",
            "Chunk 3408: is introduced in Deﬁnition 1. The space Zis\n",
            "Chunk 3409: in Deﬁnition 1. The space Zis usually\n",
            "Chunk 3410: 1. The space Zis usually low-dimensional, so\n",
            "Chunk 3411: that the support of αθis localized along a\n",
            "Chunk 3412: support of αθis localized along a low-dimensional\n",
            "Chunk 3413: αθis localized along a low-dimensional “manifold”\n",
            "Chunk 3414: along a low-dimensional “manifold” and the\n",
            "Chunk 3415: a low-dimensional “manifold” and the resulting\n",
            "Chunk 3416: “manifold” and the resulting density is highly\n",
            "Chunk 3417: singular (it does not have a density with respect\n",
            "Chunk 3418: does not have a density with respect to Lebesgue\n",
            "Chunk 3419: have a density with respect to Lebesgue measure).\n",
            "Chunk 3420: with respect to Lebesgue measure). Furthermore,\n",
            "Chunk 3421: to Lebesgue measure). Furthermore, computing this\n",
            "Chunk 3422: measure). Furthermore, computing this density\n",
            "Chunk 3423: is usually intractable, while generating i.i.d.\n",
            "Chunk 3424: intractable, while generating i.i.d. samples from\n",
            "Chunk 3425: while generating i.i.d. samples from αθis\n",
            "Chunk 3426: generating i.i.d. samples from αθis achieved by\n",
            "Chunk 3427: i.i.d. samples from αθis achieved by computing\n",
            "Chunk 3428: samples from αθis achieved by computing xi=hθ(zi)\n",
            "Chunk 3429: αθis achieved by computing xi=hθ(zi) where\n",
            "Chunk 3430: (zi)iare i.i.d. samples from ζ.\n",
            "Chunk 3431: In order to cope with such diﬃcult scenario, one\n",
            "Chunk 3432: to cope with such diﬃcult scenario, one has to\n",
            "Chunk 3433: with such diﬃcult scenario, one has to use weak\n",
            "Chunk 3434: diﬃcult scenario, one has to use weak metrics in\n",
            "Chunk 3435: one has to use weak metrics in place of the MLE\n",
            "Chunk 3436: use weak metrics in place of the MLE functional\n",
            "Chunk 3437: LMLE, which needs to be written in dual form as\n",
            "Chunk 3438: L(α,β)def.= max\n",
            "(f,g)∈C(X)2{∫\n",
            "Xf(x)dα(x) +∫\n",
            "Chunk 3439: (f,g)∈C(X)2{∫\n",
            "Xf(x)dα(x) +∫\n",
            "Xg(x)dβ(x) ; (f,g)∈R}\n",
            "Chunk 3440: Xf(x)dα(x) +∫\n",
            "Xg(x)dβ(x) ; (f,g)∈R}\n",
            ". (1.82)\n",
            "Chunk 3441: Dual norms exposed in §??correspond to imposing\n",
            "Chunk 3442: exposed in §??correspond to imposing R={(f,−f)\n",
            "Chunk 3443: in §??correspond to imposing R={(f,−f) ;f∈B},\n",
            "Chunk 3444: to imposing R={(f,−f) ;f∈B}, while optimal\n",
            "Chunk 3445: imposing R={(f,−f) ;f∈B}, while optimal transport\n",
            "Chunk 3446: ;f∈B}, while optimal transport (1.21)\n",
            "Chunk 3447: setsR=R(c) as deﬁned in (1.22).\n",
            "28\n",
            "Chunk 3448: For a ﬁxed θ, evaluating the energy to be\n",
            "Chunk 3449: a ﬁxed θ, evaluating the energy to be minimized\n",
            "Chunk 3450: evaluating the energy to be minimized in (1.81)\n",
            "Chunk 3451: the energy to be minimized in (1.81) using such a\n",
            "Chunk 3452: to be minimized in (1.81) using such a loss\n",
            "Chunk 3453: minimized in (1.81) using such a loss function\n",
            "Chunk 3454: in (1.81) using such a loss function corresponds\n",
            "Chunk 3455: using such a loss function corresponds to\n",
            "Chunk 3456: solving a semi-discrete optimal transport, which\n",
            "Chunk 3457: semi-discrete optimal transport, which is the\n",
            "Chunk 3458: optimal transport, which is the focus of Chapter\n",
            "Chunk 3459: which is the focus of Chapter ??. Minimizing the\n",
            "Chunk 3460: the focus of Chapter ??. Minimizing the energy\n",
            "Chunk 3461: of Chapter ??. Minimizing the energy with\n",
            "Chunk 3462: respect toθis much more involved, and is\n",
            "Chunk 3463: toθis much more involved, and is typically highly\n",
            "Chunk 3464: involved, and is typically highly non-convex.\n",
            "Chunk 3465: The class of estimators obtained using L=Lc,\n",
            "Chunk 3466: of estimators obtained using L=Lc, often called\n",
            "Chunk 3467: obtained using L=Lc, often called “Minimum\n",
            "Chunk 3468: using L=Lc, often called “Minimum Kantorovitch\n",
            "Chunk 3469: often called “Minimum Kantorovitch Estimators”\n",
            "Chunk 3470: “Minimum Kantorovitch Estimators” (MKE),\n",
            "Chunk 3471: was initially introduced in [ ?], see also [ ?].\n",
            "Chunk 3472: Gromov-Wasserstein. Optimal transport needs a\n",
            "Chunk 3473: Optimal transport needs a ground cost Cto compare\n",
            "Chunk 3474: needs a ground cost Cto compare histograms (\n",
            "Chunk 3475: a ground cost Cto compare histograms ( a,b), it\n",
            "Chunk 3476: cost Cto compare histograms ( a,b), it can\n",
            "Chunk 3477: thus not be used if the histograms are not deﬁned\n",
            "Chunk 3478: used if the histograms are not deﬁned on the same\n",
            "Chunk 3479: histograms are not deﬁned on the same underlying\n",
            "Chunk 3480: are not deﬁned on the same underlying space, or\n",
            "Chunk 3481: deﬁned on the same underlying space, or if one\n",
            "Chunk 3482: on the same underlying space, or if one cannot\n",
            "Chunk 3483: underlying space, or if one cannot pre-register\n",
            "Chunk 3484: these spaces to deﬁne a ground cost. To address\n",
            "Chunk 3485: to deﬁne a ground cost. To address this issue,\n",
            "Chunk 3486: a ground cost. To address this issue, one can\n",
            "Chunk 3487: cost. To address this issue, one can instead only\n",
            "Chunk 3488: this issue, one can instead only assume a weaker\n",
            "Chunk 3489: one can instead only assume a weaker assumption,\n",
            "Chunk 3490: namely that one has at its disposal two matrices\n",
            "Chunk 3491: at its disposal two matrices D∈Rn×nandD′∈Rm×mthat\n",
            "Chunk 3492: two matrices D∈Rn×nandD′∈Rm×mthat represent some\n",
            "Chunk 3493: D∈Rn×nandD′∈Rm×mthat represent some relationship\n",
            "Chunk 3494: between the points on which the histograms are\n",
            "Chunk 3495: the points on which the histograms are deﬁned. A\n",
            "Chunk 3496: on which the histograms are deﬁned. A typical\n",
            "Chunk 3497: the histograms are deﬁned. A typical scenario is\n",
            "Chunk 3498: are deﬁned. A typical scenario is when these\n",
            "Chunk 3499: A typical scenario is when these matrices are\n",
            "Chunk 3500: scenario is when these matrices are (power\n",
            "Chunk 3501: of) distance matrices. The Gromov-Wasserstein\n",
            "Chunk 3502: matrices. The Gromov-Wasserstein problem reads\n",
            "Chunk 3503: GW(( a,D),(b,D′))2def.= min\n",
            "Chunk 3504: P∈U(a,b)ED,D′(P)def.=∑\n",
            "i,j,i′,j′|Di,i′−D′\n",
            "Chunk 3505: i,j,i′,j′|Di,i′−D′\n",
            "j,j′|2Pi,jPi′,j′. (1.83)\n",
            "Chunk 3506: This is a non-convex problem, which can be recast\n",
            "Chunk 3507: non-convex problem, which can be recast as a\n",
            "Chunk 3508: problem, which can be recast as a Quadratic\n",
            "Chunk 3509: which can be recast as a Quadratic Assignment\n",
            "Chunk 3510: can be recast as a Quadratic Assignment Problem\n",
            "Chunk 3511: as a Quadratic Assignment Problem (QAP) [ ?] and\n",
            "Chunk 3512: Assignment Problem (QAP) [ ?] and is in\n",
            "Chunk 3513: full generality NP-hard to solve for arbitrary\n",
            "Chunk 3514: NP-hard to solve for arbitrary inputs. It is in\n",
            "Chunk 3515: to solve for arbitrary inputs. It is in fact\n",
            "Chunk 3516: for arbitrary inputs. It is in fact equivalent to\n",
            "Chunk 3517: inputs. It is in fact equivalent to a graph\n",
            "Chunk 3518: It is in fact equivalent to a graph matching\n",
            "Chunk 3519: in fact equivalent to a graph matching problem [\n",
            "Chunk 3520: to a graph matching problem [ ?]\n",
            "Chunk 3521: for a particular cost.\n",
            "Chunk 3522: One can show that GW satisﬁes the triangular\n",
            "Chunk 3523: show that GW satisﬁes the triangular inequality,\n",
            "Chunk 3524: GW satisﬁes the triangular inequality, and in\n",
            "Chunk 3525: the triangular inequality, and in fact it deﬁnes\n",
            "Chunk 3526: inequality, and in fact it deﬁnes a distance\n",
            "Chunk 3527: and in fact it deﬁnes a distance between\n",
            "Chunk 3528: metric spaces equipped with a probability\n",
            "Chunk 3529: spaces equipped with a probability distribution\n",
            "Chunk 3530: with a probability distribution (here assumed to\n",
            "Chunk 3531: distribution (here assumed to be discrete in\n",
            "Chunk 3532: (here assumed to be discrete in deﬁnition (1.83))\n",
            "Chunk 3533: up to isometries preserving the measures. This\n",
            "Chunk 3534: preserving the measures. This distance was\n",
            "Chunk 3535: the measures. This distance was introduced and\n",
            "Chunk 3536: This distance was introduced and studied in\n",
            "Chunk 3537: distance was introduced and studied in details by\n",
            "Chunk 3538: introduced and studied in details by Memoli\n",
            "Chunk 3539: in [?]. An in-depth mathematical exposition (in\n",
            "Chunk 3540: in-depth mathematical exposition (in particular,\n",
            "Chunk 3541: mathematical exposition (in particular, its\n",
            "Chunk 3542: exposition (in particular, its geodesic structure\n",
            "Chunk 3543: (in particular, its geodesic structure and\n",
            "Chunk 3544: particular, its geodesic structure and gradient\n",
            "Chunk 3545: its geodesic structure and gradient ﬂows) is\n",
            "Chunk 3546: structure and gradient ﬂows) is given\n",
            "Chunk 3547: in [?]. See also [ ?] for applications in\n",
            "Chunk 3548: [?]. See also [ ?] for applications in computer\n",
            "Chunk 3549: also [ ?] for applications in computer vision.\n",
            "Chunk 3550: ?] for applications in computer vision. This\n",
            "Chunk 3551: applications in computer vision. This distance is\n",
            "Chunk 3552: in computer vision. This distance is also tightly\n",
            "Chunk 3553: vision. This distance is also tightly connected\n",
            "Chunk 3554: This distance is also tightly connected with the\n",
            "Chunk 3555: Gromov-Hausdorﬀ distance [ ?] between metric\n",
            "Chunk 3556: distance [ ?] between metric spaces, which have\n",
            "Chunk 3557: [ ?] between metric spaces, which have been used\n",
            "Chunk 3558: metric spaces, which have been used for shape\n",
            "Chunk 3559: spaces, which have been used for shape matching [\n",
            "Chunk 3560: have been used for shape matching [ ?,?].\n",
            "Chunk 3561: Remark 19.Gromov-Wasserstein distance The general\n",
            "Chunk 3562: distance The general setting corresponds to\n",
            "Chunk 3563: The general setting corresponds to computing\n",
            "Chunk 3564: setting corresponds to computing couplings\n",
            "Chunk 3565: corresponds to computing couplings between\n",
            "Chunk 3566: metric measure spaces ( X,dX,αX) and (Y,dY,αY)\n",
            "Chunk 3567: measure spaces ( X,dX,αX) and (Y,dY,αY) where\n",
            "Chunk 3568: spaces ( X,dX,αX) and (Y,dY,αY) where (dX,dY) are\n",
            "Chunk 3569: and (Y,dY,αY) where (dX,dY) are distances and (\n",
            "Chunk 3570: where (dX,dY) are distances and ( αX,αY) are\n",
            "Chunk 3571: (dX,dY) are distances and ( αX,αY) are measures\n",
            "Chunk 3572: on their respective spaces. One deﬁnes\n",
            "Chunk 3573: GW((αX,dX),(αY,dY))2def.= min\n",
            "π∈U(αX,αY)∫\n",
            "Chunk 3574: X2×Y2|dX(x,x′)−dY(y,y′)|2dπ(x,y)dπ(x′,y′). (1.84)\n",
            "Chunk 3575: GW deﬁnes a distance between metric measure\n",
            "Chunk 3576: a distance between metric measure spaces up to\n",
            "Chunk 3577: between metric measure spaces up to isometries,\n",
            "Chunk 3578: metric measure spaces up to isometries, where one\n",
            "Chunk 3579: spaces up to isometries, where one says that (\n",
            "Chunk 3580: up to isometries, where one says that ( αX,dX)\n",
            "Chunk 3581: where one says that ( αX,dX) and\n",
            "Chunk 3582: (αY,dY) are isometric if there exists ϕ:X→Y such\n",
            "Chunk 3583: exists ϕ:X→Y such thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′))\n",
            "Chunk 3584: such thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′)) =dX(x,x′).\n",
            "Chunk 3585: Remark 20.Gromov-Wasserstein geodesics The space\n",
            "Chunk 3586: geodesics The space of metric spaces (up to\n",
            "Chunk 3587: The space of metric spaces (up to isometries)\n",
            "Chunk 3588: of metric spaces (up to isometries) endowed with\n",
            "Chunk 3589: thisGW distance (1.84) has a geodesic structure.\n",
            "Chunk 3590: (1.84) has a geodesic structure. [ ?] shows that\n",
            "Chunk 3591: a geodesic structure. [ ?] shows that the\n",
            "Chunk 3592: geodesic structure. [ ?] shows that the geodesic\n",
            "Chunk 3593: structure. [ ?] shows that the geodesic between (\n",
            "Chunk 3594: [ ?] shows that the geodesic between ( X0,dX0,α0)\n",
            "Chunk 3595: that the geodesic between ( X0,dX0,α0) and\n",
            "Chunk 3596: (X1,dX1,α1) can be chosen to be t∈[0,1]↦→(X0×X\n",
            "Chunk 3597: can be chosen to be t∈[0,1]↦→(X0×X 1,dt,π⋆)\n",
            "Chunk 3598: be chosen to be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is\n",
            "Chunk 3599: to be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is a\n",
            "Chunk 3600: be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is a solution\n",
            "Chunk 3601: 1,dt,π⋆) whereπ⋆is a solution of (1.84) and for\n",
            "Chunk 3602: whereπ⋆is a solution of (1.84) and for all\n",
            "Chunk 3603: ((x0,x1),(x′\n",
            "0,x′\n",
            "1))∈(X0×X 1)2,\n",
            "dt((x0,x1),(x′\n",
            "Chunk 3604: 0,x′\n",
            "1))∈(X0×X 1)2,\n",
            "dt((x0,x1),(x′\n",
            "0,x′\n",
            "Chunk 3605: dt((x0,x1),(x′\n",
            "0,x′\n",
            "1))def.= (1−t)dX0(x0,x′\n",
            "Chunk 3606: 0,x′\n",
            "1))def.= (1−t)dX0(x0,x′\n",
            "0) +tdX1(x1,x′\n",
            "1).\n",
            "Chunk 3607: This formula allows one to deﬁne and analyze\n",
            "Chunk 3608: formula allows one to deﬁne and analyze gradient\n",
            "Chunk 3609: one to deﬁne and analyze gradient ﬂows which\n",
            "Chunk 3610: deﬁne and analyze gradient ﬂows which minimize\n",
            "Chunk 3611: analyze gradient ﬂows which minimize functionals\n",
            "Chunk 3612: ﬂows which minimize functionals involving metric\n",
            "Chunk 3613: spaces, see [ ?]. It is however diﬃcult to handle\n",
            "Chunk 3614: ?]. It is however diﬃcult to handle numerically,\n",
            "Chunk 3615: however diﬃcult to handle numerically, because it\n",
            "Chunk 3616: to handle numerically, because it involves\n",
            "Chunk 3617: numerically, because it involves computations\n",
            "Chunk 3618: because it involves computations over the product\n",
            "Chunk 3619: spaceX0×X 1. A heuristic approach is used in [ ?]\n",
            "Chunk 3620: 1. A heuristic approach is used in [ ?] to deﬁne\n",
            "Chunk 3621: approach is used in [ ?] to deﬁne geodesics and\n",
            "Chunk 3622: used in [ ?] to deﬁne geodesics and barycenters\n",
            "Chunk 3623: [ ?] to deﬁne geodesics and barycenters of metric\n",
            "Chunk 3624: geodesics and barycenters of metric measure\n",
            "Chunk 3625: spaces while imposing the cardinality of the\n",
            "Chunk 3626: while imposing the cardinality of the involved\n",
            "Chunk 3627: the cardinality of the involved spaces and making\n",
            "Chunk 3628: of the involved spaces and making use of the\n",
            "Chunk 3629: involved spaces and making use of the entropic\n",
            "Chunk 3630: spaces and making use of the entropic smoothing\n",
            "Chunk 3631: making use of the entropic smoothing (1.85)\n",
            "Chunk 3632: detailed below.\n",
            "Chunk 3633: To approximate the computation of GW, and to help\n",
            "Chunk 3634: the computation of GW, and to help convergence of\n",
            "Chunk 3635: of GW, and to help convergence of minimization\n",
            "Chunk 3636: and to help convergence of minimization schemes\n",
            "Chunk 3637: convergence of minimization schemes to better\n",
            "Chunk 3638: minima, one can consider the entropic regularized\n",
            "Chunk 3639: can consider the entropic regularized variant\n",
            "Chunk 3640: min\n",
            "P∈U(a,b)ED,D′(P)−εH(P). (1.85)\n",
            "29\n",
            "Chunk 3641: Figure 1.17: Example of fuzzy correspondences\n",
            "Chunk 3642: 1.17: Example of fuzzy correspondences computed\n",
            "Chunk 3643: of fuzzy correspondences computed by solving GW\n",
            "Chunk 3644: correspondences computed by solving GW problem\n",
            "Chunk 3645: computed by solving GW problem (1.85) with\n",
            "Chunk 3646: by solving GW problem (1.85) with Sinkhorn\n",
            "Chunk 3647: iterations (1.86). Extracted from [ ?].\n",
            "Chunk 3648: As proposed initially in [ ?,?], and later\n",
            "Chunk 3649: proposed initially in [ ?,?], and later revisited\n",
            "Chunk 3650: in [ ?,?], and later revisited in [ ?] for\n",
            "Chunk 3651: and later revisited in [ ?] for applications in\n",
            "Chunk 3652: revisited in [ ?] for applications in graphics,\n",
            "Chunk 3653: in [ ?] for applications in graphics, one can use\n",
            "Chunk 3654: applications in graphics, one can use iteratively\n",
            "Chunk 3655: Sinkhorn’s algorithm to progressively compute a\n",
            "Chunk 3656: algorithm to progressively compute a stationary\n",
            "Chunk 3657: to progressively compute a stationary point of\n",
            "Chunk 3658: compute a stationary point of (1.85). Indeed,\n",
            "Chunk 3659: a stationary point of (1.85). Indeed, successive\n",
            "Chunk 3660: of (1.85). Indeed, successive linearizations\n",
            "Chunk 3661: of the objective function lead to consider the\n",
            "Chunk 3662: function lead to consider the succession of\n",
            "Chunk 3663: lead to consider the succession of updates\n",
            "Chunk 3664: P(ℓ+1) def.= min\n",
            "Chunk 3665: P∈U(a,b)⟨P,C(ℓ)⟩−εH(P) where (1.86)\n",
            "Chunk 3666: C(ℓ)def.=∇ED,D′(P(ℓ)) =−D′TP(ℓ)D,\n",
            "Chunk 3667: which can be interpreted as a mirror-descent\n",
            "Chunk 3668: can be interpreted as a mirror-descent scheme [\n",
            "Chunk 3669: as a mirror-descent scheme [ ?]. Each update can\n",
            "Chunk 3670: scheme [ ?]. Each update can thus be solved using\n",
            "Chunk 3671: Each update can thus be solved using Sinkhorn\n",
            "Chunk 3672: iterations (1.51) with cost C(ℓ). Figure (1.17)\n",
            "Chunk 3673: (1.51) with cost C(ℓ). Figure (1.17) illustrates\n",
            "Chunk 3674: cost C(ℓ). Figure (1.17) illustrates the use of\n",
            "Chunk 3675: Figure (1.17) illustrates the use of this\n",
            "Chunk 3676: (1.17) illustrates the use of this entropic\n",
            "Chunk 3677: the use of this entropic Gromov-Wasserstein to\n",
            "Chunk 3678: compute soft maps between domains.\n",
            "30\n",
            "Chunk 3679: 30\n",
            "Bibliography\n",
            "Chunk 3680: [1] Amir Beck. Introduction to Nonlinear\n",
            "Chunk 3681: Beck. Introduction to Nonlinear Optimization:\n",
            "Chunk 3682: Introduction to Nonlinear Optimization: Theory,\n",
            "Chunk 3683: to Nonlinear Optimization: Theory, Algorithms,\n",
            "Chunk 3684: Optimization: Theory, Algorithms, and\n",
            "Chunk 3685: Theory, Algorithms, and Applications with MAT-\n",
            "Chunk 3686: LAB. SIAM, 2014.\n",
            "Chunk 3687: [2] Stephen Boyd, Neal Parikh, Eric Chu, Borja\n",
            "Chunk 3688: Boyd, Neal Parikh, Eric Chu, Borja Peleato, and\n",
            "Chunk 3689: Parikh, Eric Chu, Borja Peleato, and Jonathan\n",
            "Chunk 3690: Eric Chu, Borja Peleato, and Jonathan Eckstein.\n",
            "Chunk 3691: Borja Peleato, and Jonathan Eckstein. Distributed\n",
            "Chunk 3692: and Jonathan Eckstein. Distributed optimization\n",
            "Chunk 3693: and statistical learning via the alternating\n",
            "Chunk 3694: learning via the alternating direction method of\n",
            "Chunk 3695: the alternating direction method of multipliers.\n",
            "Chunk 3696: direction method of multipliers. Foundations and\n",
            "Chunk 3697: method of multipliers. Foundations and Trends R⃝\n",
            "Chunk 3698: in Machine Learning , 3(1):1–122, 2011.\n",
            "Chunk 3699: [3] Stephen Boyd and Lieven Vandenberghe. Convex\n",
            "Chunk 3700: Boyd and Lieven Vandenberghe. Convex optimization\n",
            "Chunk 3701: Vandenberghe. Convex optimization . Cambridge\n",
            "Chunk 3702: Convex optimization . Cambridge university press,\n",
            "Chunk 3703: . Cambridge university press, 2004.\n",
            "Chunk 3704: [4] E. Cand` es and D. Donoho. New tight frames\n",
            "Chunk 3705: es and D. Donoho. New tight frames of curvelets\n",
            "Chunk 3706: Donoho. New tight frames of curvelets and optimal\n",
            "Chunk 3707: frames of curvelets and optimal representations\n",
            "Chunk 3708: curvelets and optimal representations of objects\n",
            "Chunk 3709: and optimal representations of objects with\n",
            "Chunk 3710: piecewise C2singularities. Commun. on Pure and\n",
            "Chunk 3711: C2singularities. Commun. on Pure and Appl. Math.\n",
            "Chunk 3712: Commun. on Pure and Appl. Math. , 57(2):219–266,\n",
            "Chunk 3713: Pure and Appl. Math. , 57(2):219–266, 2004.\n",
            "Chunk 3714: [5] E. J. Cand` es, L. Demanet, D. L. Donoho, and\n",
            "Chunk 3715: Cand` es, L. Demanet, D. L. Donoho, and L. Ying.\n",
            "Chunk 3716: L. Demanet, D. L. Donoho, and L. Ying. Fast\n",
            "Chunk 3717: D. L. Donoho, and L. Ying. Fast discrete curvelet\n",
            "Chunk 3718: and L. Ying. Fast discrete curvelet transforms.\n",
            "Chunk 3719: Fast discrete curvelet transforms. SIAM\n",
            "Chunk 3720: Multiscale Modeling and Simulation , 5:861–899,\n",
            "Chunk 3721: Modeling and Simulation , 5:861–899, 2005.\n",
            "Chunk 3722: [6] A. Chambolle. An algorithm for total\n",
            "Chunk 3723: A. Chambolle. An algorithm for total variation\n",
            "Chunk 3724: An algorithm for total variation minimization and\n",
            "Chunk 3725: total variation minimization and applications. J.\n",
            "Chunk 3726: minimization and applications. J. Math. Imaging\n",
            "Chunk 3727: and applications. J. Math. Imaging Vis. ,\n",
            "Chunk 3728: 20:89–97, 2004.\n",
            "Chunk 3729: [7] Antonin Chambolle, Vicent Caselles, Daniel\n",
            "Chunk 3730: Chambolle, Vicent Caselles, Daniel Cremers,\n",
            "Chunk 3731: Vicent Caselles, Daniel Cremers, Matteo Novaga,\n",
            "Chunk 3732: Daniel Cremers, Matteo Novaga, and Thomas Pock.\n",
            "Chunk 3733: Matteo Novaga, and Thomas Pock. An intro-\n",
            "Chunk 3734: duction to total variation for image analysis.\n",
            "Chunk 3735: total variation for image analysis. Theoretical\n",
            "Chunk 3736: for image analysis. Theoretical foundations and\n",
            "Chunk 3737: analysis. Theoretical foundations and numerical\n",
            "Chunk 3738: Theoretical foundations and numerical methods for\n",
            "Chunk 3739: foundations and numerical methods for sparse\n",
            "Chunk 3740: recovery , 9(263-340):227, 2010.\n",
            "Chunk 3741: [8] Antonin Chambolle and Thomas Pock. An\n",
            "Chunk 3742: Chambolle and Thomas Pock. An introduction to\n",
            "Chunk 3743: and Thomas Pock. An introduction to continuous\n",
            "Chunk 3744: Pock. An introduction to continuous optimization\n",
            "Chunk 3745: introduction to continuous optimization for\n",
            "Chunk 3746: to continuous optimization for imaging. Acta\n",
            "Chunk 3747: Numerica , 25:161–319, 2016.\n",
            "Chunk 3748: [9] S.S. Chen, D.L. Donoho, and M.A. Saunders.\n",
            "Chunk 3749: Chen, D.L. Donoho, and M.A. Saunders. Atomic\n",
            "Chunk 3750: Donoho, and M.A. Saunders. Atomic decomposition\n",
            "Chunk 3751: and M.A. Saunders. Atomic decomposition by basis\n",
            "Chunk 3752: Saunders. Atomic decomposition by basis pursuit.\n",
            "Chunk 3753: Atomic decomposition by basis pursuit. SIAM\n",
            "Chunk 3754: decomposition by basis pursuit. SIAM Journal\n",
            "Chunk 3755: on Scientiﬁc Computing , 20(1):33–61, 1999.\n",
            "Chunk 3756: [10] Philippe G Ciarlet. Introduction ` a\n",
            "Chunk 3757: Philippe G Ciarlet. Introduction ` a l’analyse\n",
            "Chunk 3758: G Ciarlet. Introduction ` a l’analyse num´ erique\n",
            "Chunk 3759: ` a l’analyse num´ erique matricielle et ` a\n",
            "Chunk 3760: num´ erique matricielle et ` a l’optimisation.\n",
            "Chunk 3761: matricielle et ` a l’optimisation. 1982.\n",
            "Chunk 3762: [11] P. L. Combettes and V. R. Wajs. Signal\n",
            "Chunk 3763: P. L. Combettes and V. R. Wajs. Signal recovery\n",
            "Chunk 3764: and V. R. Wajs. Signal recovery by proximal\n",
            "Chunk 3765: Signal recovery by proximal forward-backward\n",
            "Chunk 3766: recovery by proximal forward-backward splitting.\n",
            "Chunk 3767: by proximal forward-backward splitting. SIAM\n",
            "Chunk 3768: Multiscale Modeling and Simulation , 4(4), 2005.\n",
            "Chunk 3769: [12] I. Daubechies, M. Defrise, and C. De Mol. An\n",
            "Chunk 3770: M. Defrise, and C. De Mol. An iterative\n",
            "Chunk 3771: Defrise, and C. De Mol. An iterative thresholding\n",
            "Chunk 3772: C. De Mol. An iterative thresholding algorithm\n",
            "Chunk 3773: An iterative thresholding algorithm for linear\n",
            "Chunk 3774: thresholding algorithm for linear inverse\n",
            "Chunk 3775: algorithm for linear inverse problems\n",
            "Chunk 3776: with a sparsity constraint. Commun. on Pure and\n",
            "Chunk 3777: constraint. Commun. on Pure and Appl. Math. ,\n",
            "Chunk 3778: Commun. on Pure and Appl. Math. , 57:1413–1541,\n",
            "Chunk 3779: on Pure and Appl. Math. , 57:1413–1541, 2004.\n",
            "Chunk 3780: [13] D. Donoho and I. Johnstone. Ideal spatial\n",
            "Chunk 3781: Donoho and I. Johnstone. Ideal spatial adaptation\n",
            "Chunk 3782: I. Johnstone. Ideal spatial adaptation via\n",
            "Chunk 3783: Johnstone. Ideal spatial adaptation via wavelet\n",
            "Chunk 3784: Ideal spatial adaptation via wavelet shrinkage.\n",
            "Chunk 3785: adaptation via wavelet shrinkage. Biometrika ,\n",
            "Chunk 3786: via wavelet shrinkage. Biometrika , 81:425–455,\n",
            "Chunk 3787: Dec 1994.\n",
            "Chunk 3788: [14] Heinz Werner Engl, Martin Hanke, and Andreas\n",
            "Chunk 3789: Werner Engl, Martin Hanke, and Andreas Neubauer.\n",
            "Chunk 3790: Hanke, and Andreas Neubauer. Regularization of\n",
            "Chunk 3791: and Andreas Neubauer. Regularization of inverse\n",
            "Chunk 3792: Neubauer. Regularization of inverse problems ,\n",
            "Chunk 3793: Regularization of inverse problems , volume\n",
            "Chunk 3794: 375. Springer Science & Business Media, 1996.\n",
            "Chunk 3795: [15] M. Figueiredo and R. Nowak. An EM Algorithm\n",
            "Chunk 3796: and R. Nowak. An EM Algorithm for Wavelet-Based\n",
            "Chunk 3797: An EM Algorithm for Wavelet-Based Image\n",
            "Chunk 3798: EM Algorithm for Wavelet-Based Image Restoration.\n",
            "Chunk 3799: for Wavelet-Based Image Restoration. IEEE Trans.\n",
            "Chunk 3800: Image Proc. , 12(8):906–916, 2003.\n",
            "Chunk 3801: [16] Simon Foucart and Holger Rauhut. A\n",
            "Chunk 3802: Simon Foucart and Holger Rauhut. A mathematical\n",
            "Chunk 3803: and Holger Rauhut. A mathematical introduction to\n",
            "Chunk 3804: A mathematical introduction to compressive\n",
            "Chunk 3805: introduction to compressive sensing , volume 1.\n",
            "Chunk 3806: Birkh¨ auser Basel, 2013.\n",
            "31\n",
            "Chunk 3807: [17] Stephane Mallat. A wavelet tour of signal\n",
            "Chunk 3808: Mallat. A wavelet tour of signal processing: the\n",
            "Chunk 3809: wavelet tour of signal processing: the sparse way\n",
            "Chunk 3810: of signal processing: the sparse way . Academic\n",
            "Chunk 3811: processing: the sparse way . Academic press,\n",
            "Chunk 3812: the sparse way . Academic press, 2008.\n",
            "Chunk 3813: [18] D. Mumford and J. Shah. Optimal\n",
            "Chunk 3814: D. Mumford and J. Shah. Optimal approximation by\n",
            "Chunk 3815: and J. Shah. Optimal approximation by piecewise\n",
            "Chunk 3816: Optimal approximation by piecewise smooth\n",
            "Chunk 3817: approximation by piecewise smooth functions and\n",
            "Chunk 3818: by piecewise smooth functions and associated\n",
            "Chunk 3819: smooth functions and associated varia-\n",
            "Chunk 3820: tional problems. Commun. on Pure and Appl. Math.\n",
            "Chunk 3821: Commun. on Pure and Appl. Math. , 42:577–685,\n",
            "Chunk 3822: on Pure and Appl. Math. , 42:577–685, 1989.\n",
            "Chunk 3823: [19] Neal Parikh, Stephen Boyd, et al. Proximal\n",
            "Chunk 3824: Parikh, Stephen Boyd, et al. Proximal algorithms.\n",
            "Chunk 3825: Boyd, et al. Proximal algorithms. Foundations and\n",
            "Chunk 3826: Proximal algorithms. Foundations and Trends R⃝in\n",
            "Chunk 3827: Foundations and Trends R⃝in Optimization ,\n",
            "Chunk 3828: 1(3):127–239, 2014.\n",
            "Chunk 3829: [20] Gabriel Peyr´ e. L’alg` ebre discr` ete de\n",
            "Chunk 3830: Peyr´ e. L’alg` ebre discr` ete de la transform´\n",
            "Chunk 3831: L’alg` ebre discr` ete de la transform´ ee de\n",
            "Chunk 3832: ebre discr` ete de la transform´ ee de Fourier .\n",
            "Chunk 3833: ete de la transform´ ee de Fourier . Ellipses,\n",
            "Chunk 3834: la transform´ ee de Fourier . Ellipses, 2004.\n",
            "Chunk 3835: [21] J. Portilla, V. Strela, M.J. Wainwright, and\n",
            "Chunk 3836: V. Strela, M.J. Wainwright, and Simoncelli E.P.\n",
            "Chunk 3837: M.J. Wainwright, and Simoncelli E.P. Image\n",
            "Chunk 3838: Wainwright, and Simoncelli E.P. Image denoising\n",
            "Chunk 3839: and Simoncelli E.P. Image denoising using scale\n",
            "Chunk 3840: E.P. Image denoising using scale mixtures of\n",
            "Chunk 3841: Gaussians in the wavelet domain. IEEE Trans.\n",
            "Chunk 3842: in the wavelet domain. IEEE Trans. Image Proc. ,\n",
            "Chunk 3843: IEEE Trans. Image Proc. , 12(11):1338–1351,\n",
            "Chunk 3844: Trans. Image Proc. , 12(11):1338–1351, November\n",
            "Chunk 3845: Proc. , 12(11):1338–1351, November 2003.\n",
            "Chunk 3846: [22] L. I. Rudin, S. Osher, and E. Fatemi.\n",
            "Chunk 3847: L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear\n",
            "Chunk 3848: S. Osher, and E. Fatemi. Nonlinear total\n",
            "Chunk 3849: Osher, and E. Fatemi. Nonlinear total variation\n",
            "Chunk 3850: E. Fatemi. Nonlinear total variation based noise\n",
            "Chunk 3851: Nonlinear total variation based noise removal\n",
            "Chunk 3852: total variation based noise removal algorithms.\n",
            "Chunk 3853: based noise removal algorithms. Phys.\n",
            "Chunk 3854: D, 60(1-4):259–268, 1992.\n",
            "Chunk 3855: [23] Otmar Scherzer, Markus Grasmair, Harald\n",
            "Chunk 3856: Scherzer, Markus Grasmair, Harald Grossauer,\n",
            "Chunk 3857: Markus Grasmair, Harald Grossauer, Markus\n",
            "Chunk 3858: Grasmair, Harald Grossauer, Markus Haltmeier,\n",
            "Chunk 3859: Harald Grossauer, Markus Haltmeier, Frank Lenzen,\n",
            "Chunk 3860: Markus Haltmeier, Frank Lenzen, and L Sirovich.\n",
            "Chunk 3861: Variational methods in imaging . Springer, 2009.\n",
            "Chunk 3862: [24] C. E. Shannon. A mathematical theory of\n",
            "Chunk 3863: Shannon. A mathematical theory of communication.\n",
            "Chunk 3864: A mathematical theory of communication. The Bell\n",
            "Chunk 3865: theory of communication. The Bell System\n",
            "Chunk 3866: of communication. The Bell System Technical\n",
            "Chunk 3867: The Bell System Technical Journal ,\n",
            "Chunk 3868: 27(3):379–423, 1948.\n",
            "Chunk 3869: [25] Jean-Luc Starck, Fionn Murtagh, and Jalal\n",
            "Chunk 3870: Starck, Fionn Murtagh, and Jalal Fadili. Sparse\n",
            "Chunk 3871: Fionn Murtagh, and Jalal Fadili. Sparse image and\n",
            "Chunk 3872: and Jalal Fadili. Sparse image and signal\n",
            "Chunk 3873: Jalal Fadili. Sparse image and signal processing:\n",
            "Chunk 3874: Sparse image and signal processing: Wavelets and\n",
            "Chunk 3875: related geometric multiscale analysis . Cambridge\n",
            "Chunk 3876: multiscale analysis . Cambridge university press,\n",
            "Chunk 3877: analysis . Cambridge university press, 2015.\n",
            "Chunk 3878: 32\n",
            "Char count chunking non overlap:\n",
            "Chunk 1: Mathematical Foundations of Data Sciences\n",
            "Chunk 2: Gabriel Peyr´ e\n",
            "CNRS & DMA\n",
            "Chunk 3: ´Ecole Normale Sup´ erieure\n",
            "gabriel.peyre@ens.fr\n",
            "Chunk 4: https://mathematical-tours.github.io\n",
            "Chunk 5: www.numerical-tours.com\n",
            "August 14, 2019\n",
            "2\n",
            "Chunk 6: Chapter 1\n",
            "Optimal Transport\n",
            "1.1 Radon Measures\n",
            "Chunk 7: Measures. We will interchangeably the term\n",
            "Chunk 8: histogram or probability vector for any element\n",
            "Chunk 9: a∈Σnthat\n",
            "Chunk 10: belongs to the probability simplex\n",
            "Σndef.={\n",
            "a∈Rn\n",
            "Chunk 11: +;n∑\n",
            "i=1ai= 1}\n",
            ".\n",
            "Chunk 12: A discrete measure with weights aand locations\n",
            "Chunk 13: x1,...,xn∈X reads\n",
            "Chunk 14: α=n∑\n",
            "i=1aiδxi (1.1)\n",
            "Chunk 15: whereδxis the Dirac at position x, intuitively a\n",
            "Chunk 16: unit of mass which is inﬁnitely concentrated at\n",
            "Chunk 17: location\n",
            "Chunk 18: x. Such as measure describes a probability\n",
            "Chunk 19: measure if, additionally, a∈Σn, and more\n",
            "Chunk 20: generally a positive\n",
            "Chunk 21: measure if each of the “weights” described in\n",
            "Chunk 22: vector ais positive itself.\n",
            "Chunk 23: Remark 1 (General measures) .A convenient feature\n",
            "Chunk 24: of OT is that it can deal with discrete and\n",
            "Chunk 25: continuous\n",
            "Chunk 26: “objects” within the same framework. Such objects\n",
            "Chunk 27: only need to be modelled as measures. This\n",
            "Chunk 28: corresponds\n",
            "Chunk 29: to the notion of Radon measures M(X) on the\n",
            "Chunk 30: spaceX. The formal deﬁnition of that set requires\n",
            "Chunk 31: that Xis\n",
            "Chunk 32: equipped with a distance, usually denoted d,\n",
            "Chunk 33: because one can only access a measure by\n",
            "Chunk 34: “testing” (integrating)\n",
            "Chunk 35: it against continuous functions, denoted f∈C(X).\n",
            "Chunk 36: Integration of f∈C(X) against a discrete measure\n",
            "Chunk 37: αcomputes a sum\n",
            "Chunk 38: ∫\n",
            "Xf(x)dα(x) =n∑\n",
            "i=1aif(xi).\n",
            "Chunk 39: More general measures, for instance on\n",
            "Chunk 40: X=Rd(whered∈N∗is the dimension), can have a\n",
            "Chunk 41: density\n",
            "Chunk 42: dα(x) =ρα(x)dxw.r.t. the Lebesgue measure, often\n",
            "Chunk 43: denoted ρα=dα\n",
            "Chunk 44: dx, which means that\n",
            "∀h∈C(Rd),∫\n",
            "Rdh(x)dα(x) =∫\n",
            "Chunk 45: Rdh(x)ρα(x)dx.\n",
            "Chunk 46: An arbitrary measure α∈M (X) (which needs not to\n",
            "Chunk 47: have a density nor be a sum of Diracs) is deﬁned\n",
            "Chunk 48: by\n",
            "Chunk 49: the fact that it can be integrated agains any\n",
            "Chunk 50: continuous function f∈C(X) and obtain∫\n",
            "Chunk 51: Xf(x)dα(x)∈R.\n",
            "Chunk 52: IfXis not compact, one should also impose that\n",
            "Chunk 53: fhas compact support or at least as 0 limit at\n",
            "Chunk 54: inﬁnity.\n",
            "Chunk 55: Measure as thus in some sense “less regular” than\n",
            "Chunk 56: functions, but more regular than distributions\n",
            "Chunk 57: (which are\n",
            "Chunk 58: dual to smooth functions). For instance, the\n",
            "Chunk 59: derivative of a Dirac is not a measure. We denote\n",
            "Chunk 60: M+(X) the\n",
            "Chunk 61: set of all positive measures on X. The set of\n",
            "Chunk 62: probability measures is denoted M1\n",
            "Chunk 63: +(X), which means that\n",
            "anyα∈M1\n",
            "Chunk 64: +(X) is positive, and that α(X) =∫\n",
            "Chunk 65: Xdα= 1. Figure 1.1 oﬀers a visualization of the\n",
            "Chunk 66: diﬀerent\n",
            "Chunk 67: classes of measures, beyond histograms,\n",
            "Chunk 68: considered in this work.\n",
            "Chunk 69: 3\n",
            "Chunk 70: Discreted= 1 Discrete d= 2 Density d= 1 Density\n",
            "Chunk 71: d= 2\n",
            "Chunk 72: Figure 1.1: Schematic display of discrete\n",
            "Chunk 73: distributions α=∑n\n",
            "Chunk 74: i=1aiδxi(red corresponds to empirical uniform\n",
            "Chunk 75: distribution ai= 1/n, and blue to arbitrary\n",
            "Chunk 76: distributions) and densities d α(x) =ρα(x)dx(in\n",
            "Chunk 77: violet), in both\n",
            "Chunk 78: 1-D and 2-D. Discrete distributions in 1-D are\n",
            "Chunk 79: displayed using vertical segments (with length\n",
            "Chunk 80: equal to ai)\n",
            "Chunk 81: and in 2-D using point clouds (radius equal to\n",
            "Chunk 82: ai).\n",
            "Chunk 83: Operators on measures. For some continuous map\n",
            "Chunk 84: T:X →Y , we deﬁne the pushforward operator\n",
            "Chunk 85: T♯:M(X)→M (Y). For discrete measures (1.1), the\n",
            "Chunk 86: pushforward operation consists simply in moving\n",
            "Chunk 87: the\n",
            "Chunk 88: positions of all the points in the support of the\n",
            "Chunk 89: measure\n",
            "Chunk 90: T♯αdef.=∑\n",
            "iaiδT(xi).\n",
            "Chunk 91: For more general measures, for instance for those\n",
            "Chunk 92: with a density, the notion of push-forward plays\n",
            "Chunk 93: a funda-\n",
            "Chunk 94: mental to describe spatial modiﬁcations of\n",
            "Chunk 95: probability measures. The formal deﬁnition reads\n",
            "Chunk 96: as follow.\n",
            "Chunk 97: Deﬁnition 1 (Push-forward) .ForT:X → Y , the push\n",
            "Chunk 98: forward measure β=T♯α∈ M (Y)of some\n",
            "Chunk 99: α∈M (X)reads\n",
            "∀h∈C(Y),∫\n",
            "Yh(y)dβ(y) =∫\n",
            "Chunk 100: Xh(T(x))dα(x). (1.2)\n",
            "Chunk 101: Equivalently, for any measurable set B⊂Y, one has\n",
            "Chunk 102: β(B) =α({x∈X;T(x)∈B}). (1.3)\n",
            "Chunk 103: Note thatT♯preserves positivity and total mass,\n",
            "Chunk 104: so that if α∈M1\n",
            "Chunk 105: +(X)thenT♯α∈M1\n",
            "+(Y).\n",
            "Chunk 106: Intuitively, a measurable map T:X→Y , can be\n",
            "Chunk 107: interpreted as a function “moving” a single point\n",
            "Chunk 108: from a\n",
            "Chunk 109: measurable space to another. The more general\n",
            "Chunk 110: extension T♯can now “move” an entire probability\n",
            "Chunk 111: measure\n",
            "Chunk 112: onXtowards a new probability measure on Y. The\n",
            "Chunk 113: operator T♯“pushes forward” each elementary mass\n",
            "Chunk 114: of\n",
            "Chunk 115: a measureαonXby applying the map Tto obtain then\n",
            "Chunk 116: an elementary mass in Y, to build on aggregate a\n",
            "Chunk 117: new measure onY) writtenT♯α. Note that such a\n",
            "Chunk 118: push-forward T♯:M1\n",
            "Chunk 119: +(X)→M1\n",
            "+(Y) is a linear operator\n",
            "Chunk 120: between measures in the sense that for two\n",
            "Chunk 121: measures α1,α2onX,T♯(α1+α2) =T♯α1+T♯α2.\n",
            "Chunk 122: Remark 2 (Push-forward for densities) .Explicitly\n",
            "Chunk 123: doing the change of variable in formula (1.2) for\n",
            "Chunk 124: measures\n",
            "Chunk 125: with densities ( ρα,ρβ) onRd(assumingTis smooth\n",
            "Chunk 126: and a bijection) shows that a push-forward acts\n",
            "Chunk 127: on\n",
            "Chunk 128: densities linearly as a change of variables in\n",
            "Chunk 129: the integration formula, indeed\n",
            "Chunk 130: ρα(x) =|det(T′(x))|ρβ(T(x)) (1.4)\n",
            "Chunk 131: whereT′(x)∈Rd×dis the Jacobian matrix of T(the\n",
            "Chunk 132: matrix formed by taking the gradient of each\n",
            "Chunk 133: coordinate\n",
            "Chunk 134: ofT). This implies, denoting y=T(x)\n",
            "Chunk 135: |det(T′(x))|=ρα(x)\n",
            "ρβ(y).\n",
            "4\n",
            "Chunk 136: =Pi\u0000xiT↵T]↵def.=Pi\u0000T(xi)\n",
            "Chunk 137: TT]gdef.=g\u0000TgPush-forward of measures Pull-back\n",
            "Chunk 138: of functions\n",
            "Chunk 139: Figure 1.2: Comparison of push-forward T♯and\n",
            "Chunk 140: pull-back T♯.\n",
            "Chunk 141: Remark 3 (Push-forward vs. pull-back) .The\n",
            "Chunk 142: push-forward T♯of measures should not be\n",
            "Chunk 143: confounded with\n",
            "Chunk 144: the pull-back of function T♯:C(Y)→C(X) which\n",
            "Chunk 145: corresponds to the “warping” of functions. It is\n",
            "Chunk 146: the linear\n",
            "Chunk 147: map deﬁned, for g∈C(Y) byT♯g=g◦T. Push-forward\n",
            "Chunk 148: and pull-back are actually adjoint one from each\n",
            "Chunk 149: others, in the sense that\n",
            "∀(α,g)∈M (X)×C(Y),∫\n",
            "Chunk 150: Ygd(T♯α) =∫\n",
            "X(T♯g)dα.\n",
            "Chunk 151: It is important to realize that even if ( α,β)\n",
            "Chunk 152: have densities ( ρα,ρβ),T♯αis not equal to T♯ρβ,\n",
            "Chunk 153: because of\n",
            "Chunk 154: the presence of the Jacobian in (1.4). This\n",
            "Chunk 155: explains why OT should be used with caution to\n",
            "Chunk 156: perform image\n",
            "Chunk 157: registration, because it does not operate as an\n",
            "Chunk 158: image warping method. Figure 1.2 illustrate the\n",
            "Chunk 159: distinction\n",
            "Chunk 160: between these push-forward and pull-back\n",
            "Chunk 161: operators.\n",
            "Chunk 162: Remark 4 (Measures and random variables) .Radon\n",
            "Chunk 163: measures can also be viewed as representing the\n",
            "Chunk 164: distri-\n",
            "Chunk 165: butions of random variables. A random variable\n",
            "Chunk 166: XonXis actually a map X: Ω→X from some abstract\n",
            "Chunk 167: (often un-speciﬁed) probabized space (Ω ,P), and\n",
            "Chunk 168: its distribution αis the Radon measure X∈M1\n",
            "Chunk 169: +(X) such\n",
            "thatP(X∈A) =α(A) =∫\n",
            "Chunk 170: Adα(x). Equivalently, it is the push-forward of\n",
            "Chunk 171: PbyX,α=X♯P. Applying\n",
            "Chunk 172: another push-forward β=T♯αforT:X →Y , following\n",
            "Chunk 173: (1.2), is equivalent to deﬁning another random\n",
            "Chunk 174: variableY=T(X) :ω∈Ω→T(X(ω))∈Y, so thatβis the\n",
            "Chunk 175: distribution of Y. Drawing a random sample\n",
            "Chunk 176: yfromYis thus simply achieved by computing y=T(x)\n",
            "Chunk 177: wherexis drawn from X.\n",
            "Chunk 178: Convergence of random variable. Convergence of\n",
            "Chunk 179: random variable (in probability, almost sure, in\n",
            "Chunk 180: law),\n",
            "Chunk 181: convergence of measures (strong, weak).\n",
            "Chunk 182: 1.2 Monge Problem\n",
            "Chunk 183: Given a cost matrix ( Ci,j)i∈JnK,j∈JmK, assuming\n",
            "Chunk 184: n=m, the optimal assignment problem seeks for a\n",
            "Chunk 185: bijectionσin the set Perm( n) of permutations of\n",
            "Chunk 186: nelements solving\n",
            "Chunk 187: min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i). (1.5)\n",
            "Chunk 188: One could naively evaluate the cost function\n",
            "Chunk 189: above using all permutations in the set Perm( n).\n",
            "Chunk 190: However,\n",
            "Chunk 191: that set has size n!, which is gigantic even for\n",
            "Chunk 192: small n. Consider for instance that such a set\n",
            "Chunk 193: has more than\n",
            "Chunk 194: 10100elements [ ?] whennis as small as 70. That\n",
            "Chunk 195: problem can therefore only be solved if there\n",
            "Chunk 196: exist eﬃcient\n",
            "Chunk 197: algorithms to optimize that cost function over\n",
            "Chunk 198: the set of permutations, which will be the\n",
            "Chunk 199: subject of §??.\n",
            "Chunk 200: 5\n",
            "Chunk 201: x1x2y1y2x1x2y1y2x4x5x6x3y3x7Figure 1.3: (left)\n",
            "Chunk 202: blue dots from measure αand red dots from measure\n",
            "Chunk 203: βare pairwise equidistant. Hence,\n",
            "Chunk 204: either matching σ= (1,2) (full line) or σ= (2,1)\n",
            "Chunk 205: (dotted line) is optimal. (right) a Monge map can\n",
            "Chunk 206: associate\n",
            "Chunk 207: the blue measure αto the red measure β. The\n",
            "Chunk 208: weights αiare displayed proportionally to the\n",
            "Chunk 209: area of the\n",
            "Chunk 210: disk marked at each location. The mapping here is\n",
            "Chunk 211: such that T(x1) =T(x2) =y2,T(x3) =y3, whereas for\n",
            "Chunk 212: 4⩽i⩽7 we haveT(xi) =y1.\n",
            "Chunk 213: Remark 5 (Uniqueness) .Note that the optimal\n",
            "Chunk 214: assignment problem may have several optimal\n",
            "Chunk 215: solutions.\n",
            "Chunk 216: Suppose for instance that n=m= 2 and that the\n",
            "Chunk 217: matrix Cis the pairwise distance matrix between\n",
            "Chunk 218: the 4\n",
            "Chunk 219: corners of a 2-dimensional square of side length\n",
            "Chunk 220: 1, as represented in the left plot in Figure 1.3.\n",
            "Chunk 221: In that case\n",
            "Chunk 222: only two assignments exist, and they share the\n",
            "Chunk 223: same cost.\n",
            "Chunk 224: For discrete measures\n",
            "α=n∑\n",
            "i=1aiδxiandβ=m∑\n",
            "Chunk 225: j=1bjδyj (1.6)\n",
            "Chunk 226: the Monge problem [ ?] seeks for a map that\n",
            "Chunk 227: associates to each point xia single point yj, and\n",
            "Chunk 228: which must\n",
            "Chunk 229: push the mass of αtoward the mass of β, which is\n",
            "Chunk 230: to say that such a map T:{x1,...,xn}→{y1,...,ym}\n",
            "Chunk 231: must verify that\n",
            "∀j∈JmK,bj=∑\n",
            "i:T(xi)=yjai (1.7)\n",
            "Chunk 232: which we write in compact form as T♯α=β. This map\n",
            "Chunk 233: should minimize some transportation cost, which\n",
            "Chunk 234: is\n",
            "Chunk 235: parameterized by a function c(x,y) deﬁned for\n",
            "Chunk 236: points ( x,y)∈X×Y\n",
            "Chunk 237: min\n",
            "T{∑\n",
            "ic(xi,T(xi)) ;T♯α=β}\n",
            ". (1.8)\n",
            "Chunk 238: Such a map between discrete points can be of\n",
            "Chunk 239: course encoded, assuming all x’s andy’s are\n",
            "Chunk 240: distinct, using\n",
            "Chunk 241: indicesσ:JnK→JmKso thatj=σ(i), and the mass\n",
            "Chunk 242: conservation is written as\n",
            "Chunk 243: ∑\n",
            "i∈σ−1(j)ai=bj.\n",
            "Chunk 244: In the special case when n=mand all weights are\n",
            "Chunk 245: uniform, that is ai=bj= 1/n, then the mass\n",
            "Chunk 246: conservation\n",
            "Chunk 247: constraint implies that Tis a bijection, such\n",
            "Chunk 248: that T(xi) =yσ(i), and the Monge problem is\n",
            "Chunk 249: equivalent to the\n",
            "Chunk 250: optimal matching problem (1.5) where the cost\n",
            "Chunk 251: matrix is\n",
            "Chunk 252: Ci,jdef.=c(xi,yj).\n",
            "Chunk 253: Whenn̸=m, note that, optimality aside, Monge maps\n",
            "Chunk 254: may not even exist between an empirical measure\n",
            "Chunk 255: to another. This happens when their weight\n",
            "Chunk 256: vectors are not compatible, which is always the\n",
            "Chunk 257: case when the\n",
            "Chunk 258: target measure has more points than the source\n",
            "Chunk 259: measure. For instance, the right plot in Figure\n",
            "Chunk 260: 1.3 shows\n",
            "Chunk 261: an (optimal) Monge map between αandβ, but there\n",
            "Chunk 262: is no Monge map from βtoα.\n",
            "Chunk 263: 6\n",
            "Chunk 264: Monge problem (1.8) is extended to the setting of\n",
            "Chunk 265: two arbitrary probability measures ( α,β) on two\n",
            "Chunk 266: spaces\n",
            "Chunk 267: (X,Y) as ﬁnding a map T:X→Y that minimizes\n",
            "min\n",
            "Chunk 268: T{∫\n",
            "Xc(x,T(x))dα(x) ;T♯α=β}\n",
            "(1.9)\n",
            "Chunk 269: The constraint T♯α=βmeans that Tpushes forward\n",
            "Chunk 270: the mass of αtoβ, and makes use of the\n",
            "Chunk 271: push-forward\n",
            "Chunk 272: operator (1.2).\n",
            "1.3 Kantorovitch Problem\n",
            "Chunk 273: The assignment problem has several limitations in\n",
            "Chunk 274: practical settings, also encountered when using\n",
            "Chunk 275: the\n",
            "Chunk 276: Monge problem. Indeed, because the assignment\n",
            "Chunk 277: problem is formulated as a permutation problem,\n",
            "Chunk 278: it can only\n",
            "Chunk 279: be used to compare two points clouds of the same\n",
            "Chunk 280: size. A direct generalization to discrete\n",
            "Chunk 281: measures with non-\n",
            "Chunk 282: uniform weights can be carried out using Monge’s\n",
            "Chunk 283: formalism of pushforward maps, but that\n",
            "Chunk 284: formulation may\n",
            "Chunk 285: also be degenerate it there does not exist\n",
            "Chunk 286: feasible solutions satisfying the mass\n",
            "Chunk 287: conservation constraint (1.7)\n",
            "Chunk 288: (see the end of Remark ??). Additionally, the\n",
            "Chunk 289: assignment Problem (1.8) is combinatorial,\n",
            "Chunk 290: whereas the feasible\n",
            "Chunk 291: set for the Monge Problem (1.9), consisting in\n",
            "Chunk 292: all push-forward measures that satisfy the mass\n",
            "Chunk 293: conservation\n",
            "Chunk 294: constraint, is non-convex . Both are therefore\n",
            "Chunk 295: diﬃcult to solve in their original formulation.\n",
            "Chunk 296: Kantorovitch formulation for discrete measures.\n",
            "Chunk 297: The key idea of [ ?] is to relax the\n",
            "Chunk 298: deterministic na-\n",
            "Chunk 299: ture of transportation, namely the fact that a\n",
            "Chunk 300: source point xican only be assigned to another,\n",
            "Chunk 301: or transported\n",
            "Chunk 302: to one and one location T(xi) only. Kantorovich\n",
            "Chunk 303: proposes instead that the mass at any point xibe\n",
            "Chunk 304: potentially\n",
            "Chunk 305: dispatched across several locations. Kantorovich\n",
            "Chunk 306: moves away from the idea that mass transportation\n",
            "Chunk 307: should\n",
            "Chunk 308: be “deterministic” to consider instead a\n",
            "Chunk 309: “probabilistic” (or “fuzzy”) transportation,\n",
            "Chunk 310: which allows what is\n",
            "Chunk 311: commonly known now as “mass splitting” from a\n",
            "Chunk 312: source towards several targets. This ﬂexibility\n",
            "Chunk 313: is encoded\n",
            "Chunk 314: using, in place of a permutation σor a mapT, a\n",
            "Chunk 315: coupling matrix P∈Rn×m\n",
            "Chunk 316: +, where Pi,jdescribes the\n",
            "Chunk 317: amount of mass ﬂowing from bin i(or pointxi)\n",
            "Chunk 318: towards bin j(or pointxj),xitowardsyjin the\n",
            "Chunk 319: formalism\n",
            "Chunk 320: of discrete measures (1.6). Admissible couplings\n",
            "Chunk 321: admit a far simpler characterization than Monge\n",
            "Chunk 322: maps:\n",
            "Chunk 323: U(a,b)def.={\n",
            "P∈Rn×m\n",
            "+ ;P1m=aand PT1n=b}\n",
            ", (1.10)\n",
            "Chunk 324: where we used the following matrix-vector\n",
            "Chunk 325: notation\n",
            "Chunk 326: P1m=\n",
            "∑\n",
            "jPi,j\n",
            "\n",
            "i∈Rnand PT1n=(∑\n",
            "iPi,j)\n",
            "j∈Rm.\n",
            "Chunk 327: The set of matrices U(a,b) is bounded, deﬁned by\n",
            "Chunk 328: n+mequality constraints, and therefore a convex\n",
            "Chunk 329: polytope (the convex hull of a ﬁnite set of\n",
            "Chunk 330: matrices).\n",
            "Chunk 331: Additionally, whereas the Monge formulation (as\n",
            "Chunk 332: illustrated in the right plot of Figure 1.3) was\n",
            "Chunk 333: intrisically\n",
            "Chunk 334: asymmetric, Kantorovich’s relaxed formulation is\n",
            "Chunk 335: always symmetric, in the sense that a coupling\n",
            "Chunk 336: Pis in\n",
            "Chunk 337: U(a,b) if and only if PTis inU(b,a).\n",
            "Chunk 338: Kantorovich’s optimal transport problem now reads\n",
            "Chunk 339: LC(a,b)def.= min\n",
            "P∈U(a,b)⟨C,P⟩def.=∑\n",
            "Chunk 340: i,jCi,jPi,j. (1.11)\n",
            "Chunk 341: This is a linear program (see Chapter ??), and as\n",
            "Chunk 342: is usually the case with such programs, its\n",
            "Chunk 343: solutions are\n",
            "Chunk 344: not necessarily unique.\n",
            "7\n",
            "↵\u0000\n",
            "Chunk 345: ↵\u0000Figure 1.4: Comparison of optimal matching and\n",
            "Chunk 346: generic couplings. A black segment between\n",
            "Chunk 347: xiandyj\n",
            "Chunk 348: indicates a non-zero element in the displayed\n",
            "Chunk 349: optimal coupling Pi,jsolving (1.11). Left:\n",
            "Chunk 350: optimal matching,\n",
            "Chunk 351: corresponding to the setting of Proposition (1)\n",
            "Chunk 352: (empirical measures with the same number n=mof\n",
            "Chunk 353: points).\n",
            "Chunk 354: Right: these two weighted point clouds cannot be\n",
            "Chunk 355: matched; instead a Kantorovich coupling can be\n",
            "Chunk 356: used to\n",
            "Chunk 357: associate two arbitrary discrete measures.\n",
            "Chunk 358: Permutation Matrices as Couplings For a\n",
            "Chunk 359: permutation σ∈Perm(n), we write Pσfor the\n",
            "Chunk 360: correspond-\n",
            "Chunk 361: ing permutation matrix,\n",
            "Chunk 362: ∀(i,j)∈JnK2,(Pσ)i,j={1/n ifj=σi,\n",
            "Chunk 363: 0 otherwise.(1.12)\n",
            "Chunk 364: One can check that in that case\n",
            "⟨C,Pσ⟩=1\n",
            "nn∑\n",
            "Chunk 365: i=1Ci,σi,\n",
            "Chunk 366: which shows that the assignment problem (1.5) can\n",
            "Chunk 367: be recast as a Kantorovich problem (1.11) where\n",
            "Chunk 368: the\n",
            "Chunk 369: couplings Pare restricted to be exactly\n",
            "Chunk 370: permutation matrices:\n",
            "Chunk 371: min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i)= min\n",
            "Chunk 372: σ∈Perm(n)⟨C,Pσ⟩.\n",
            "Chunk 373: Next, one can easily check that the set of\n",
            "Chunk 374: permutation matrices is strictly included in the\n",
            "Chunk 375: so-called Birkhoﬀ\n",
            "Chunk 376: polytope U(1n/n,1n,n). Indeed, for any\n",
            "Chunk 377: permutation σwe have Pσ1=1nandPσT1=1n, whereas\n",
            "Chunk 378: 1n1nT/n2is a valid coupling but not a permutation\n",
            "Chunk 379: matrix. Therefore, one has naturally that\n",
            "Chunk 380: min\n",
            "σ∈Perm(n)⟨C,Pσ⟩⩽LC(1n/n,1n/n).\n",
            "Chunk 381: The following proposition shows that these\n",
            "Chunk 382: problems result in fact in the same optimum,\n",
            "Chunk 383: namely that\n",
            "Chunk 384: one can always ﬁnd a permutation matrix that\n",
            "Chunk 385: minimizes Kantorovich’s problem (1.11) between\n",
            "Chunk 386: two uniform\n",
            "Chunk 387: measures a=b=1n/n, which shows that the\n",
            "Chunk 388: Kantorovich relaxation is tight when considered\n",
            "Chunk 389: on assignment\n",
            "Chunk 390: problems. Figure 1.4 shows on the left a 2-D\n",
            "Chunk 391: example of optimal matching corresponding to this\n",
            "Chunk 392: special\n",
            "Chunk 393: case.\n",
            "Chunk 394: Proposition 1 (Kantorovich for matching)\n",
            "Chunk 395: .Ifm=nanda=b=1n/n, then there exists an optimal\n",
            "Chunk 396: solution for Problem (1.11) Pσ⋆, which is a\n",
            "Chunk 397: permutation matrix associated to an optimal\n",
            "Chunk 398: permutation σ⋆∈\n",
            "Chunk 399: Perm(n)for Problem (1.5) .\n",
            "Chunk 400: Proof. Birkhoﬀ’s theorem states that the set of\n",
            "Chunk 401: extremal points of U(1n/n,1n/n) is equal to the\n",
            "Chunk 402: set of\n",
            "Chunk 403: permutation matrices. A fundamental theorem of\n",
            "Chunk 404: linear programming [ ?, Theorem 2.7] states that\n",
            "Chunk 405: the\n",
            "Chunk 406: minimum of a linear objective in a non-empty\n",
            "Chunk 407: polyhedron, if ﬁnite, is reached at an extremal\n",
            "Chunk 408: point of the\n",
            "Chunk 409: polyhedron.\n",
            "8\n",
            "⇡\u0000↵\u0000↵\n",
            "⇡\u0000↵\u0000↵\n",
            "⇡\u0000↵\u0000↵\n",
            "Chunk 410: Discrete Semi-discrete Continuous\n",
            "Chunk 411: Figure 1.5: Schematic viewed of input measures (\n",
            "Chunk 412: α,β) and couplingsU(α,β) encountered in the three\n",
            "Chunk 413: main\n",
            "Chunk 414: scenario for Kantorovich OT. Chapter ??is\n",
            "Chunk 415: dedicated to the semi-discrete setup.\n",
            "Chunk 416: ⇡\u0000↵\n",
            "⇡\u0000↵\n",
            "Chunk 417: Figure 1.6: Left: “continuous” coupling πsolving\n",
            "Chunk 418: (1.13) between two 1-D measure with density. The\n",
            "Chunk 419: coupling is localized along the graph of the\n",
            "Chunk 420: Monge map ( x,T(x)) (displayed in black). Right:\n",
            "Chunk 421: “discrete”\n",
            "Chunk 422: couplingTsolving (1.11) between two discrete\n",
            "Chunk 423: measures of the form (1.6). The non-zero entries\n",
            "Chunk 424: Ti,jare\n",
            "Chunk 425: display with a black disk at position ( i,j) with\n",
            "Chunk 426: radius proportional to Ti,j.\n",
            "Chunk 427: Kantorovitch formulation for arbitrary measures.\n",
            "Chunk 428: The deﬁnition of Lcin (??) can be extended to\n",
            "Chunk 429: arbitrary measures by considering couplings π∈M1\n",
            "Chunk 430: +(X×Y ) which are joint distributions over the\n",
            "Chunk 431: product\n",
            "Chunk 432: space. The discrete case is a special situation\n",
            "Chunk 433: where one imposes this product measure to be of\n",
            "Chunk 434: the form\n",
            "Chunk 435: π=∑\n",
            "Chunk 436: i,jPi,jδ(xi,yj). In the general case, the mass\n",
            "Chunk 437: conservation constraint (1.10) should be\n",
            "Chunk 438: rewritten as a\n",
            "Chunk 439: marginal constraint on joint probability\n",
            "Chunk 440: distributions\n",
            "Chunk 441: U(α,β)def.={\n",
            "π∈M1\n",
            "+(X×Y ) ;PX♯π=αandPY♯π=β}\n",
            "Chunk 442: . (1.13)\n",
            "Chunk 443: HerePX♯andPY♯are the push-forward (see Deﬁnition\n",
            "Chunk 444: 1) by the projections PX(x,y) =xandPY(x,y) =y.\n",
            "Chunk 445: Figure 1.5 shows a schematic visualization of the\n",
            "Chunk 446: coupling constraints for diﬀerent class of\n",
            "Chunk 447: problem (discrete\n",
            "Chunk 448: measures and densities). Using (1.3), these\n",
            "Chunk 449: marginal constraints are equivalent to imposing\n",
            "Chunk 450: that π(A×Y) =\n",
            "Chunk 451: α(A) andπ(X×B) =β(B) for setsA⊂X andB⊂Y.\n",
            "Chunk 452: The Kantorovich problem (1.11) is then\n",
            "Chunk 453: generalized as\n",
            "Chunk 454: Lc(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "Chunk 455: X×Yc(x,y)dπ(x,y). (1.14)\n",
            "Chunk 456: This is an inﬁnite-dimensional linear program\n",
            "Chunk 457: over a space of measures. Figure 1.6 shows\n",
            "Chunk 458: examples of discrete\n",
            "Chunk 459: and continuous optimal coupling solving (1.14).\n",
            "Chunk 460: Figure 1.7 shows other examples of optimal 1-D\n",
            "Chunk 461: couplings,\n",
            "Chunk 462: involving discrete and continuous marginals.\n",
            "Chunk 463: On compact domain ( X,Y), (1.14) always has a\n",
            "Chunk 464: solution, because using the weak-* topology (so\n",
            "Chunk 465: called\n",
            "Chunk 466: weak topology of measures), the set of measure is\n",
            "Chunk 467: compact, and a linear function with a continuous\n",
            "Chunk 468: c(x,y)\n",
            "Chunk 469: 9\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "Chunk 470: ↵\u0000↵⇡\u0000Figure 1.7: Four simple examples of optimal\n",
            "Chunk 471: couplings between 1-D distributions, represented\n",
            "Chunk 472: as maps\n",
            "Chunk 473: above (arrows) and couplings below. Inspired by [\n",
            "Chunk 474: ?].\n",
            "Chunk 475: is weak-* continuous. And the set of constraint\n",
            "Chunk 476: is non empty, taking α⊗β. On non compact domain,\n",
            "Chunk 477: needs\n",
            "Chunk 478: to impose moment condition on αandβ.\n",
            "Chunk 479: Wasserstein distances. An important feature of OT\n",
            "Chunk 480: is that it deﬁnes a distance between histograms\n",
            "Chunk 481: and probability measures as soon as the cost\n",
            "Chunk 482: matrix satisﬁes certain suitable properties.\n",
            "Chunk 483: Indeed, OT can be\n",
            "Chunk 484: understood as a canonical way to lift a ground\n",
            "Chunk 485: distance between points to a distance between\n",
            "Chunk 486: histogram or\n",
            "Chunk 487: measures.\n",
            "Chunk 488: We ﬁrst consider the case where, using a term\n",
            "Chunk 489: ﬁrst introduce by [ ?], the “ground metric”\n",
            "Chunk 490: matrix C\n",
            "Chunk 491: is ﬁxed, representing substitution costs between\n",
            "Chunk 492: bins, and shared across several histograms we\n",
            "Chunk 493: would like\n",
            "Chunk 494: to compare. The following proposition states that\n",
            "Chunk 495: OT provides a meaningful distance between\n",
            "Chunk 496: histograms\n",
            "Chunk 497: supported on these bins.\n",
            "Chunk 498: Proposition 2. We suppose n=m, and that for some\n",
            "Chunk 499: p⩾1,C=Dp= (Dp\n",
            "Chunk 500: i,j)i,j∈Rn×nwhere D∈Rn×n\n",
            "+\n",
            "Chunk 501: is a distance on JnK,i.e.\n",
            "1.D∈Rn×n\n",
            "Chunk 502: + is symmetric;\n",
            "2.Di,j= 0if and only if i=j;\n",
            "Chunk 503: 3.∀(i,j,k )∈JnK3,Di,k⩽Di,j+Dj,k.\n",
            "Then\n",
            "Chunk 504: Wp(a,b)def.= LDp(a,b)1/p(1.15)\n",
            "Chunk 505: (note that Wpdepends on D) deﬁnes the\n",
            "Chunk 506: p-Wasserstein distance on Σn,i.e. Wpis symmetric,\n",
            "Chunk 507: positive,\n",
            "Chunk 508: Wp(a,b) = 0 if and only if a=b, and it satisﬁes\n",
            "Chunk 509: the triangle inequality\n",
            "Chunk 510: ∀a,a′,b∈Σn,Wp(a,b)⩽Wp(a,a′) + Wp(a′,b).\n",
            "Chunk 511: Proof. Symmetry and deﬁniteness of the distance\n",
            "Chunk 512: are easy to prove: since C=Dphas a null diagonal,\n",
            "Chunk 513: Wp(a,a) = 0, with corresponding optimal transport\n",
            "Chunk 514: matrix P⋆= diag( a); by the positivity of all\n",
            "Chunk 515: oﬀ-diagonal\n",
            "Chunk 516: elements of Dp, Wp(a,b)>0 whenever a̸=b(because\n",
            "Chunk 517: in this case, an admissible coupling necessarily\n",
            "Chunk 518: has\n",
            "Chunk 519: a non-zero element outside the diagonal); by\n",
            "Chunk 520: symmetry of Dp, Wp(a,b) = 0 is itself a symmetric\n",
            "Chunk 521: function.\n",
            "Chunk 522: To prove the triangle inequality of Wasserstein\n",
            "Chunk 523: distances for arbitrary measures, [ ?, Theorem\n",
            "Chunk 524: 7.3] uses the\n",
            "Chunk 525: gluing lemma, which stresses the existence of\n",
            "Chunk 526: couplings with a prescribed structure. In the\n",
            "Chunk 527: discrete setting,\n",
            "Chunk 528: the explicit constuction of this glued coupling\n",
            "Chunk 529: is simple. Let a,b,c∈Σn. Let PandQbe two optimal\n",
            "Chunk 530: solutions of the transport problems between\n",
            "Chunk 531: aandb, and bandcrespectively. We deﬁne\n",
            "Chunk 532: ¯bjdef.=bjifbj>0\n",
            "Chunk 533: and set otherwise ¯bj= 1 (or actually any other\n",
            "Chunk 534: value). We then deﬁne\n",
            "Chunk 535: Sdef.=Pdiag(1/¯b)Q∈Rn×n\n",
            "+.\n",
            "10\n",
            "Chunk 536: We remark that S∈U(a,c) because\n",
            "Chunk 537: S1n=Pdiag(1/¯b)Q1n=P(b/¯b) =P1Supp( b)=a\n",
            "Chunk 538: where we denoted 1Supp( b)the indicator of the\n",
            "Chunk 539: support of b, and we use the fact that P1Supp(\n",
            "Chunk 540: b)=P1=b\n",
            "Chunk 541: because necessarily Pi,j= 0 forj /∈Supp( b).\n",
            "Chunk 542: Similarly one veriﬁes that S⊤1n=c.\n",
            "Chunk 543: The triangle inequality follows from\n",
            "Wp(a,c) =(\n",
            "Chunk 544: min\n",
            "P∈U(a,c)⟨P,Dp⟩)1/p\n",
            "⩽⟨S,Dp⟩1/p\n",
            "=\n",
            "∑\n",
            "ikDp\n",
            "ik∑\n",
            "Chunk 545: jPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "⩽\n",
            "∑\n",
            "ijk(Dij+Djk)pPijQjk\n",
            "¯bj\n",
            "Chunk 546: 1/p\n",
            "⩽\n",
            "∑\n",
            "ijkDp\n",
            "ijPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "ijkDp\n",
            "Chunk 547: jkPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "ijDp\n",
            "ijPij∑\n",
            "kQjk\n",
            "¯bj\n",
            "Chunk 548: 1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk∑\n",
            "iPij\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "ijDp\n",
            "Chunk 549: ijPij\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk\n",
            "1/p\n",
            "Chunk 550: = Wp(a,b) + Wp(b,b).\n",
            "Chunk 551: The ﬁrst inequality is due to the suboptimality\n",
            "Chunk 552: of S, the second is the usual triangle inequality\n",
            "Chunk 553: for elements\n",
            "Chunk 554: inD, and the third comes from Minkowski’s\n",
            "Chunk 555: inequality.\n",
            "Chunk 556: Proposition 2 generalizes from histogram to\n",
            "Chunk 557: arbitrary measures that need not be discrete.\n",
            "Chunk 558: Proposition 3. We assumeX=Y, and that for some\n",
            "Chunk 559: p⩾1,c(x,y) =d(x,y)pwheredis a distance on\n",
            "Chunk 560: X,i.e.\n",
            "(i)d(x,y) =d(y,x)⩾0;\n",
            "Chunk 561: (ii)d(x,y) = 0 if and only if x=y;\n",
            "Chunk 562: (ii)∀(x,y,z )∈X3,d(x,z)⩽d(x,y) +d(y,z).\n",
            "Then\n",
            "Chunk 563: Wp(α,β)def.=Ldp(α,β)1/p(1.16)\n",
            "Chunk 564: (note thatWpdepends on d) deﬁnes the\n",
            "Chunk 565: p-Wasserstein distance on X,i.e.Wpis symmetric,\n",
            "Chunk 566: positive,\n",
            "Chunk 567: Wp(α,β) = 0 if and only if α=β, and it satisﬁes\n",
            "Chunk 568: the triangle inequality\n",
            "Chunk 569: ∀(α,β,γ )∈M1\n",
            "+(X)3,Wp(α,γ)⩽Wp(α,β) +Wp(β,γ).\n",
            "Chunk 570: Proof. The proof follows the same approach as\n",
            "Chunk 571: that for Proposition 2 and relies on the\n",
            "Chunk 572: existence of a coupling\n",
            "Chunk 573: between (α,γ) obtained by “guying” optimal\n",
            "Chunk 574: couplings between ( α,β) and (β,γ).\n",
            "Chunk 575: The Wasserstein distance Wphas many important\n",
            "Chunk 576: properties, the most important one being that it\n",
            "Chunk 577: is a\n",
            "Chunk 578: weak distance, i.e.it allows to compare singular\n",
            "Chunk 579: distributions (for instance discrete ones) and to\n",
            "Chunk 580: quantify\n",
            "Chunk 581: spatial shift between the supports of the\n",
            "Chunk 582: distributions. In particular, “classical”\n",
            "Chunk 583: distances (or divergences)\n",
            "Chunk 584: are not even deﬁned between discrete\n",
            "Chunk 585: distributions (the L2norm can only be applied to\n",
            "Chunk 586: continuous measures\n",
            "Chunk 587: with a density with respect to a base measure,\n",
            "Chunk 588: and the discrete ℓ2norm requires the positions (\n",
            "Chunk 589: xi,yj) to\n",
            "Chunk 590: be ﬁxed to work). In sharp contrast, one has that\n",
            "Chunk 591: for any p >0,Wp\n",
            "Chunk 592: p(δx,δy) =d(x,y). Indeed, it suﬃces\n",
            "Chunk 593: to notice thatU(δx,δy) ={δx,y}and therefore the\n",
            "Chunk 594: Kantorovich problem having only one feasible\n",
            "Chunk 595: solution,\n",
            "Chunk 596: Wp\n",
            "Chunk 597: p(δx,δy) is necessarily ( d(x,y)p)1/p=d(x,y).\n",
            "Chunk 598: This shows that Wp(δx,δy)→0 ifx→y. This property\n",
            "Chunk 599: corresponds to the fact that Wpis a way to\n",
            "Chunk 600: quantify the weak convergence as we now deﬁne.\n",
            "Chunk 601: 11\n",
            "Chunk 602: Deﬁnition 2 (Weak convergence) .(αk)kconverges\n",
            "Chunk 603: weakly to αinM1\n",
            "Chunk 604: +(X)(denotedαk⇀α ) if and only if\n",
            "Chunk 605: for any continuous function g∈C(X),∫\n",
            "Xgdαk→∫\n",
            "Chunk 606: Xgdα. This notion of weak convergence corresponds\n",
            "Chunk 607: to\n",
            "Chunk 608: the convergence in law of random vectors.\n",
            "Chunk 609: This convergence can be shown to be equivalent to\n",
            "Chunk 610: Wp(αk,α)→0 [?, Theorem 6.8] (together with a\n",
            "Chunk 611: convergence of the moments up to order pfor\n",
            "Chunk 612: unbounded metric spaces).\n",
            "Chunk 613: Note that there exists alternative distances\n",
            "Chunk 614: which also metrize weak convergence. The simplest\n",
            "Chunk 615: one are\n",
            "Chunk 616: Hilbertian norms, deﬁned as\n",
            "||α||2\n",
            "Chunk 617: kdef.=Eα⊗α(k) =∫\n",
            "X×Xk(x,y)dα(x)dα(y)\n",
            "Chunk 618: for a suitable choice of kernel k:X2→R. The most\n",
            "Chunk 619: famous of such kernel is the Gaussian one k(x,y)\n",
            "Chunk 620: =\n",
            "Chunk 621: e−||x−y||2\n",
            "2σ2for some choice of bandwidth σ>0.\n",
            "Chunk 622: This convergence should not be confounded with\n",
            "Chunk 623: the strong convergence of measures, which is\n",
            "Chunk 624: metrized\n",
            "Chunk 625: by the TV norm ||α||TVdef.=|α|(X), which is the\n",
            "Chunk 626: total mass of the absolute value of the measure.\n",
            "Chunk 627: Algorithms Since ( ??)ˆA is a linear program, it\n",
            "Chunk 628: is possible to use any classical linear program\n",
            "Chunk 629: solver, such\n",
            "Chunk 630: as interior point methods or simplex. In\n",
            "Chunk 631: practice, the network simplex is an eﬃcient\n",
            "Chunk 632: option, and it used\n",
            "Chunk 633: pivoting rule adapted to the OT constraint set.\n",
            "Chunk 634: In the case of the assignment problem, a=b=1n/n,\n",
            "Chunk 635: there\n",
            "Chunk 636: exists faster combinatorial optimization scheme,\n",
            "Chunk 637: the most famous ones being the Hungarian\n",
            "Chunk 638: algorithm and\n",
            "Chunk 639: the auction algorithm, which have roughly O(n3)\n",
            "Chunk 640: complexity. Section 1.5 details an approximate\n",
            "Chunk 641: algorithm,\n",
            "Chunk 642: which is typically faster, and amenable to\n",
            "Chunk 643: parallelisation, but do not compute exactly the\n",
            "Chunk 644: solution to the\n",
            "Chunk 645: OT problem.\n",
            "1.4 Duality\n",
            "Chunk 646: The Kantorovich problem (1.11) is a constrained\n",
            "Chunk 647: convex minimization problem, and as such, it can\n",
            "Chunk 648: be\n",
            "Chunk 649: naturally paired with a so-called dual problem,\n",
            "Chunk 650: which is a constrained concave maximization\n",
            "Chunk 651: problem. The\n",
            "Chunk 652: following fundamental proposition, which is a\n",
            "Chunk 653: special case of Fenchel-Rockafellar duality\n",
            "Chunk 654: theory, explains the\n",
            "Chunk 655: relationship between the primal and dual\n",
            "Chunk 656: problems.\n",
            "Chunk 657: Proposition 4. One has\n",
            "LC(a,b) = max\n",
            "Chunk 658: (f,g)∈R(a,b)⟨f,a⟩+⟨g,b⟩ (1.17)\n",
            "Chunk 659: where the set of admissible potentials is\n",
            "Chunk 660: R(a,b)def.={(f,g)∈Rn×Rm;∀(i,j)∈JnK×JmK,f⊕g⩽C}\n",
            "Chunk 661: (1.18)\n",
            "Chunk 662: Proof. This result is a direct consequence of the\n",
            "Chunk 663: more general result on the strong duality for\n",
            "Chunk 664: linear pro-\n",
            "Chunk 665: grams [ ?, p.148,Theo.4.4]. The easier part of\n",
            "Chunk 666: that result, namely that the right-hand side of\n",
            "Chunk 667: Equation (1.17)\n",
            "Chunk 668: is a lower bound on L C(a,b) is discussed in ??.\n",
            "Chunk 669: For the sake of completeness, let us derive this\n",
            "Chunk 670: dual problem\n",
            "Chunk 671: with the use of Lagrangian duality. The Lagangian\n",
            "Chunk 672: associate to (1.11) reads\n",
            "Chunk 673: min\n",
            "P⩾0max\n",
            "Chunk 674: (f,g)∈Rn×Rm⟨C,P⟩+⟨a−P1m,f⟩+⟨b−P⊤1n,g⟩. (1.19)\n",
            "Chunk 675: For linear program, one can always exchange the\n",
            "Chunk 676: min and the max and get the same value of the\n",
            "Chunk 677: linear\n",
            "Chunk 678: program, and one thus consider\n",
            "max\n",
            "Chunk 679: (f,g)∈Rn×Rm⟨a,f⟩+⟨b,g⟩+ min\n",
            "P⩾0⟨C−f1⊤\n",
            "m−1ng⊤,P⟩.\n",
            "Chunk 680: We conclude by remarking that\n",
            "min\n",
            "Chunk 681: P⩾0⟨Q,P⟩={0 if Q⩾0\n",
            "−∞ otherwise\n",
            "Chunk 682: so that the constraint reads C−f1⊤\n",
            "Chunk 683: m−1ng⊤=C−f⊕g⩾0.\n",
            "12\n",
            "Chunk 684: The primal-dual optimality relation for the\n",
            "Chunk 685: Lagrangian (1.19) allows to locate the support of\n",
            "Chunk 686: the optimal\n",
            "Chunk 687: transport plan\n",
            "Supp( P)⊂{\n",
            "Chunk 688: (i,j)∈JnK×JmK;fi+gj=Ci,j}\n",
            ". (1.20)\n",
            "Chunk 689: To extend this primal-dual construction to\n",
            "Chunk 690: arbitrary measures, it is important to realize\n",
            "Chunk 691: that measures\n",
            "Chunk 692: are naturally paired in duality with continuous\n",
            "Chunk 693: functions (a measure can only be accessed through\n",
            "Chunk 694: integration\n",
            "Chunk 695: against continuous functions). The duality is\n",
            "Chunk 696: formalized in the following proposition, which\n",
            "Chunk 697: boils down to\n",
            "Chunk 698: Proposition 4 when dealing with discrete\n",
            "Chunk 699: measures.\n",
            "Chunk 700: Proposition 5. One has\n",
            "Lc(α,β) = max\n",
            "(f,g)∈R(c)∫\n",
            "Chunk 701: Xf(x)dα(x) +∫\n",
            "Yg(y)dβ(y), (1.21)\n",
            "Chunk 702: where the set of admissible dual potentials is\n",
            "Chunk 703: R(c)def.={(f,g)∈C(X)×C(Y) ;∀(x,y),f(x)\n",
            "Chunk 704: +g(y)⩽c(x,y)}. (1.22)\n",
            "Chunk 705: Here, (f,g)is a pair of continuous functions, and\n",
            "Chunk 706: are often called “Kantorovich potentials”.\n",
            "Chunk 707: The discrete case (1.17) corresponds to the dual\n",
            "Chunk 708: vectors being samples of the continuous\n",
            "Chunk 709: potentials, i.e.\n",
            "Chunk 710: (fi,gj) = (f(xi),g(yj)). The primal-dual\n",
            "Chunk 711: optimality conditions allow to track the support\n",
            "Chunk 712: of optimal plan,\n",
            "Chunk 713: and (1.20) is generalized as\n",
            "Chunk 714: Supp(π)⊂{(x,y)∈X×Y ;f(x) +g(y) =c(x,y)}. (1.23)\n",
            "Chunk 715: Note that in contrast to the primal problem\n",
            "Chunk 716: (1.14), showing the existence of solutions to\n",
            "Chunk 717: (1.21) is non-\n",
            "Chunk 718: trivial, because the constraint set R(c) is not\n",
            "Chunk 719: compact and the function to minimize\n",
            "Chunk 720: non-coercive. Using the\n",
            "Chunk 721: machinery of c-transform detailed in Section ??,\n",
            "Chunk 722: one can however show that optimal ( f,g) are\n",
            "Chunk 723: necessarily\n",
            "Chunk 724: Lipschitz regular, which enable to replace the\n",
            "Chunk 725: constraint by a compact one.\n",
            "Chunk 726: Benier’s Theorem and Monge-Amp` ere PDE The\n",
            "Chunk 727: following celebrated theorem of [ ?] ensures that\n",
            "Chunk 728: in\n",
            "Chunk 729: Rdforp= 2, if at least one of the two inputs\n",
            "Chunk 730: measures has a density, then Kantorovitch and\n",
            "Chunk 731: Monge problems\n",
            "Chunk 732: are equivalent.\n",
            "Chunk 733: Theorem 1 (Brenier) .In the caseX=Y=Rdandc(x,y)\n",
            "Chunk 734: =||x−y||2, if at least one of the two inputs\n",
            "Chunk 735: measures (denoted α) has a density ραwith respect\n",
            "Chunk 736: to the Lebesgue measure, then the optimal πin the\n",
            "Chunk 737: Kantorovich formulation (1.14) is unique, and is\n",
            "Chunk 738: supported on the graph (x,T(x))of a “Monge map”\n",
            "Chunk 739: T:\n",
            "Chunk 740: Rd→Rd. This means that π= (Id,T)♯µ,i.e.\n",
            "Chunk 741: ∀h∈C(X×Y ),∫\n",
            "X×Yh(x,y)dπ(x,y) =∫\n",
            "Chunk 742: Xh(x,T(x))dµ(x). (1.24)\n",
            "Chunk 743: Furthermore, this map Tis uniquely deﬁned as the\n",
            "Chunk 744: gradient of a convex function ϕ,T(x) =∇ϕ(x),\n",
            "Chunk 745: where\n",
            "Chunk 746: ϕis the unique (up to an additive constant)\n",
            "Chunk 747: convex function such that (∇ϕ)♯µ=ν. This convex\n",
            "Chunk 748: function is\n",
            "Chunk 749: related to the dual potential fsolving (1.21)\n",
            "Chunk 750: asϕ(x) =||x||2\n",
            "Chunk 751: 2−f(x).\n",
            "Chunk 752: Proof. We sketch the main ingredients of the\n",
            "Chunk 753: proof, more details can be found for instance in\n",
            "Chunk 754: [ ?]. We remark\n",
            "Chunk 755: that∫\n",
            "cdπ=Cα,β−2∫\n",
            "Chunk 756: ⟨x, y⟩dπ(x,y) where the constant is Cα,β=∫\n",
            "Chunk 757: ||x||2dα(x) +∫\n",
            "||y||2dβ(y). Instead of\n",
            "Chunk 758: solving (1.14), one can thus consider the\n",
            "Chunk 759: following problem\n",
            "Chunk 760: max\n",
            "π∈U(α,β)∫\n",
            "X×Y⟨x, y⟩dπ(x,y),\n",
            "whose dual reads\n",
            "Chunk 761: min\n",
            "(ϕ,ψ){∫\n",
            "Xϕdα+∫\n",
            "Chunk 762: Yψdβ;∀(x,y), ϕ (x) +ψ(y)⩾⟨x, y⟩}\n",
            ". (1.25)\n",
            "13\n",
            "Chunk 763: The relation between these variables and those of\n",
            "Chunk 764: (1.22) is ( ϕ,ψ) = (||·||2\n",
            "Chunk 765: 2−f,||·||2\n",
            "2−g). One can replace the\n",
            "Chunk 766: constraint by\n",
            "∀y, ψ (y)⩾ϕ∗(y)def.= sup\n",
            "Chunk 767: x⟨x, y⟩−ϕ(x). (1.26)\n",
            "Chunk 768: Hereϕ∗is the Legendre transform of ϕand is a\n",
            "Chunk 769: convex function as a supremum of linear forms\n",
            "Chunk 770: (see\n",
            "Chunk 771: also ( ??)). Since the objective appearing in\n",
            "Chunk 772: (1.27) is linear and the integrating measures\n",
            "Chunk 773: positive, one can\n",
            "Chunk 774: minimize explicitly with respect to ϕand\n",
            "Chunk 775: setψ=ϕ∗in order to consider the unconstraint\n",
            "Chunk 776: problem\n",
            "Chunk 777: min\n",
            "ϕ∫\n",
            "Xϕdα+∫\n",
            "Yϕ∗dβ, (1.27)\n",
            "Chunk 778: see also Section ??for a generalization of this\n",
            "Chunk 779: idea to generic costs c(x,y). By iterating this\n",
            "Chunk 780: argument\n",
            "Chunk 781: twice, one can replace ϕbyϕ∗∗, which is a convex\n",
            "Chunk 782: function, and thus impose in (1.27) that ϕis\n",
            "Chunk 783: convex.\n",
            "Chunk 784: Condition (1.23) shows that an optimal πis\n",
            "Chunk 785: supported on{(x,y) ;ϕ(x) +ϕ∗(y) =⟨x, y⟩}which\n",
            "Chunk 786: shows that\n",
            "Chunk 787: such anyis optimal for the minimization (1.26) of\n",
            "Chunk 788: the Legendre transform, whose optimality\n",
            "Chunk 789: condition reads\n",
            "Chunk 790: y∈∂ϕ(x). Sinceϕis convex, it is diﬀerentiable\n",
            "Chunk 791: almost everywhere, and since αhas a density, it\n",
            "Chunk 792: is also\n",
            "Chunk 793: diﬀerentiable α-almost everywhere. This shows\n",
            "Chunk 794: that for each x, the associated yis uniquely\n",
            "Chunk 795: deﬁned α-almost\n",
            "Chunk 796: everywhere as y=∇ϕ(x), and shows that necessarily\n",
            "Chunk 797: π= (Id,∇ϕ)♯α.\n",
            "Chunk 798: This results shows that in the setting of W2with\n",
            "Chunk 799: non-singular densities, the Monge problem (1.9)\n",
            "Chunk 800: and its Kantorovich relaxation (1.14) are equal\n",
            "Chunk 801: (the relaxation is tight). This is the continuous\n",
            "Chunk 802: analog\n",
            "Chunk 803: of Proposition 1 for the assignment case (1),\n",
            "Chunk 804: which states that the minimum of the optimal\n",
            "Chunk 805: transport\n",
            "Chunk 806: problem is achieved, when the marginals are equal\n",
            "Chunk 807: and uniform, at a permutation matrix (a discrete\n",
            "Chunk 808: map).\n",
            "Chunk 809: Brenier’s theorem, stating that an optimal\n",
            "Chunk 810: transport map must be the gradient of a convex\n",
            "Chunk 811: function, should\n",
            "Chunk 812: be examined under the light that a convex\n",
            "Chunk 813: function is the natural generalization of the\n",
            "Chunk 814: notion of increasing\n",
            "Chunk 815: functions in dimension more than one. Optimal\n",
            "Chunk 816: transport can thus plays an important role to\n",
            "Chunk 817: deﬁne quantile\n",
            "Chunk 818: functions in arbitrary dimensions, which in turn\n",
            "Chunk 819: is useful for applications to quantile regression\n",
            "Chunk 820: problems [ ?].\n",
            "Chunk 821: Note also that this theorem can be extended in\n",
            "Chunk 822: many directions. The condition that αhas a\n",
            "Chunk 823: density can\n",
            "Chunk 824: be weakened to the condition that it does not\n",
            "Chunk 825: give mass to “small sets” having Hausdorﬀ\n",
            "Chunk 826: dimension smaller\n",
            "Chunk 827: thand−1 (e.g. hypersurfaces). One can also\n",
            "Chunk 828: consider costs of the form c(x,y) =h(x−y)\n",
            "Chunk 829: wherehis a\n",
            "Chunk 830: strictly convex function.\n",
            "Chunk 831: For measures with densities, using (1.4), one\n",
            "Chunk 832: obtains that ϕis the unique (up to the addition\n",
            "Chunk 833: of a\n",
            "Chunk 834: constant) convex function which solves the\n",
            "Chunk 835: following Monge-Amp ˜A¨re-type equation\n",
            "Chunk 836: det(∂2ϕ(x))ρβ(∇ϕ(x)) =ρα(x) (1.28)\n",
            "Chunk 837: where∂2ϕ(x)∈Rd×dis the hessian of ϕ. The\n",
            "Chunk 838: Monge-Amp` ere operator det( ∂2ϕ(x)) can be\n",
            "Chunk 839: understood as a\n",
            "Chunk 840: non-linear degenerate Laplacian. In the limit of\n",
            "Chunk 841: small displacements, ϕ= Id +εϕ, one indeed\n",
            "Chunk 842: recovers the\n",
            "Chunk 843: Laplacian ∆ as a linearization since for smooth\n",
            "Chunk 844: maps\n",
            "Chunk 845: det(∂2ϕ(x)) = 1 +ε∆ϕ(x) +o(ε).\n",
            "Chunk 846: The convexity constraint forces det( ∂2ϕ(x))⩾0\n",
            "Chunk 847: and is necessary for this equation to have a\n",
            "Chunk 848: solution.\n",
            "Chunk 849: Special cases In general, computing OT distances\n",
            "Chunk 850: is numerically involved. We review special\n",
            "Chunk 851: favorable\n",
            "Chunk 852: cases where the resolution of the OT problem is\n",
            "Chunk 853: easy.\n",
            "Chunk 854: Remark 6 (Binary Cost Matrix and 1-Norm) .One can\n",
            "Chunk 855: easily check that when the cost matrix Cis zero\n",
            "Chunk 856: on\n",
            "Chunk 857: the diagonal and 1 elsewhere, namely when\n",
            "Chunk 858: C=1n×n−In, the OT distance between aandbis equal\n",
            "Chunk 859: to\n",
            "Chunk 860: the 1-norm of their diﬀerence, L C(a,b)\n",
            "Chunk 861: =||a−b||1. One can also easily check that this\n",
            "Chunk 862: result extends to\n",
            "Chunk 863: discrete and discrete measures in the case where\n",
            "Chunk 864: c(x,y) is 0 ifx=yand 1 when x̸=y. The OT distance\n",
            "Chunk 865: between two discrete measures αandβis equal to\n",
            "Chunk 866: their total variation distance.\n",
            "Chunk 867: 14\n",
            "Chunk 868: \u0000\u0000↵Figure 1.8: 1-D optimal couplings: each arrow\n",
            "Chunk 869: xi→yjindicate a non-zero Pi,jin the optimal\n",
            "Chunk 870: coupling.\n",
            "Chunk 871: Top: empirical measures with same number of\n",
            "Chunk 872: points (optimal matching). Bottom: generic case.\n",
            "Chunk 873: This\n",
            "Chunk 874: corresponds to monotone rearrangements, if\n",
            "Chunk 875: xi⩽xi′are such that Pi,j̸= 0,Pi′,j′̸= 0, then\n",
            "Chunk 876: necessarily\n",
            "Chunk 877: yj⩽yj′.\n",
            "Chunk 878: Remark 7 (1-D case – Empirical measures)\n",
            "Chunk 879: .HereX=R. Assuming α=1\n",
            "Chunk 880: n∑n\n",
            "i=1δxiandβ=1\n",
            "n∑n\n",
            "j=1δyj,\n",
            "Chunk 881: and assuming (without loss of generality) that\n",
            "Chunk 882: the points are ordered, i.e.x1⩽x2⩽...⩽xnand\n",
            "Chunk 883: y1⩽y2⩽...⩽yn, then one has the simple formula\n",
            "Chunk 884: Wp(α,β)p=p∑\n",
            "i=1|xi−yi|p, (1.29)\n",
            "Chunk 885: i.e.locally (if one assumes distinct points),\n",
            "Chunk 886: Wp(α,β) is theℓpnorm between two vectors of\n",
            "Chunk 887: ordered values of\n",
            "Chunk 888: αandβ. That statement is only valid locally, in\n",
            "Chunk 889: the sense that the order (and those vector\n",
            "Chunk 890: representations)\n",
            "Chunk 891: might change whenever some of the values change.\n",
            "Chunk 892: That formula is a simple consequence of the more\n",
            "Chunk 893: general\n",
            "Chunk 894: remark given below. Figure 1.8, top row,\n",
            "Chunk 895: illustrates the 1-D transportation map between\n",
            "Chunk 896: empirical measures\n",
            "Chunk 897: with the same number of points. The bottom row\n",
            "Chunk 898: shows how this monotone map generalizes to\n",
            "Chunk 899: arbitrary\n",
            "Chunk 900: discrete measures. It is possible to leverage\n",
            "Chunk 901: this 1-D computation to also compute eﬃciently OT\n",
            "Chunk 902: on the\n",
            "Chunk 903: circle, see [ ?]. Note that in the case of\n",
            "Chunk 904: concave cost of the distance, for instance when\n",
            "Chunk 905: p<1, the behaviour\n",
            "Chunk 906: of the optimal transport plan is very diﬀerent,\n",
            "Chunk 907: see [ ?], which describes an eﬃcient solver in\n",
            "Chunk 908: this case.\n",
            "Chunk 909: Remark 8 (1-D case – Generic case) .For a measure\n",
            "Chunk 910: αonR, we introduce the cumulative function\n",
            "Chunk 911: ∀x∈R,Cα(x)def.=∫x\n",
            "−∞dα, (1.30)\n",
            "Chunk 912: which is a function Cα:R→[0,1], and its\n",
            "Chunk 913: pseudo-inverse C−1\n",
            "Chunk 914: α: [0,1]→R∪{−∞}\n",
            "∀r∈[0,1],C−1\n",
            "α(r) = min\n",
            "Chunk 915: x{x∈R∪{−∞} ;Cα(x)⩾r}.\n",
            "Chunk 916: That function is also called the generalized\n",
            "Chunk 917: quantile function of α. For anyp⩾1, one has\n",
            "Chunk 918: Wp(α,β)p=||C−1\n",
            "α−C−1\n",
            "β||p\n",
            "Lp([0,1])=∫1\n",
            "0|C−1\n",
            "Chunk 919: α(r)−C−1\n",
            "β(r)|pdr. (1.31)\n",
            "Chunk 920: This means that through the map α↦→C−1\n",
            "Chunk 921: α, the Wasserstein distance is isometric to a\n",
            "Chunk 922: linear space equipped\n",
            "Chunk 923: with theLpnorm, or, equivalently, that the\n",
            "Chunk 924: Wasserstein distance for measures on the real\n",
            "Chunk 925: line is a Hilbertian\n",
            "Chunk 926: metric. This makes the geometry of 1-D optimal\n",
            "Chunk 927: transport very simple, but also very diﬀerent\n",
            "Chunk 928: from its\n",
            "Chunk 929: geometry in higher dimensions, which is not\n",
            "Chunk 930: Hilbertian as discussed in Proposition ??and more\n",
            "Chunk 931: generally\n",
            "Chunk 932: in§??. Forp= 1, one even has the simpler formula\n",
            "Chunk 933: W1(α,β) =||Cα−Cβ||L1(R)=∫\n",
            "R|Cα(x)−Cβ(x)|dx (1.32)\n",
            "Chunk 934: =∫\n",
            "R⏐⏐⏐⏐∫x\n",
            "−∞d(α−β)⏐⏐⏐⏐dx. (1.33)\n",
            "15\n",
            "Chunk 935: µ ν (tT+ (1−t)Id)♯µ\n",
            "0 0.5 10.5Cµ\n",
            "Cν\n",
            "0 0.5 100.51\n",
            "Chunk 936: Cµ-1\n",
            "Cν-1\n",
            "0 0.5 100.51\n",
            "T\n",
            "T-1\n",
            "0 0.5 100.51\n",
            "Chunk 937: (Cα,Cβ) (C−1\n",
            "α,C−1\n",
            "β) ( T,T−1) (1−t)C−1\n",
            "α+tC−1\n",
            "β\n",
            "Chunk 938: Figure 1.9: Computation of OT and displacement\n",
            "Chunk 939: interpolation between two 1-D measures, using\n",
            "Chunk 940: cumulant\n",
            "Chunk 941: function as detailed in (1.34).\n",
            "Chunk 942: which shows that W1is a norm (see§??for the\n",
            "Chunk 943: generalization to arbitrary dimensions). An\n",
            "Chunk 944: optimal Monge\n",
            "Chunk 945: mapTsuch thatT♯α=βis then deﬁned by\n",
            "T=C−1\n",
            "Chunk 946: β◦Cα. (1.34)\n",
            "Chunk 947: Figure 1.9 illustrates the computation of 1-D OT\n",
            "Chunk 948: through cumulative functions. It also displays\n",
            "Chunk 949: displacement\n",
            "Chunk 950: interpolations, computed as detailed in ( ??),\n",
            "Chunk 951: see also Remark ??. For a detailed survey of the\n",
            "Chunk 952: properties of\n",
            "Chunk 953: optimal transport in 1-D, we refer the reader to\n",
            "Chunk 954: [ ?, Chapter 2].\n",
            "Chunk 955: Remark 9 (Distance between Gaussians)\n",
            "Chunk 956: .Ifα=N(mα,Σα) andβ=N(mβ,Σβ) are two Gaussians in\n",
            "Chunk 957: Rd,\n",
            "Chunk 958: then one can show that the following map\n",
            "Chunk 959: T:x↦→mβ+A(x−mα), (1.35)\n",
            "where\n",
            "A=Σ−1\n",
            "2α(\n",
            "Σ1\n",
            "2αΣβΣ1\n",
            "Chunk 960: 2α)1\n",
            "2Σ−1\n",
            "2α=AT,\n",
            "Chunk 961: is such that T♯ρα=ρβ. Indeed, one simply has to\n",
            "Chunk 962: notice that the change of variables formula (1.4)\n",
            "Chunk 963: is satisﬁed\n",
            "Chunk 964: since\n",
            "ρβ(T(x)) = det(2πΣβ)−1\n",
            "2exp(−⟨T(x)−mβ,Σ−1\n",
            "Chunk 965: β(T(x)−mβ)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα, ATΣ−1\n",
            "Chunk 966: βA(x−mα)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα,Σ−1\n",
            "Chunk 967: α(x−mα)⟩),\n",
            "and sinceTis a linear map we have that\n",
            "Chunk 968: |detT′(x)|= detA=(detΣβ\n",
            "detΣα)1\n",
            "2\n",
            "Chunk 969: and we therefore recover\n",
            "Chunk 970: ρα=|detT′|ρβmeaningT♯α=β. Notice now that Tis the\n",
            "Chunk 971: gradient of the convex\n",
            "Chunk 972: functionψ:x↦→1\n",
            "Chunk 973: 2⟨x−mα, A(x−mα)⟩+⟨mβ, x⟩to conclude, using\n",
            "Chunk 974: Brenier’s theorem [ ?] (see Remark ??)\n",
            "Chunk 975: thatTis optimal. Both that map Tand the\n",
            "Chunk 976: corresponding potential ψare illustrated in\n",
            "Chunk 977: Figures 1.10 and ??\n",
            "Chunk 978: 16\n",
            "-4 -2 0 2 4 6-3-2-101234\n",
            "Chunk 979: ρβραFigure 1.10: Two Gaussians ραandρβ,\n",
            "Chunk 980: represented using the contour plots of their\n",
            "Chunk 981: densities, with respective\n",
            "Chunk 982: mean and variance matrices mα= (−2,0),Σα=1\n",
            "2(\n",
            "1−1\n",
            "Chunk 983: 2;−1\n",
            "21)\n",
            "andmβ= (3,1),Σβ=(\n",
            "2,1\n",
            "2;1\n",
            "2,1)\n",
            ". The\n",
            "Chunk 984: arrows originate at random points xtaken on the\n",
            "Chunk 985: plane and end at the corresponding mappings of\n",
            "Chunk 986: those\n",
            "Chunk 987: pointsT(x) =mβ+A(x−mα).\n",
            "\u0000m\n",
            "Chunk 988: Figure 1.11: Computation of displacement\n",
            "Chunk 989: interpolation between two 1-D Gaussians. Denoting\n",
            "Chunk 990: Gm,σ(x)def.=\n",
            "Chunk 991: 1√\n",
            "2πse−(x−m)2\n",
            "Chunk 992: 2s2the Gaussian density, it thus shows the\n",
            "Chunk 993: interpolation G(1−t)m0+tm1,(1−t)σ0+tσ1.\n",
            "Chunk 994: With additional calculations involving ﬁrst and\n",
            "Chunk 995: second order moments of ρα, we obtain that the\n",
            "Chunk 996: transport\n",
            "Chunk 997: cost of that map is\n",
            "W2\n",
            "Chunk 998: 2(α,β) =||mα−mβ||2+B(Σα,Σβ)2(1.36)\n",
            "Chunk 999: whereBis the so-called Bures’ metric [ ?] between\n",
            "Chunk 1000: positive deﬁnite matrices (see also [ ?,?]),\n",
            "Chunk 1001: B(Σα,Σβ)2def.= tr(\n",
            "Σα+Σβ−2(Σ1/2\n",
            "αΣβΣ1/2\n",
            "α)1/2)\n",
            "Chunk 1002: , (1.37)\n",
            "Chunk 1003: where Σ1/2is the matrix square root. One can show\n",
            "Chunk 1004: that Bis a distance on covariance matrices, and\n",
            "Chunk 1005: that\n",
            "Chunk 1006: B2is convex with respect to both its arguments.\n",
            "Chunk 1007: In the case where Σα= diag(ri)iandΣβ=\n",
            "Chunk 1008: diag(si)iare\n",
            "Chunk 1009: diagonals, the Bures metric is the Hellinger\n",
            "Chunk 1010: distance\n",
            "Chunk 1011: B(Σα,Σβ) =||√r−√s||2.\n",
            "Chunk 1012: For 1-D Gaussians, W2is thus the Euclidean\n",
            "Chunk 1013: distance on the 2-D plane ( m,√\n",
            "Chunk 1014: Σ), as illustrated in Figure 1.11.\n",
            "Chunk 1015: For a detailed treatment of the Wasserstein\n",
            "Chunk 1016: geometry of Gaussian distributions, we refer to [\n",
            "Chunk 1017: ?].\n",
            "Chunk 1018: 1.5 Sinkhorn\n",
            "Chunk 1019: This section introduces a family of numerical\n",
            "Chunk 1020: scheme to approximate solutions to Kantorovich\n",
            "Chunk 1021: formulation\n",
            "Chunk 1022: of optimal transport and its many\n",
            "Chunk 1023: generalizations. It operates by adding an\n",
            "Chunk 1024: entropic regularization penalty to\n",
            "Chunk 1025: the original problem. This regularization has\n",
            "Chunk 1026: several important advantages, but a few stand out\n",
            "Chunk 1027: particularly:\n",
            "Chunk 1028: The minimization of the regularized problen can\n",
            "Chunk 1029: be solved using a simple alternate minimization\n",
            "Chunk 1030: scheme;\n",
            "Chunk 1031: that scheme translates into iterations that are\n",
            "Chunk 1032: simple matrix products, making them particularly\n",
            "Chunk 1033: suited to\n",
            "Chunk 1034: execution of GPU; the resulting approximate\n",
            "Chunk 1035: distance is smooth with respect to input\n",
            "Chunk 1036: histogram weights\n",
            "Chunk 1037: and positions of the Diracs.\n",
            "17\n",
            "Chunk 1038: c\"P\"Figure 1.12: Impact of εon the optimization\n",
            "Chunk 1039: of a linear function on the simplex, solving Pε=\n",
            "Chunk 1040: argminP∈Σ3⟨C,P⟩−εH(P) for a varying ε.\n",
            "Chunk 1041: Entropic Regularization. The discrete entropy of\n",
            "Chunk 1042: a coupling matrix is deﬁned as\n",
            "Chunk 1043: H(P)def.=−∑\n",
            "i,jPi,j(log(Pi,j)−1), (1.38)\n",
            "Chunk 1044: with an analogous deﬁnition for vectors, with the\n",
            "Chunk 1045: convention that H(a) =−∞ if one of the entries\n",
            "Chunk 1046: ajis\n",
            "Chunk 1047: 0 or negative. The function His 1-strongly\n",
            "Chunk 1048: concave, because its hessian is ∂2H(P)\n",
            "Chunk 1049: =−diag(1/Pi,j) and\n",
            "Chunk 1050: Pi,j⩽1. The idea of the entropic regularization\n",
            "Chunk 1051: of optimal transport is to use −Has a\n",
            "Chunk 1052: regularizing function\n",
            "Chunk 1053: to obtain approximate solutions to the original\n",
            "Chunk 1054: transport problem (1.11):\n",
            "Chunk 1055: Lε\n",
            "C(a,b)def.= min\n",
            "P∈U(a,b)⟨P,C⟩−εH(P). (1.39)\n",
            "Chunk 1056: Since the objective is a ε-strongly convex\n",
            "Chunk 1057: function, problem 1.39 has a unique optimal\n",
            "Chunk 1058: solution. The idea\n",
            "Chunk 1059: to regularize the optimal transport problem by an\n",
            "Chunk 1060: entropic term can be traced back to modeling\n",
            "Chunk 1061: ideas in\n",
            "Chunk 1062: transportation theory [ ?]: Actual traﬃc patterns\n",
            "Chunk 1063: in a network do not agree with those predicted by\n",
            "Chunk 1064: the\n",
            "Chunk 1065: solution of the optimal transport problem.\n",
            "Chunk 1066: Indeed, the former are more diﬀuse than the\n",
            "Chunk 1067: latter, which tend\n",
            "Chunk 1068: to rely on a few routes as a result of the\n",
            "Chunk 1069: sparsity of optimal couplings to the solution of\n",
            "Chunk 1070: 1.11. To balance for\n",
            "Chunk 1071: that, researchers in transportation proposed a\n",
            "Chunk 1072: model, called the “gravity” model [ ?], that is\n",
            "Chunk 1073: able to form a\n",
            "Chunk 1074: more “blurred” traﬃc prediction.\n",
            "Chunk 1075: Figure 1.12 illustrates the eﬀect of the entropy\n",
            "Chunk 1076: to regularize a linear program over the simples Σ\n",
            "Chunk 1077: 3(which\n",
            "Chunk 1078: can thus be visualized as a triangle in 2-D).\n",
            "Chunk 1079: Note how the entropy pushes the original LP\n",
            "Chunk 1080: solution away\n",
            "Chunk 1081: from the boundary of the triangle. The optimal\n",
            "Chunk 1082: Pεprogressively moves toward an “entropic center”\n",
            "Chunk 1083: of the\n",
            "Chunk 1084: triangle. This is further detailed in the\n",
            "Chunk 1085: proposition below. The convergence of the\n",
            "Chunk 1086: solution of that regularized\n",
            "Chunk 1087: problem towards an optimal solution of the\n",
            "Chunk 1088: original linear program has been studied by [ ?].\n",
            "Chunk 1089: Proposition 6 (Convergence with ε).The unique\n",
            "Chunk 1090: solution Pεof(1.39) converges to the optimal\n",
            "Chunk 1091: solution\n",
            "Chunk 1092: with maximal entropy within the set of all\n",
            "Chunk 1093: optimal solutions of the Kantorovich problem,\n",
            "Chunk 1094: namely\n",
            "Chunk 1095: Pεε→0−→argmin\n",
            "Chunk 1096: P{−H(P) ;P∈U(a,b),⟨P,C⟩= LC(a,b)} (1.40)\n",
            "Chunk 1097: so that in particular\n",
            "Lε\n",
            "C(a,b)ε→0−→LC(a,b).\n",
            "Chunk 1098: One has\n",
            "Pεε→∞−→abT= (aibj)i,j. (1.41)\n",
            "Chunk 1099: Proof. We consider a sequence ( εℓ)ℓsuch thatεℓ→0\n",
            "Chunk 1100: andεℓ>0. We denote Pℓthe solution of (1.39) for\n",
            "Chunk 1101: ε=εℓ. Since U(a,b) is bounded, we can extract a\n",
            "Chunk 1102: sequence (that we do not relabel for sake of\n",
            "Chunk 1103: simplicity)\n",
            "Chunk 1104: such that Pℓ→P⋆. Since U(a,b) is closed,\n",
            "Chunk 1105: P⋆∈U(a,b). We consider any Psuch that⟨C,P⟩=\n",
            "Chunk 1106: LC(a,b).\n",
            "Chunk 1107: By optimality of PandPℓfor their respective\n",
            "Chunk 1108: optimization problems (for ε= 0 andε=εℓ), one has\n",
            "Chunk 1109: 0⩽⟨C,Pℓ⟩−⟨C,P⟩⩽εℓ(H(Pℓ)−H(P)). (1.42)\n",
            "18\n",
            "⇡\"↵\u0000\n",
            "Chunk 1110: \"\u0000↵Figure 1.13: Impact of εon coupling between\n",
            "Chunk 1111: densities and discrete distributions,\n",
            "Chunk 1112: illustrating Proposition 6.\n",
            "Chunk 1113: Left: between two 1-D densities. Right: between\n",
            "Chunk 1114: two 2-D discrete empirical densities with same\n",
            "Chunk 1115: number\n",
            "Chunk 1116: n=mof points (only entries of the optimal (\n",
            "Chunk 1117: Pi,j)i,jabove a small threshold are displayed as\n",
            "Chunk 1118: segments\n",
            "Chunk 1119: betweenxiandyj).\n",
            "Chunk 1120: Since His continuous, taking the limit ℓ→+∞in\n",
            "Chunk 1121: this expression shows that ⟨C,P⋆⟩=⟨C,P⟩so that\n",
            "Chunk 1122: P⋆is a feasible point of (1.40). Furthermore,\n",
            "Chunk 1123: dividing by εℓin (1.42) and taking the limit\n",
            "Chunk 1124: shows that\n",
            "Chunk 1125: H(P)⩽H(P⋆), which shows that P⋆is a solution of\n",
            "Chunk 1126: (1.40). Since the solution P⋆\n",
            "Chunk 1127: 0to this program is unique\n",
            "Chunk 1128: by strict convexity of −H, one has P⋆=P⋆\n",
            "Chunk 1129: 0, and the whole sequence is converging.\n",
            "Chunk 1130: Formula (1.40) states that for low\n",
            "Chunk 1131: regularization, the solution converges to the\n",
            "Chunk 1132: maximum entropy optimal\n",
            "Chunk 1133: transport coupling. In sharp contrast, (1.41)\n",
            "Chunk 1134: shows that for large regularization, the solution\n",
            "Chunk 1135: converges to the\n",
            "Chunk 1136: coupling with maximal entropy between two\n",
            "Chunk 1137: prescribed marginals a,b, namely the joint\n",
            "Chunk 1138: probability between\n",
            "Chunk 1139: two independent random variables with prescribed\n",
            "Chunk 1140: distributions. A reﬁned analysis of this\n",
            "Chunk 1141: convergence is\n",
            "Chunk 1142: performed in [ ?], including a ﬁrst order\n",
            "Chunk 1143: expansion in ε(resp. 1/ε) nearε= 0 (respε= +∞).\n",
            "Chunk 1144: Figure 1.13\n",
            "Chunk 1145: shows visually the eﬀect of these two\n",
            "Chunk 1146: convergence. A key insight is that, as\n",
            "Chunk 1147: εincreases, the optimal coupling\n",
            "Chunk 1148: becomes less and less sparse (in the sense of\n",
            "Chunk 1149: having entries larger than a prescribed\n",
            "Chunk 1150: thresholds), which in\n",
            "Chunk 1151: turn as the eﬀect of both accelerating\n",
            "Chunk 1152: computational algorithms (as we study in §1.5)\n",
            "Chunk 1153: but also leading to\n",
            "Chunk 1154: faster statistical convergence (as exposed in\n",
            "Chunk 1155: §??).\n",
            "Chunk 1156: Deﬁning the Kullback-Leibler divergence between\n",
            "Chunk 1157: couplings as\n",
            "Chunk 1158: KL(P|K)def.=∑\n",
            "i,jPi,jlog(Pi,j\n",
            "Ki,j)\n",
            "Chunk 1159: −Pi,j+Ki,j, (1.43)\n",
            "Chunk 1160: the unique solution Pεof (1.39) is a projection\n",
            "Chunk 1161: onto U(a,b) of the Gibbs kernel associated to the\n",
            "Chunk 1162: cost matrix\n",
            "Chunk 1163: Cas\n",
            "Ki,jdef.=e−Ci,j\n",
            "ε\n",
            "Chunk 1164: Indeed one has that using the deﬁnition above\n",
            "Chunk 1165: Pε= ProjKL\n",
            "U(a,b)(K)def.= argmin\n",
            "Chunk 1166: P∈U(a,b)KL(P|K). (1.44)\n",
            "Chunk 1167: Remark 10 (General formulation) .One can consider\n",
            "Chunk 1168: arbitrary measures by replacing the discrete\n",
            "Chunk 1169: entropy\n",
            "Chunk 1170: by the relative entropy with respect to the\n",
            "Chunk 1171: product measure d α⊗dβ(x,y)def.= dα(x)dβ(y), and\n",
            "Chunk 1172: propose a\n",
            "Chunk 1173: regularized counterpart to (1.14) using\n",
            "Lε\n",
            "Chunk 1174: c(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "Chunk 1175: X×Yc(x,y)dπ(x,y) +εKL(π|α⊗β) (1.45)\n",
            "Chunk 1176: where the relative entropy is a generalization of\n",
            "Chunk 1177: the discrete Kullback-Leibler divergence (1.43)\n",
            "Chunk 1178: KL(π|ξ)def.=∫\n",
            "X×Ylog(dπ\n",
            "dξ(x,y))\n",
            "dπ(x,y)+\n",
            "∫\n",
            "Chunk 1179: X×Y(dξ(x,y)−dπ(x,y)),(1.46)\n",
            "19\n",
            "Chunk 1180: and by convention KL( π|ξ) = +∞ifπdoes not have a\n",
            "Chunk 1181: densitydπ\n",
            "Chunk 1182: dξwith respect to ξ. It is important to\n",
            "Chunk 1183: realize that the reference measure α⊗βchosen in\n",
            "Chunk 1184: (1.45) to deﬁne the entropic regularizing term\n",
            "Chunk 1185: KL( ·|α⊗β)\n",
            "Chunk 1186: plays no speciﬁc role, only its support matters.\n",
            "Chunk 1187: Formula (1.45) can be re-factored as a projection\n",
            "Chunk 1188: problem\n",
            "Chunk 1189: min\n",
            "π∈U(α,β)KL(π|K) (1.47)\n",
            "Chunk 1190: whereKis the Gibbs distributions d\n",
            "Chunk 1191: K(x,y)def.=e−c(x,y)\n",
            "Chunk 1192: εdµ(x)dν(y). This problem is often referred to as\n",
            "Chunk 1193: the\n",
            "Chunk 1194: “static Schr¨ odinger problem” [ ?,?], since it\n",
            "Chunk 1195: was initially considered by Schr¨ odinger in\n",
            "Chunk 1196: statistical physics [ ?].\n",
            "Chunk 1197: Asε→0, the unique solution to (1.47) converges to\n",
            "Chunk 1198: the maximum entropy solution to (1.14), see [\n",
            "Chunk 1199: ?,?].§??\n",
            "Chunk 1200: details an alternate “dynamic” formulation of the\n",
            "Chunk 1201: Schr¨ odinger problem over the space of paths\n",
            "Chunk 1202: connecting\n",
            "Chunk 1203: the points of two measures.\n",
            "Chunk 1204: Sinkhorn’s Algorithm The following proposition\n",
            "Chunk 1205: shows that the solution of (1.39) has a speciﬁc\n",
            "Chunk 1206: form,\n",
            "Chunk 1207: which can be parameterized using n+mvariables.\n",
            "Chunk 1208: That parameterization is therefore essentially\n",
            "Chunk 1209: dual, in\n",
            "Chunk 1210: the sense that a coupling PinU(a,b)\n",
            "Chunk 1211: hasnmvariables but n+mconstraints.\n",
            "Chunk 1212: Proposition 7. The solution to (1.39) is unique\n",
            "Chunk 1213: and has the form\n",
            "Chunk 1214: ∀(i,j)∈JnK×JmK,Pi,j=uiKi,jvj (1.48)\n",
            "Chunk 1215: for two (unknown) scaling variable (u,v)∈Rn\n",
            "+×Rm\n",
            "Chunk 1216: +.\n",
            "Chunk 1217: Proof. Introducing two dual variables\n",
            "Chunk 1218: f∈Rn,g∈Rmfor each marginal constraint, the\n",
            "Chunk 1219: Lagrangian of (1.39)\n",
            "Chunk 1220: reads\n",
            "E(P,f,g) =⟨P,C⟩−εH(P)−⟨f,P1m−a⟩−⟨g,PT1n−b⟩.\n",
            "Chunk 1221: Considering ﬁrst order conditions, we have\n",
            "Chunk 1222: ∂E(P,f,g)\n",
            "∂Pi,j=Ci,j−εlog(Pi,j)−fi−gj.\n",
            "Chunk 1223: which results, for an optimal Pcoupling to the\n",
            "Chunk 1224: regularized problem, in the expression\n",
            "Chunk 1225: Pi,j=efi/εe−Ci,j/εegj/ε\n",
            "Chunk 1226: which can be rewritten in the form provided in\n",
            "Chunk 1227: the proposition using non-negative vectors uandv.\n",
            "Chunk 1228: The factorization of the optimal solution\n",
            "Chunk 1229: exhibited in Equation (1.48) can be conveniently\n",
            "Chunk 1230: rewritten in\n",
            "Chunk 1231: matrix form as P= diag( u)Kdiag(v).u,vmust\n",
            "Chunk 1232: therefore satisfy the following non-linear\n",
            "Chunk 1233: equations which\n",
            "Chunk 1234: correspond to the mass conservation constraints\n",
            "Chunk 1235: inherent to U(a,b),\n",
            "Chunk 1236: diag(u)Kdiag(v)1m=a,and diag( v)K⊤diag(u)1n=b,\n",
            "Chunk 1237: (1.49)\n",
            "Chunk 1238: These two equations can be further simpliﬁed,\n",
            "Chunk 1239: since diag( v)1mis simply v, and the\n",
            "Chunk 1240: multiplication of diag( u)\n",
            "Chunk 1241: times Kvis\n",
            "u⊙(Kv) =aand v⊙(KTu) =b (1.50)\n",
            "Chunk 1242: where⊙corresponds to entry-wise multiplication of\n",
            "Chunk 1243: vectors. That problem is known in the numerical\n",
            "Chunk 1244: analysis\n",
            "Chunk 1245: community as the matrix scaling problem (see [ ?]\n",
            "Chunk 1246: and references therein). An intuitive way to try\n",
            "Chunk 1247: to solve\n",
            "Chunk 1248: these equations is to solve them iteratively, by\n",
            "Chunk 1249: modifying ﬁrst uso that it satisﬁes the left-hand\n",
            "Chunk 1250: side of\n",
            "Chunk 1251: Equation (1.50) and then vto satisfy its\n",
            "Chunk 1252: right-hand side. These two updates deﬁne\n",
            "Chunk 1253: Sinkhorn’s algorithm:\n",
            "Chunk 1254: u(ℓ+1)def.=a\n",
            "Kv(ℓ)and v(ℓ+1)def.=b\n",
            "Chunk 1255: KTu(ℓ+1), (1.51)\n",
            "Chunk 1256: initialized with an arbitrary positive vector\n",
            "Chunk 1257: v(0)=1m. The division operator used above between\n",
            "Chunk 1258: two\n",
            "Chunk 1259: vectors is to be understood entry-wise. Note that\n",
            "Chunk 1260: a diﬀerent initialization will likely lead to a\n",
            "Chunk 1261: diﬀerent\n",
            "Chunk 1262: 20\n",
            "`⇡(`)\"\n",
            "Chunk 1263: 1000 2000 3000 4000 5000-2-1.5-1-0.50`Figure\n",
            "Chunk 1264: 1.14: Left: evolution of the coupling πℓ\n",
            "Chunk 1265: ε= diag( U(ℓ))Kdiag(V(ℓ)) computed at iteration\n",
            "Chunk 1266: ℓof\n",
            "Chunk 1267: Sinkhorn’s iterations, for 1-D densities. Right:\n",
            "Chunk 1268: impact of εthe convergence rate of Sinkhorn, as\n",
            "Chunk 1269: measured\n",
            "Chunk 1270: in term of marginal constraint violation log(\n",
            "Chunk 1271: ||πℓ\n",
            "Chunk 1272: ε1m−b||1).\n",
            "Chunk 1273: solution for u,v, since u,vare only deﬁned up to\n",
            "Chunk 1274: a multiplicative constant (if u,vsatisfy (1.49)\n",
            "Chunk 1275: then\n",
            "Chunk 1276: so doλu,v/λfor anyλ > 0). It turns out however\n",
            "Chunk 1277: that these iterations converge (see Remark 11 for\n",
            "Chunk 1278: a justiﬁcation using iterative projections, and\n",
            "Chunk 1279: Remark 13 for a strict contraction result) and\n",
            "Chunk 1280: all result in\n",
            "Chunk 1281: the same optimal coupling diag( u)Kdiag(v).\n",
            "Chunk 1282: Figure 1.14, top row, shows the evolution of the\n",
            "Chunk 1283: coupling\n",
            "Chunk 1284: diag(U(ℓ))Kdiag(V(ℓ)) computed by Sinkhorn\n",
            "Chunk 1285: iterations. It evolves from the Gibbs kernel\n",
            "Chunk 1286: Ktowards the\n",
            "Chunk 1287: optimal coupling solving (1.39) by progressively\n",
            "Chunk 1288: shifting the mass away from the diagonal.\n",
            "Chunk 1289: Remark 11 (Relation with iterative projections)\n",
            "Chunk 1290: .Denoting\n",
            "Chunk 1291: C1\n",
            "adef.={P;P1m=a}andC2\n",
            "bdef.={\n",
            "P;PT1m=b}\n",
            "Chunk 1292: the rows and columns constraints, one has U(a,b)\n",
            "Chunk 1293: =C1\n",
            "Chunk 1294: a∩C2\n",
            "Chunk 1295: b. One can use Bregman iterative projections [ ?]\n",
            "Chunk 1296: P(ℓ+1) def.= ProjKL\n",
            "Chunk 1297: C1a(P(ℓ)) and P(ℓ+2) def.= ProjKL\n",
            "C2\n",
            "Chunk 1298: b(P(ℓ+1)). (1.52)\n",
            "Since the setsC1\n",
            "aandC2\n",
            "Chunk 1299: bare aﬃne, these iterations are known to converge\n",
            "Chunk 1300: to the solution of (1.44), see [ ?].\n",
            "Chunk 1301: These iterate are equivalent to Sinkhorn\n",
            "Chunk 1302: iterations (1.51) since deﬁning\n",
            "Chunk 1303: P(2ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)),\n",
            "one has\n",
            "Chunk 1304: P(2ℓ+1) def.= diag( u(ℓ+1))Kdiag(v(ℓ))\n",
            "Chunk 1305: and P(2ℓ+2) def.= diag( u(ℓ+1))Kdiag(v(ℓ+1))\n",
            "Chunk 1306: In practice however one should prefer using\n",
            "Chunk 1307: (1.51) which only requires manipulating scaling\n",
            "Chunk 1308: vectors and\n",
            "Chunk 1309: multiplication against a Gibbs kernel, which can\n",
            "Chunk 1310: often be accelerated (see below Remarks ??and??).\n",
            "Chunk 1311: Remark 12 (Hilbert metric) .As initially\n",
            "Chunk 1312: explained by [ ?], the global convergence\n",
            "Chunk 1313: analysis of Sinkhorn is\n",
            "Chunk 1314: greatly simpliﬁed using Hilbert projective metric\n",
            "Chunk 1315: on Rn\n",
            "Chunk 1316: +,∗(positive vectors), deﬁned as\n",
            "∀(u,u′)∈(Rn\n",
            "Chunk 1317: +,∗)2, dH(u,u′)def.= log max\n",
            "i,i′uiu′\n",
            "i′\n",
            "ui′u′\n",
            "i.\n",
            "Chunk 1318: This can be shows to be a distance on the\n",
            "Chunk 1319: projective cone Rn\n",
            "Chunk 1320: +,∗/∼, where u∼u′means that∃s>0,u=su′\n",
            "Chunk 1321: (the vector are equal up to rescaling, hence the\n",
            "Chunk 1322: naming “projective”). This means that dHsatisﬁes\n",
            "Chunk 1323: the\n",
            "Chunk 1324: triangular inequality and dH(u,u′) = 0 if and\n",
            "Chunk 1325: only if u∼u′. This is a projective version of\n",
            "Chunk 1326: Hilbert’s original\n",
            "Chunk 1327: distance on bounded open convex sets [ ?]. The\n",
            "Chunk 1328: projective cone Rn\n",
            "Chunk 1329: +,∗/∼is a complete metric space for this\n",
            "Chunk 1330: distance. It was introduced independently by [ ?]\n",
            "Chunk 1331: and [ ?] to provide a quantitative proof of\n",
            "Chunk 1332: Perron-Frobenius\n",
            "Chunk 1333: theorem, which, as explained in Remark ??is\n",
            "Chunk 1334: linked to a local linearization of Sinkhorn’s\n",
            "Chunk 1335: iterates. They\n",
            "Chunk 1336: proved the following fundamental theorem, which\n",
            "Chunk 1337: shows that a positive matrix is a strict\n",
            "Chunk 1338: contraction on the\n",
            "Chunk 1339: cone of positive vectors.\n",
            "21\n",
            "Chunk 1340: Theorem 2. Let K∈Rn×m\n",
            "+,∗, then for (v,v′)∈(Rm\n",
            "Chunk 1341: +,∗)2\n",
            "dH(Kv,Kv′)⩽λ(K)dH(v,v′)where\n",
            "\n",
            "Chunk 1342: λ(K)def.=√\n",
            "η(K)−1√\n",
            "η(K)+1<1\n",
            "η(K)def.= max\n",
            "Chunk 1343: i,j,k,ℓKi,kKj,ℓ\n",
            "Kj,kKi,ℓ.\n",
            "Chunk 1344: Remark 13 (Global convergence) .The following\n",
            "Chunk 1345: theorem, proved by [ ?], makes use of this\n",
            "Chunk 1346: Theorem 2 to\n",
            "Chunk 1347: show the linear convergence of Sinkhorn’s\n",
            "Chunk 1348: iterations.\n",
            "Chunk 1349: Theorem 3. One has (u(ℓ),v(ℓ))→(u⋆,v⋆)and\n",
            "Chunk 1350: dH(u(ℓ),u⋆) =O(λ(K)2ℓ), dH(v(ℓ),v⋆) =O(λ(K)2ℓ).\n",
            "Chunk 1351: (1.53)\n",
            "Chunk 1352: One also has\n",
            "dH(u(ℓ),u⋆)⩽dH(P(ℓ)1m,a)\n",
            "1−λ(K)\n",
            "Chunk 1353: dH(v(ℓ),v⋆)⩽dH(P(ℓ),⊤1n,b)\n",
            "1−λ(K)(1.54)\n",
            "Chunk 1354: where we denoted P(ℓ)def.= diag(\n",
            "Chunk 1355: u(ℓ))Kdiag(v(ℓ)). Lastly, one has\n",
            "Chunk 1356: ∥log(P(ℓ))−log(P⋆)∥∞⩽dH(u(ℓ),u⋆) +dH(v(ℓ),v⋆)\n",
            "Chunk 1357: (1.55)\n",
            "Chunk 1358: where P⋆is the unique solution of (1.39) .\n",
            "Chunk 1359: Proof. One notice that for any ( v,v′)∈(Rm\n",
            "Chunk 1360: +,∗)2, one has\n",
            "Chunk 1361: dH(v,v′) =dH(v/v′,1m) =dH(1m/v,1m/v′).\n",
            "Chunk 1362: This shows that\n",
            "dH(u(ℓ+1),u⋆) =dH(a\n",
            "Kv(ℓ),a\n",
            "Kv⋆)\n",
            "Chunk 1363: =dH(Kv(ℓ),Kv⋆)⩽λ(K)dH(v(ℓ),v⋆).\n",
            "Chunk 1364: where we used Theorem 2. This shows (1.53). One\n",
            "Chunk 1365: also has, using the triangular inequality\n",
            "Chunk 1366: dH(u(ℓ),u⋆)⩽dH(u(ℓ+1),u(ℓ)) +dH(u(ℓ+1),u⋆)\n",
            "⩽dH(a\n",
            "Chunk 1367: Kv(ℓ),u(ℓ))\n",
            "+λ(K)dH(u(ℓ),u⋆)\n",
            "=dH(\n",
            "a,u(ℓ)⊙(Kv(ℓ)))\n",
            "Chunk 1368: +λ(K)dH(u(ℓ),u⋆),\n",
            "Chunk 1369: which gives the ﬁrst part of (1.54) since\n",
            "Chunk 1370: u(ℓ)⊙(Kv(ℓ)) =P(ℓ)1m(the second one being\n",
            "Chunk 1371: similar). The proof\n",
            "Chunk 1372: of (1.55) follows from [ ?, Lemma 3]\n",
            "Chunk 1373: The bound (1.54) shows that some error measures\n",
            "Chunk 1374: on the marginal constraints violation, for\n",
            "Chunk 1375: instance\n",
            "Chunk 1376: ∥P(ℓ)1m−a∥1and∥P(ℓ)T1n−b∥1, are useful stopping\n",
            "Chunk 1377: criteria to monitor the convergence.\n",
            "Chunk 1378: Figure 1.14, bottom row, highlights this linear\n",
            "Chunk 1379: rate on the constraint violation, and shows how\n",
            "Chunk 1380: this rate\n",
            "Chunk 1381: degrades as ε→0. These results are proved in [ ?]\n",
            "Chunk 1382: and are tightly connected to nonlinear\n",
            "Chunk 1383: Perron-Frobenius\n",
            "Chunk 1384: Theory [ ?]. Perron-Frobenius theory corresponds\n",
            "Chunk 1385: to the linearization of the iterations, see (\n",
            "Chunk 1386: ??). This\n",
            "Chunk 1387: convergence analysis is extended in [ ?], who\n",
            "Chunk 1388: shows that each iteration of Sinkhorn increases\n",
            "Chunk 1389: the permanent\n",
            "Chunk 1390: of the scaled coupling matrix.\n",
            "22\n",
            "Chunk 1391: Regularized Dual and Log-domain Computations The\n",
            "Chunk 1392: following proposition details the dual problem\n",
            "Chunk 1393: associated to (1.39).\n",
            "Proposition 8. One has\n",
            "Lε\n",
            "Chunk 1394: C(a,b) = max\n",
            "Chunk 1395: f∈Rn,g∈Rm⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩. (1.56)\n",
            "Chunk 1396: The optimal (f,g)are linked to scalings\n",
            "Chunk 1397: (u,v)appearing in (1.48) through\n",
            "Chunk 1398: (u,v) = (ef/ε,eg/ε). (1.57)\n",
            "Chunk 1399: Proof. We start from the end of the proof of\n",
            "Chunk 1400: Proposition 7, which links the optimal primal\n",
            "Chunk 1401: solution P\n",
            "Chunk 1402: and dual multipliers fandgfor the marginal\n",
            "Chunk 1403: constraints as Pi,j=efi/εe−Ci,j/εegj/ε.\n",
            "Chunk 1404: Substituting in the\n",
            "Chunk 1405: LagrangianE(P,f,g) of Equation (1.5) the optimal\n",
            "Chunk 1406: Pas a function of fandg, we obtain that the\n",
            "Chunk 1407: Lagrange\n",
            "Chunk 1408: dual function equals\n",
            "Chunk 1409: f,g↦→⟨ef/ε,(K⊙C)eg/ε⟩−εH(diag(ef/ε)Kdiag(eg/ε)).\n",
            "Chunk 1410: (1.58)\n",
            "Chunk 1411: The entropy of Pscaled byε,\n",
            "Chunk 1412: namelyε⟨P,logP−1n×m⟩can be stated explicitly as a\n",
            "Chunk 1413: function of f,g,C\n",
            "Chunk 1414: ⟨diag(ef/ε)Kdiag(eg/ε),f1mT+1ngT−C−ε1n×m⟩\n",
            "Chunk 1415: =−⟨ef/ε,(K⊙C)eg/ε⟩+⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩\n",
            "Chunk 1416: therefore, the ﬁrst term in (1.58) cancels out\n",
            "Chunk 1417: with the ﬁrst term in the entropy above. The\n",
            "Chunk 1418: remaining times\n",
            "Chunk 1419: are those displayed in (1.56).\n",
            "Chunk 1420: Remark 14.Dual for generic measures For generic\n",
            "Chunk 1421: (non-necessarily discrete) input measures ( α,β),\n",
            "Chunk 1422: the dual\n",
            "Chunk 1423: problem (1.56) reads\n",
            "sup\n",
            "f,g∈C(X)×C(Y)∫\n",
            "Chunk 1424: Xf(x)dα(x) +∫\n",
            "Yg(x)dβ(x)−ε∫\n",
            "X×Ye−c(x,y)+f(x)+g(y)\n",
            "Chunk 1425: ε dα(x)dβ(y)\n",
            "Chunk 1426: This corresponds to a smoothing of the constraint\n",
            "Chunk 1427: R(c) appearing in the original problem (1.21),\n",
            "Chunk 1428: which\n",
            "Chunk 1429: is retrieved in the limit ε→0. Proving existence\n",
            "Chunk 1430: ( i.e. the sup is actually a max) of these\n",
            "Chunk 1431: Kantorovich\n",
            "Chunk 1432: potentials ( f,g) in the case of entropic\n",
            "Chunk 1433: transport is less easy than for classical OT\n",
            "Chunk 1434: (because one cannot\n",
            "Chunk 1435: usec-transform and potentials are not\n",
            "Chunk 1436: automatically Lipschitz). Proof of existence can\n",
            "Chunk 1437: be done using the\n",
            "Chunk 1438: convergence of Sinkhorn iterations, see [ ?] for\n",
            "Chunk 1439: more details.\n",
            "Chunk 1440: Remark 15 (Sinkhorn as a Block Coordinate Ascent\n",
            "Chunk 1441: on the Dual Problem) .A simple approach to solve\n",
            "Chunk 1442: the\n",
            "Chunk 1443: unconstrained maximization problem (1.56) is to\n",
            "Chunk 1444: use an exact block coordinate ascent strategy,\n",
            "Chunk 1445: namely to\n",
            "Chunk 1446: update alternatively fandgto cancel their\n",
            "Chunk 1447: gradients with respect to the objective of\n",
            "Chunk 1448: (1.56). Indeed, one\n",
            "Chunk 1449: can easily notice that, writing Q(f,g) for the\n",
            "Chunk 1450: objective of (1.56) that\n",
            "Chunk 1451: ∇|fQ(f,g) =a−ef/ε⊙(\n",
            "Keg/ε)\n",
            ", (1.59)\n",
            "Chunk 1452: ∇|gQ(f,g) =b−eg/ε⊙(\n",
            "KTef/ε)\n",
            ". (1.60)\n",
            "Chunk 1453: Block coordinate ascent can therefore be\n",
            "Chunk 1454: implemented in a closed form by applying\n",
            "Chunk 1455: successively the following\n",
            "Chunk 1456: updates, starting from any arbitrary g(0),\n",
            "Chunk 1457: forl⩾0,\n",
            "Chunk 1458: f(ℓ+1)=εloga−εlog(\n",
            "Keg(ℓ)/ε)\n",
            ", (1.61)\n",
            "Chunk 1459: g(ℓ+1)=εlogb−εlog(\n",
            "KTef(ℓ+1)/ε)\n",
            ". (1.62)\n",
            "Chunk 1460: Such iterations are mathematically equivalent to\n",
            "Chunk 1461: the Sinkhorn iterations (1.51) when considering\n",
            "Chunk 1462: the primal-\n",
            "Chunk 1463: dual relations highlighted in (1.57). Indeed, we\n",
            "Chunk 1464: recover that at any iteration\n",
            "Chunk 1465: (f(ℓ),g(ℓ)) =ε(log(u(ℓ)),log(v(ℓ))).\n",
            "23\n",
            "Chunk 1466: Remark 16 (Soft-min rewriting) .Iterations (1.61)\n",
            "Chunk 1467: and (1.62) can be given an alternative\n",
            "Chunk 1468: interpretation,\n",
            "Chunk 1469: using the following notation. Given a vector zof\n",
            "Chunk 1470: real numbers we write min εzfor the soft-minimum\n",
            "Chunk 1471: of its\n",
            "Chunk 1472: coordinates, namely\n",
            "minεz=−εlog∑\n",
            "ie−zi/ε.\n",
            "Chunk 1473: Note that min ε(z) converges to min zfor any\n",
            "Chunk 1474: vector zasε→0. Indeed, min εcan be interpreted as\n",
            "Chunk 1475: a\n",
            "Chunk 1476: diﬀerentiable approximation of the min function.\n",
            "Chunk 1477: Using these notations, Equations (1.61) and\n",
            "Chunk 1478: (1.62) can be\n",
            "Chunk 1479: rewritten\n",
            "(f(ℓ+1))i= minε(Cij−g(ℓ)\n",
            "Chunk 1480: j)j+εlogai, (1.63)\n",
            "(g(ℓ+1))j= minε(Cij−f(ℓ)\n",
            "Chunk 1481: i)i+εlogbj. (1.64)\n",
            "Here the term min ε(Cij−g(ℓ)\n",
            "Chunk 1482: j)jdenotes the soft-minimum of all values of the\n",
            "Chunk 1483: j-th column of matrix\n",
            "Chunk 1484: (C−1n(g(ℓ))⊤). To simplify notations, we\n",
            "Chunk 1485: introduce an operator that takes a matrix as\n",
            "Chunk 1486: input and outputs\n",
            "Chunk 1487: now a column vector of the soft-minimum values of\n",
            "Chunk 1488: its columns or rows. Namely, for any matrix\n",
            "Chunk 1489: A∈Rn×m,\n",
            "Chunk 1490: we deﬁne\n",
            "Minrow\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)j)\n",
            "i∈Rn,\n",
            "Chunk 1491: Mincol\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)i)\n",
            "j∈Rm.\n",
            "Chunk 1492: Note that these operations are equivalent to the\n",
            "Chunk 1493: entropic c-transform introduced in §??(see in\n",
            "Chunk 1494: particu-\n",
            "Chunk 1495: lar (??)). Using these notations, Sinkhorn’s\n",
            "Chunk 1496: iterates read\n",
            "Chunk 1497: f(ℓ+1)= Minrow\n",
            "ε(C−1ng(ℓ)T) +εloga, (1.65)\n",
            "Chunk 1498: g(ℓ+1)= Mincol\n",
            "ε(C−f(ℓ)1mT) +εlogb. (1.66)\n",
            "Chunk 1499: Note that as ε→0, minεconverges to min, but the\n",
            "Chunk 1500: iterations do not converge anymore in the limit\n",
            "Chunk 1501: ε= 0,\n",
            "Chunk 1502: because alternate minimization does not converge\n",
            "Chunk 1503: for constrained problems (which is the case for\n",
            "Chunk 1504: the un-\n",
            "Chunk 1505: regularized dual (1.17)).\n",
            "Chunk 1506: Remark 17 (Log-domain Sinkhorn) .While\n",
            "Chunk 1507: mathematically equivalent to the Sinkhorn updates\n",
            "Chunk 1508: (1.51), itera-\n",
            "Chunk 1509: tions (1.63) and (1.64) suggest to use the\n",
            "Chunk 1510: log-sum-exp stabilization trick to avoid underﬂow\n",
            "Chunk 1511: for small values\n",
            "Chunk 1512: ofε. Writing z = min z, that trick suggests to\n",
            "Chunk 1513: evaluate min εzas\n",
            "Chunk 1514: minεz= z−εlog∑\n",
            "ie−(zi−z)/ε. (1.67)\n",
            "Chunk 1515: Instead of substracting z to stabilize the log\n",
            "Chunk 1516: domain iterations as in (1.67), one can actually\n",
            "Chunk 1517: substract the\n",
            "Chunk 1518: previously computed scalings. This leads to the\n",
            "Chunk 1519: following stabilized iteration\n",
            "Chunk 1520: f(ℓ+1)= Minrow\n",
            "Chunk 1521: ε(S(f(ℓ),g(ℓ)))−f(ℓ)+εlog(a) (1.68)\n",
            "Chunk 1522: g(ℓ+1)= Mincol\n",
            "Chunk 1523: ε(S(f(ℓ+1),g(ℓ)))−g(ℓ)+εlog(b), (1.69)\n",
            "Chunk 1524: where we deﬁned\n",
            "S(f,g) =(\n",
            "Ci,j−fi−gj)\n",
            "i,j.\n",
            "Chunk 1525: In contrast to the original iterations (1.51),\n",
            "Chunk 1526: these log-domain iterations (1.68) and (1.69) are\n",
            "Chunk 1527: stable for\n",
            "Chunk 1528: arbitraryε >0, because the quantity S(f,g) stays\n",
            "Chunk 1529: bounded during the iterations. The downside is\n",
            "Chunk 1530: that it\n",
            "Chunk 1531: requiresnmcomputations of exp at each step.\n",
            "Chunk 1532: Computing a Minrow\n",
            "Chunk 1533: εor Mincol\n",
            "εis typically substantially\n",
            "Chunk 1534: slower than matrix multiplications, and requires\n",
            "Chunk 1535: computing line by line soft-minima of matrices S.\n",
            "Chunk 1536: There is\n",
            "Chunk 1537: therefore no eﬃcient way to parallelize the\n",
            "Chunk 1538: application of Sinkhorn maps for several\n",
            "Chunk 1539: marginals simultaneously.\n",
            "Chunk 1540: In Euclidean domain of small dimension, it is\n",
            "Chunk 1541: possible to develop eﬃcient multiscale solvers\n",
            "Chunk 1542: with a decaying\n",
            "Chunk 1543: εstrategy to signiﬁcantly speed up the\n",
            "Chunk 1544: computation using sparse grids [ ?].\n",
            "Chunk 1545: 24\n",
            "1.6 Extensions\n",
            "Chunk 1546: Wasserstein Barycenters. Given input histogram\n",
            "Chunk 1547: {bs}S\n",
            "Chunk 1548: s=1, wherebs∈Σns, and weights λ∈ΣS, a\n",
            "Chunk 1549: Wasserstein barycenter is computed by minimizing\n",
            "Chunk 1550: min\n",
            "a∈ΣnS∑\n",
            "s=1λsLCs(a,bs) (1.70)\n",
            "Chunk 1551: where the cost matrices Cs∈Rn×nsneed to be\n",
            "Chunk 1552: speciﬁed. A typical setup is “Eulerian”, so that\n",
            "Chunk 1553: all the\n",
            "Chunk 1554: barycenters are deﬁned on the same grid,\n",
            "Chunk 1555: ns=n,Cs=C=Dpis set to be a distance matrix, so\n",
            "Chunk 1556: that one\n",
            "Chunk 1557: solves\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsWp\n",
            "p(a,bs).\n",
            "Chunk 1558: This barycenter problem (1.70) was originally\n",
            "Chunk 1559: introduced by [ ?] following earlier ideas of [\n",
            "Chunk 1560: ?]. They proved\n",
            "Chunk 1561: in particular uniqueness of the barycenter for\n",
            "Chunk 1562: c(x,y) =||x−y||2overX=Rd, if one of the input\n",
            "Chunk 1563: measure\n",
            "Chunk 1564: has a density with respect to the Lebesgue\n",
            "Chunk 1565: measure (and more generally under the same\n",
            "Chunk 1566: hypothesis as the\n",
            "Chunk 1567: one guaranteeing the existence of a Monge map,\n",
            "Chunk 1568: see Remark ??).\n",
            "Chunk 1569: The barycenter problem for histograms (1.70) is\n",
            "Chunk 1570: in fact a linear program, since one can look for\n",
            "Chunk 1571: the S\n",
            "Chunk 1572: couplings ( Ps)sbetween each input and the\n",
            "Chunk 1573: barycenter itself\n",
            "Chunk 1574: min\n",
            "a∈Σn,(Ps∈Rn×ns)s{S∑\n",
            "s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "Chunk 1575: s1ns=a,P⊤\n",
            "s1n=bs}\n",
            ".\n",
            "Chunk 1576: Although this problem is an LP, its scale forbids\n",
            "Chunk 1577: the use generic solvers for medium scale\n",
            "Chunk 1578: problems. One\n",
            "Chunk 1579: can therefore resort to using ﬁrst order methods\n",
            "Chunk 1580: such as subgradient descent on the dual [ ?].\n",
            "Chunk 1581: Remark 18.Barycenter of arbitrary measures Given\n",
            "Chunk 1582: a set of input measure ( βs)sdeﬁned on some space\n",
            "Chunk 1583: X,\n",
            "Chunk 1584: the barycenter problem becomes\n",
            "min\n",
            "α∈M1\n",
            "+(X)S∑\n",
            "Chunk 1585: s=1λsLc(α,βs). (1.71)\n",
            "Chunk 1586: In the case where X=Rdandc(x,y) =||x−y||2, [?]\n",
            "Chunk 1587: shows that if one of the input measures has a\n",
            "Chunk 1588: density,\n",
            "Chunk 1589: then this barycenter is unique. Problem (1.71)\n",
            "Chunk 1590: can be viewed as a generalization of the problem\n",
            "Chunk 1591: of computing\n",
            "Chunk 1592: barycenters of points ( xs)S\n",
            "Chunk 1593: s=1∈XSto arbitrary measures. Indeed, if βs=δxsis\n",
            "Chunk 1594: a single Dirac mass, then a\n",
            "Chunk 1595: solution to (1.71) is δx⋆wherex⋆is a Fr´ echet\n",
            "Chunk 1596: mean solving ( ??). Note that for c(x,y)\n",
            "Chunk 1597: =||x−y||2, the mean\n",
            "Chunk 1598: of the barycenter α⋆is necessarily the barycenter\n",
            "Chunk 1599: of the mean, i.e.\n",
            "Chunk 1600: ∫\n",
            "Xxdα⋆(x) =∑\n",
            "sλs∫\n",
            "Xxdαs(x),\n",
            "Chunk 1601: and the support of α⋆is located in the convex\n",
            "Chunk 1602: hull of the supports of the ( αs)s. The\n",
            "Chunk 1603: consistency of the\n",
            "Chunk 1604: approximation of the inﬁnite dimensional\n",
            "Chunk 1605: optimization (1.71) when approximating the input\n",
            "Chunk 1606: distribution\n",
            "Chunk 1607: using discrete ones (and thus solving (1.70) in\n",
            "Chunk 1608: place) is studied in [ ?]. Let us also note that\n",
            "Chunk 1609: it is possible to\n",
            "Chunk 1610: re-cast (1.71) as a multi-marginal OT problem,\n",
            "Chunk 1611: see Remark ??.\n",
            "Chunk 1612: One can use entropic smoothing and approximate\n",
            "Chunk 1613: the solution of (1.70) using\n",
            "Chunk 1614: min\n",
            "a∈ΣnS∑\n",
            "s=1λsLε\n",
            "Cs(a,bs) (1.72)\n",
            "Chunk 1615: for someε > 0. This is a smooth convex\n",
            "Chunk 1616: minimization problem, which can be tackled using\n",
            "Chunk 1617: gradient\n",
            "Chunk 1618: descent [ ?]. An alternative is to use descent\n",
            "Chunk 1619: method (typically quasi-Newton) on the semi-dual\n",
            "Chunk 1620: [ ?], which is\n",
            "Chunk 1621: 25\n",
            "Chunk 1622: useful to integrate additional regularizations on\n",
            "Chunk 1623: the barycenter (e.g. to impose some smoothness).\n",
            "Chunk 1624: A simple\n",
            "Chunk 1625: but eﬀective approach, as remarked in [ ?] is to\n",
            "Chunk 1626: rewrite (1.72) as a (weighted) KL projection\n",
            "Chunk 1627: problem\n",
            "Chunk 1628: min\n",
            "(Ps)s{∑\n",
            "Chunk 1629: sλsKL(Ps|Ks) ;∀s,PsT1m=bs,P111=...=PS1S}\n",
            "(1.73)\n",
            "Chunk 1630: where we denoted Ksdef.=e−Cs/ε. Here, the\n",
            "Chunk 1631: barycenter ais implicitly encoded in the row\n",
            "Chunk 1632: marginals of all\n",
            "Chunk 1633: the couplings Ps∈Rn×nsasa=P111=...=PS1S. As\n",
            "Chunk 1634: detailed in [ ?], one can generalize Sinkhorn to\n",
            "Chunk 1635: this problem, which also corresponds to iterative\n",
            "Chunk 1636: projection. This can also be seen as a special\n",
            "Chunk 1637: case of the\n",
            "Chunk 1638: generalized Sinkhorn detailed in §??. The optimal\n",
            "Chunk 1639: couplings ( Ps)ssolving (1.73) are computed in\n",
            "Chunk 1640: scaling\n",
            "Chunk 1641: form as\n",
            "Ps= diag( us)Kdiag(vs), (1.74)\n",
            "Chunk 1642: and the scalings are sequentially updated as\n",
            "Chunk 1643: ∀s∈J1,SK,v(ℓ+1)\n",
            "sdef.=bs\n",
            "KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "Chunk 1644: ∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Ksv(ℓ+1)\n",
            "s, (1.76)\n",
            "Chunk 1645: where a(ℓ+1)def.=∏\n",
            "s(Ksv(ℓ+1)\n",
            "s)λs. (1.77)\n",
            "Chunk 1646: An alternative way to derive these iterations is\n",
            "Chunk 1647: to perform alternate minimization on the\n",
            "Chunk 1648: variables of a dual\n",
            "Chunk 1649: problem, which detailed in the following\n",
            "Chunk 1650: proposition.\n",
            "Chunk 1651: Proposition 9. The optimal (us,vs)appearing in\n",
            "Chunk 1652: (1.74) can be written as (us,vs) =\n",
            "Chunk 1653: (efs/ε,egs/ε)where\n",
            "Chunk 1654: (fs,gs)sare the solutions of the following\n",
            "Chunk 1655: program (whose value matches the one of (1.72) )\n",
            "Chunk 1656: max\n",
            "(fs,gs)s{∑\n",
            "sλs(\n",
            "⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "Chunk 1657: sλsfs= 0}\n",
            ". (1.78)\n",
            "Chunk 1658: Proof. Introducing Lagrange multipliers in (1.73)\n",
            "Chunk 1659: leads to\n",
            "Chunk 1660: min\n",
            "(Ps)s,amax\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "Chunk 1661: εKL(Ps|Ks) +⟨a−Ps1m,fs⟩\n",
            "+⟨bs−PsT1m,gs⟩)\n",
            ".\n",
            "Chunk 1662: Strong duality holds, so that one can exchange\n",
            "Chunk 1663: the min and the max, and gets\n",
            "Chunk 1664: max\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "⟨gs,bs⟩+ min\n",
            "Chunk 1665: PsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\n",
            "+ min\n",
            "a⟨∑\n",
            "sλsfs,a⟩.\n",
            "Chunk 1666: The explicit minimization on agives the\n",
            "Chunk 1667: constraint∑\n",
            "Chunk 1668: sλsfs= 0 together with\n",
            "max\n",
            "(fs,gs)s∑\n",
            "Chunk 1669: sλs⟨gs,bs⟩−εKL∗(fs⊕gs\n",
            "ε|Ks)\n",
            "Chunk 1670: where KL∗(·|Ks) is the Legendre transform ( ??)\n",
            "Chunk 1671: of the function KL∗(·|Ks). This Legendre\n",
            "Chunk 1672: transform reads\n",
            "Chunk 1673: KL∗(U|K) =∑\n",
            "i,jKi,j(eUi,j−1), (1.79)\n",
            "26\n",
            "Chunk 1674: Figure 1.15: Barycenters between 4 input 3-D\n",
            "Chunk 1675: shapes using entropic regularization (1.72). The\n",
            "Chunk 1676: weights\n",
            "Chunk 1677: (λs)sare bilinear with respect to the four\n",
            "Chunk 1678: corners of the square. Shapes are represented as\n",
            "Chunk 1679: measures that\n",
            "Chunk 1680: are uniform within the boundaries of the shape\n",
            "Chunk 1681: and null outside.\n",
            "Chunk 1682: which shows the desired formula. To show (1.79),\n",
            "Chunk 1683: since this function is separable, one needs to\n",
            "Chunk 1684: compute\n",
            "Chunk 1685: ∀(u,k)∈R2\n",
            "+,KL∗(u|k)def.= max\n",
            "rur−(rlog(r/k)−r+k)\n",
            "Chunk 1686: whose optimality condition reads u= log(r/k),\n",
            "Chunk 1687: i.e.r=keu, hence the result.\n",
            "Chunk 1688: Minimizing (1.78) with respect to each gs, while\n",
            "Chunk 1689: keeping all the other variable ﬁxed, is obtained\n",
            "Chunk 1690: in closed\n",
            "Chunk 1691: form by (1.75). Minimizing (1.78) with respect to\n",
            "Chunk 1692: all the ( fs)srequires to solve for ausing (1.77)\n",
            "Chunk 1693: and leads\n",
            "Chunk 1694: to the expression (1.76).\n",
            "Chunk 1695: Figures ??and??show applications to 2-D and 3-D\n",
            "Chunk 1696: shapes interpolation. Figure ??shows a\n",
            "Chunk 1697: computation\n",
            "Chunk 1698: of barycenters on a surface, where the ground\n",
            "Chunk 1699: cost is the square of the geodesic distance. For\n",
            "Chunk 1700: this ﬁgure,\n",
            "Chunk 1701: the computations are performed using the geodesic\n",
            "Chunk 1702: in heat approximation detailed in Remark ??. We\n",
            "Chunk 1703: refer\n",
            "Chunk 1704: to [?] for more details and other applications to\n",
            "Chunk 1705: computer graphics and imaging sciences.\n",
            "Chunk 1706: Wasserstein Loss. In statistics, text processing\n",
            "Chunk 1707: or imaging, one must usually compare a\n",
            "Chunk 1708: probability\n",
            "Chunk 1709: distribution βarising from measurements to a\n",
            "Chunk 1710: model, namely a parameterized family of\n",
            "Chunk 1711: distributions {αθ,θ∈\n",
            "Chunk 1712: Θ}where Θ is a subset of an Euclidean space. Such\n",
            "Chunk 1713: a comparison is done through a “loss” or a\n",
            "Chunk 1714: “ﬁdelity”\n",
            "Chunk 1715: term, which, in this section, is the Wasserstein\n",
            "Chunk 1716: distance. In the simplest scenario, the\n",
            "Chunk 1717: computation of a\n",
            "Chunk 1718: suitable parameter θis obtained by minimizing\n",
            "Chunk 1719: directly\n",
            "Chunk 1720: min\n",
            "θ∈ΘE(θ)def.=Lc(αθ,β). (1.80)\n",
            "Chunk 1721: Of course, one can consider more complicated\n",
            "Chunk 1722: problems: for instance, the barycenter problem\n",
            "Chunk 1723: described\n",
            "Chunk 1724: in§??consists in a sum of such terms. However,\n",
            "Chunk 1725: most of these more advanced problems can be\n",
            "Chunk 1726: usually\n",
            "Chunk 1727: solved by adapting tools deﬁned for basic case:\n",
            "Chunk 1728: either using the chain rule to compute explicitly\n",
            "Chunk 1729: derivatives,\n",
            "Chunk 1730: or using automatic diﬀerentiation.\n",
            "Chunk 1731: The Wasserstein distance between two histograms\n",
            "Chunk 1732: or two densities is convex with respect to these\n",
            "Chunk 1733: inputs,\n",
            "Chunk 1734: as shown by (1.17) and (1.21) respectively.\n",
            "Chunk 1735: Therefore, when the parameter θis itself a\n",
            "Chunk 1736: histogram, namely Θ =\n",
            "Chunk 1737: Σnandαθ=θ, or more generally when\n",
            "Chunk 1738: θdescribesKweights in the simplex, Θ = Σ K,\n",
            "Chunk 1739: andαθ=∑K\n",
            "Chunk 1740: i=1θiαi\n",
            "Chunk 1741: is a convex combination of known atoms\n",
            "Chunk 1742: α1,...,αKin ΣN, Problem (1.80) remains convex\n",
            "Chunk 1743: (the ﬁrst case\n",
            "Chunk 1744: corresponds to the barycenter problem, the second\n",
            "Chunk 1745: to one iteration of the dictionary learning\n",
            "Chunk 1746: problem with\n",
            "Chunk 1747: a Wasserstein loss [ ?]). However, for more\n",
            "Chunk 1748: general parameterizations θ↦→αθ, Problem (1.80)\n",
            "Chunk 1749: is in general\n",
            "Chunk 1750: not convex.\n",
            "27\n",
            "Chunk 1751: g✓XZ⇣xz\u0000↵✓Figure 1.16: Schematic display of the\n",
            "Chunk 1752: density ﬁtting problem 1.81.\n",
            "Chunk 1753: A practical problem of paramount importance in\n",
            "Chunk 1754: statistic and machine learning is density ﬁtting.\n",
            "Chunk 1755: Given\n",
            "Chunk 1756: some discrete samples ( xi)n\n",
            "Chunk 1757: i=1⊂X from some unknown distribution, the goal is\n",
            "Chunk 1758: to ﬁt a parametric model\n",
            "Chunk 1759: θ↦→αθ∈M (X) to the observed empirical input\n",
            "Chunk 1760: measure β\n",
            "Chunk 1761: min\n",
            "θ∈ΘL(αθ,β) where β=1\n",
            "n∑\n",
            "iδxi, (1.81)\n",
            "Chunk 1762: whereLis some “loss” function between a discrete\n",
            "Chunk 1763: and a “continuous” (arbitrary) distribution (see\n",
            "Chunk 1764: Fig-\n",
            "Chunk 1765: ure 1.16).\n",
            "Chunk 1766: In the case where αθas a densify ρθdef.=ραθwith\n",
            "Chunk 1767: respect to the Lebesgue measure (or any other\n",
            "Chunk 1768: ﬁxed\n",
            "Chunk 1769: reference measure), the maximum likelihood\n",
            "Chunk 1770: estimator (MLE) is obtained by solving\n",
            "Chunk 1771: min\n",
            "θLMLE(αθ,β)def.=−∑\n",
            "ilog(ρθ(xi)).\n",
            "Chunk 1772: This corresponds to using an empirical\n",
            "Chunk 1773: counterpart of a Kullback-Leibler loss since,\n",
            "Chunk 1774: assuming the xiare i.i.d.\n",
            "Chunk 1775: samples of some ¯β, then\n",
            "LMLE(α,β)n→+∞−→ KL(α|¯β)\n",
            "Chunk 1776: This MLE approach is known to lead to optimal\n",
            "Chunk 1777: estimation procedures in many cases (see for\n",
            "Chunk 1778: instance [ ?]).\n",
            "Chunk 1779: However, it fails to work when estimating\n",
            "Chunk 1780: singular distributions, typically when the αθdoes\n",
            "Chunk 1781: not has a density\n",
            "Chunk 1782: (so thatLMLE(αθ,β) = +∞) or when ( xi)iare\n",
            "Chunk 1783: samples from some singular ¯β(so that the\n",
            "Chunk 1784: αθshould share\n",
            "Chunk 1785: the same support as βfor KL(α|¯β) to be ﬁnite,\n",
            "Chunk 1786: but this support is usually unknown). Another\n",
            "Chunk 1787: issue is that\n",
            "Chunk 1788: in several cases of practical interest, the\n",
            "Chunk 1789: density ρθis inaccessible (or too hard to\n",
            "Chunk 1790: compute).\n",
            "Chunk 1791: A typical setup where both problems (singular and\n",
            "Chunk 1792: unknown densities) occur is for so-called\n",
            "Chunk 1793: generative\n",
            "Chunk 1794: models, where the parametric measure is written\n",
            "Chunk 1795: as a push-forward of a ﬁxed reference measure ζ∈M\n",
            "Chunk 1796: (Z)\n",
            "Chunk 1797: αθ=hθ,♯ζwherehθ:Z→X\n",
            "Chunk 1798: where the push-forward operator is introduced in\n",
            "Chunk 1799: Deﬁnition 1. The space Zis usually\n",
            "Chunk 1800: low-dimensional, so\n",
            "Chunk 1801: that the support of αθis localized along a\n",
            "Chunk 1802: low-dimensional “manifold” and the resulting\n",
            "Chunk 1803: density is highly\n",
            "Chunk 1804: singular (it does not have a density with respect\n",
            "Chunk 1805: to Lebesgue measure). Furthermore, computing this\n",
            "Chunk 1806: density\n",
            "Chunk 1807: is usually intractable, while generating i.i.d.\n",
            "Chunk 1808: samples from αθis achieved by computing xi=hθ(zi)\n",
            "Chunk 1809: where\n",
            "Chunk 1810: (zi)iare i.i.d. samples from ζ.\n",
            "Chunk 1811: In order to cope with such diﬃcult scenario, one\n",
            "Chunk 1812: has to use weak metrics in place of the MLE\n",
            "Chunk 1813: functional\n",
            "Chunk 1814: LMLE, which needs to be written in dual form as\n",
            "Chunk 1815: L(α,β)def.= max\n",
            "(f,g)∈C(X)2{∫\n",
            "Xf(x)dα(x) +∫\n",
            "Chunk 1816: Xg(x)dβ(x) ; (f,g)∈R}\n",
            ". (1.82)\n",
            "Chunk 1817: Dual norms exposed in §??correspond to imposing\n",
            "Chunk 1818: R={(f,−f) ;f∈B}, while optimal transport (1.21)\n",
            "Chunk 1819: setsR=R(c) as deﬁned in (1.22).\n",
            "28\n",
            "Chunk 1820: For a ﬁxed θ, evaluating the energy to be\n",
            "Chunk 1821: minimized in (1.81) using such a loss function\n",
            "Chunk 1822: corresponds to\n",
            "Chunk 1823: solving a semi-discrete optimal transport, which\n",
            "Chunk 1824: is the focus of Chapter ??. Minimizing the energy\n",
            "Chunk 1825: with\n",
            "Chunk 1826: respect toθis much more involved, and is\n",
            "Chunk 1827: typically highly non-convex.\n",
            "Chunk 1828: The class of estimators obtained using L=Lc,\n",
            "Chunk 1829: often called “Minimum Kantorovitch Estimators”\n",
            "Chunk 1830: (MKE),\n",
            "Chunk 1831: was initially introduced in [ ?], see also [ ?].\n",
            "Chunk 1832: Gromov-Wasserstein. Optimal transport needs a\n",
            "Chunk 1833: ground cost Cto compare histograms ( a,b), it can\n",
            "Chunk 1834: thus not be used if the histograms are not deﬁned\n",
            "Chunk 1835: on the same underlying space, or if one cannot\n",
            "Chunk 1836: pre-register\n",
            "Chunk 1837: these spaces to deﬁne a ground cost. To address\n",
            "Chunk 1838: this issue, one can instead only assume a weaker\n",
            "Chunk 1839: assumption,\n",
            "Chunk 1840: namely that one has at its disposal two matrices\n",
            "Chunk 1841: D∈Rn×nandD′∈Rm×mthat represent some relationship\n",
            "Chunk 1842: between the points on which the histograms are\n",
            "Chunk 1843: deﬁned. A typical scenario is when these matrices\n",
            "Chunk 1844: are (power\n",
            "Chunk 1845: of) distance matrices. The Gromov-Wasserstein\n",
            "Chunk 1846: problem reads\n",
            "Chunk 1847: GW(( a,D),(b,D′))2def.= min\n",
            "Chunk 1848: P∈U(a,b)ED,D′(P)def.=∑\n",
            "i,j,i′,j′|Di,i′−D′\n",
            "Chunk 1849: j,j′|2Pi,jPi′,j′. (1.83)\n",
            "Chunk 1850: This is a non-convex problem, which can be recast\n",
            "Chunk 1851: as a Quadratic Assignment Problem (QAP) [ ?] and\n",
            "Chunk 1852: is in\n",
            "Chunk 1853: full generality NP-hard to solve for arbitrary\n",
            "Chunk 1854: inputs. It is in fact equivalent to a graph\n",
            "Chunk 1855: matching problem [ ?]\n",
            "Chunk 1856: for a particular cost.\n",
            "Chunk 1857: One can show that GW satisﬁes the triangular\n",
            "Chunk 1858: inequality, and in fact it deﬁnes a distance\n",
            "Chunk 1859: between\n",
            "Chunk 1860: metric spaces equipped with a probability\n",
            "Chunk 1861: distribution (here assumed to be discrete in\n",
            "Chunk 1862: deﬁnition (1.83))\n",
            "Chunk 1863: up to isometries preserving the measures. This\n",
            "Chunk 1864: distance was introduced and studied in details by\n",
            "Chunk 1865: Memoli\n",
            "Chunk 1866: in [?]. An in-depth mathematical exposition (in\n",
            "Chunk 1867: particular, its geodesic structure and gradient\n",
            "Chunk 1868: ﬂows) is given\n",
            "Chunk 1869: in [?]. See also [ ?] for applications in\n",
            "Chunk 1870: computer vision. This distance is also tightly\n",
            "Chunk 1871: connected with the\n",
            "Chunk 1872: Gromov-Hausdorﬀ distance [ ?] between metric\n",
            "Chunk 1873: spaces, which have been used for shape matching [\n",
            "Chunk 1874: ?,?].\n",
            "Chunk 1875: Remark 19.Gromov-Wasserstein distance The general\n",
            "Chunk 1876: setting corresponds to computing couplings\n",
            "Chunk 1877: between\n",
            "Chunk 1878: metric measure spaces ( X,dX,αX) and (Y,dY,αY)\n",
            "Chunk 1879: where (dX,dY) are distances and ( αX,αY) are\n",
            "Chunk 1880: measures\n",
            "Chunk 1881: on their respective spaces. One deﬁnes\n",
            "Chunk 1882: GW((αX,dX),(αY,dY))2def.= min\n",
            "π∈U(αX,αY)∫\n",
            "Chunk 1883: X2×Y2|dX(x,x′)−dY(y,y′)|2dπ(x,y)dπ(x′,y′). (1.84)\n",
            "Chunk 1884: GW deﬁnes a distance between metric measure\n",
            "Chunk 1885: spaces up to isometries, where one says that (\n",
            "Chunk 1886: αX,dX) and\n",
            "Chunk 1887: (αY,dY) are isometric if there exists ϕ:X→Y such\n",
            "Chunk 1888: thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′)) =dX(x,x′).\n",
            "Chunk 1889: Remark 20.Gromov-Wasserstein geodesics The space\n",
            "Chunk 1890: of metric spaces (up to isometries) endowed with\n",
            "Chunk 1891: thisGW distance (1.84) has a geodesic structure.\n",
            "Chunk 1892: [ ?] shows that the geodesic between ( X0,dX0,α0)\n",
            "Chunk 1893: and\n",
            "Chunk 1894: (X1,dX1,α1) can be chosen to be t∈[0,1]↦→(X0×X\n",
            "Chunk 1895: 1,dt,π⋆) whereπ⋆is a solution of (1.84) and for\n",
            "Chunk 1896: all\n",
            "Chunk 1897: ((x0,x1),(x′\n",
            "0,x′\n",
            "1))∈(X0×X 1)2,\n",
            "dt((x0,x1),(x′\n",
            "Chunk 1898: 0,x′\n",
            "1))def.= (1−t)dX0(x0,x′\n",
            "0) +tdX1(x1,x′\n",
            "1).\n",
            "Chunk 1899: This formula allows one to deﬁne and analyze\n",
            "Chunk 1900: gradient ﬂows which minimize functionals\n",
            "Chunk 1901: involving metric\n",
            "Chunk 1902: spaces, see [ ?]. It is however diﬃcult to handle\n",
            "Chunk 1903: numerically, because it involves computations\n",
            "Chunk 1904: over the product\n",
            "Chunk 1905: spaceX0×X 1. A heuristic approach is used in [ ?]\n",
            "Chunk 1906: to deﬁne geodesics and barycenters of metric\n",
            "Chunk 1907: measure\n",
            "Chunk 1908: spaces while imposing the cardinality of the\n",
            "Chunk 1909: involved spaces and making use of the entropic\n",
            "Chunk 1910: smoothing (1.85)\n",
            "Chunk 1911: detailed below.\n",
            "Chunk 1912: To approximate the computation of GW, and to help\n",
            "Chunk 1913: convergence of minimization schemes to better\n",
            "Chunk 1914: minima, one can consider the entropic regularized\n",
            "Chunk 1915: variant\n",
            "Chunk 1916: min\n",
            "P∈U(a,b)ED,D′(P)−εH(P). (1.85)\n",
            "29\n",
            "Chunk 1917: Figure 1.17: Example of fuzzy correspondences\n",
            "Chunk 1918: computed by solving GW problem (1.85) with\n",
            "Chunk 1919: Sinkhorn\n",
            "Chunk 1920: iterations (1.86). Extracted from [ ?].\n",
            "Chunk 1921: As proposed initially in [ ?,?], and later\n",
            "Chunk 1922: revisited in [ ?] for applications in graphics,\n",
            "Chunk 1923: one can use iteratively\n",
            "Chunk 1924: Sinkhorn’s algorithm to progressively compute a\n",
            "Chunk 1925: stationary point of (1.85). Indeed, successive\n",
            "Chunk 1926: linearizations\n",
            "Chunk 1927: of the objective function lead to consider the\n",
            "Chunk 1928: succession of updates\n",
            "Chunk 1929: P(ℓ+1) def.= min\n",
            "Chunk 1930: P∈U(a,b)⟨P,C(ℓ)⟩−εH(P) where (1.86)\n",
            "Chunk 1931: C(ℓ)def.=∇ED,D′(P(ℓ)) =−D′TP(ℓ)D,\n",
            "Chunk 1932: which can be interpreted as a mirror-descent\n",
            "Chunk 1933: scheme [ ?]. Each update can thus be solved using\n",
            "Chunk 1934: Sinkhorn\n",
            "Chunk 1935: iterations (1.51) with cost C(ℓ). Figure (1.17)\n",
            "Chunk 1936: illustrates the use of this entropic\n",
            "Chunk 1937: Gromov-Wasserstein to\n",
            "Chunk 1938: compute soft maps between domains.\n",
            "30\n",
            "Chunk 1939: Bibliography\n",
            "Chunk 1940: [1] Amir Beck. Introduction to Nonlinear\n",
            "Chunk 1941: Optimization: Theory, Algorithms, and\n",
            "Chunk 1942: Applications with MAT-\n",
            "Chunk 1943: LAB. SIAM, 2014.\n",
            "Chunk 1944: [2] Stephen Boyd, Neal Parikh, Eric Chu, Borja\n",
            "Chunk 1945: Peleato, and Jonathan Eckstein. Distributed\n",
            "Chunk 1946: optimization\n",
            "Chunk 1947: and statistical learning via the alternating\n",
            "Chunk 1948: direction method of multipliers. Foundations and\n",
            "Chunk 1949: Trends R⃝\n",
            "Chunk 1950: in Machine Learning , 3(1):1–122, 2011.\n",
            "Chunk 1951: [3] Stephen Boyd and Lieven Vandenberghe. Convex\n",
            "Chunk 1952: optimization . Cambridge university press, 2004.\n",
            "Chunk 1953: [4] E. Cand` es and D. Donoho. New tight frames\n",
            "Chunk 1954: of curvelets and optimal representations of\n",
            "Chunk 1955: objects with\n",
            "Chunk 1956: piecewise C2singularities. Commun. on Pure and\n",
            "Chunk 1957: Appl. Math. , 57(2):219–266, 2004.\n",
            "Chunk 1958: [5] E. J. Cand` es, L. Demanet, D. L. Donoho, and\n",
            "Chunk 1959: L. Ying. Fast discrete curvelet transforms. SIAM\n",
            "Chunk 1960: Multiscale Modeling and Simulation , 5:861–899,\n",
            "Chunk 1961: 2005.\n",
            "Chunk 1962: [6] A. Chambolle. An algorithm for total\n",
            "Chunk 1963: variation minimization and applications. J. Math.\n",
            "Chunk 1964: Imaging Vis. ,\n",
            "Chunk 1965: 20:89–97, 2004.\n",
            "Chunk 1966: [7] Antonin Chambolle, Vicent Caselles, Daniel\n",
            "Chunk 1967: Cremers, Matteo Novaga, and Thomas Pock. An\n",
            "Chunk 1968: intro-\n",
            "Chunk 1969: duction to total variation for image analysis.\n",
            "Chunk 1970: Theoretical foundations and numerical methods for\n",
            "Chunk 1971: sparse\n",
            "Chunk 1972: recovery , 9(263-340):227, 2010.\n",
            "Chunk 1973: [8] Antonin Chambolle and Thomas Pock. An\n",
            "Chunk 1974: introduction to continuous optimization for\n",
            "Chunk 1975: imaging. Acta\n",
            "Chunk 1976: Numerica , 25:161–319, 2016.\n",
            "Chunk 1977: [9] S.S. Chen, D.L. Donoho, and M.A. Saunders.\n",
            "Chunk 1978: Atomic decomposition by basis pursuit. SIAM\n",
            "Chunk 1979: Journal\n",
            "Chunk 1980: on Scientiﬁc Computing , 20(1):33–61, 1999.\n",
            "Chunk 1981: [10] Philippe G Ciarlet. Introduction ` a\n",
            "Chunk 1982: l’analyse num´ erique matricielle et ` a\n",
            "Chunk 1983: l’optimisation. 1982.\n",
            "Chunk 1984: [11] P. L. Combettes and V. R. Wajs. Signal\n",
            "Chunk 1985: recovery by proximal forward-backward splitting.\n",
            "Chunk 1986: SIAM\n",
            "Chunk 1987: Multiscale Modeling and Simulation , 4(4), 2005.\n",
            "Chunk 1988: [12] I. Daubechies, M. Defrise, and C. De Mol. An\n",
            "Chunk 1989: iterative thresholding algorithm for linear\n",
            "Chunk 1990: inverse problems\n",
            "Chunk 1991: with a sparsity constraint. Commun. on Pure and\n",
            "Chunk 1992: Appl. Math. , 57:1413–1541, 2004.\n",
            "Chunk 1993: [13] D. Donoho and I. Johnstone. Ideal spatial\n",
            "Chunk 1994: adaptation via wavelet shrinkage. Biometrika ,\n",
            "Chunk 1995: 81:425–455,\n",
            "Chunk 1996: Dec 1994.\n",
            "Chunk 1997: [14] Heinz Werner Engl, Martin Hanke, and Andreas\n",
            "Chunk 1998: Neubauer. Regularization of inverse problems ,\n",
            "Chunk 1999: volume\n",
            "Chunk 2000: 375. Springer Science & Business Media, 1996.\n",
            "Chunk 2001: [15] M. Figueiredo and R. Nowak. An EM Algorithm\n",
            "Chunk 2002: for Wavelet-Based Image Restoration. IEEE Trans.\n",
            "Chunk 2003: Image Proc. , 12(8):906–916, 2003.\n",
            "Chunk 2004: [16] Simon Foucart and Holger Rauhut. A\n",
            "Chunk 2005: mathematical introduction to compressive sensing\n",
            "Chunk 2006: , volume 1.\n",
            "Chunk 2007: Birkh¨ auser Basel, 2013.\n",
            "31\n",
            "Chunk 2008: [17] Stephane Mallat. A wavelet tour of signal\n",
            "Chunk 2009: processing: the sparse way . Academic press,\n",
            "Chunk 2010: 2008.\n",
            "Chunk 2011: [18] D. Mumford and J. Shah. Optimal\n",
            "Chunk 2012: approximation by piecewise smooth functions and\n",
            "Chunk 2013: associated varia-\n",
            "Chunk 2014: tional problems. Commun. on Pure and Appl. Math.\n",
            "Chunk 2015: , 42:577–685, 1989.\n",
            "Chunk 2016: [19] Neal Parikh, Stephen Boyd, et al. Proximal\n",
            "Chunk 2017: algorithms. Foundations and Trends R⃝in\n",
            "Chunk 2018: Optimization ,\n",
            "Chunk 2019: 1(3):127–239, 2014.\n",
            "Chunk 2020: [20] Gabriel Peyr´ e. L’alg` ebre discr` ete de\n",
            "Chunk 2021: la transform´ ee de Fourier . Ellipses, 2004.\n",
            "Chunk 2022: [21] J. Portilla, V. Strela, M.J. Wainwright, and\n",
            "Chunk 2023: Simoncelli E.P. Image denoising using scale\n",
            "Chunk 2024: mixtures of\n",
            "Chunk 2025: Gaussians in the wavelet domain. IEEE Trans.\n",
            "Chunk 2026: Image Proc. , 12(11):1338–1351, November 2003.\n",
            "Chunk 2027: [22] L. I. Rudin, S. Osher, and E. Fatemi.\n",
            "Chunk 2028: Nonlinear total variation based noise removal\n",
            "Chunk 2029: algorithms. Phys.\n",
            "Chunk 2030: D, 60(1-4):259–268, 1992.\n",
            "Chunk 2031: [23] Otmar Scherzer, Markus Grasmair, Harald\n",
            "Chunk 2032: Grossauer, Markus Haltmeier, Frank Lenzen, and L\n",
            "Chunk 2033: Sirovich.\n",
            "Chunk 2034: Variational methods in imaging . Springer, 2009.\n",
            "Chunk 2035: [24] C. E. Shannon. A mathematical theory of\n",
            "Chunk 2036: communication. The Bell System Technical Journal\n",
            "Chunk 2037: ,\n",
            "Chunk 2038: 27(3):379–423, 1948.\n",
            "Chunk 2039: [25] Jean-Luc Starck, Fionn Murtagh, and Jalal\n",
            "Chunk 2040: Fadili. Sparse image and signal processing:\n",
            "Chunk 2041: Wavelets and\n",
            "Chunk 2042: related geometric multiscale analysis . Cambridge\n",
            "Chunk 2043: university press, 2015.\n",
            "Chunk 2044: 32\n",
            "\n",
            "Char count chunking with custom delimiter:\n",
            "Chunk 1: Mathematical Foundations of Data Sciences\n",
            "Gabriel Peyr´ e\n",
            "CNRS & DMA\n",
            "´Ecole Normale Sup´ erieure\n",
            "gabriel.peyre\n",
            "Chunk 2: ens.fr\n",
            "https://mathematical-tours.github.io\n",
            "www.numerical-tours.com\n",
            "August 14, 2019\n",
            "2\n",
            "Chapter 1\n",
            "Optimal Transport\n",
            "1.1 Radon Measures\n",
            "Measures. We will interchangeably the term histogram or probability vector for any element a∈Σnthat\n",
            "belongs to the probability simplex\n",
            "Σndef.={\n",
            "a∈Rn\n",
            "+;n∑\n",
            "i=1ai= 1}\n",
            ".\n",
            "A discrete measure with weights aand locations x1,...,xn∈X reads\n",
            "α=n∑\n",
            "i=1aiδxi (1.1)\n",
            "whereδxis the Dirac at position x, intuitively a unit of mass which is inﬁnitely concentrated at location\n",
            "x. Such as measure describes a probability measure if, additionally, a∈Σn, and more generally a positive\n",
            "measure if each of the “weights” described in vector ais positive itself.\n",
            "Remark 1 (General measures) .A convenient feature of OT is that it can deal with discrete and continuous\n",
            "“objects” within the same framework. Such objects only need to be modelled as measures. This corresponds\n",
            "to the notion of Radon measures M(X) on the spaceX. The formal deﬁnition of that set requires that Xis\n",
            "equipped with a distance, usually denoted d, because one can only access a measure by “testing” (integrating)\n",
            "it against continuous functions, denoted f∈C(X).\n",
            "Integration of f∈C(X) against a discrete measure αcomputes a sum\n",
            "∫\n",
            "Xf(x)dα(x) =n∑\n",
            "i=1aif(xi).\n",
            "More general measures, for instance on X=Rd(whered∈N∗is the dimension), can have a density\n",
            "dα(x) =ρα(x)dxw.r.t. the Lebesgue measure, often denoted ρα=dα\n",
            "dx, which means that\n",
            "∀h∈C(Rd),∫\n",
            "Rdh(x)dα(x) =∫\n",
            "Rdh(x)ρα(x)dx.\n",
            "An arbitrary measure α∈M (X) (which needs not to have a density nor be a sum of Diracs) is deﬁned by\n",
            "the fact that it can be integrated agains any continuous function f∈C(X) and obtain∫\n",
            "Xf(x)dα(x)∈R.\n",
            "IfXis not compact, one should also impose that fhas compact support or at least as 0 limit at inﬁnity.\n",
            "Measure as thus in some sense “less regular” than functions, but more regular than distributions (which are\n",
            "dual to smooth functions). For instance, the derivative of a Dirac is not a measure. We denote M+(X) the\n",
            "set of all positive measures on X. The set of probability measures is denoted M1\n",
            "+(X), which means that\n",
            "anyα∈M1\n",
            "+(X) is positive, and that α(X) =∫\n",
            "Xdα= 1. Figure 1.1 oﬀers a visualization of the diﬀerent\n",
            "classes of measures, beyond histograms, considered in this work.\n",
            "3\n",
            "Discreted= 1 Discrete d= 2 Density d= 1 Density d= 2\n",
            "Figure 1.1: Schematic display of discrete distributions α=∑n\n",
            "i=1aiδxi(red corresponds to empirical uniform\n",
            "distribution ai= 1/n, and blue to arbitrary distributions) and densities d α(x) =ρα(x)dx(in violet), in both\n",
            "1-D and 2-D. Discrete distributions in 1-D are displayed using vertical segments (with length equal to ai)\n",
            "and in 2-D using point clouds (radius equal to ai).\n",
            "Operators on measures. For some continuous map T:X →Y , we deﬁne the pushforward operator\n",
            "T♯:M(X)→M (Y). For discrete measures (1.1), the pushforward operation consists simply in moving the\n",
            "positions of all the points in the support of the measure\n",
            "T♯αdef.=∑\n",
            "iaiδT(xi).\n",
            "For more general measures, for instance for those with a density, the notion of push-forward plays a funda-\n",
            "mental to describe spatial modiﬁcations of probability measures. The formal deﬁnition reads as follow.\n",
            "Deﬁnition 1 (Push-forward) .ForT:X → Y , the push forward measure β=T♯α∈ M (Y)of some\n",
            "α∈M (X)reads\n",
            "∀h∈C(Y),∫\n",
            "Yh(y)dβ(y) =∫\n",
            "Xh(T(x))dα(x). (1.2)\n",
            "Equivalently, for any measurable set B⊂Y, one has\n",
            "β(B) =α({x∈X;T(x)∈B}). (1.3)\n",
            "Note thatT♯preserves positivity and total mass, so that if α∈M1\n",
            "+(X)thenT♯α∈M1\n",
            "+(Y).\n",
            "Intuitively, a measurable map T:X→Y , can be interpreted as a function “moving” a single point from a\n",
            "measurable space to another. The more general extension T♯can now “move” an entire probability measure\n",
            "onXtowards a new probability measure on Y. The operator T♯“pushes forward” each elementary mass of\n",
            "a measureαonXby applying the map Tto obtain then an elementary mass in Y, to build on aggregate a\n",
            "new measure onY) writtenT♯α. Note that such a push-forward T♯:M1\n",
            "+(X)→M1\n",
            "+(Y) is a linear operator\n",
            "between measures in the sense that for two measures α1,α2onX,T♯(α1+α2) =T♯α1+T♯α2.\n",
            "Remark 2 (Push-forward for densities) .Explicitly doing the change of variable in formula (1.2) for measures\n",
            "with densities ( ρα,ρβ) onRd(assumingTis smooth and a bijection) shows that a push-forward acts on\n",
            "densities linearly as a change of variables in the integration formula, indeed\n",
            "ρα(x) =|det(T′(x))|ρβ(T(x)) (1.4)\n",
            "whereT′(x)∈Rd×dis the Jacobian matrix of T(the matrix formed by taking the gradient of each coordinate\n",
            "ofT). This implies, denoting y=T(x)\n",
            "|det(T′(x))|=ρα(x)\n",
            "ρβ(y).\n",
            "4\n",
            "=Pi\u0000xiT↵T]↵def.=Pi\u0000T(xi)\n",
            "TT]gdef.=g\u0000TgPush-forward of measures Pull-back of functions\n",
            "Figure 1.2: Comparison of push-forward T♯and pull-back T♯.\n",
            "Remark 3 (Push-forward vs. pull-back) .The push-forward T♯of measures should not be confounded with\n",
            "the pull-back of function T♯:C(Y)→C(X) which corresponds to the “warping” of functions. It is the linear\n",
            "map deﬁned, for g∈C(Y) byT♯g=g◦T. Push-forward and pull-back are actually adjoint one from each\n",
            "others, in the sense that\n",
            "∀(α,g)∈M (X)×C(Y),∫\n",
            "Ygd(T♯α) =∫\n",
            "X(T♯g)dα.\n",
            "It is important to realize that even if ( α,β) have densities ( ρα,ρβ),T♯αis not equal to T♯ρβ, because of\n",
            "the presence of the Jacobian in (1.4). This explains why OT should be used with caution to perform image\n",
            "registration, because it does not operate as an image warping method. Figure 1.2 illustrate the distinction\n",
            "between these push-forward and pull-back operators.\n",
            "Remark 4 (Measures and random variables) .Radon measures can also be viewed as representing the distri-\n",
            "butions of random variables. A random variable XonXis actually a map X: Ω→X from some abstract\n",
            "(often un-speciﬁed) probabized space (Ω ,P), and its distribution αis the Radon measure X∈M1\n",
            "+(X) such\n",
            "thatP(X∈A) =α(A) =∫\n",
            "Adα(x). Equivalently, it is the push-forward of PbyX,α=X♯P. Applying\n",
            "another push-forward β=T♯αforT:X →Y , following (1.2), is equivalent to deﬁning another random\n",
            "variableY=T(X) :ω∈Ω→T(X(ω))∈Y, so thatβis the distribution of Y. Drawing a random sample\n",
            "yfromYis thus simply achieved by computing y=T(x) wherexis drawn from X.\n",
            "Convergence of random variable. Convergence of random variable (in probability, almost sure, in law),\n",
            "convergence of measures (strong, weak).\n",
            "1.2 Monge Problem\n",
            "Given a cost matrix ( Ci,j)i∈JnK,j∈JmK, assuming n=m, the optimal assignment problem seeks for a\n",
            "bijectionσin the set Perm( n) of permutations of nelements solving\n",
            "min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i). (1.5)\n",
            "One could naively evaluate the cost function above using all permutations in the set Perm( n). However,\n",
            "that set has size n!, which is gigantic even for small n. Consider for instance that such a set has more than\n",
            "10100elements [ ?] whennis as small as 70. That problem can therefore only be solved if there exist eﬃcient\n",
            "algorithms to optimize that cost function over the set of permutations, which will be the subject of §??.\n",
            "5\n",
            "x1x2y1y2x1x2y1y2x4x5x6x3y3x7Figure 1.3: (left) blue dots from measure αand red dots from measure βare pairwise equidistant. Hence,\n",
            "either matching σ= (1,2) (full line) or σ= (2,1) (dotted line) is optimal. (right) a Monge map can associate\n",
            "the blue measure αto the red measure β. The weights αiare displayed proportionally to the area of the\n",
            "disk marked at each location. The mapping here is such that T(x1) =T(x2) =y2,T(x3) =y3, whereas for\n",
            "4⩽i⩽7 we haveT(xi) =y1.\n",
            "Remark 5 (Uniqueness) .Note that the optimal assignment problem may have several optimal solutions.\n",
            "Suppose for instance that n=m= 2 and that the matrix Cis the pairwise distance matrix between the 4\n",
            "corners of a 2-dimensional square of side length 1, as represented in the left plot in Figure 1.3. In that case\n",
            "only two assignments exist, and they share the same cost.\n",
            "For discrete measures\n",
            "α=n∑\n",
            "i=1aiδxiandβ=m∑\n",
            "j=1bjδyj (1.6)\n",
            "the Monge problem [ ?] seeks for a map that associates to each point xia single point yj, and which must\n",
            "push the mass of αtoward the mass of β, which is to say that such a map T:{x1,...,xn}→{y1,...,ym}\n",
            "must verify that\n",
            "∀j∈JmK,bj=∑\n",
            "i:T(xi)=yjai (1.7)\n",
            "which we write in compact form as T♯α=β. This map should minimize some transportation cost, which is\n",
            "parameterized by a function c(x,y) deﬁned for points ( x,y)∈X×Y\n",
            "min\n",
            "T{∑\n",
            "ic(xi,T(xi)) ;T♯α=β}\n",
            ". (1.8)\n",
            "Such a map between discrete points can be of course encoded, assuming all x’s andy’s are distinct, using\n",
            "indicesσ:JnK→JmKso thatj=σ(i), and the mass conservation is written as\n",
            "∑\n",
            "i∈σ−1(j)ai=bj.\n",
            "In the special case when n=mand all weights are uniform, that is ai=bj= 1/n, then the mass conservation\n",
            "constraint implies that Tis a bijection, such that T(xi) =yσ(i), and the Monge problem is equivalent to the\n",
            "optimal matching problem (1.5) where the cost matrix is\n",
            "Ci,jdef.=c(xi,yj).\n",
            "Whenn̸=m, note that, optimality aside, Monge maps may not even exist between an empirical measure\n",
            "to another. This happens when their weight vectors are not compatible, which is always the case when the\n",
            "target measure has more points than the source measure. For instance, the right plot in Figure 1.3 shows\n",
            "an (optimal) Monge map between αandβ, but there is no Monge map from βtoα.\n",
            "6\n",
            "Monge problem (1.8) is extended to the setting of two arbitrary probability measures ( α,β) on two spaces\n",
            "(X,Y) as ﬁnding a map T:X→Y that minimizes\n",
            "min\n",
            "T{∫\n",
            "Xc(x,T(x))dα(x) ;T♯α=β}\n",
            "(1.9)\n",
            "The constraint T♯α=βmeans that Tpushes forward the mass of αtoβ, and makes use of the push-forward\n",
            "operator (1.2).\n",
            "1.3 Kantorovitch Problem\n",
            "The assignment problem has several limitations in practical settings, also encountered when using the\n",
            "Monge problem. Indeed, because the assignment problem is formulated as a permutation problem, it can only\n",
            "be used to compare two points clouds of the same size. A direct generalization to discrete measures with non-\n",
            "uniform weights can be carried out using Monge’s formalism of pushforward maps, but that formulation may\n",
            "also be degenerate it there does not exist feasible solutions satisfying the mass conservation constraint (1.7)\n",
            "(see the end of Remark ??). Additionally, the assignment Problem (1.8) is combinatorial, whereas the feasible\n",
            "set for the Monge Problem (1.9), consisting in all push-forward measures that satisfy the mass conservation\n",
            "constraint, is non-convex . Both are therefore diﬃcult to solve in their original formulation.\n",
            "Kantorovitch formulation for discrete measures. The key idea of [ ?] is to relax the deterministic na-\n",
            "ture of transportation, namely the fact that a source point xican only be assigned to another, or transported\n",
            "to one and one location T(xi) only. Kantorovich proposes instead that the mass at any point xibe potentially\n",
            "dispatched across several locations. Kantorovich moves away from the idea that mass transportation should\n",
            "be “deterministic” to consider instead a “probabilistic” (or “fuzzy”) transportation, which allows what is\n",
            "commonly known now as “mass splitting” from a source towards several targets. This ﬂexibility is encoded\n",
            "using, in place of a permutation σor a mapT, a coupling matrix P∈Rn×m\n",
            "+, where Pi,jdescribes the\n",
            "amount of mass ﬂowing from bin i(or pointxi) towards bin j(or pointxj),xitowardsyjin the formalism\n",
            "of discrete measures (1.6). Admissible couplings admit a far simpler characterization than Monge maps:\n",
            "U(a,b)def.={\n",
            "P∈Rn×m\n",
            "+ ;P1m=aand PT1n=b}\n",
            ", (1.10)\n",
            "where we used the following matrix-vector notation\n",
            "P1m=\n",
            "∑\n",
            "jPi,j\n",
            "\n",
            "i∈Rnand PT1n=(∑\n",
            "iPi,j)\n",
            "j∈Rm.\n",
            "The set of matrices U(a,b) is bounded, deﬁned by n+mequality constraints, and therefore a convex\n",
            "polytope (the convex hull of a ﬁnite set of matrices).\n",
            "Additionally, whereas the Monge formulation (as illustrated in the right plot of Figure 1.3) was intrisically\n",
            "asymmetric, Kantorovich’s relaxed formulation is always symmetric, in the sense that a coupling Pis in\n",
            "U(a,b) if and only if PTis inU(b,a).\n",
            "Kantorovich’s optimal transport problem now reads\n",
            "LC(a,b)def.= min\n",
            "P∈U(a,b)⟨C,P⟩def.=∑\n",
            "i,jCi,jPi,j. (1.11)\n",
            "This is a linear program (see Chapter ??), and as is usually the case with such programs, its solutions are\n",
            "not necessarily unique.\n",
            "7\n",
            "↵\u0000\n",
            "↵\u0000Figure 1.4: Comparison of optimal matching and generic couplings. A black segment between xiandyj\n",
            "indicates a non-zero element in the displayed optimal coupling Pi,jsolving (1.11). Left: optimal matching,\n",
            "corresponding to the setting of Proposition (1) (empirical measures with the same number n=mof points).\n",
            "Right: these two weighted point clouds cannot be matched; instead a Kantorovich coupling can be used to\n",
            "associate two arbitrary discrete measures.\n",
            "Permutation Matrices as Couplings For a permutation σ∈Perm(n), we write Pσfor the correspond-\n",
            "ing permutation matrix,\n",
            "∀(i,j)∈JnK2,(Pσ)i,j={1/n ifj=σi,\n",
            "0 otherwise.(1.12)\n",
            "One can check that in that case\n",
            "⟨C,Pσ⟩=1\n",
            "nn∑\n",
            "i=1Ci,σi,\n",
            "which shows that the assignment problem (1.5) can be recast as a Kantorovich problem (1.11) where the\n",
            "couplings Pare restricted to be exactly permutation matrices:\n",
            "min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i)= min\n",
            "σ∈Perm(n)⟨C,Pσ⟩.\n",
            "Next, one can easily check that the set of permutation matrices is strictly included in the so-called Birkhoﬀ\n",
            "polytope U(1n/n,1n,n). Indeed, for any permutation σwe have Pσ1=1nandPσT1=1n, whereas\n",
            "1n1nT/n2is a valid coupling but not a permutation matrix. Therefore, one has naturally that\n",
            "min\n",
            "σ∈Perm(n)⟨C,Pσ⟩⩽LC(1n/n,1n/n).\n",
            "The following proposition shows that these problems result in fact in the same optimum, namely that\n",
            "one can always ﬁnd a permutation matrix that minimizes Kantorovich’s problem (1.11) between two uniform\n",
            "measures a=b=1n/n, which shows that the Kantorovich relaxation is tight when considered on assignment\n",
            "problems. Figure 1.4 shows on the left a 2-D example of optimal matching corresponding to this special\n",
            "case.\n",
            "Proposition 1 (Kantorovich for matching) .Ifm=nanda=b=1n/n, then there exists an optimal\n",
            "solution for Problem (1.11) Pσ⋆, which is a permutation matrix associated to an optimal permutation σ⋆∈\n",
            "Perm(n)for Problem (1.5) .\n",
            "Proof. Birkhoﬀ’s theorem states that the set of extremal points of U(1n/n,1n/n) is equal to the set of\n",
            "permutation matrices. A fundamental theorem of linear programming [ ?, Theorem 2.7] states that the\n",
            "minimum of a linear objective in a non-empty polyhedron, if ﬁnite, is reached at an extremal point of the\n",
            "polyhedron.\n",
            "8\n",
            "⇡\u0000↵\u0000↵\n",
            "⇡\u0000↵\u0000↵\n",
            "⇡\u0000↵\u0000↵\n",
            "Discrete Semi-discrete Continuous\n",
            "Figure 1.5: Schematic viewed of input measures ( α,β) and couplingsU(α,β) encountered in the three main\n",
            "scenario for Kantorovich OT. Chapter ??is dedicated to the semi-discrete setup.\n",
            "⇡\u0000↵\n",
            "⇡\u0000↵\n",
            "Figure 1.6: Left: “continuous” coupling πsolving (1.13) between two 1-D measure with density. The\n",
            "coupling is localized along the graph of the Monge map ( x,T(x)) (displayed in black). Right: “discrete”\n",
            "couplingTsolving (1.11) between two discrete measures of the form (1.6). The non-zero entries Ti,jare\n",
            "display with a black disk at position ( i,j) with radius proportional to Ti,j.\n",
            "Kantorovitch formulation for arbitrary measures. The deﬁnition of Lcin (??) can be extended to\n",
            "arbitrary measures by considering couplings π∈M1\n",
            "+(X×Y ) which are joint distributions over the product\n",
            "space. The discrete case is a special situation where one imposes this product measure to be of the form\n",
            "π=∑\n",
            "i,jPi,jδ(xi,yj). In the general case, the mass conservation constraint (1.10) should be rewritten as a\n",
            "marginal constraint on joint probability distributions\n",
            "U(α,β)def.={\n",
            "π∈M1\n",
            "+(X×Y ) ;PX♯π=αandPY♯π=β}\n",
            ". (1.13)\n",
            "HerePX♯andPY♯are the push-forward (see Deﬁnition 1) by the projections PX(x,y) =xandPY(x,y) =y.\n",
            "Figure 1.5 shows a schematic visualization of the coupling constraints for diﬀerent class of problem (discrete\n",
            "measures and densities). Using (1.3), these marginal constraints are equivalent to imposing that π(A×Y) =\n",
            "α(A) andπ(X×B) =β(B) for setsA⊂X andB⊂Y.\n",
            "The Kantorovich problem (1.11) is then generalized as\n",
            "Lc(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "X×Yc(x,y)dπ(x,y). (1.14)\n",
            "This is an inﬁnite-dimensional linear program over a space of measures. Figure 1.6 shows examples of discrete\n",
            "and continuous optimal coupling solving (1.14). Figure 1.7 shows other examples of optimal 1-D couplings,\n",
            "involving discrete and continuous marginals.\n",
            "On compact domain ( X,Y), (1.14) always has a solution, because using the weak-* topology (so called\n",
            "weak topology of measures), the set of measure is compact, and a linear function with a continuous c(x,y)\n",
            "9\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "↵\u0000↵⇡\u0000Figure 1.7: Four simple examples of optimal couplings between 1-D distributions, represented as maps\n",
            "above (arrows) and couplings below. Inspired by [ ?].\n",
            "is weak-* continuous. And the set of constraint is non empty, taking α⊗β. On non compact domain, needs\n",
            "to impose moment condition on αandβ.\n",
            "Wasserstein distances. An important feature of OT is that it deﬁnes a distance between histograms\n",
            "and probability measures as soon as the cost matrix satisﬁes certain suitable properties. Indeed, OT can be\n",
            "understood as a canonical way to lift a ground distance between points to a distance between histogram or\n",
            "measures.\n",
            "We ﬁrst consider the case where, using a term ﬁrst introduce by [ ?], the “ground metric” matrix C\n",
            "is ﬁxed, representing substitution costs between bins, and shared across several histograms we would like\n",
            "to compare. The following proposition states that OT provides a meaningful distance between histograms\n",
            "supported on these bins.\n",
            "Proposition 2. We suppose n=m, and that for some p⩾1,C=Dp= (Dp\n",
            "i,j)i,j∈Rn×nwhere D∈Rn×n\n",
            "+\n",
            "is a distance on JnK,i.e.\n",
            "1.D∈Rn×n\n",
            "+ is symmetric;\n",
            "2.Di,j= 0if and only if i=j;\n",
            "3.∀(i,j,k )∈JnK3,Di,k⩽Di,j+Dj,k.\n",
            "Then\n",
            "Wp(a,b)def.= LDp(a,b)1/p(1.15)\n",
            "(note that Wpdepends on D) deﬁnes the p-Wasserstein distance on Σn,i.e. Wpis symmetric, positive,\n",
            "Wp(a,b) = 0 if and only if a=b, and it satisﬁes the triangle inequality\n",
            "∀a,a′,b∈Σn,Wp(a,b)⩽Wp(a,a′) + Wp(a′,b).\n",
            "Proof. Symmetry and deﬁniteness of the distance are easy to prove: since C=Dphas a null diagonal,\n",
            "Wp(a,a) = 0, with corresponding optimal transport matrix P⋆= diag( a); by the positivity of all oﬀ-diagonal\n",
            "elements of Dp, Wp(a,b)>0 whenever a̸=b(because in this case, an admissible coupling necessarily has\n",
            "a non-zero element outside the diagonal); by symmetry of Dp, Wp(a,b) = 0 is itself a symmetric function.\n",
            "To prove the triangle inequality of Wasserstein distances for arbitrary measures, [ ?, Theorem 7.3] uses the\n",
            "gluing lemma, which stresses the existence of couplings with a prescribed structure. In the discrete setting,\n",
            "the explicit constuction of this glued coupling is simple. Let a,b,c∈Σn. Let PandQbe two optimal\n",
            "solutions of the transport problems between aandb, and bandcrespectively. We deﬁne ¯bjdef.=bjifbj>0\n",
            "and set otherwise ¯bj= 1 (or actually any other value). We then deﬁne\n",
            "Sdef.=Pdiag(1/¯b)Q∈Rn×n\n",
            "+.\n",
            "10\n",
            "We remark that S∈U(a,c) because\n",
            "S1n=Pdiag(1/¯b)Q1n=P(b/¯b) =P1Supp( b)=a\n",
            "where we denoted 1Supp( b)the indicator of the support of b, and we use the fact that P1Supp( b)=P1=b\n",
            "because necessarily Pi,j= 0 forj /∈Supp( b). Similarly one veriﬁes that S⊤1n=c.\n",
            "The triangle inequality follows from\n",
            "Wp(a,c) =(\n",
            "min\n",
            "P∈U(a,c)⟨P,Dp⟩)1/p\n",
            "⩽⟨S,Dp⟩1/p\n",
            "=\n",
            "∑\n",
            "ikDp\n",
            "ik∑\n",
            "jPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "⩽\n",
            "∑\n",
            "ijk(Dij+Djk)pPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "⩽\n",
            "∑\n",
            "ijkDp\n",
            "ijPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "ijkDp\n",
            "jkPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "ijDp\n",
            "ijPij∑\n",
            "kQjk\n",
            "¯bj\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk∑\n",
            "iPij\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "ijDp\n",
            "ijPij\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk\n",
            "1/p\n",
            "= Wp(a,b) + Wp(b,b).\n",
            "The ﬁrst inequality is due to the suboptimality of S, the second is the usual triangle inequality for elements\n",
            "inD, and the third comes from Minkowski’s inequality.\n",
            "Proposition 2 generalizes from histogram to arbitrary measures that need not be discrete.\n",
            "Proposition 3. We assumeX=Y, and that for some p⩾1,c(x,y) =d(x,y)pwheredis a distance on\n",
            "X,i.e.\n",
            "(i)d(x,y) =d(y,x)⩾0;\n",
            "(ii)d(x,y) = 0 if and only if x=y;\n",
            "(ii)∀(x,y,z )∈X3,d(x,z)⩽d(x,y) +d(y,z).\n",
            "Then\n",
            "Wp(α,β)def.=Ldp(α,β)1/p(1.16)\n",
            "(note thatWpdepends on d) deﬁnes the p-Wasserstein distance on X,i.e.Wpis symmetric, positive,\n",
            "Wp(α,β) = 0 if and only if α=β, and it satisﬁes the triangle inequality\n",
            "∀(α,β,γ )∈M1\n",
            "+(X)3,Wp(α,γ)⩽Wp(α,β) +Wp(β,γ).\n",
            "Proof. The proof follows the same approach as that for Proposition 2 and relies on the existence of a coupling\n",
            "between (α,γ) obtained by “guying” optimal couplings between ( α,β) and (β,γ).\n",
            "The Wasserstein distance Wphas many important properties, the most important one being that it is a\n",
            "weak distance, i.e.it allows to compare singular distributions (for instance discrete ones) and to quantify\n",
            "spatial shift between the supports of the distributions. In particular, “classical” distances (or divergences)\n",
            "are not even deﬁned between discrete distributions (the L2norm can only be applied to continuous measures\n",
            "with a density with respect to a base measure, and the discrete ℓ2norm requires the positions ( xi,yj) to\n",
            "be ﬁxed to work). In sharp contrast, one has that for any p >0,Wp\n",
            "p(δx,δy) =d(x,y). Indeed, it suﬃces\n",
            "to notice thatU(δx,δy) ={δx,y}and therefore the Kantorovich problem having only one feasible solution,\n",
            "Wp\n",
            "p(δx,δy) is necessarily ( d(x,y)p)1/p=d(x,y). This shows that Wp(δx,δy)→0 ifx→y. This property\n",
            "corresponds to the fact that Wpis a way to quantify the weak convergence as we now deﬁne.\n",
            "11\n",
            "Deﬁnition 2 (Weak convergence) .(αk)kconverges weakly to αinM1\n",
            "+(X)(denotedαk⇀α ) if and only if\n",
            "for any continuous function g∈C(X),∫\n",
            "Xgdαk→∫\n",
            "Xgdα. This notion of weak convergence corresponds to\n",
            "the convergence in law of random vectors.\n",
            "This convergence can be shown to be equivalent to Wp(αk,α)→0 [?, Theorem 6.8] (together with a\n",
            "convergence of the moments up to order pfor unbounded metric spaces).\n",
            "Note that there exists alternative distances which also metrize weak convergence. The simplest one are\n",
            "Hilbertian norms, deﬁned as\n",
            "||α||2\n",
            "kdef.=Eα⊗α(k) =∫\n",
            "X×Xk(x,y)dα(x)dα(y)\n",
            "for a suitable choice of kernel k:X2→R. The most famous of such kernel is the Gaussian one k(x,y) =\n",
            "e−||x−y||2\n",
            "2σ2for some choice of bandwidth σ>0.\n",
            "This convergence should not be confounded with the strong convergence of measures, which is metrized\n",
            "by the TV norm ||α||TVdef.=|α|(X), which is the total mass of the absolute value of the measure.\n",
            "Algorithms Since ( ??)ˆA is a linear program, it is possible to use any classical linear program solver, such\n",
            "as interior point methods or simplex. In practice, the network simplex is an eﬃcient option, and it used\n",
            "pivoting rule adapted to the OT constraint set. In the case of the assignment problem, a=b=1n/n, there\n",
            "exists faster combinatorial optimization scheme, the most famous ones being the Hungarian algorithm and\n",
            "the auction algorithm, which have roughly O(n3) complexity. Section 1.5 details an approximate algorithm,\n",
            "which is typically faster, and amenable to parallelisation, but do not compute exactly the solution to the\n",
            "OT problem.\n",
            "1.4 Duality\n",
            "The Kantorovich problem (1.11) is a constrained convex minimization problem, and as such, it can be\n",
            "naturally paired with a so-called dual problem, which is a constrained concave maximization problem. The\n",
            "following fundamental proposition, which is a special case of Fenchel-Rockafellar duality theory, explains the\n",
            "relationship between the primal and dual problems.\n",
            "Proposition 4. One has\n",
            "LC(a,b) = max\n",
            "(f,g)∈R(a,b)⟨f,a⟩+⟨g,b⟩ (1.17)\n",
            "where the set of admissible potentials is\n",
            "R(a,b)def.={(f,g)∈Rn×Rm;∀(i,j)∈JnK×JmK,f⊕g⩽C} (1.18)\n",
            "Proof. This result is a direct consequence of the more general result on the strong duality for linear pro-\n",
            "grams [ ?, p.148,Theo.4.4]. The easier part of that result, namely that the right-hand side of Equation (1.17)\n",
            "is a lower bound on L C(a,b) is discussed in ??. For the sake of completeness, let us derive this dual problem\n",
            "with the use of Lagrangian duality. The Lagangian associate to (1.11) reads\n",
            "min\n",
            "P⩾0max\n",
            "(f,g)∈Rn×Rm⟨C,P⟩+⟨a−P1m,f⟩+⟨b−P⊤1n,g⟩. (1.19)\n",
            "For linear program, one can always exchange the min and the max and get the same value of the linear\n",
            "program, and one thus consider\n",
            "max\n",
            "(f,g)∈Rn×Rm⟨a,f⟩+⟨b,g⟩+ min\n",
            "P⩾0⟨C−f1⊤\n",
            "m−1ng⊤,P⟩.\n",
            "We conclude by remarking that\n",
            "min\n",
            "P⩾0⟨Q,P⟩={0 if Q⩾0\n",
            "−∞ otherwise\n",
            "so that the constraint reads C−f1⊤\n",
            "m−1ng⊤=C−f⊕g⩾0.\n",
            "12\n",
            "The primal-dual optimality relation for the Lagrangian (1.19) allows to locate the support of the optimal\n",
            "transport plan\n",
            "Supp( P)⊂{\n",
            "(i,j)∈JnK×JmK;fi+gj=Ci,j}\n",
            ". (1.20)\n",
            "To extend this primal-dual construction to arbitrary measures, it is important to realize that measures\n",
            "are naturally paired in duality with continuous functions (a measure can only be accessed through integration\n",
            "against continuous functions). The duality is formalized in the following proposition, which boils down to\n",
            "Proposition 4 when dealing with discrete measures.\n",
            "Proposition 5. One has\n",
            "Lc(α,β) = max\n",
            "(f,g)∈R(c)∫\n",
            "Xf(x)dα(x) +∫\n",
            "Yg(y)dβ(y), (1.21)\n",
            "where the set of admissible dual potentials is\n",
            "R(c)def.={(f,g)∈C(X)×C(Y) ;∀(x,y),f(x) +g(y)⩽c(x,y)}. (1.22)\n",
            "Here, (f,g)is a pair of continuous functions, and are often called “Kantorovich potentials”.\n",
            "The discrete case (1.17) corresponds to the dual vectors being samples of the continuous potentials, i.e.\n",
            "(fi,gj) = (f(xi),g(yj)). The primal-dual optimality conditions allow to track the support of optimal plan,\n",
            "and (1.20) is generalized as\n",
            "Supp(π)⊂{(x,y)∈X×Y ;f(x) +g(y) =c(x,y)}. (1.23)\n",
            "Note that in contrast to the primal problem (1.14), showing the existence of solutions to (1.21) is non-\n",
            "trivial, because the constraint set R(c) is not compact and the function to minimize non-coercive. Using the\n",
            "machinery of c-transform detailed in Section ??, one can however show that optimal ( f,g) are necessarily\n",
            "Lipschitz regular, which enable to replace the constraint by a compact one.\n",
            "Benier’s Theorem and Monge-Amp` ere PDE The following celebrated theorem of [ ?] ensures that in\n",
            "Rdforp= 2, if at least one of the two inputs measures has a density, then Kantorovitch and Monge problems\n",
            "are equivalent.\n",
            "Theorem 1 (Brenier) .In the caseX=Y=Rdandc(x,y) =||x−y||2, if at least one of the two inputs\n",
            "measures (denoted α) has a density ραwith respect to the Lebesgue measure, then the optimal πin the\n",
            "Kantorovich formulation (1.14) is unique, and is supported on the graph (x,T(x))of a “Monge map” T:\n",
            "Rd→Rd. This means that π= (Id,T)♯µ,i.e.\n",
            "∀h∈C(X×Y ),∫\n",
            "X×Yh(x,y)dπ(x,y) =∫\n",
            "Xh(x,T(x))dµ(x). (1.24)\n",
            "Furthermore, this map Tis uniquely deﬁned as the gradient of a convex function ϕ,T(x) =∇ϕ(x), where\n",
            "ϕis the unique (up to an additive constant) convex function such that (∇ϕ)♯µ=ν. This convex function is\n",
            "related to the dual potential fsolving (1.21) asϕ(x) =||x||2\n",
            "2−f(x).\n",
            "Proof. We sketch the main ingredients of the proof, more details can be found for instance in [ ?]. We remark\n",
            "that∫\n",
            "cdπ=Cα,β−2∫\n",
            "⟨x, y⟩dπ(x,y) where the constant is Cα,β=∫\n",
            "||x||2dα(x) +∫\n",
            "||y||2dβ(y). Instead of\n",
            "solving (1.14), one can thus consider the following problem\n",
            "max\n",
            "π∈U(α,β)∫\n",
            "X×Y⟨x, y⟩dπ(x,y),\n",
            "whose dual reads\n",
            "min\n",
            "(ϕ,ψ){∫\n",
            "Xϕdα+∫\n",
            "Yψdβ;∀(x,y), ϕ (x) +ψ(y)⩾⟨x, y⟩}\n",
            ". (1.25)\n",
            "13\n",
            "The relation between these variables and those of (1.22) is ( ϕ,ψ) = (||·||2\n",
            "2−f,||·||2\n",
            "2−g). One can replace the\n",
            "constraint by\n",
            "∀y, ψ (y)⩾ϕ∗(y)def.= sup\n",
            "x⟨x, y⟩−ϕ(x). (1.26)\n",
            "Hereϕ∗is the Legendre transform of ϕand is a convex function as a supremum of linear forms (see\n",
            "also ( ??)). Since the objective appearing in (1.27) is linear and the integrating measures positive, one can\n",
            "minimize explicitly with respect to ϕand setψ=ϕ∗in order to consider the unconstraint problem\n",
            "min\n",
            "ϕ∫\n",
            "Xϕdα+∫\n",
            "Yϕ∗dβ, (1.27)\n",
            "see also Section ??for a generalization of this idea to generic costs c(x,y). By iterating this argument\n",
            "twice, one can replace ϕbyϕ∗∗, which is a convex function, and thus impose in (1.27) that ϕis convex.\n",
            "Condition (1.23) shows that an optimal πis supported on{(x,y) ;ϕ(x) +ϕ∗(y) =⟨x, y⟩}which shows that\n",
            "such anyis optimal for the minimization (1.26) of the Legendre transform, whose optimality condition reads\n",
            "y∈∂ϕ(x). Sinceϕis convex, it is diﬀerentiable almost everywhere, and since αhas a density, it is also\n",
            "diﬀerentiable α-almost everywhere. This shows that for each x, the associated yis uniquely deﬁned α-almost\n",
            "everywhere as y=∇ϕ(x), and shows that necessarily π= (Id,∇ϕ)♯α.\n",
            "This results shows that in the setting of W2with non-singular densities, the Monge problem (1.9)\n",
            "and its Kantorovich relaxation (1.14) are equal (the relaxation is tight). This is the continuous analog\n",
            "of Proposition 1 for the assignment case (1), which states that the minimum of the optimal transport\n",
            "problem is achieved, when the marginals are equal and uniform, at a permutation matrix (a discrete map).\n",
            "Brenier’s theorem, stating that an optimal transport map must be the gradient of a convex function, should\n",
            "be examined under the light that a convex function is the natural generalization of the notion of increasing\n",
            "functions in dimension more than one. Optimal transport can thus plays an important role to deﬁne quantile\n",
            "functions in arbitrary dimensions, which in turn is useful for applications to quantile regression problems [ ?].\n",
            "Note also that this theorem can be extended in many directions. The condition that αhas a density can\n",
            "be weakened to the condition that it does not give mass to “small sets” having Hausdorﬀ dimension smaller\n",
            "thand−1 (e.g. hypersurfaces). One can also consider costs of the form c(x,y) =h(x−y) wherehis a\n",
            "strictly convex function.\n",
            "For measures with densities, using (1.4), one obtains that ϕis the unique (up to the addition of a\n",
            "constant) convex function which solves the following Monge-Amp ˜A¨re-type equation\n",
            "det(∂2ϕ(x))ρβ(∇ϕ(x)) =ρα(x) (1.28)\n",
            "where∂2ϕ(x)∈Rd×dis the hessian of ϕ. The Monge-Amp` ere operator det( ∂2ϕ(x)) can be understood as a\n",
            "non-linear degenerate Laplacian. In the limit of small displacements, ϕ= Id +εϕ, one indeed recovers the\n",
            "Laplacian ∆ as a linearization since for smooth maps\n",
            "det(∂2ϕ(x)) = 1 +ε∆ϕ(x) +o(ε).\n",
            "The convexity constraint forces det( ∂2ϕ(x))⩾0 and is necessary for this equation to have a solution.\n",
            "Special cases In general, computing OT distances is numerically involved. We review special favorable\n",
            "cases where the resolution of the OT problem is easy.\n",
            "Remark 6 (Binary Cost Matrix and 1-Norm) .One can easily check that when the cost matrix Cis zero on\n",
            "the diagonal and 1 elsewhere, namely when C=1n×n−In, the OT distance between aandbis equal to\n",
            "the 1-norm of their diﬀerence, L C(a,b) =||a−b||1. One can also easily check that this result extends to\n",
            "discrete and discrete measures in the case where c(x,y) is 0 ifx=yand 1 when x̸=y. The OT distance\n",
            "between two discrete measures αandβis equal to their total variation distance.\n",
            "14\n",
            "\u0000\u0000↵Figure 1.8: 1-D optimal couplings: each arrow xi→yjindicate a non-zero Pi,jin the optimal coupling.\n",
            "Top: empirical measures with same number of points (optimal matching). Bottom: generic case. This\n",
            "corresponds to monotone rearrangements, if xi⩽xi′are such that Pi,j̸= 0,Pi′,j′̸= 0, then necessarily\n",
            "yj⩽yj′.\n",
            "Remark 7 (1-D case – Empirical measures) .HereX=R. Assuming α=1\n",
            "n∑n\n",
            "i=1δxiandβ=1\n",
            "n∑n\n",
            "j=1δyj,\n",
            "and assuming (without loss of generality) that the points are ordered, i.e.x1⩽x2⩽...⩽xnand\n",
            "y1⩽y2⩽...⩽yn, then one has the simple formula\n",
            "Wp(α,β)p=p∑\n",
            "i=1|xi−yi|p, (1.29)\n",
            "i.e.locally (if one assumes distinct points), Wp(α,β) is theℓpnorm between two vectors of ordered values of\n",
            "αandβ. That statement is only valid locally, in the sense that the order (and those vector representations)\n",
            "might change whenever some of the values change. That formula is a simple consequence of the more general\n",
            "remark given below. Figure 1.8, top row, illustrates the 1-D transportation map between empirical measures\n",
            "with the same number of points. The bottom row shows how this monotone map generalizes to arbitrary\n",
            "discrete measures. It is possible to leverage this 1-D computation to also compute eﬃciently OT on the\n",
            "circle, see [ ?]. Note that in the case of concave cost of the distance, for instance when p<1, the behaviour\n",
            "of the optimal transport plan is very diﬀerent, see [ ?], which describes an eﬃcient solver in this case.\n",
            "Remark 8 (1-D case – Generic case) .For a measure αonR, we introduce the cumulative function\n",
            "∀x∈R,Cα(x)def.=∫x\n",
            "−∞dα, (1.30)\n",
            "which is a function Cα:R→[0,1], and its pseudo-inverse C−1\n",
            "α: [0,1]→R∪{−∞}\n",
            "∀r∈[0,1],C−1\n",
            "α(r) = min\n",
            "x{x∈R∪{−∞} ;Cα(x)⩾r}.\n",
            "That function is also called the generalized quantile function of α. For anyp⩾1, one has\n",
            "Wp(α,β)p=||C−1\n",
            "α−C−1\n",
            "β||p\n",
            "Lp([0,1])=∫1\n",
            "0|C−1\n",
            "α(r)−C−1\n",
            "β(r)|pdr. (1.31)\n",
            "This means that through the map α↦→C−1\n",
            "α, the Wasserstein distance is isometric to a linear space equipped\n",
            "with theLpnorm, or, equivalently, that the Wasserstein distance for measures on the real line is a Hilbertian\n",
            "metric. This makes the geometry of 1-D optimal transport very simple, but also very diﬀerent from its\n",
            "geometry in higher dimensions, which is not Hilbertian as discussed in Proposition ??and more generally\n",
            "in§??. Forp= 1, one even has the simpler formula\n",
            "W1(α,β) =||Cα−Cβ||L1(R)=∫\n",
            "R|Cα(x)−Cβ(x)|dx (1.32)\n",
            "=∫\n",
            "R⏐⏐⏐⏐∫x\n",
            "−∞d(α−β)⏐⏐⏐⏐dx. (1.33)\n",
            "15\n",
            "µ ν (tT+ (1−t)Id)♯µ\n",
            "0 0.5 10.5Cµ\n",
            "Cν\n",
            "0 0.5 100.51\n",
            "Cµ-1\n",
            "Cν-1\n",
            "0 0.5 100.51\n",
            "T\n",
            "T-1\n",
            "0 0.5 100.51\n",
            "(Cα,Cβ) (C−1\n",
            "α,C−1\n",
            "β) ( T,T−1) (1−t)C−1\n",
            "α+tC−1\n",
            "β\n",
            "Figure 1.9: Computation of OT and displacement interpolation between two 1-D measures, using cumulant\n",
            "function as detailed in (1.34).\n",
            "which shows that W1is a norm (see§??for the generalization to arbitrary dimensions). An optimal Monge\n",
            "mapTsuch thatT♯α=βis then deﬁned by\n",
            "T=C−1\n",
            "β◦Cα. (1.34)\n",
            "Figure 1.9 illustrates the computation of 1-D OT through cumulative functions. It also displays displacement\n",
            "interpolations, computed as detailed in ( ??), see also Remark ??. For a detailed survey of the properties of\n",
            "optimal transport in 1-D, we refer the reader to [ ?, Chapter 2].\n",
            "Remark 9 (Distance between Gaussians) .Ifα=N(mα,Σα) andβ=N(mβ,Σβ) are two Gaussians in Rd,\n",
            "then one can show that the following map\n",
            "T:x↦→mβ+A(x−mα), (1.35)\n",
            "where\n",
            "A=Σ−1\n",
            "2α(\n",
            "Σ1\n",
            "2αΣβΣ1\n",
            "2α)1\n",
            "2Σ−1\n",
            "2α=AT,\n",
            "is such that T♯ρα=ρβ. Indeed, one simply has to notice that the change of variables formula (1.4) is satisﬁed\n",
            "since\n",
            "ρβ(T(x)) = det(2πΣβ)−1\n",
            "2exp(−⟨T(x)−mβ,Σ−1\n",
            "β(T(x)−mβ)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα, ATΣ−1\n",
            "βA(x−mα)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα,Σ−1\n",
            "α(x−mα)⟩),\n",
            "and sinceTis a linear map we have that\n",
            "|detT′(x)|= detA=(detΣβ\n",
            "detΣα)1\n",
            "2\n",
            "and we therefore recover ρα=|detT′|ρβmeaningT♯α=β. Notice now that Tis the gradient of the convex\n",
            "functionψ:x↦→1\n",
            "2⟨x−mα, A(x−mα)⟩+⟨mβ, x⟩to conclude, using Brenier’s theorem [ ?] (see Remark ??)\n",
            "thatTis optimal. Both that map Tand the corresponding potential ψare illustrated in Figures 1.10 and ??\n",
            "16\n",
            "-4 -2 0 2 4 6-3-2-101234\n",
            "ρβραFigure 1.10: Two Gaussians ραandρβ, represented using the contour plots of their densities, with respective\n",
            "mean and variance matrices mα= (−2,0),Σα=1\n",
            "2(\n",
            "1−1\n",
            "2;−1\n",
            "21)\n",
            "andmβ= (3,1),Σβ=(\n",
            "2,1\n",
            "2;1\n",
            "2,1)\n",
            ". The\n",
            "arrows originate at random points xtaken on the plane and end at the corresponding mappings of those\n",
            "pointsT(x) =mβ+A(x−mα).\n",
            "\u0000m\n",
            "Figure 1.11: Computation of displacement interpolation between two 1-D Gaussians. Denoting Gm,σ(x)def.=\n",
            "1√\n",
            "2πse−(x−m)2\n",
            "2s2the Gaussian density, it thus shows the interpolation G(1−t)m0+tm1,(1−t)σ0+tσ1.\n",
            "With additional calculations involving ﬁrst and second order moments of ρα, we obtain that the transport\n",
            "cost of that map is\n",
            "W2\n",
            "2(α,β) =||mα−mβ||2+B(Σα,Σβ)2(1.36)\n",
            "whereBis the so-called Bures’ metric [ ?] between positive deﬁnite matrices (see also [ ?,?]),\n",
            "B(Σα,Σβ)2def.= tr(\n",
            "Σα+Σβ−2(Σ1/2\n",
            "αΣβΣ1/2\n",
            "α)1/2)\n",
            ", (1.37)\n",
            "where Σ1/2is the matrix square root. One can show that Bis a distance on covariance matrices, and that\n",
            "B2is convex with respect to both its arguments. In the case where Σα= diag(ri)iandΣβ= diag(si)iare\n",
            "diagonals, the Bures metric is the Hellinger distance\n",
            "B(Σα,Σβ) =||√r−√s||2.\n",
            "For 1-D Gaussians, W2is thus the Euclidean distance on the 2-D plane ( m,√\n",
            "Σ), as illustrated in Figure 1.11.\n",
            "For a detailed treatment of the Wasserstein geometry of Gaussian distributions, we refer to [ ?].\n",
            "1.5 Sinkhorn\n",
            "This section introduces a family of numerical scheme to approximate solutions to Kantorovich formulation\n",
            "of optimal transport and its many generalizations. It operates by adding an entropic regularization penalty to\n",
            "the original problem. This regularization has several important advantages, but a few stand out particularly:\n",
            "The minimization of the regularized problen can be solved using a simple alternate minimization scheme;\n",
            "that scheme translates into iterations that are simple matrix products, making them particularly suited to\n",
            "execution of GPU; the resulting approximate distance is smooth with respect to input histogram weights\n",
            "and positions of the Diracs.\n",
            "17\n",
            "c\"P\"Figure 1.12: Impact of εon the optimization of a linear function on the simplex, solving Pε=\n",
            "argminP∈Σ3⟨C,P⟩−εH(P) for a varying ε.\n",
            "Entropic Regularization. The discrete entropy of a coupling matrix is deﬁned as\n",
            "H(P)def.=−∑\n",
            "i,jPi,j(log(Pi,j)−1), (1.38)\n",
            "with an analogous deﬁnition for vectors, with the convention that H(a) =−∞ if one of the entries ajis\n",
            "0 or negative. The function His 1-strongly concave, because its hessian is ∂2H(P) =−diag(1/Pi,j) and\n",
            "Pi,j⩽1. The idea of the entropic regularization of optimal transport is to use −Has a regularizing function\n",
            "to obtain approximate solutions to the original transport problem (1.11):\n",
            "Lε\n",
            "C(a,b)def.= min\n",
            "P∈U(a,b)⟨P,C⟩−εH(P). (1.39)\n",
            "Since the objective is a ε-strongly convex function, problem 1.39 has a unique optimal solution. The idea\n",
            "to regularize the optimal transport problem by an entropic term can be traced back to modeling ideas in\n",
            "transportation theory [ ?]: Actual traﬃc patterns in a network do not agree with those predicted by the\n",
            "solution of the optimal transport problem. Indeed, the former are more diﬀuse than the latter, which tend\n",
            "to rely on a few routes as a result of the sparsity of optimal couplings to the solution of 1.11. To balance for\n",
            "that, researchers in transportation proposed a model, called the “gravity” model [ ?], that is able to form a\n",
            "more “blurred” traﬃc prediction.\n",
            "Figure 1.12 illustrates the eﬀect of the entropy to regularize a linear program over the simples Σ 3(which\n",
            "can thus be visualized as a triangle in 2-D). Note how the entropy pushes the original LP solution away\n",
            "from the boundary of the triangle. The optimal Pεprogressively moves toward an “entropic center” of the\n",
            "triangle. This is further detailed in the proposition below. The convergence of the solution of that regularized\n",
            "problem towards an optimal solution of the original linear program has been studied by [ ?].\n",
            "Proposition 6 (Convergence with ε).The unique solution Pεof(1.39) converges to the optimal solution\n",
            "with maximal entropy within the set of all optimal solutions of the Kantorovich problem, namely\n",
            "Pεε→0−→argmin\n",
            "P{−H(P) ;P∈U(a,b),⟨P,C⟩= LC(a,b)} (1.40)\n",
            "so that in particular\n",
            "Lε\n",
            "C(a,b)ε→0−→LC(a,b).\n",
            "One has\n",
            "Pεε→∞−→abT= (aibj)i,j. (1.41)\n",
            "Proof. We consider a sequence ( εℓ)ℓsuch thatεℓ→0 andεℓ>0. We denote Pℓthe solution of (1.39) for\n",
            "ε=εℓ. Since U(a,b) is bounded, we can extract a sequence (that we do not relabel for sake of simplicity)\n",
            "such that Pℓ→P⋆. Since U(a,b) is closed, P⋆∈U(a,b). We consider any Psuch that⟨C,P⟩= LC(a,b).\n",
            "By optimality of PandPℓfor their respective optimization problems (for ε= 0 andε=εℓ), one has\n",
            "0⩽⟨C,Pℓ⟩−⟨C,P⟩⩽εℓ(H(Pℓ)−H(P)). (1.42)\n",
            "18\n",
            "⇡\"↵\u0000\n",
            "\"\u0000↵Figure 1.13: Impact of εon coupling between densities and discrete distributions, illustrating Proposition 6.\n",
            "Left: between two 1-D densities. Right: between two 2-D discrete empirical densities with same number\n",
            "n=mof points (only entries of the optimal ( Pi,j)i,jabove a small threshold are displayed as segments\n",
            "betweenxiandyj).\n",
            "Since His continuous, taking the limit ℓ→+∞in this expression shows that ⟨C,P⋆⟩=⟨C,P⟩so that\n",
            "P⋆is a feasible point of (1.40). Furthermore, dividing by εℓin (1.42) and taking the limit shows that\n",
            "H(P)⩽H(P⋆), which shows that P⋆is a solution of (1.40). Since the solution P⋆\n",
            "0to this program is unique\n",
            "by strict convexity of −H, one has P⋆=P⋆\n",
            "0, and the whole sequence is converging.\n",
            "Formula (1.40) states that for low regularization, the solution converges to the maximum entropy optimal\n",
            "transport coupling. In sharp contrast, (1.41) shows that for large regularization, the solution converges to the\n",
            "coupling with maximal entropy between two prescribed marginals a,b, namely the joint probability between\n",
            "two independent random variables with prescribed distributions. A reﬁned analysis of this convergence is\n",
            "performed in [ ?], including a ﬁrst order expansion in ε(resp. 1/ε) nearε= 0 (respε= +∞). Figure 1.13\n",
            "shows visually the eﬀect of these two convergence. A key insight is that, as εincreases, the optimal coupling\n",
            "becomes less and less sparse (in the sense of having entries larger than a prescribed thresholds), which in\n",
            "turn as the eﬀect of both accelerating computational algorithms (as we study in §1.5) but also leading to\n",
            "faster statistical convergence (as exposed in §??).\n",
            "Deﬁning the Kullback-Leibler divergence between couplings as\n",
            "KL(P|K)def.=∑\n",
            "i,jPi,jlog(Pi,j\n",
            "Ki,j)\n",
            "−Pi,j+Ki,j, (1.43)\n",
            "the unique solution Pεof (1.39) is a projection onto U(a,b) of the Gibbs kernel associated to the cost matrix\n",
            "Cas\n",
            "Ki,jdef.=e−Ci,j\n",
            "ε\n",
            "Indeed one has that using the deﬁnition above\n",
            "Pε= ProjKL\n",
            "U(a,b)(K)def.= argmin\n",
            "P∈U(a,b)KL(P|K). (1.44)\n",
            "Remark 10 (General formulation) .One can consider arbitrary measures by replacing the discrete entropy\n",
            "by the relative entropy with respect to the product measure d α⊗dβ(x,y)def.= dα(x)dβ(y), and propose a\n",
            "regularized counterpart to (1.14) using\n",
            "Lε\n",
            "c(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "X×Yc(x,y)dπ(x,y) +εKL(π|α⊗β) (1.45)\n",
            "where the relative entropy is a generalization of the discrete Kullback-Leibler divergence (1.43)\n",
            "KL(π|ξ)def.=∫\n",
            "X×Ylog(dπ\n",
            "dξ(x,y))\n",
            "dπ(x,y)+\n",
            "∫\n",
            "X×Y(dξ(x,y)−dπ(x,y)),(1.46)\n",
            "19\n",
            "and by convention KL( π|ξ) = +∞ifπdoes not have a densitydπ\n",
            "dξwith respect to ξ. It is important to\n",
            "realize that the reference measure α⊗βchosen in (1.45) to deﬁne the entropic regularizing term KL( ·|α⊗β)\n",
            "plays no speciﬁc role, only its support matters.\n",
            "Formula (1.45) can be re-factored as a projection problem\n",
            "min\n",
            "π∈U(α,β)KL(π|K) (1.47)\n",
            "whereKis the Gibbs distributions d K(x,y)def.=e−c(x,y)\n",
            "εdµ(x)dν(y). This problem is often referred to as the\n",
            "“static Schr¨ odinger problem” [ ?,?], since it was initially considered by Schr¨ odinger in statistical physics [ ?].\n",
            "Asε→0, the unique solution to (1.47) converges to the maximum entropy solution to (1.14), see [ ?,?].§??\n",
            "details an alternate “dynamic” formulation of the Schr¨ odinger problem over the space of paths connecting\n",
            "the points of two measures.\n",
            "Sinkhorn’s Algorithm The following proposition shows that the solution of (1.39) has a speciﬁc form,\n",
            "which can be parameterized using n+mvariables. That parameterization is therefore essentially dual, in\n",
            "the sense that a coupling PinU(a,b) hasnmvariables but n+mconstraints.\n",
            "Proposition 7. The solution to (1.39) is unique and has the form\n",
            "∀(i,j)∈JnK×JmK,Pi,j=uiKi,jvj (1.48)\n",
            "for two (unknown) scaling variable (u,v)∈Rn\n",
            "+×Rm\n",
            "+.\n",
            "Proof. Introducing two dual variables f∈Rn,g∈Rmfor each marginal constraint, the Lagrangian of (1.39)\n",
            "reads\n",
            "E(P,f,g) =⟨P,C⟩−εH(P)−⟨f,P1m−a⟩−⟨g,PT1n−b⟩.\n",
            "Considering ﬁrst order conditions, we have\n",
            "∂E(P,f,g)\n",
            "∂Pi,j=Ci,j−εlog(Pi,j)−fi−gj.\n",
            "which results, for an optimal Pcoupling to the regularized problem, in the expression Pi,j=efi/εe−Ci,j/εegj/ε\n",
            "which can be rewritten in the form provided in the proposition using non-negative vectors uandv.\n",
            "The factorization of the optimal solution exhibited in Equation (1.48) can be conveniently rewritten in\n",
            "matrix form as P= diag( u)Kdiag(v).u,vmust therefore satisfy the following non-linear equations which\n",
            "correspond to the mass conservation constraints inherent to U(a,b),\n",
            "diag(u)Kdiag(v)1m=a,and diag( v)K⊤diag(u)1n=b, (1.49)\n",
            "These two equations can be further simpliﬁed, since diag( v)1mis simply v, and the multiplication of diag( u)\n",
            "times Kvis\n",
            "u⊙(Kv) =aand v⊙(KTu) =b (1.50)\n",
            "where⊙corresponds to entry-wise multiplication of vectors. That problem is known in the numerical analysis\n",
            "community as the matrix scaling problem (see [ ?] and references therein). An intuitive way to try to solve\n",
            "these equations is to solve them iteratively, by modifying ﬁrst uso that it satisﬁes the left-hand side of\n",
            "Equation (1.50) and then vto satisfy its right-hand side. These two updates deﬁne Sinkhorn’s algorithm:\n",
            "u(ℓ+1)def.=a\n",
            "Kv(ℓ)and v(ℓ+1)def.=b\n",
            "KTu(ℓ+1), (1.51)\n",
            "initialized with an arbitrary positive vector v(0)=1m. The division operator used above between two\n",
            "vectors is to be understood entry-wise. Note that a diﬀerent initialization will likely lead to a diﬀerent\n",
            "20\n",
            "`⇡(`)\"\n",
            "1000 2000 3000 4000 5000-2-1.5-1-0.50`Figure 1.14: Left: evolution of the coupling πℓ\n",
            "ε= diag( U(ℓ))Kdiag(V(ℓ)) computed at iteration ℓof\n",
            "Sinkhorn’s iterations, for 1-D densities. Right: impact of εthe convergence rate of Sinkhorn, as measured\n",
            "in term of marginal constraint violation log( ||πℓ\n",
            "ε1m−b||1).\n",
            "solution for u,v, since u,vare only deﬁned up to a multiplicative constant (if u,vsatisfy (1.49) then\n",
            "so doλu,v/λfor anyλ > 0). It turns out however that these iterations converge (see Remark 11 for\n",
            "a justiﬁcation using iterative projections, and Remark 13 for a strict contraction result) and all result in\n",
            "the same optimal coupling diag( u)Kdiag(v). Figure 1.14, top row, shows the evolution of the coupling\n",
            "diag(U(ℓ))Kdiag(V(ℓ)) computed by Sinkhorn iterations. It evolves from the Gibbs kernel Ktowards the\n",
            "optimal coupling solving (1.39) by progressively shifting the mass away from the diagonal.\n",
            "Remark 11 (Relation with iterative projections) .Denoting\n",
            "C1\n",
            "adef.={P;P1m=a}andC2\n",
            "bdef.={\n",
            "P;PT1m=b}\n",
            "the rows and columns constraints, one has U(a,b) =C1\n",
            "a∩C2\n",
            "b. One can use Bregman iterative projections [ ?]\n",
            "P(ℓ+1) def.= ProjKL\n",
            "C1a(P(ℓ)) and P(ℓ+2) def.= ProjKL\n",
            "C2\n",
            "b(P(ℓ+1)). (1.52)\n",
            "Since the setsC1\n",
            "aandC2\n",
            "bare aﬃne, these iterations are known to converge to the solution of (1.44), see [ ?].\n",
            "These iterate are equivalent to Sinkhorn iterations (1.51) since deﬁning\n",
            "P(2ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)),\n",
            "one has\n",
            "P(2ℓ+1) def.= diag( u(ℓ+1))Kdiag(v(ℓ))\n",
            "and P(2ℓ+2) def.= diag( u(ℓ+1))Kdiag(v(ℓ+1))\n",
            "In practice however one should prefer using (1.51) which only requires manipulating scaling vectors and\n",
            "multiplication against a Gibbs kernel, which can often be accelerated (see below Remarks ??and??).\n",
            "Remark 12 (Hilbert metric) .As initially explained by [ ?], the global convergence analysis of Sinkhorn is\n",
            "greatly simpliﬁed using Hilbert projective metric on Rn\n",
            "+,∗(positive vectors), deﬁned as\n",
            "∀(u,u′)∈(Rn\n",
            "+,∗)2, dH(u,u′)def.= log max\n",
            "i,i′uiu′\n",
            "i′\n",
            "ui′u′\n",
            "i.\n",
            "This can be shows to be a distance on the projective cone Rn\n",
            "+,∗/∼, where u∼u′means that∃s>0,u=su′\n",
            "(the vector are equal up to rescaling, hence the naming “projective”). This means that dHsatisﬁes the\n",
            "triangular inequality and dH(u,u′) = 0 if and only if u∼u′. This is a projective version of Hilbert’s original\n",
            "distance on bounded open convex sets [ ?]. The projective cone Rn\n",
            "+,∗/∼is a complete metric space for this\n",
            "distance. It was introduced independently by [ ?] and [ ?] to provide a quantitative proof of Perron-Frobenius\n",
            "theorem, which, as explained in Remark ??is linked to a local linearization of Sinkhorn’s iterates. They\n",
            "proved the following fundamental theorem, which shows that a positive matrix is a strict contraction on the\n",
            "cone of positive vectors.\n",
            "21\n",
            "Theorem 2. Let K∈Rn×m\n",
            "+,∗, then for (v,v′)∈(Rm\n",
            "+,∗)2\n",
            "dH(Kv,Kv′)⩽λ(K)dH(v,v′)where\n",
            "\n",
            "λ(K)def.=√\n",
            "η(K)−1√\n",
            "η(K)+1<1\n",
            "η(K)def.= max\n",
            "i,j,k,ℓKi,kKj,ℓ\n",
            "Kj,kKi,ℓ.\n",
            "Remark 13 (Global convergence) .The following theorem, proved by [ ?], makes use of this Theorem 2 to\n",
            "show the linear convergence of Sinkhorn’s iterations.\n",
            "Theorem 3. One has (u(ℓ),v(ℓ))→(u⋆,v⋆)and\n",
            "dH(u(ℓ),u⋆) =O(λ(K)2ℓ), dH(v(ℓ),v⋆) =O(λ(K)2ℓ). (1.53)\n",
            "One also has\n",
            "dH(u(ℓ),u⋆)⩽dH(P(ℓ)1m,a)\n",
            "1−λ(K)\n",
            "dH(v(ℓ),v⋆)⩽dH(P(ℓ),⊤1n,b)\n",
            "1−λ(K)(1.54)\n",
            "where we denoted P(ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)). Lastly, one has\n",
            "∥log(P(ℓ))−log(P⋆)∥∞⩽dH(u(ℓ),u⋆) +dH(v(ℓ),v⋆) (1.55)\n",
            "where P⋆is the unique solution of (1.39) .\n",
            "Proof. One notice that for any ( v,v′)∈(Rm\n",
            "+,∗)2, one has\n",
            "dH(v,v′) =dH(v/v′,1m) =dH(1m/v,1m/v′).\n",
            "This shows that\n",
            "dH(u(ℓ+1),u⋆) =dH(a\n",
            "Kv(ℓ),a\n",
            "Kv⋆)\n",
            "=dH(Kv(ℓ),Kv⋆)⩽λ(K)dH(v(ℓ),v⋆).\n",
            "where we used Theorem 2. This shows (1.53). One also has, using the triangular inequality\n",
            "dH(u(ℓ),u⋆)⩽dH(u(ℓ+1),u(ℓ)) +dH(u(ℓ+1),u⋆)\n",
            "⩽dH(a\n",
            "Kv(ℓ),u(ℓ))\n",
            "+λ(K)dH(u(ℓ),u⋆)\n",
            "=dH(\n",
            "a,u(ℓ)⊙(Kv(ℓ)))\n",
            "+λ(K)dH(u(ℓ),u⋆),\n",
            "which gives the ﬁrst part of (1.54) since u(ℓ)⊙(Kv(ℓ)) =P(ℓ)1m(the second one being similar). The proof\n",
            "of (1.55) follows from [ ?, Lemma 3]\n",
            "The bound (1.54) shows that some error measures on the marginal constraints violation, for instance\n",
            "∥P(ℓ)1m−a∥1and∥P(ℓ)T1n−b∥1, are useful stopping criteria to monitor the convergence.\n",
            "Figure 1.14, bottom row, highlights this linear rate on the constraint violation, and shows how this rate\n",
            "degrades as ε→0. These results are proved in [ ?] and are tightly connected to nonlinear Perron-Frobenius\n",
            "Theory [ ?]. Perron-Frobenius theory corresponds to the linearization of the iterations, see ( ??). This\n",
            "convergence analysis is extended in [ ?], who shows that each iteration of Sinkhorn increases the permanent\n",
            "of the scaled coupling matrix.\n",
            "22\n",
            "Regularized Dual and Log-domain Computations The following proposition details the dual problem\n",
            "associated to (1.39).\n",
            "Proposition 8. One has\n",
            "Lε\n",
            "C(a,b) = max\n",
            "f∈Rn,g∈Rm⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩. (1.56)\n",
            "The optimal (f,g)are linked to scalings (u,v)appearing in (1.48) through\n",
            "(u,v) = (ef/ε,eg/ε). (1.57)\n",
            "Proof. We start from the end of the proof of Proposition 7, which links the optimal primal solution P\n",
            "and dual multipliers fandgfor the marginal constraints as Pi,j=efi/εe−Ci,j/εegj/ε. Substituting in the\n",
            "LagrangianE(P,f,g) of Equation (1.5) the optimal Pas a function of fandg, we obtain that the Lagrange\n",
            "dual function equals\n",
            "f,g↦→⟨ef/ε,(K⊙C)eg/ε⟩−εH(diag(ef/ε)Kdiag(eg/ε)). (1.58)\n",
            "The entropy of Pscaled byε, namelyε⟨P,logP−1n×m⟩can be stated explicitly as a function of f,g,C\n",
            "⟨diag(ef/ε)Kdiag(eg/ε),f1mT+1ngT−C−ε1n×m⟩\n",
            "=−⟨ef/ε,(K⊙C)eg/ε⟩+⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩\n",
            "therefore, the ﬁrst term in (1.58) cancels out with the ﬁrst term in the entropy above. The remaining times\n",
            "are those displayed in (1.56).\n",
            "Remark 14.Dual for generic measures For generic (non-necessarily discrete) input measures ( α,β), the dual\n",
            "problem (1.56) reads\n",
            "sup\n",
            "f,g∈C(X)×C(Y)∫\n",
            "Xf(x)dα(x) +∫\n",
            "Yg(x)dβ(x)−ε∫\n",
            "X×Ye−c(x,y)+f(x)+g(y)\n",
            "ε dα(x)dβ(y)\n",
            "This corresponds to a smoothing of the constraint R(c) appearing in the original problem (1.21), which\n",
            "is retrieved in the limit ε→0. Proving existence ( i.e. the sup is actually a max) of these Kantorovich\n",
            "potentials ( f,g) in the case of entropic transport is less easy than for classical OT (because one cannot\n",
            "usec-transform and potentials are not automatically Lipschitz). Proof of existence can be done using the\n",
            "convergence of Sinkhorn iterations, see [ ?] for more details.\n",
            "Remark 15 (Sinkhorn as a Block Coordinate Ascent on the Dual Problem) .A simple approach to solve the\n",
            "unconstrained maximization problem (1.56) is to use an exact block coordinate ascent strategy, namely to\n",
            "update alternatively fandgto cancel their gradients with respect to the objective of (1.56). Indeed, one\n",
            "can easily notice that, writing Q(f,g) for the objective of (1.56) that\n",
            "∇|fQ(f,g) =a−ef/ε⊙(\n",
            "Keg/ε)\n",
            ", (1.59)\n",
            "∇|gQ(f,g) =b−eg/ε⊙(\n",
            "KTef/ε)\n",
            ". (1.60)\n",
            "Block coordinate ascent can therefore be implemented in a closed form by applying successively the following\n",
            "updates, starting from any arbitrary g(0), forl⩾0,\n",
            "f(ℓ+1)=εloga−εlog(\n",
            "Keg(ℓ)/ε)\n",
            ", (1.61)\n",
            "g(ℓ+1)=εlogb−εlog(\n",
            "KTef(ℓ+1)/ε)\n",
            ". (1.62)\n",
            "Such iterations are mathematically equivalent to the Sinkhorn iterations (1.51) when considering the primal-\n",
            "dual relations highlighted in (1.57). Indeed, we recover that at any iteration\n",
            "(f(ℓ),g(ℓ)) =ε(log(u(ℓ)),log(v(ℓ))).\n",
            "23\n",
            "Remark 16 (Soft-min rewriting) .Iterations (1.61) and (1.62) can be given an alternative interpretation,\n",
            "using the following notation. Given a vector zof real numbers we write min εzfor the soft-minimum of its\n",
            "coordinates, namely\n",
            "minεz=−εlog∑\n",
            "ie−zi/ε.\n",
            "Note that min ε(z) converges to min zfor any vector zasε→0. Indeed, min εcan be interpreted as a\n",
            "diﬀerentiable approximation of the min function. Using these notations, Equations (1.61) and (1.62) can be\n",
            "rewritten\n",
            "(f(ℓ+1))i= minε(Cij−g(ℓ)\n",
            "j)j+εlogai, (1.63)\n",
            "(g(ℓ+1))j= minε(Cij−f(ℓ)\n",
            "i)i+εlogbj. (1.64)\n",
            "Here the term min ε(Cij−g(ℓ)\n",
            "j)jdenotes the soft-minimum of all values of the j-th column of matrix\n",
            "(C−1n(g(ℓ))⊤). To simplify notations, we introduce an operator that takes a matrix as input and outputs\n",
            "now a column vector of the soft-minimum values of its columns or rows. Namely, for any matrix A∈Rn×m,\n",
            "we deﬁne\n",
            "Minrow\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)j)\n",
            "i∈Rn,\n",
            "Mincol\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)i)\n",
            "j∈Rm.\n",
            "Note that these operations are equivalent to the entropic c-transform introduced in §??(see in particu-\n",
            "lar (??)). Using these notations, Sinkhorn’s iterates read\n",
            "f(ℓ+1)= Minrow\n",
            "ε(C−1ng(ℓ)T) +εloga, (1.65)\n",
            "g(ℓ+1)= Mincol\n",
            "ε(C−f(ℓ)1mT) +εlogb. (1.66)\n",
            "Note that as ε→0, minεconverges to min, but the iterations do not converge anymore in the limit ε= 0,\n",
            "because alternate minimization does not converge for constrained problems (which is the case for the un-\n",
            "regularized dual (1.17)).\n",
            "Remark 17 (Log-domain Sinkhorn) .While mathematically equivalent to the Sinkhorn updates (1.51), itera-\n",
            "tions (1.63) and (1.64) suggest to use the log-sum-exp stabilization trick to avoid underﬂow for small values\n",
            "ofε. Writing z = min z, that trick suggests to evaluate min εzas\n",
            "minεz= z−εlog∑\n",
            "ie−(zi−z)/ε. (1.67)\n",
            "Instead of substracting z to stabilize the log domain iterations as in (1.67), one can actually substract the\n",
            "previously computed scalings. This leads to the following stabilized iteration\n",
            "f(ℓ+1)= Minrow\n",
            "ε(S(f(ℓ),g(ℓ)))−f(ℓ)+εlog(a) (1.68)\n",
            "g(ℓ+1)= Mincol\n",
            "ε(S(f(ℓ+1),g(ℓ)))−g(ℓ)+εlog(b), (1.69)\n",
            "where we deﬁned\n",
            "S(f,g) =(\n",
            "Ci,j−fi−gj)\n",
            "i,j.\n",
            "In contrast to the original iterations (1.51), these log-domain iterations (1.68) and (1.69) are stable for\n",
            "arbitraryε >0, because the quantity S(f,g) stays bounded during the iterations. The downside is that it\n",
            "requiresnmcomputations of exp at each step. Computing a Minrow\n",
            "εor Mincol\n",
            "εis typically substantially\n",
            "slower than matrix multiplications, and requires computing line by line soft-minima of matrices S. There is\n",
            "therefore no eﬃcient way to parallelize the application of Sinkhorn maps for several marginals simultaneously.\n",
            "In Euclidean domain of small dimension, it is possible to develop eﬃcient multiscale solvers with a decaying\n",
            "εstrategy to signiﬁcantly speed up the computation using sparse grids [ ?].\n",
            "24\n",
            "1.6 Extensions\n",
            "Wasserstein Barycenters. Given input histogram {bs}S\n",
            "s=1, wherebs∈Σns, and weights λ∈ΣS, a\n",
            "Wasserstein barycenter is computed by minimizing\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsLCs(a,bs) (1.70)\n",
            "where the cost matrices Cs∈Rn×nsneed to be speciﬁed. A typical setup is “Eulerian”, so that all the\n",
            "barycenters are deﬁned on the same grid, ns=n,Cs=C=Dpis set to be a distance matrix, so that one\n",
            "solves\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsWp\n",
            "p(a,bs).\n",
            "This barycenter problem (1.70) was originally introduced by [ ?] following earlier ideas of [ ?]. They proved\n",
            "in particular uniqueness of the barycenter for c(x,y) =||x−y||2overX=Rd, if one of the input measure\n",
            "has a density with respect to the Lebesgue measure (and more generally under the same hypothesis as the\n",
            "one guaranteeing the existence of a Monge map, see Remark ??).\n",
            "The barycenter problem for histograms (1.70) is in fact a linear program, since one can look for the S\n",
            "couplings ( Ps)sbetween each input and the barycenter itself\n",
            "min\n",
            "a∈Σn,(Ps∈Rn×ns)s{S∑\n",
            "s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "s1ns=a,P⊤\n",
            "s1n=bs}\n",
            ".\n",
            "Although this problem is an LP, its scale forbids the use generic solvers for medium scale problems. One\n",
            "can therefore resort to using ﬁrst order methods such as subgradient descent on the dual [ ?].\n",
            "Remark 18.Barycenter of arbitrary measures Given a set of input measure ( βs)sdeﬁned on some space X,\n",
            "the barycenter problem becomes\n",
            "min\n",
            "α∈M1\n",
            "+(X)S∑\n",
            "s=1λsLc(α,βs). (1.71)\n",
            "In the case where X=Rdandc(x,y) =||x−y||2, [?] shows that if one of the input measures has a density,\n",
            "then this barycenter is unique. Problem (1.71) can be viewed as a generalization of the problem of computing\n",
            "barycenters of points ( xs)S\n",
            "s=1∈XSto arbitrary measures. Indeed, if βs=δxsis a single Dirac mass, then a\n",
            "solution to (1.71) is δx⋆wherex⋆is a Fr´ echet mean solving ( ??). Note that for c(x,y) =||x−y||2, the mean\n",
            "of the barycenter α⋆is necessarily the barycenter of the mean, i.e.\n",
            "∫\n",
            "Xxdα⋆(x) =∑\n",
            "sλs∫\n",
            "Xxdαs(x),\n",
            "and the support of α⋆is located in the convex hull of the supports of the ( αs)s. The consistency of the\n",
            "approximation of the inﬁnite dimensional optimization (1.71) when approximating the input distribution\n",
            "using discrete ones (and thus solving (1.70) in place) is studied in [ ?]. Let us also note that it is possible to\n",
            "re-cast (1.71) as a multi-marginal OT problem, see Remark ??.\n",
            "One can use entropic smoothing and approximate the solution of (1.70) using\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsLε\n",
            "Cs(a,bs) (1.72)\n",
            "for someε > 0. This is a smooth convex minimization problem, which can be tackled using gradient\n",
            "descent [ ?]. An alternative is to use descent method (typically quasi-Newton) on the semi-dual [ ?], which is\n",
            "25\n",
            "useful to integrate additional regularizations on the barycenter (e.g. to impose some smoothness). A simple\n",
            "but eﬀective approach, as remarked in [ ?] is to rewrite (1.72) as a (weighted) KL projection problem\n",
            "min\n",
            "(Ps)s{∑\n",
            "sλsKL(Ps|Ks) ;∀s,PsT1m=bs,P111=...=PS1S}\n",
            "(1.73)\n",
            "where we denoted Ksdef.=e−Cs/ε. Here, the barycenter ais implicitly encoded in the row marginals of all\n",
            "the couplings Ps∈Rn×nsasa=P111=...=PS1S. As detailed in [ ?], one can generalize Sinkhorn to\n",
            "this problem, which also corresponds to iterative projection. This can also be seen as a special case of the\n",
            "generalized Sinkhorn detailed in §??. The optimal couplings ( Ps)ssolving (1.73) are computed in scaling\n",
            "form as\n",
            "Ps= diag( us)Kdiag(vs), (1.74)\n",
            "and the scalings are sequentially updated as\n",
            "∀s∈J1,SK,v(ℓ+1)\n",
            "sdef.=bs\n",
            "KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Ksv(ℓ+1)\n",
            "s, (1.76)\n",
            "where a(ℓ+1)def.=∏\n",
            "s(Ksv(ℓ+1)\n",
            "s)λs. (1.77)\n",
            "An alternative way to derive these iterations is to perform alternate minimization on the variables of a dual\n",
            "problem, which detailed in the following proposition.\n",
            "Proposition 9. The optimal (us,vs)appearing in (1.74) can be written as (us,vs) = (efs/ε,egs/ε)where\n",
            "(fs,gs)sare the solutions of the following program (whose value matches the one of (1.72) )\n",
            "max\n",
            "(fs,gs)s{∑\n",
            "sλs(\n",
            "⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "sλsfs= 0}\n",
            ". (1.78)\n",
            "Proof. Introducing Lagrange multipliers in (1.73) leads to\n",
            "min\n",
            "(Ps)s,amax\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "εKL(Ps|Ks) +⟨a−Ps1m,fs⟩\n",
            "+⟨bs−PsT1m,gs⟩)\n",
            ".\n",
            "Strong duality holds, so that one can exchange the min and the max, and gets\n",
            "max\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "⟨gs,bs⟩+ min\n",
            "PsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\n",
            "+ min\n",
            "a⟨∑\n",
            "sλsfs,a⟩.\n",
            "The explicit minimization on agives the constraint∑\n",
            "sλsfs= 0 together with\n",
            "max\n",
            "(fs,gs)s∑\n",
            "sλs⟨gs,bs⟩−εKL∗(fs⊕gs\n",
            "ε|Ks)\n",
            "where KL∗(·|Ks) is the Legendre transform ( ??) of the function KL∗(·|Ks). This Legendre transform reads\n",
            "KL∗(U|K) =∑\n",
            "i,jKi,j(eUi,j−1), (1.79)\n",
            "26\n",
            "Figure 1.15: Barycenters between 4 input 3-D shapes using entropic regularization (1.72). The weights\n",
            "(λs)sare bilinear with respect to the four corners of the square. Shapes are represented as measures that\n",
            "are uniform within the boundaries of the shape and null outside.\n",
            "which shows the desired formula. To show (1.79), since this function is separable, one needs to compute\n",
            "∀(u,k)∈R2\n",
            "+,KL∗(u|k)def.= max\n",
            "rur−(rlog(r/k)−r+k)\n",
            "whose optimality condition reads u= log(r/k), i.e.r=keu, hence the result.\n",
            "Minimizing (1.78) with respect to each gs, while keeping all the other variable ﬁxed, is obtained in closed\n",
            "form by (1.75). Minimizing (1.78) with respect to all the ( fs)srequires to solve for ausing (1.77) and leads\n",
            "to the expression (1.76).\n",
            "Figures ??and??show applications to 2-D and 3-D shapes interpolation. Figure ??shows a computation\n",
            "of barycenters on a surface, where the ground cost is the square of the geodesic distance. For this ﬁgure,\n",
            "the computations are performed using the geodesic in heat approximation detailed in Remark ??. We refer\n",
            "to [?] for more details and other applications to computer graphics and imaging sciences.\n",
            "Wasserstein Loss. In statistics, text processing or imaging, one must usually compare a probability\n",
            "distribution βarising from measurements to a model, namely a parameterized family of distributions {αθ,θ∈\n",
            "Θ}where Θ is a subset of an Euclidean space. Such a comparison is done through a “loss” or a “ﬁdelity”\n",
            "term, which, in this section, is the Wasserstein distance. In the simplest scenario, the computation of a\n",
            "suitable parameter θis obtained by minimizing directly\n",
            "min\n",
            "θ∈ΘE(θ)def.=Lc(αθ,β). (1.80)\n",
            "Of course, one can consider more complicated problems: for instance, the barycenter problem described\n",
            "in§??consists in a sum of such terms. However, most of these more advanced problems can be usually\n",
            "solved by adapting tools deﬁned for basic case: either using the chain rule to compute explicitly derivatives,\n",
            "or using automatic diﬀerentiation.\n",
            "The Wasserstein distance between two histograms or two densities is convex with respect to these inputs,\n",
            "as shown by (1.17) and (1.21) respectively. Therefore, when the parameter θis itself a histogram, namely Θ =\n",
            "Σnandαθ=θ, or more generally when θdescribesKweights in the simplex, Θ = Σ K, andαθ=∑K\n",
            "i=1θiαi\n",
            "is a convex combination of known atoms α1,...,αKin ΣN, Problem (1.80) remains convex (the ﬁrst case\n",
            "corresponds to the barycenter problem, the second to one iteration of the dictionary learning problem with\n",
            "a Wasserstein loss [ ?]). However, for more general parameterizations θ↦→αθ, Problem (1.80) is in general\n",
            "not convex.\n",
            "27\n",
            "g✓XZ⇣xz\u0000↵✓Figure 1.16: Schematic display of the density ﬁtting problem 1.81.\n",
            "A practical problem of paramount importance in statistic and machine learning is density ﬁtting. Given\n",
            "some discrete samples ( xi)n\n",
            "i=1⊂X from some unknown distribution, the goal is to ﬁt a parametric model\n",
            "θ↦→αθ∈M (X) to the observed empirical input measure β\n",
            "min\n",
            "θ∈ΘL(αθ,β) where β=1\n",
            "n∑\n",
            "iδxi, (1.81)\n",
            "whereLis some “loss” function between a discrete and a “continuous” (arbitrary) distribution (see Fig-\n",
            "ure 1.16).\n",
            "In the case where αθas a densify ρθdef.=ραθwith respect to the Lebesgue measure (or any other ﬁxed\n",
            "reference measure), the maximum likelihood estimator (MLE) is obtained by solving\n",
            "min\n",
            "θLMLE(αθ,β)def.=−∑\n",
            "ilog(ρθ(xi)).\n",
            "This corresponds to using an empirical counterpart of a Kullback-Leibler loss since, assuming the xiare i.i.d.\n",
            "samples of some ¯β, then\n",
            "LMLE(α,β)n→+∞−→ KL(α|¯β)\n",
            "This MLE approach is known to lead to optimal estimation procedures in many cases (see for instance [ ?]).\n",
            "However, it fails to work when estimating singular distributions, typically when the αθdoes not has a density\n",
            "(so thatLMLE(αθ,β) = +∞) or when ( xi)iare samples from some singular ¯β(so that the αθshould share\n",
            "the same support as βfor KL(α|¯β) to be ﬁnite, but this support is usually unknown). Another issue is that\n",
            "in several cases of practical interest, the density ρθis inaccessible (or too hard to compute).\n",
            "A typical setup where both problems (singular and unknown densities) occur is for so-called generative\n",
            "models, where the parametric measure is written as a push-forward of a ﬁxed reference measure ζ∈M (Z)\n",
            "αθ=hθ,♯ζwherehθ:Z→X\n",
            "where the push-forward operator is introduced in Deﬁnition 1. The space Zis usually low-dimensional, so\n",
            "that the support of αθis localized along a low-dimensional “manifold” and the resulting density is highly\n",
            "singular (it does not have a density with respect to Lebesgue measure). Furthermore, computing this density\n",
            "is usually intractable, while generating i.i.d. samples from αθis achieved by computing xi=hθ(zi) where\n",
            "(zi)iare i.i.d. samples from ζ.\n",
            "In order to cope with such diﬃcult scenario, one has to use weak metrics in place of the MLE functional\n",
            "LMLE, which needs to be written in dual form as\n",
            "L(α,β)def.= max\n",
            "(f,g)∈C(X)2{∫\n",
            "Xf(x)dα(x) +∫\n",
            "Xg(x)dβ(x) ; (f,g)∈R}\n",
            ". (1.82)\n",
            "Dual norms exposed in §??correspond to imposing R={(f,−f) ;f∈B}, while optimal transport (1.21)\n",
            "setsR=R(c) as deﬁned in (1.22).\n",
            "28\n",
            "For a ﬁxed θ, evaluating the energy to be minimized in (1.81) using such a loss function corresponds to\n",
            "solving a semi-discrete optimal transport, which is the focus of Chapter ??. Minimizing the energy with\n",
            "respect toθis much more involved, and is typically highly non-convex.\n",
            "The class of estimators obtained using L=Lc, often called “Minimum Kantorovitch Estimators” (MKE),\n",
            "was initially introduced in [ ?], see also [ ?].\n",
            "Gromov-Wasserstein. Optimal transport needs a ground cost Cto compare histograms ( a,b), it can\n",
            "thus not be used if the histograms are not deﬁned on the same underlying space, or if one cannot pre-register\n",
            "these spaces to deﬁne a ground cost. To address this issue, one can instead only assume a weaker assumption,\n",
            "namely that one has at its disposal two matrices D∈Rn×nandD′∈Rm×mthat represent some relationship\n",
            "between the points on which the histograms are deﬁned. A typical scenario is when these matrices are (power\n",
            "of) distance matrices. The Gromov-Wasserstein problem reads\n",
            "GW(( a,D),(b,D′))2def.= min\n",
            "P∈U(a,b)ED,D′(P)def.=∑\n",
            "i,j,i′,j′|Di,i′−D′\n",
            "j,j′|2Pi,jPi′,j′. (1.83)\n",
            "This is a non-convex problem, which can be recast as a Quadratic Assignment Problem (QAP) [ ?] and is in\n",
            "full generality NP-hard to solve for arbitrary inputs. It is in fact equivalent to a graph matching problem [ ?]\n",
            "for a particular cost.\n",
            "One can show that GW satisﬁes the triangular inequality, and in fact it deﬁnes a distance between\n",
            "metric spaces equipped with a probability distribution (here assumed to be discrete in deﬁnition (1.83))\n",
            "up to isometries preserving the measures. This distance was introduced and studied in details by Memoli\n",
            "in [?]. An in-depth mathematical exposition (in particular, its geodesic structure and gradient ﬂows) is given\n",
            "in [?]. See also [ ?] for applications in computer vision. This distance is also tightly connected with the\n",
            "Gromov-Hausdorﬀ distance [ ?] between metric spaces, which have been used for shape matching [ ?,?].\n",
            "Remark 19.Gromov-Wasserstein distance The general setting corresponds to computing couplings between\n",
            "metric measure spaces ( X,dX,αX) and (Y,dY,αY) where (dX,dY) are distances and ( αX,αY) are measures\n",
            "on their respective spaces. One deﬁnes\n",
            "GW((αX,dX),(αY,dY))2def.= min\n",
            "π∈U(αX,αY)∫\n",
            "X2×Y2|dX(x,x′)−dY(y,y′)|2dπ(x,y)dπ(x′,y′). (1.84)\n",
            "GW deﬁnes a distance between metric measure spaces up to isometries, where one says that ( αX,dX) and\n",
            "(αY,dY) are isometric if there exists ϕ:X→Y such thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′)) =dX(x,x′).\n",
            "Remark 20.Gromov-Wasserstein geodesics The space of metric spaces (up to isometries) endowed with\n",
            "thisGW distance (1.84) has a geodesic structure. [ ?] shows that the geodesic between ( X0,dX0,α0) and\n",
            "(X1,dX1,α1) can be chosen to be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is a solution of (1.84) and for all\n",
            "((x0,x1),(x′\n",
            "0,x′\n",
            "1))∈(X0×X 1)2,\n",
            "dt((x0,x1),(x′\n",
            "0,x′\n",
            "1))def.= (1−t)dX0(x0,x′\n",
            "0) +tdX1(x1,x′\n",
            "1).\n",
            "This formula allows one to deﬁne and analyze gradient ﬂows which minimize functionals involving metric\n",
            "spaces, see [ ?]. It is however diﬃcult to handle numerically, because it involves computations over the product\n",
            "spaceX0×X 1. A heuristic approach is used in [ ?] to deﬁne geodesics and barycenters of metric measure\n",
            "spaces while imposing the cardinality of the involved spaces and making use of the entropic smoothing (1.85)\n",
            "detailed below.\n",
            "To approximate the computation of GW, and to help convergence of minimization schemes to better\n",
            "minima, one can consider the entropic regularized variant\n",
            "min\n",
            "P∈U(a,b)ED,D′(P)−εH(P). (1.85)\n",
            "29\n",
            "Figure 1.17: Example of fuzzy correspondences computed by solving GW problem (1.85) with Sinkhorn\n",
            "iterations (1.86). Extracted from [ ?].\n",
            "As proposed initially in [ ?,?], and later revisited in [ ?] for applications in graphics, one can use iteratively\n",
            "Sinkhorn’s algorithm to progressively compute a stationary point of (1.85). Indeed, successive linearizations\n",
            "of the objective function lead to consider the succession of updates\n",
            "P(ℓ+1) def.= min\n",
            "P∈U(a,b)⟨P,C(ℓ)⟩−εH(P) where (1.86)\n",
            "C(ℓ)def.=∇ED,D′(P(ℓ)) =−D′TP(ℓ)D,\n",
            "which can be interpreted as a mirror-descent scheme [ ?]. Each update can thus be solved using Sinkhorn\n",
            "iterations (1.51) with cost C(ℓ). Figure (1.17) illustrates the use of this entropic Gromov-Wasserstein to\n",
            "compute soft maps between domains.\n",
            "30\n",
            "Bibliography\n",
            "[1] Amir Beck. Introduction to Nonlinear Optimization: Theory, Algorithms, and Applications with MAT-\n",
            "LAB. SIAM, 2014.\n",
            "[2] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization\n",
            "and statistical learning via the alternating direction method of multipliers. Foundations and Trends R⃝\n",
            "in Machine Learning , 3(1):1–122, 2011.\n",
            "[3] Stephen Boyd and Lieven Vandenberghe. Convex optimization . Cambridge university press, 2004.\n",
            "[4] E. Cand` es and D. Donoho. New tight frames of curvelets and optimal representations of objects with\n",
            "piecewise C2singularities. Commun. on Pure and Appl. Math. , 57(2):219–266, 2004.\n",
            "[5] E. J. Cand` es, L. Demanet, D. L. Donoho, and L. Ying. Fast discrete curvelet transforms. SIAM\n",
            "Multiscale Modeling and Simulation , 5:861–899, 2005.\n",
            "[6] A. Chambolle. An algorithm for total variation minimization and applications. J. Math. Imaging Vis. ,\n",
            "20:89–97, 2004.\n",
            "[7] Antonin Chambolle, Vicent Caselles, Daniel Cremers, Matteo Novaga, and Thomas Pock. An intro-\n",
            "duction to total variation for image analysis. Theoretical foundations and numerical methods for sparse\n",
            "recovery , 9(263-340):227, 2010.\n",
            "[8] Antonin Chambolle and Thomas Pock. An introduction to continuous optimization for imaging. Acta\n",
            "Numerica , 25:161–319, 2016.\n",
            "[9] S.S. Chen, D.L. Donoho, and M.A. Saunders. Atomic decomposition by basis pursuit. SIAM Journal\n",
            "on Scientiﬁc Computing , 20(1):33–61, 1999.\n",
            "[10] Philippe G Ciarlet. Introduction ` a l’analyse num´ erique matricielle et ` a l’optimisation. 1982.\n",
            "[11] P. L. Combettes and V. R. Wajs. Signal recovery by proximal forward-backward splitting. SIAM\n",
            "Multiscale Modeling and Simulation , 4(4), 2005.\n",
            "[12] I. Daubechies, M. Defrise, and C. De Mol. An iterative thresholding algorithm for linear inverse problems\n",
            "with a sparsity constraint. Commun. on Pure and Appl. Math. , 57:1413–1541, 2004.\n",
            "[13] D. Donoho and I. Johnstone. Ideal spatial adaptation via wavelet shrinkage. Biometrika , 81:425–455,\n",
            "Dec 1994.\n",
            "[14] Heinz Werner Engl, Martin Hanke, and Andreas Neubauer. Regularization of inverse problems , volume\n",
            "375. Springer Science & Business Media, 1996.\n",
            "[15] M. Figueiredo and R. Nowak. An EM Algorithm for Wavelet-Based Image Restoration. IEEE Trans.\n",
            "Image Proc. , 12(8):906–916, 2003.\n",
            "[16] Simon Foucart and Holger Rauhut. A mathematical introduction to compressive sensing , volume 1.\n",
            "Birkh¨ auser Basel, 2013.\n",
            "31\n",
            "[17] Stephane Mallat. A wavelet tour of signal processing: the sparse way . Academic press, 2008.\n",
            "[18] D. Mumford and J. Shah. Optimal approximation by piecewise smooth functions and associated varia-\n",
            "tional problems. Commun. on Pure and Appl. Math. , 42:577–685, 1989.\n",
            "[19] Neal Parikh, Stephen Boyd, et al. Proximal algorithms. Foundations and Trends R⃝in Optimization ,\n",
            "1(3):127–239, 2014.\n",
            "[20] Gabriel Peyr´ e. L’alg` ebre discr` ete de la transform´ ee de Fourier . Ellipses, 2004.\n",
            "[21] J. Portilla, V. Strela, M.J. Wainwright, and Simoncelli E.P. Image denoising using scale mixtures of\n",
            "Gaussians in the wavelet domain. IEEE Trans. Image Proc. , 12(11):1338–1351, November 2003.\n",
            "[22] L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear total variation based noise removal algorithms. Phys.\n",
            "D, 60(1-4):259–268, 1992.\n",
            "[23] Otmar Scherzer, Markus Grasmair, Harald Grossauer, Markus Haltmeier, Frank Lenzen, and L Sirovich.\n",
            "Variational methods in imaging . Springer, 2009.\n",
            "[24] C. E. Shannon. A mathematical theory of communication. The Bell System Technical Journal ,\n",
            "27(3):379–423, 1948.\n",
            "[25] Jean-Luc Starck, Fionn Murtagh, and Jalal Fadili. Sparse image and signal processing: Wavelets and\n",
            "related geometric multiscale analysis . Cambridge university press, 2015.\n",
            "32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (26209 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Semantic section chunking:\n",
            "Chunk 1: \n",
            "Mathematical Foundations of Data Sciences\n",
            "Gabriel Peyr´ e\n",
            "CNRS & DMA\n",
            "´Ecole Normale Sup´ erieure\n",
            "gabriel.peyre@ens.fr\n",
            "https://mathematical-tours.github.io\n",
            "www.numerical-tours.com\n",
            "August 14, 2019\n",
            "2\n",
            "Chapter 1\n",
            "Optimal Transport\n",
            "1.1 Radon Measures\n",
            "Measures. We will interchangeably the term histogram or probability vector for any element a∈Σnthat\n",
            "belongs to the probability simplex\n",
            "Σndef.={\n",
            "a∈Rn\n",
            "+;n∑\n",
            "i=1ai= 1}\n",
            "Chunk 2: \n",
            ".\n",
            "A discrete measure with weights aand locations x1,...,xn∈X reads\n",
            "α=n∑\n",
            "i=1aiδxi (1.1)\n",
            "whereδxis the Dirac at position x, intuitively a unit of mass which is inﬁnitely concentrated at location\n",
            "x. Such as measure describes a probability measure if, additionally, a∈Σn, and more generally a positive\n",
            "measure if each of the “weights” described in vector ais positive itself.\n",
            "Remark 1 (General measures).A convenient feature of OT is that it can deal with discrete and continuous\n",
            "“objects” within the same framework.\n",
            "Chunk 3:  Such objects only need to be modelled as measures. This corresponds\n",
            "to the notion of Radon measures M(X) on the spaceX. The formal deﬁnition of that set requires that Xis\n",
            "equipped with a distance, usually denoted d, because one can only access a measure by “testing” (integrating)\n",
            "it against continuous functions, denoted f∈C(X).\n",
            "Integration of f∈C(X) against a discrete measure αcomputes a sum\n",
            "∫\n",
            "Xf(x)dα(x) =n∑\n",
            "i=1aif(xi).\n",
            "More general measures, for instance on X=Rd(whered\n",
            "Chunk 4: ∈N∗is the dimension), can have a density\n",
            "dα(x) =ρα(x)dxw.r.t. the Lebesgue measure, often denoted ρα=dα\n",
            "dx, which means that\n",
            "∀h∈C(Rd),∫\n",
            "Rdh(x)dα(x) =∫\n",
            "Rdh(x)ρα(x)dx.\n",
            "An arbitrary measure α∈M (X) (which needs not to have a density nor be a sum of Diracs) is deﬁned by\n",
            "the fact that it can be integrated agains any continuous function f∈C(X) and obtain�\n",
            "Chunk 5: �\n",
            "Xf(x)dα(x)∈R.\n",
            "IfXis not compact, one should also impose that fhas compact support or at least as 0 limit at inﬁnity.\n",
            "Measure as thus in some sense “less regular” than functions, but more regular than distributions (which are\n",
            "dual to smooth functions). For instance, the derivative of a Dirac is not a measure. We denote M+(X) the\n",
            "set of all positive measures on X. The set of probability measures is denoted M1\n",
            "+(X), which means that\n",
            "anyα∈M1\n",
            "+(X) is positive, and that α(X) =∫\n",
            "Xd\n",
            "Chunk 6: α= 1. Figure 1.1 oﬀers a visualization of the diﬀerent\n",
            "classes of measures, beyond histograms, considered in this work.\n",
            "3\n",
            "Discreted= 1 Discrete d= 2 Density d= 1 Density d= 2\n",
            "Figure 1.1: Schematic display of discrete distributions α=∑n\n",
            "i=1aiδxi(red corresponds to empirical uniform\n",
            "distribution ai= 1/n, and blue to arbitrary distributions) and densities d α(x) =ρα(x)dx(in violet), in both\n",
            "1-D and 2-D. Discrete distributions in 1-D are displayed using vertical segments (with\n",
            "Chunk 7:  length equal to ai)\n",
            "and in 2-D using point clouds (radius equal to ai).\n",
            "Operators on measures. For some continuous map T:X →Y, we deﬁne the pushforward operator\n",
            "T♯:M(X)→M (Y). For discrete measures (1.1), the pushforward operation consists simply in moving the\n",
            "positions of all the points in the support of the measure\n",
            "T♯αdef.=∑\n",
            "iaiδT(xi).\n",
            "For more general measures, for instance for those with a density, the notion of push-forward plays a funda-\n",
            "mental to describe spatial modiﬁcations of probability\n",
            "Chunk 8:  measures. The formal deﬁnition reads as follow.\n",
            "Deﬁnition 1 (Push-forward).ForT:X → Y, the push forward measure β=T♯α∈ M (Y)of some\n",
            "α∈M (X)reads\n",
            "∀h∈C(Y),∫\n",
            "Yh(y)dβ(y) =∫\n",
            "Xh(T(x))dα(x). (1.2)\n",
            "Equivalently, for any measurable set B⊂Y, one has\n",
            "β(B) =α({x∈X;T(x)∈B}). (1.3)\n",
            "Chunk 9: \n",
            "Note thatT♯preserves positivity and total mass, so that if α∈M1\n",
            "+(X)thenT♯α∈M1\n",
            "+(Y).\n",
            "Intuitively, a measurable map T:X→Y, can be interpreted as a function “moving” a single point from a\n",
            "measurable space to another. The more general extension T♯can now “move” an entire probability measure\n",
            "onXtowards a new probability measure on Y. The operator T♯“pushes forward” each elementary mass of\n",
            "a measureαonXby applying the map Tto obtain then an elementary mass in Y, to build on aggregate a\n",
            "\n",
            "Chunk 10: new measure onY) writtenT♯α. Note that such a push-forward T♯:M1\n",
            "+(X)→M1\n",
            "+(Y) is a linear operator\n",
            "between measures in the sense that for two measures α1,α2onX,T♯(α1+α2) =T♯α1+T♯α2.\n",
            "Remark 2 (Push-forward for densities).Explicitly doing the change of variable in formula (1.2) for measures\n",
            "with densities ( ρα,ρβ) onRd(assumingTis smooth and a bijection) shows that a push-forward acts on\n",
            "densities linearly as\n",
            "Chunk 11:  a change of variables in the integration formula, indeed\n",
            "ρα(x) =|det(T′(x))|ρβ(T(x)) (1.4)\n",
            "whereT′(x)∈Rd×dis the Jacobian matrix of T(the matrix formed by taking the gradient of each coordinate\n",
            "ofT). This implies, denoting y=T(x)\n",
            "|det(T′(x))|=ρα(x)\n",
            "ρβ(y).\n",
            "4\n",
            "=Pi\u0000xiT↵T]↵def.=Pi\u0000T(xi)\n",
            "TT]gdef.=g\u0000TgPush-forward of measures Pull-back of functions\n",
            "\n",
            "Chunk 12: Figure 1.2: Comparison of push-forward T♯and pull-back T♯.\n",
            "Remark 3 (Push-forward vs. pull-back).The push-forward T♯of measures should not be confounded with\n",
            "the pull-back of function T♯:C(Y)→C(X) which corresponds to the “warping” of functions. It is the linear\n",
            "map deﬁned, for g∈C(Y) byT♯g=g◦T. Push-forward and pull-back are actually adjoint one from each\n",
            "others, in the sense that\n",
            "∀(α,g)∈M (\n",
            "Chunk 13: X)×C(Y),∫\n",
            "Ygd(T♯α) =∫\n",
            "X(T♯g)dα.\n",
            "It is important to realize that even if ( α,β) have densities ( ρα,ρβ),T♯αis not equal to T♯ρβ, because of\n",
            "the presence of the Jacobian in (1.4). This explains why OT should be used with caution to perform image\n",
            "registration, because it does not operate as an image warping method. Figure 1.2 illustrate the distinction\n",
            "between these push-forward and pull-back operators.\n",
            "Remark 4 (Measures and random variables).Radon measures can also\n",
            "Chunk 14:  be viewed as representing the distri-\n",
            "butions of random variables. A random variable XonXis actually a map X: Ω→X from some abstract\n",
            "(often un-speciﬁed) probabized space (Ω,P), and its distribution αis the Radon measure X∈M1\n",
            "+(X) such\n",
            "thatP(X∈A) =α(A) =∫\n",
            "Adα(x). Equivalently, it is the push-forward of PbyX,α=X♯P. Applying\n",
            "another push-forward β=T♯αforT:X →Y, following (1.2), is equivalent\n",
            "Chunk 15:  to deﬁning another random\n",
            "variableY=T(X) :ω∈Ω→T(X(ω))∈Y, so thatβis the distribution of Y. Drawing a random sample\n",
            "yfromYis thus simply achieved by computing y=T(x) wherexis drawn from X.\n",
            "Convergence of random variable. Convergence of random variable (in probability, almost sure, in law),\n",
            "convergence of measures (strong, weak).\n",
            "1.2 Monge Problem\n",
            "Given a cost matrix ( Ci,j)i∈JnK,j∈JmK, assuming n=m, the optimal assignment problem seeks for a\n",
            "bijection\n",
            "Chunk 16: σin the set Perm( n) of permutations of nelements solving\n",
            "min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i). (1.5)\n",
            "One could naively evaluate the cost function above using all permutations in the set Perm( n). However,\n",
            "that set has size n!, which is gigantic even for small n. Consider for instance that such a set has more than\n",
            "10100elements [?] whennis as small as 70. That problem can therefore only be solved if there exist eﬃcient\n",
            "algorithms to optimize that cost function over the set of permutations, which will be the subject of §\n",
            "Chunk 17: ??.\n",
            "5\n",
            "x1x2y1y2x1x2y1y2x4x5x6x3y3x7Figure 1.3: (left) blue dots from measure αand red dots from measure βare pairwise equidistant. Hence,\n",
            "either matching σ= (1,2) (full line) or σ= (2,1) (dotted line) is optimal. (right) a Monge map can associate\n",
            "the blue measure αto the red measure β. The weights αiare displayed proportionally to the area of the\n",
            "disk marked at each location. The mapping here is such that T(x1) =T(x2)\n",
            "Chunk 18:  =y2,T(x3) =y3, whereas for\n",
            "4⩽i⩽7 we haveT(xi) =y1.\n",
            "Remark 5 (Uniqueness).Note that the optimal assignment problem may have several optimal solutions.\n",
            "Suppose for instance that n=m= 2 and that the matrix Cis the pairwise distance matrix between the 4\n",
            "corners of a 2-dimensional square of side length 1, as represented in the left plot in Figure 1.3. In that case\n",
            "only two assignments exist, and they share the same cost.\n",
            "For discrete measures\n",
            "α=n∑\n",
            "i=1aiδxiandβ=m∑\n",
            "j=\n",
            "Chunk 19: 1bjδyj (1.6)\n",
            "the Monge problem [?] seeks for a map that associates to each point xia single point yj, and which must\n",
            "push the mass of αtoward the mass of β, which is to say that such a map T:{x1,...,xn}→{y1,...,ym}\n",
            "must verify that\n",
            "∀j∈JmK,bj=∑\n",
            "i:T(xi)=yjai (1.7)\n",
            "which we write in compact form as T♯α=β. This map should minimize some transportation cost, which is\n",
            "parameterized by a function c(x,y) de�\n",
            "Chunk 20: �ned for points ( x,y)∈X×Y\n",
            "min\n",
            "T{∑\n",
            "ic(xi,T(xi)) ;T♯α=β}\n",
            ". (1.8)\n",
            "Such a map between discrete points can be of course encoded, assuming all x’s andy’s are distinct, using\n",
            "indicesσ:JnK→JmKso thatj=σ(i), and the mass conservation is written as\n",
            "∑\n",
            "i∈σ−1(j)ai=bj.\n",
            "In the special case when n=mand all weights are uniform, that is ai=bj= 1/n, then the mass conservation\n",
            "constraint\n",
            "Chunk 21:  implies that Tis a bijection, such that T(xi) =yσ(i), and the Monge problem is equivalent to the\n",
            "optimal matching problem (1.5) where the cost matrix is\n",
            "Ci,jdef.=c(xi,yj).\n",
            "Whenn̸=m, note that, optimality aside, Monge maps may not even exist between an empirical measure\n",
            "to another. This happens when their weight vectors are not compatible, which is always the case when the\n",
            "target measure has more points than the source measure. For instance, the right plot in Figure 1.3 shows\n",
            "an (optimal) Monge map between αandβ, but there is no Monge map\n",
            "Chunk 22:  from βtoα.\n",
            "6\n",
            "Monge problem (1.8) is extended to the setting of two arbitrary probability measures ( α,β) on two spaces\n",
            "(X,Y) as ﬁnding a map T:X→Y that minimizes\n",
            "min\n",
            "T{∫\n",
            "Xc(x,T(x))dα(x) ;T♯α=β}\n",
            "(1.9)\n",
            "The constraint T♯α=βmeans that Tpushes forward the mass of αtoβ, and makes use of the push-forward\n",
            "operator (1.2).\n",
            "1.3 Kantorovitch Problem\n",
            "The assignment problem has several limitations in practical settings,\n",
            "Chunk 23:  also encountered when using the\n",
            "Monge problem. Indeed, because the assignment problem is formulated as a permutation problem, it can only\n",
            "be used to compare two points clouds of the same size. A direct generalization to discrete measures with non-\n",
            "uniform weights can be carried out using Monge’s formalism of pushforward maps, but that formulation may\n",
            "also be degenerate it there does not exist feasible solutions satisfying the mass conservation constraint (1.7)\n",
            "(see the end of Remark??). Additionally, the assignment Problem (1.8) is combinatorial, whereas the feasible\n",
            "set for the Monge Problem (1.9), consisting in all push-forward measures that satisfy the mass conservation\n",
            "\n",
            "Chunk 24: constraint, is non-convex. Both are therefore diﬃcult to solve in their original formulation.\n",
            "Kantorovitch formulation for discrete measures. The key idea of [?] is to relax the deterministic na-\n",
            "ture of transportation, namely the fact that a source point xican only be assigned to another, or transported\n",
            "to one and one location T(xi) only. Kantorovich proposes instead that the mass at any point xibe potentially\n",
            "dispatched across several locations. Kantorovich moves away from the idea that mass transportation should\n",
            "be “deterministic” to consider instead a “probabilistic” (or “fuzzy�\n",
            "Chunk 25: �) transportation, which allows what is\n",
            "commonly known now as “mass splitting” from a source towards several targets. This ﬂexibility is encoded\n",
            "using, in place of a permutation σor a mapT, a coupling matrix P∈Rn×m\n",
            "+, where Pi,jdescribes the\n",
            "amount of mass ﬂowing from bin i(or pointxi) towards bin j(or pointxj),xitowardsyjin the formalism\n",
            "of discrete measures (1.6). Admissible couplings admit a far simpler characterization than Monge maps:\n",
            "U(a,b)def.={\n",
            "P∈Rn×m\n",
            "+ ;P1m\n",
            "Chunk 26: =aand PT1n=b}\n",
            ", (1.10)\n",
            "where we used the following matrix-vector notation\n",
            "P1m=\n",
            "∑\n",
            "jPi,j\n",
            "\n",
            "i∈Rnand PT1n=(∑\n",
            "iPi,j)\n",
            "j∈Rm.\n",
            "The set of matrices U(a,b) is bounded, deﬁned by n+mequality constraints, and therefore a convex\n",
            "polytope (the convex hull of a ﬁnite set of matrices).\n",
            "Additionally, whereas the Monge formulation (as illustrated in the right plot of Figure 1.\n",
            "Chunk 27: 3) was intrisically\n",
            "asymmetric, Kantorovich’s relaxed formulation is always symmetric, in the sense that a coupling Pis in\n",
            "U(a,b) if and only if PTis inU(b,a).\n",
            "Kantorovich’s optimal transport problem now reads\n",
            "LC(a,b)def.= min\n",
            "P∈U(a,b)⟨C,P⟩def.=∑\n",
            "i,jCi,jPi,j. (1.11)\n",
            "This is a linear program (see Chapter??), and as is usually the case with such programs, its solutions are\n",
            "not necessarily unique.\n",
            "7\n",
            "�\n",
            "Chunk 28: �\u0000\n",
            "↵\u0000Figure 1.4: Comparison of optimal matching and generic couplings. A black segment between xiandyj\n",
            "indicates a non-zero element in the displayed optimal coupling Pi,jsolving (1.11). Left: optimal matching,\n",
            "corresponding to the setting of Proposition (1) (empirical measures with the same number n=mof points).\n",
            "Right: these two weighted point clouds cannot be matched; instead a Kantorovich coupling can be used to\n",
            "associate two arbitrary discrete measures.\n",
            "Permutation Matrices as Couplings For a permutation σ∈Perm(n), we write Pσfor the correspond-\n",
            "ing permutation matrix,\n",
            "�\n",
            "Chunk 29: �(i,j)∈JnK2,(Pσ)i,j={1/n ifj=σi,\n",
            "0 otherwise.(1.12)\n",
            "One can check that in that case\n",
            "⟨C,Pσ⟩=1\n",
            "nn∑\n",
            "i=1Ci,σi,\n",
            "which shows that the assignment problem (1.5) can be recast as a Kantorovich problem (1.11) where the\n",
            "couplings Pare restricted to be exactly permutation matrices:\n",
            "min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i)= min\n",
            "σ∈Per\n",
            "Chunk 30: m(n)⟨C,Pσ⟩.\n",
            "Next, one can easily check that the set of permutation matrices is strictly included in the so-called Birkhoﬀ\n",
            "polytope U(1n/n,1n,n). Indeed, for any permutation σwe have Pσ1=1nandPσT1=1n, whereas\n",
            "1n1nT/n2is a valid coupling but not a permutation matrix. Therefore, one has naturally that\n",
            "min\n",
            "σ∈Perm(n)⟨C,Pσ⟩⩽LC(1n/n,1n/n).\n",
            "The\n",
            "Chunk 31:  following proposition shows that these problems result in fact in the same optimum, namely that\n",
            "one can always ﬁnd a permutation matrix that minimizes Kantorovich’s problem (1.11) between two uniform\n",
            "measures a=b=1n/n, which shows that the Kantorovich relaxation is tight when considered on assignment\n",
            "problems. Figure 1.4 shows on the left a 2-D example of optimal matching corresponding to this special\n",
            "case.\n",
            "Proposition 1 (Kantorovich for matching).Ifm=nanda=b=1n/n, then there exists an optimal\n",
            "solution for Problem (1.11) Pσ⋆, which is a permutation\n",
            "Chunk 32:  matrix associated to an optimal permutation σ⋆∈\n",
            "Perm(n)for Problem (1.5).\n",
            "Proof. Birkhoﬀ’s theorem states that the set of extremal points of U(1n/n,1n/n) is equal to the set of\n",
            "permutation matrices. A fundamental theorem of linear programming [?, Theorem 2.7] states that the\n",
            "minimum of a linear objective in a non-empty polyhedron, if ﬁnite, is reached at an extremal point of the\n",
            "polyhedron.\n",
            "8\n",
            "⇡\u0000↵\u0000↵\n",
            "⇡\u0000↵\u0000↵\n",
            "Chunk 33: \n",
            "⇡\u0000↵\u0000↵\n",
            "Discrete Semi-discrete Continuous\n",
            "Figure 1.5: Schematic viewed of input measures ( α,β) and couplingsU(α,β) encountered in the three main\n",
            "scenario for Kantorovich OT. Chapter??is dedicated to the semi-discrete setup.\n",
            "⇡\u0000↵\n",
            "⇡\u0000↵\n",
            "Figure 1.6: Left: “continuous” coupling πsolving (1.13) between two 1-D measure with density. The\n",
            "coupling is localized along the graph of the Monge map ( x,T(x)) (displayed in black). Right: “disc\n",
            "Chunk 34: rete”\n",
            "couplingTsolving (1.11) between two discrete measures of the form (1.6). The non-zero entries Ti,jare\n",
            "display with a black disk at position ( i,j) with radius proportional to Ti,j.\n",
            "Kantorovitch formulation for arbitrary measures. The deﬁnition of Lcin (??) can be extended to\n",
            "arbitrary measures by considering couplings π∈M1\n",
            "+(X×Y ) which are joint distributions over the product\n",
            "space. The discrete case is a special situation where one imposes this product measure to be of the form\n",
            "π=∑\n",
            "i,jPi,jδ(xi,\n",
            "Chunk 35: yj). In the general case, the mass conservation constraint (1.10) should be rewritten as a\n",
            "marginal constraint on joint probability distributions\n",
            "U(α,β)def.={\n",
            "π∈M1\n",
            "+(X×Y ) ;PX♯π=αandPY♯π=β}\n",
            ". (1.13)\n",
            "HerePX♯andPY♯are the push-forward (see Deﬁnition 1) by the projections PX(x,y) =xandPY(x,y) =y.\n",
            "Figure 1.5 shows a schematic visualization of the coupling constraints for diﬀerent class of problem (discrete\n",
            "Chunk 36: \n",
            "measures and densities). Using (1.3), these marginal constraints are equivalent to imposing that π(A×Y) =\n",
            "α(A) andπ(X×B) =β(B) for setsA⊂X andB⊂Y.\n",
            "The Kantorovich problem (1.11) is then generalized as\n",
            "Lc(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "X×Yc(x,y)dπ(x,y). (1.14)\n",
            "This is an inﬁnite-dimensional linear program over a space of measures. Figure 1.6 shows examples of discrete\n",
            "and\n",
            "Chunk 37:  continuous optimal coupling solving (1.14). Figure 1.7 shows other examples of optimal 1-D couplings,\n",
            "involving discrete and continuous marginals.\n",
            "On compact domain ( X,Y), (1.14) always has a solution, because using the weak-* topology (so called\n",
            "weak topology of measures), the set of measure is compact, and a linear function with a continuous c(x,y)\n",
            "9\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "↵\u0000↵⇡\u0000Figure 1.7: Four simple examples of optimal couplings between 1-D distributions\n",
            "Chunk 38: , represented as maps\n",
            "above (arrows) and couplings below. Inspired by [?].\n",
            "is weak-* continuous. And the set of constraint is non empty, taking α⊗β. On non compact domain, needs\n",
            "to impose moment condition on αandβ.\n",
            "Wasserstein distances. An important feature of OT is that it deﬁnes a distance between histograms\n",
            "and probability measures as soon as the cost matrix satisﬁes certain suitable properties. Indeed, OT can be\n",
            "understood as a canonical way to lift a ground distance between points to a distance between histogram or\n",
            "measures.\n",
            "We ﬁrst consider the case where, using a term ﬁ\n",
            "Chunk 39: rst introduce by [?], the “ground metric” matrix C\n",
            "is ﬁxed, representing substitution costs between bins, and shared across several histograms we would like\n",
            "to compare. The following proposition states that OT provides a meaningful distance between histograms\n",
            "supported on these bins.\n",
            "Proposition 2. We suppose n=m, and that for some p⩾1,C=Dp= (Dp\n",
            "i,j)i,j∈Rn×nwhere D∈Rn×n\n",
            "+\n",
            "is a distance on JnK,i.e.\n",
            "1.D∈Rn×n\n",
            "+ is symmetric;\n",
            "2.Di,j\n",
            "Chunk 40: = 0if and only if i=j;\n",
            "3.∀(i,j,k )∈JnK3,Di,k⩽Di,j+Dj,k.\n",
            "Then\n",
            "Wp(a,b)def.= LDp(a,b)1/p(1.15)\n",
            "(note that Wpdepends on D) deﬁnes the p-Wasserstein distance on Σn,i.e. Wpis symmetric, positive,\n",
            "Wp(a,b) = 0 if and only if a=b, and it satisﬁes the triangle inequality\n",
            "∀a,a′,b\n",
            "Chunk 41: ∈Σn,Wp(a,b)⩽Wp(a,a′) + Wp(a′,b).\n",
            "Proof. Symmetry and deﬁniteness of the distance are easy to prove: since C=Dphas a null diagonal,\n",
            "Wp(a,a) = 0, with corresponding optimal transport matrix P⋆= diag( a); by the positivity of all oﬀ-diagonal\n",
            "elements of Dp, Wp(a,b)>0 whenever a̸=b(because in this case, an admissible coupling necessarily has\n",
            "a non-zero element outside the diagonal); by symmetry of D\n",
            "Chunk 42: p, Wp(a,b) = 0 is itself a symmetric function.\n",
            "To prove the triangle inequality of Wasserstein distances for arbitrary measures, [?, Theorem 7.3] uses the\n",
            "gluing lemma, which stresses the existence of couplings with a prescribed structure. In the discrete setting,\n",
            "the explicit constuction of this glued coupling is simple. Let a,b,c∈Σn. Let PandQbe two optimal\n",
            "solutions of the transport problems between aandb, and bandcrespectively. We deﬁne ¯bjdef.=bjifbj>0\n",
            "and set otherwise ¯bj= 1 (or actually any other value). We then de\n",
            "Chunk 43: ﬁne\n",
            "Sdef.=Pdiag(1/¯b)Q∈Rn×n\n",
            "+.\n",
            "10\n",
            "We remark that S∈U(a,c) because\n",
            "S1n=Pdiag(1/¯b)Q1n=P(b/¯b) =P1Supp( b)=a\n",
            "where we denoted 1Supp( b)the indicator of the support of b, and we use the fact that P1Supp( b)=P1=b\n",
            "because necessarily Pi,j= 0 forj /∈Supp( b). Similarly one veriﬁes that S⊤1n=c.\n",
            "The triangle inequality follows\n",
            "Chunk 44:  from\n",
            "Wp(a,c) =(\n",
            "min\n",
            "P∈U(a,c)⟨P,Dp⟩)1/p\n",
            "⩽⟨S,Dp⟩1/p\n",
            "=\n",
            "∑\n",
            "ikDp\n",
            "ik∑\n",
            "jPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "⩽\n",
            "∑\n",
            "ijk(Dij+Djk)pPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "⩽\n",
            "∑\n",
            "ijk\n",
            "Chunk 45: Dp\n",
            "ijPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "ijkDp\n",
            "jkPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "ijDp\n",
            "ijPij∑\n",
            "kQjk\n",
            "¯bj\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk∑\n",
            "iPij\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "\n",
            "Chunk 46: ijDp\n",
            "ijPij\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk\n",
            "1/p\n",
            "= Wp(a,b) + Wp(b,b).\n",
            "The ﬁrst inequality is due to the suboptimality of S, the second is the usual triangle inequality for elements\n",
            "inD, and the third comes from Minkowski’s inequality.\n",
            "Proposition 2 generalizes from histogram to arbitrary measures that need not be discrete.\n",
            "Proposition 3. We assumeX=Y, and that for some p⩾1,c\n",
            "Chunk 47: (x,y) =d(x,y)pwheredis a distance on\n",
            "X,i.e.\n",
            "(i)d(x,y) =d(y,x)⩾0;\n",
            "(ii)d(x,y) = 0 if and only if x=y;\n",
            "(ii)∀(x,y,z )∈X3,d(x,z)⩽d(x,y) +d(y,z).\n",
            "Then\n",
            "Wp(α,β)def.=Ldp(α,β)1/p(1.16)\n",
            "(note thatWpdepends on d) de�\n",
            "Chunk 48: �nes the p-Wasserstein distance on X,i.e.Wpis symmetric, positive,\n",
            "Wp(α,β) = 0 if and only if α=β, and it satisﬁes the triangle inequality\n",
            "∀(α,β,γ )∈M1\n",
            "+(X)3,Wp(α,γ)⩽Wp(α,β) +Wp(β,γ).\n",
            "Proof. The proof follows the same approach as that for Proposition 2 and relies on the existence of a coupling\n",
            "between (α,γ) obtained by “guying” optimal couplings between ( α,β) and (β,γ).\n",
            "Chunk 49: \n",
            "The Wasserstein distance Wphas many important properties, the most important one being that it is a\n",
            "weak distance, i.e.it allows to compare singular distributions (for instance discrete ones) and to quantify\n",
            "spatial shift between the supports of the distributions. In particular, “classical” distances (or divergences)\n",
            "are not even deﬁned between discrete distributions (the L2norm can only be applied to continuous measures\n",
            "with a density with respect to a base measure, and the discrete ℓ2norm requires the positions ( xi,yj) to\n",
            "be ﬁxed to work). In sharp contrast, one has that for any p >0,Wp\n",
            "Chunk 50: \n",
            "p(δx,δy) =d(x,y). Indeed, it suﬃces\n",
            "to notice thatU(δx,δy) ={δx,y}and therefore the Kantorovich problem having only one feasible solution,\n",
            "Wp\n",
            "p(δx,δy) is necessarily ( d(x,y)p)1/p=d(x,y). This shows that Wp(δx,δy)→0 ifx→y. This property\n",
            "corresponds to the fact that Wpis a way to quantify the weak convergence as we now deﬁne.\n",
            "11\n",
            "De\n",
            "Chunk 51: ﬁnition 2 (Weak convergence).(αk)kconverges weakly to αinM1\n",
            "+(X)(denotedαk⇀α ) if and only if\n",
            "for any continuous function g∈C(X),∫\n",
            "Xgdαk→∫\n",
            "Xgdα. This notion of weak convergence corresponds to\n",
            "the convergence in law of random vectors.\n",
            "This convergence can be shown to be equivalent to Wp(αk,α)→0 [?, Theorem 6.8] (together with a\n",
            "convergence of the moments up to order pfor unbounded metric spaces).\n",
            "Note that there exists alternative distances which also metrize weak convergence.\n",
            "Chunk 52:  The simplest one are\n",
            "Hilbertian norms, deﬁned as\n",
            "||α||2\n",
            "kdef.=Eα⊗α(k) =∫\n",
            "X×Xk(x,y)dα(x)dα(y)\n",
            "for a suitable choice of kernel k:X2→R. The most famous of such kernel is the Gaussian one k(x,y) =\n",
            "e−||x−y||2\n",
            "2σ2for some choice of bandwidth σ>0.\n",
            "This convergence should not be confounded with the strong convergence of measures, which is metrized\n",
            "by the TV norm ||α||TVdef.=|α|(\n",
            "Chunk 53: X), which is the total mass of the absolute value of the measure.\n",
            "Algorithms Since (??)ˆA is a linear program, it is possible to use any classical linear program solver, such\n",
            "as interior point methods or simplex. In practice, the network simplex is an eﬃcient option, and it used\n",
            "pivoting rule adapted to the OT constraint set. In the case of the assignment problem, a=b=1n/n, there\n",
            "exists faster combinatorial optimization scheme, the most famous ones being the Hungarian algorithm and\n",
            "the auction algorithm, which have roughly O(n3) complexity. Section 1.5 details an approximate algorithm,\n",
            "which is typically faster\n",
            "Chunk 54: , and amenable to parallelisation, but do not compute exactly the solution to the\n",
            "OT problem.\n",
            "1.4 Duality\n",
            "The Kantorovich problem (1.11) is a constrained convex minimization problem, and as such, it can be\n",
            "naturally paired with a so-called dual problem, which is a constrained concave maximization problem. The\n",
            "following fundamental proposition, which is a special case of Fenchel-Rockafellar duality theory, explains the\n",
            "relationship between the primal and dual problems.\n",
            "Proposition 4. One has\n",
            "LC(a,b) = max\n",
            "(f,g)∈R(a,b)⟨f,a⟩\n",
            "Chunk 55: +⟨g,b⟩ (1.17)\n",
            "where the set of admissible potentials is\n",
            "R(a,b)def.={(f,g)∈Rn×Rm;∀(i,j)∈JnK×JmK,f⊕g⩽C} (1.18)\n",
            "Proof. This result is a direct consequence of the more general result on the strong duality for linear pro-\n",
            "grams [?, p.148,Theo.4.4]. The easier part of that result, namely that the right-hand side of Equation (1.17)\n",
            "is a lower bound on L C\n",
            "Chunk 56: (a,b) is discussed in??. For the sake of completeness, let us derive this dual problem\n",
            "with the use of Lagrangian duality. The Lagangian associate to (1.11) reads\n",
            "min\n",
            "P⩾0max\n",
            "(f,g)∈Rn×Rm⟨C,P⟩+⟨a−P1m,f⟩+⟨b−P⊤1n,g⟩. (1.19)\n",
            "For linear program, one can always exchange the min and the max and get the same value of the linear\n",
            "program, and one thus consider\n",
            "max\n",
            "(f,g\n",
            "Chunk 57: )∈Rn×Rm⟨a,f⟩+⟨b,g⟩+ min\n",
            "P⩾0⟨C−f1⊤\n",
            "m−1ng⊤,P⟩.\n",
            "We conclude by remarking that\n",
            "min\n",
            "P⩾0⟨Q,P⟩={0 if Q⩾0\n",
            "−∞ otherwise\n",
            "so that the constraint reads C−f1⊤\n",
            "m−1ng⊤=C−f⊕g⩾0.\n",
            "12\n",
            "The primal-dual optimality relation for the Lagrangian (1.19\n",
            "Chunk 58: ) allows to locate the support of the optimal\n",
            "transport plan\n",
            "Supp( P)⊂{\n",
            "(i,j)∈JnK×JmK;fi+gj=Ci,j}\n",
            ". (1.20)\n",
            "To extend this primal-dual construction to arbitrary measures, it is important to realize that measures\n",
            "are naturally paired in duality with continuous functions (a measure can only be accessed through integration\n",
            "against continuous functions). The duality is formalized in the following proposition, which boils down to\n",
            "Proposition 4 when dealing with discrete measures.\n",
            "Proposition 5. One has\n",
            "Lc(α,β) = max\n",
            "(f,g)∈R\n",
            "Chunk 59: (c)∫\n",
            "Xf(x)dα(x) +∫\n",
            "Yg(y)dβ(y), (1.21)\n",
            "where the set of admissible dual potentials is\n",
            "R(c)def.={(f,g)∈C(X)×C(Y) ;∀(x,y),f(x) +g(y)⩽c(x,y)}. (1.22)\n",
            "Here, (f,g)is a pair of continuous functions, and are often called “Kantorovich potentials”.\n",
            "The discrete case (1.17) corresponds to the dual vectors being samples of the\n",
            "Chunk 60:  continuous potentials, i.e.\n",
            "(fi,gj) = (f(xi),g(yj)). The primal-dual optimality conditions allow to track the support of optimal plan,\n",
            "and (1.20) is generalized as\n",
            "Supp(π)⊂{(x,y)∈X×Y ;f(x) +g(y) =c(x,y)}. (1.23)\n",
            "Note that in contrast to the primal problem (1.14), showing the existence of solutions to (1.21) is non-\n",
            "trivial, because the constraint set R(c) is not compact and the function to minimize non-coercive.\n",
            "Chunk 61:  Using the\n",
            "machinery of c-transform detailed in Section??, one can however show that optimal ( f,g) are necessarily\n",
            "Lipschitz regular, which enable to replace the constraint by a compact one.\n",
            "Benier’s Theorem and Monge-Amp` ere PDE The following celebrated theorem of [?] ensures that in\n",
            "Rdforp= 2, if at least one of the two inputs measures has a density, then Kantorovitch and Monge problems\n",
            "are equivalent.\n",
            "Theorem 1 (Brenier).In the caseX=Y=Rdandc(x,y) =||x−y||2, if at least one of the\n",
            "Chunk 62:  two inputs\n",
            "measures (denoted α) has a density ραwith respect to the Lebesgue measure, then the optimal πin the\n",
            "Kantorovich formulation (1.14) is unique, and is supported on the graph (x,T(x))of a “Monge map” T:\n",
            "Rd→Rd. This means that π= (Id,T)♯µ,i.e.\n",
            "∀h∈C(X×Y ),∫\n",
            "X×Yh(x,y)dπ(x,y) =∫\n",
            "Xh(x,T(x))dµ(x). (1.24\n",
            "Chunk 63: )\n",
            "Furthermore, this map Tis uniquely deﬁned as the gradient of a convex function ϕ,T(x) =∇ϕ(x), where\n",
            "ϕis the unique (up to an additive constant) convex function such that (∇ϕ)♯µ=ν. This convex function is\n",
            "related to the dual potential fsolving (1.21) asϕ(x) =||x||2\n",
            "2−f(x).\n",
            "Proof. We sketch the main ingredients of the proof, more details can be found for instance in [?]. We remark\n",
            "that∫\n",
            "cdπ=Cα,β−2∫\n",
            "⟨\n",
            "Chunk 64: x, y⟩dπ(x,y) where the constant is Cα,β=∫\n",
            "||x||2dα(x) +∫\n",
            "||y||2dβ(y). Instead of\n",
            "solving (1.14), one can thus consider the following problem\n",
            "max\n",
            "π∈U(α,β)∫\n",
            "X×Y⟨x, y⟩dπ(x,y),\n",
            "whose dual reads\n",
            "min\n",
            "(ϕ,ψ){∫\n",
            "Xϕdα+∫\n",
            "Yψdβ;∀(x,y), ϕ (x) +ψ(y)�\n",
            "Chunk 65: �⟨x, y⟩}\n",
            ". (1.25)\n",
            "13\n",
            "The relation between these variables and those of (1.22) is ( ϕ,ψ) = (||·||2\n",
            "2−f,||·||2\n",
            "2−g). One can replace the\n",
            "constraint by\n",
            "∀y, ψ (y)⩾ϕ∗(y)def.= sup\n",
            "x⟨x, y⟩−ϕ(x). (1.26)\n",
            "Hereϕ∗is the Legendre transform of ϕand is a convex function as a supremum of linear forms (see\n",
            "also (??\n",
            "Chunk 66: )). Since the objective appearing in (1.27) is linear and the integrating measures positive, one can\n",
            "minimize explicitly with respect to ϕand setψ=ϕ∗in order to consider the unconstraint problem\n",
            "min\n",
            "ϕ∫\n",
            "Xϕdα+∫\n",
            "Yϕ∗dβ, (1.27)\n",
            "see also Section??for a generalization of this idea to generic costs c(x,y). By iterating this argument\n",
            "twice, one can replace ϕbyϕ∗∗, which is a convex function, and thus impose in (1.27) that ϕis convex.\n",
            "Condition (1.23\n",
            "Chunk 67: ) shows that an optimal πis supported on{(x,y) ;ϕ(x) +ϕ∗(y) =⟨x, y⟩}which shows that\n",
            "such anyis optimal for the minimization (1.26) of the Legendre transform, whose optimality condition reads\n",
            "y∈∂ϕ(x). Sinceϕis convex, it is diﬀerentiable almost everywhere, and since αhas a density, it is also\n",
            "diﬀerentiable α-almost everywhere. This shows that for each x, the associated yis uniquely deﬁned α-almost\n",
            "everywhere as y=∇ϕ\n",
            "Chunk 68: (x), and shows that necessarily π= (Id,∇ϕ)♯α.\n",
            "This results shows that in the setting of W2with non-singular densities, the Monge problem (1.9)\n",
            "and its Kantorovich relaxation (1.14) are equal (the relaxation is tight). This is the continuous analog\n",
            "of Proposition 1 for the assignment case (1), which states that the minimum of the optimal transport\n",
            "problem is achieved, when the marginals are equal and uniform, at a permutation matrix (a discrete map).\n",
            "Brenier’s theorem, stating that an optimal transport map must be the gradient of a convex function, should\n",
            "be examined under the\n",
            "Chunk 69:  light that a convex function is the natural generalization of the notion of increasing\n",
            "functions in dimension more than one. Optimal transport can thus plays an important role to deﬁne quantile\n",
            "functions in arbitrary dimensions, which in turn is useful for applications to quantile regression problems [?].\n",
            "Note also that this theorem can be extended in many directions. The condition that αhas a density can\n",
            "be weakened to the condition that it does not give mass to “small sets” having Hausdorﬀ dimension smaller\n",
            "thand−1 (e.g. hypersurfaces). One can also consider costs of the form c(x,y) =h(x−y) wherehis\n",
            "Chunk 70:  a\n",
            "strictly convex function.\n",
            "For measures with densities, using (1.4), one obtains that ϕis the unique (up to the addition of a\n",
            "constant) convex function which solves the following Monge-Amp ˜A¨re-type equation\n",
            "det(∂2ϕ(x))ρβ(∇ϕ(x)) =ρα(x) (1.28)\n",
            "where∂2ϕ(x)∈Rd×dis the hessian of ϕ. The Monge-Amp` ere operator det( ∂2ϕ(x)) can be understood as a\n",
            "non-linear degenerate La\n",
            "Chunk 71: placian. In the limit of small displacements, ϕ= Id +εϕ, one indeed recovers the\n",
            "Laplacian ∆ as a linearization since for smooth maps\n",
            "det(∂2ϕ(x)) = 1 +ε∆ϕ(x) +o(ε).\n",
            "The convexity constraint forces det( ∂2ϕ(x))⩾0 and is necessary for this equation to have a solution.\n",
            "Special cases In general, computing OT distances is numerically involved. We review special favorable\n",
            "cases where the resolution of the OT problem is easy.\n",
            "Remark 6 (Binary Cost Matrix and 1-Norm).One can easily check that when\n",
            "Chunk 72:  the cost matrix Cis zero on\n",
            "the diagonal and 1 elsewhere, namely when C=1n×n−In, the OT distance between aandbis equal to\n",
            "the 1-norm of their diﬀerence, L C(a,b) =||a−b||1. One can also easily check that this result extends to\n",
            "discrete and discrete measures in the case where c(x,y) is 0 ifx=yand 1 when x̸=y. The OT distance\n",
            "between two discrete measures αandβis equal to their total variation distance.\n",
            "14\n",
            "\u0000\u0000↵Figure 1.8: 1-D optimal couplings: each arrow xi→yjindicate\n",
            "Chunk 73:  a non-zero Pi,jin the optimal coupling.\n",
            "Top: empirical measures with same number of points (optimal matching). Bottom: generic case. This\n",
            "corresponds to monotone rearrangements, if xi⩽xi′are such that Pi,j̸= 0,Pi′,j′̸= 0, then necessarily\n",
            "yj⩽yj′.\n",
            "Remark 7 (1-D case – Empirical measures).HereX=R. Assuming α=1\n",
            "n∑n\n",
            "i=1δxiandβ=1\n",
            "n∑n\n",
            "j=1δyj,\n",
            "and assuming (without loss of generality)\n",
            "Chunk 74:  that the points are ordered, i.e.x1⩽x2⩽...⩽xnand\n",
            "y1⩽y2⩽...⩽yn, then one has the simple formula\n",
            "Wp(α,β)p=p∑\n",
            "i=1|xi−yi|p, (1.29)\n",
            "i.e.locally (if one assumes distinct points), Wp(α,β) is theℓpnorm between two vectors of ordered values of\n",
            "αandβ. That statement is only valid locally, in the sense that the order (and those vector representations)\n",
            "might change whenever some of the values change. That formula\n",
            "Chunk 75:  is a simple consequence of the more general\n",
            "remark given below. Figure 1.8, top row, illustrates the 1-D transportation map between empirical measures\n",
            "with the same number of points. The bottom row shows how this monotone map generalizes to arbitrary\n",
            "discrete measures. It is possible to leverage this 1-D computation to also compute eﬃciently OT on the\n",
            "circle, see [?]. Note that in the case of concave cost of the distance, for instance when p<1, the behaviour\n",
            "of the optimal transport plan is very diﬀerent, see [?], which describes an eﬃcient solver in this case.\n",
            "Remark 8 (1-D\n",
            "Chunk 76:  case – Generic case).For a measure αonR, we introduce the cumulative function\n",
            "∀x∈R,Cα(x)def.=∫x\n",
            "−∞dα, (1.30)\n",
            "which is a function Cα:R→[0,1], and its pseudo-inverse C−1\n",
            "α: [0,1]→R∪{−∞}\n",
            "∀r∈[0,1],C−1\n",
            "α(r) = min\n",
            "x{x∈R∪{−∞} ;Cα(x)⩾r}.\n",
            "That function is also called the generalized quantile function of α.\n",
            "Chunk 77:  For anyp⩾1, one has\n",
            "Wp(α,β)p=||C−1\n",
            "α−C−1\n",
            "β||p\n",
            "Lp([0,1])=∫1\n",
            "0|C−1\n",
            "α(r)−C−1\n",
            "β(r)|pdr. (1.31)\n",
            "This means that through the map α↦→C−1\n",
            "α, the Wasserstein distance is isometric to a linear space equipped\n",
            "with theLpnorm, or, equivalently, that the Wasserstein distance for measures on the real line is a Hilbertian\n",
            "metric. This makes the geometry of 1-D optimal transport very simple, but\n",
            "Chunk 78:  also very diﬀerent from its\n",
            "geometry in higher dimensions, which is not Hilbertian as discussed in Proposition??and more generally\n",
            "in§??. Forp= 1, one even has the simpler formula\n",
            "W1(α,β) =||Cα−Cβ||L1(R)=∫\n",
            "R|Cα(x)−Cβ(x)|dx (1.32)\n",
            "=∫\n",
            "R⏐⏐⏐⏐∫x\n",
            "−∞d(α−β)⏐⏐⏐⏐dx. (1.33)\n",
            "15\n",
            "µ ν (tT+ (\n",
            "Chunk 79: 1−t)Id)♯µ\n",
            "0 0.5 10.5Cµ\n",
            "Cν\n",
            "0 0.5 100.51\n",
            "Cµ-1\n",
            "Cν-1\n",
            "0 0.5 100.51\n",
            "T\n",
            "T-1\n",
            "0 0.5 100.51\n",
            "(Cα,Cβ) (C−1\n",
            "α,C−1\n",
            "β) ( T,T−1) (1−t)C−1\n",
            "α+tC−1\n",
            "β\n",
            "Figure 1.9: Computation of OT and displacement interpolation between two 1-D measures, using cumulant\n",
            "function as detailed in (1.34).\n",
            "which shows that W\n",
            "Chunk 80: 1is a norm (see§??for the generalization to arbitrary dimensions). An optimal Monge\n",
            "mapTsuch thatT♯α=βis then deﬁned by\n",
            "T=C−1\n",
            "β◦Cα. (1.34)\n",
            "Figure 1.9 illustrates the computation of 1-D OT through cumulative functions. It also displays displacement\n",
            "interpolations, computed as detailed in (??), see also Remark??. For a detailed survey of the properties of\n",
            "optimal transport in 1-D, we refer the reader to [?, Chapter 2].\n",
            "Remark 9 (Distance between Gaussians).Ifα=N(mα,Σα) andβ\n",
            "Chunk 81: =N(mβ,Σβ) are two Gaussians in Rd,\n",
            "then one can show that the following map\n",
            "T:x↦→mβ+A(x−mα), (1.35)\n",
            "where\n",
            "A=Σ−1\n",
            "2α(\n",
            "Σ1\n",
            "2αΣβΣ1\n",
            "2α)1\n",
            "2Σ−1\n",
            "2α=AT,\n",
            "is such that T♯ρα=ρβ. Indeed, one simply has to notice that the change of variables formula (1.4) is satisﬁed\n",
            "since\n",
            "ρβ(T(x)) = det(2πΣβ)−\n",
            "Chunk 82: 1\n",
            "2exp(−⟨T(x)−mβ,Σ−1\n",
            "β(T(x)−mβ)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα, ATΣ−1\n",
            "βA(x−mα)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα,Σ−1\n",
            "α(x−mα)⟩),\n",
            "and sinceTis a linear map we have that\n",
            "|detT′(x)|= detA=(detΣβ\n",
            "det�\n",
            "Chunk 83: �α)1\n",
            "2\n",
            "and we therefore recover ρα=|detT′|ρβmeaningT♯α=β. Notice now that Tis the gradient of the convex\n",
            "functionψ:x↦→1\n",
            "2⟨x−mα, A(x−mα)⟩+⟨mβ, x⟩to conclude, using Brenier’s theorem [?] (see Remark??)\n",
            "thatTis optimal. Both that map Tand the corresponding potential ψare illustrated in Figures 1.10 and??\n",
            "16\n",
            "-4 -2 0 2 4 6-3-2-101234\n",
            "ρβραFigure\n",
            "Chunk 84:  1.10: Two Gaussians ραandρβ, represented using the contour plots of their densities, with respective\n",
            "mean and variance matrices mα= (−2,0),Σα=1\n",
            "2(\n",
            "1−1\n",
            "2;−1\n",
            "21)\n",
            "andmβ= (3,1),Σβ=(\n",
            "2,1\n",
            "2;1\n",
            "2,1)\n",
            ". The\n",
            "arrows originate at random points xtaken on the plane and end at the corresponding mappings of those\n",
            "pointsT(x) =mβ+A(x−mα).\n",
            "\u0000m\n",
            "Figure 1.11: Computation of displacement interpolation between two 1-\n",
            "Chunk 85: D Gaussians. Denoting Gm,σ(x)def.=\n",
            "1√\n",
            "2πse−(x−m)2\n",
            "2s2the Gaussian density, it thus shows the interpolation G(1−t)m0+tm1,(1−t)σ0+tσ1.\n",
            "With additional calculations involving ﬁrst and second order moments of ρα, we obtain that the transport\n",
            "cost of that map is\n",
            "W2\n",
            "2(α,β) =||mα−mβ||2+B(Σα,Σβ)2(1.36)\n",
            "whereBis the so-called Bures’ metric\n",
            "Chunk 86:  [?] between positive deﬁnite matrices (see also [?,?]),\n",
            "B(Σα,Σβ)2def.= tr(\n",
            "Σα+Σβ−2(Σ1/2\n",
            "αΣβΣ1/2\n",
            "α)1/2)\n",
            ", (1.37)\n",
            "where Σ1/2is the matrix square root. One can show that Bis a distance on covariance matrices, and that\n",
            "B2is convex with respect to both its arguments. In the case where Σα= diag(ri)iandΣβ= diag(si)iare\n",
            "diagonals,\n",
            "Chunk 87:  the Bures metric is the Hellinger distance\n",
            "B(Σα,Σβ) =||√r−√s||2.\n",
            "For 1-D Gaussians, W2is thus the Euclidean distance on the 2-D plane ( m,√\n",
            "Σ), as illustrated in Figure 1.11.\n",
            "For a detailed treatment of the Wasserstein geometry of Gaussian distributions, we refer to [?].\n",
            "1.5 Sinkhorn\n",
            "This section introduces a family of numerical scheme to approximate solutions to Kantorovich formulation\n",
            "of optimal transport and its many generalizations. It operates by adding an entropic regularization penalty to\n",
            "the original problem. This regularization\n",
            "Chunk 88:  has several important advantages, but a few stand out particularly:\n",
            "The minimization of the regularized problen can be solved using a simple alternate minimization scheme;\n",
            "that scheme translates into iterations that are simple matrix products, making them particularly suited to\n",
            "execution of GPU; the resulting approximate distance is smooth with respect to input histogram weights\n",
            "and positions of the Diracs.\n",
            "17\n",
            "c\"P\"Figure 1.12: Impact of εon the optimization of a linear function on the simplex, solving Pε=\n",
            "argminP∈Σ3⟨C,P⟩−εH(P) for a varying ε.\n",
            "Entropic Regularization. The discrete entropy of\n",
            "Chunk 89:  a coupling matrix is deﬁned as\n",
            "H(P)def.=−∑\n",
            "i,jPi,j(log(Pi,j)−1), (1.38)\n",
            "with an analogous deﬁnition for vectors, with the convention that H(a) =−∞ if one of the entries ajis\n",
            "0 or negative. The function His 1-strongly concave, because its hessian is ∂2H(P) =−diag(1/Pi,j) and\n",
            "Pi,j⩽1. The idea of the entropic regularization of optimal transport is to use −Has a regularizing function\n",
            "to obtain approximate\n",
            "Chunk 90:  solutions to the original transport problem (1.11):\n",
            "Lε\n",
            "C(a,b)def.= min\n",
            "P∈U(a,b)⟨P,C⟩−εH(P). (1.39)\n",
            "Since the objective is a ε-strongly convex function, problem 1.39 has a unique optimal solution. The idea\n",
            "to regularize the optimal transport problem by an entropic term can be traced back to modeling ideas in\n",
            "transportation theory [?]: Actual traﬃc patterns in a network do not agree with those predicted by the\n",
            "solution of the optimal transport problem. Indeed, the former are more diﬀuse than\n",
            "Chunk 91:  the latter, which tend\n",
            "to rely on a few routes as a result of the sparsity of optimal couplings to the solution of 1.11. To balance for\n",
            "that, researchers in transportation proposed a model, called the “gravity” model [?], that is able to form a\n",
            "more “blurred” traﬃc prediction.\n",
            "Figure 1.12 illustrates the eﬀect of the entropy to regularize a linear program over the simples Σ 3(which\n",
            "can thus be visualized as a triangle in 2-D). Note how the entropy pushes the original LP solution away\n",
            "from the boundary of the triangle. The optimal Pεprogressively moves toward an “ent\n",
            "Chunk 92: ropic center” of the\n",
            "triangle. This is further detailed in the proposition below. The convergence of the solution of that regularized\n",
            "problem towards an optimal solution of the original linear program has been studied by [?].\n",
            "Proposition 6 (Convergence with ε).The unique solution Pεof(1.39) converges to the optimal solution\n",
            "with maximal entropy within the set of all optimal solutions of the Kantorovich problem, namely\n",
            "Pεε→0−→argmin\n",
            "P{−H(P) ;P∈U(a,b),⟨P,C⟩= LC(a,b)} (1.40)\n",
            "so that in particular\n",
            "\n",
            "Chunk 93: Lε\n",
            "C(a,b)ε→0−→LC(a,b).\n",
            "One has\n",
            "Pεε→∞−→abT= (aibj)i,j. (1.41)\n",
            "Proof. We consider a sequence ( εℓ)ℓsuch thatεℓ→0 andεℓ>0. We denote Pℓthe solution of (1.39) for\n",
            "ε=εℓ. Since U(a,b) is bounded, we can extract a sequence (that we do not relabel for sake of simplicity)\n",
            "such that Pℓ→P⋆. Since U(a,\n",
            "Chunk 94: b) is closed, P⋆∈U(a,b). We consider any Psuch that⟨C,P⟩= LC(a,b).\n",
            "By optimality of PandPℓfor their respective optimization problems (for ε= 0 andε=εℓ), one has\n",
            "0⩽⟨C,Pℓ⟩−⟨C,P⟩⩽εℓ(H(Pℓ)−H(P)). (1.42)\n",
            "18\n",
            "⇡\"↵\u0000\n",
            "\"\u0000↵Figure 1.13: Impact of εon coupling between dens\n",
            "Chunk 95: ities and discrete distributions, illustrating Proposition 6.\n",
            "Left: between two 1-D densities. Right: between two 2-D discrete empirical densities with same number\n",
            "n=mof points (only entries of the optimal ( Pi,j)i,jabove a small threshold are displayed as segments\n",
            "betweenxiandyj).\n",
            "Since His continuous, taking the limit ℓ→+∞in this expression shows that ⟨C,P⋆⟩=⟨C,P⟩so that\n",
            "P⋆is a feasible point of (1.40). Furthermore, dividing by εℓin (1.42) and taking the limit shows that\n",
            "H\n",
            "Chunk 96: (P)⩽H(P⋆), which shows that P⋆is a solution of (1.40). Since the solution P⋆\n",
            "0to this program is unique\n",
            "by strict convexity of −H, one has P⋆=P⋆\n",
            "0, and the whole sequence is converging.\n",
            "Formula (1.40) states that for low regularization, the solution converges to the maximum entropy optimal\n",
            "transport coupling. In sharp contrast, (1.41) shows that for large regularization, the solution converges to the\n",
            "coupling with maximal entropy between two prescribed marginals a,b, namely the joint probability between\n",
            "two independent\n",
            "Chunk 97:  random variables with prescribed distributions. A reﬁned analysis of this convergence is\n",
            "performed in [?], including a ﬁrst order expansion in ε(resp. 1/ε) nearε= 0 (respε= +∞). Figure 1.13\n",
            "shows visually the eﬀect of these two convergence. A key insight is that, as εincreases, the optimal coupling\n",
            "becomes less and less sparse (in the sense of having entries larger than a prescribed thresholds), which in\n",
            "turn as the eﬀect of both accelerating computational algorithms (as we study in §1.5) but also leading to\n",
            "faster statistical convergence (as exposed in §??).\n",
            "Chunk 98: \n",
            "Deﬁning the Kullback-Leibler divergence between couplings as\n",
            "KL(P|K)def.=∑\n",
            "i,jPi,jlog(Pi,j\n",
            "Ki,j)\n",
            "−Pi,j+Ki,j, (1.43)\n",
            "the unique solution Pεof (1.39) is a projection onto U(a,b) of the Gibbs kernel associated to the cost matrix\n",
            "Cas\n",
            "Ki,jdef.=e−Ci,j\n",
            "ε\n",
            "Indeed one has that using the deﬁnition above\n",
            "Pε= ProjKL\n",
            "U(a,b)(K)def.= arg\n",
            "Chunk 99: min\n",
            "P∈U(a,b)KL(P|K). (1.44)\n",
            "Remark 10 (General formulation).One can consider arbitrary measures by replacing the discrete entropy\n",
            "by the relative entropy with respect to the product measure d α⊗dβ(x,y)def.= dα(x)dβ(y), and propose a\n",
            "regularized counterpart to (1.14) using\n",
            "Lε\n",
            "c(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "X×Yc(x,y)dπ(x,y) +εKL(π|α⊗β) (1\n",
            "Chunk 100: .45)\n",
            "where the relative entropy is a generalization of the discrete Kullback-Leibler divergence (1.43)\n",
            "KL(π|ξ)def.=∫\n",
            "X×Ylog(dπ\n",
            "dξ(x,y))\n",
            "dπ(x,y)+\n",
            "∫\n",
            "X×Y(dξ(x,y)−dπ(x,y)),(1.46)\n",
            "19\n",
            "and by convention KL( π|ξ) = +∞ifπdoes not have a densitydπ\n",
            "dξwith respect to ξ. It is important to\n",
            "realize that the reference measure α⊗βch\n",
            "Chunk 101: osen in (1.45) to deﬁne the entropic regularizing term KL( ·|α⊗β)\n",
            "plays no speciﬁc role, only its support matters.\n",
            "Formula (1.45) can be re-factored as a projection problem\n",
            "min\n",
            "π∈U(α,β)KL(π|K) (1.47)\n",
            "whereKis the Gibbs distributions d K(x,y)def.=e−c(x,y)\n",
            "εdµ(x)dν(y). This problem is often referred to as the\n",
            "“static Schr¨ odinger problem” [?,?],\n",
            "Chunk 102:  since it was initially considered by Schr¨ odinger in statistical physics [?].\n",
            "Asε→0, the unique solution to (1.47) converges to the maximum entropy solution to (1.14), see [?,?].§??\n",
            "details an alternate “dynamic” formulation of the Schr¨ odinger problem over the space of paths connecting\n",
            "the points of two measures.\n",
            "Sinkhorn’s Algorithm The following proposition shows that the solution of (1.39) has a speciﬁc form,\n",
            "which can be parameterized using n+mvariables. That parameterization is therefore essentially dual, in\n",
            "the sense that a coupling PinU(a,b)\n",
            "Chunk 103:  hasnmvariables but n+mconstraints.\n",
            "Proposition 7. The solution to (1.39) is unique and has the form\n",
            "∀(i,j)∈JnK×JmK,Pi,j=uiKi,jvj (1.48)\n",
            "for two (unknown) scaling variable (u,v)∈Rn\n",
            "+×Rm\n",
            "+.\n",
            "Proof. Introducing two dual variables f∈Rn,g∈Rmfor each marginal constraint, the Lagrangian of (1.39)\n",
            "reads\n",
            "E(P,f,g) =⟨P,C⟩−εH(P)\n",
            "Chunk 104: −⟨f,P1m−a⟩−⟨g,PT1n−b⟩.\n",
            "Considering ﬁrst order conditions, we have\n",
            "∂E(P,f,g)\n",
            "∂Pi,j=Ci,j−εlog(Pi,j)−fi−gj.\n",
            "which results, for an optimal Pcoupling to the regularized problem, in the expression Pi,j=efi/εe−Ci,j/εegj/ε\n",
            "which can be rewritten in the form provided in the proposition using non-negative vectors uandv.\n",
            "The factorization of the optimal solution exhibited in Equation\n",
            "Chunk 105:  (1.48) can be conveniently rewritten in\n",
            "matrix form as P= diag( u)Kdiag(v).u,vmust therefore satisfy the following non-linear equations which\n",
            "correspond to the mass conservation constraints inherent to U(a,b),\n",
            "diag(u)Kdiag(v)1m=a,and diag( v)K⊤diag(u)1n=b, (1.49)\n",
            "These two equations can be further simpliﬁed, since diag( v)1mis simply v, and the multiplication of diag( u)\n",
            "times Kvis\n",
            "u⊙(Kv) =aand v\n",
            "Chunk 106: ⊙(KTu) =b (1.50)\n",
            "where⊙corresponds to entry-wise multiplication of vectors. That problem is known in the numerical analysis\n",
            "community as the matrix scaling problem (see [?] and references therein). An intuitive way to try to solve\n",
            "these equations is to solve them iteratively, by modifying ﬁrst uso that it satisﬁes the left-hand side of\n",
            "Equation (1.50) and then vto satisfy its right-hand side. These two updates deﬁne Sinkhorn’s algorithm:\n",
            "u(ℓ+1)def.=a\n",
            "Kv(ℓ)\n",
            "Chunk 107: and v(ℓ+1)def.=b\n",
            "KTu(ℓ+1), (1.51)\n",
            "initialized with an arbitrary positive vector v(0)=1m. The division operator used above between two\n",
            "vectors is to be understood entry-wise. Note that a diﬀerent initialization will likely lead to a diﬀerent\n",
            "20\n",
            "`⇡(`)\"\n",
            "1000 2000 3000 4000 5000-2-1.5-1-0.50`Figure 1.14: Left: evolution of the coupling πℓ\n",
            "ε= diag( U(ℓ))Kdiag(V(ℓ)) computed at iteration �\n",
            "Chunk 108: ��of\n",
            "Sinkhorn’s iterations, for 1-D densities. Right: impact of εthe convergence rate of Sinkhorn, as measured\n",
            "in term of marginal constraint violation log( ||πℓ\n",
            "ε1m−b||1).\n",
            "solution for u,v, since u,vare only deﬁned up to a multiplicative constant (if u,vsatisfy (1.49) then\n",
            "so doλu,v/λfor anyλ > 0). It turns out however that these iterations converge (see Remark 11 for\n",
            "a justiﬁcation using iterative projections, and Remark 13 for a strict contraction result) and all\n",
            "Chunk 109:  result in\n",
            "the same optimal coupling diag( u)Kdiag(v). Figure 1.14, top row, shows the evolution of the coupling\n",
            "diag(U(ℓ))Kdiag(V(ℓ)) computed by Sinkhorn iterations. It evolves from the Gibbs kernel Ktowards the\n",
            "optimal coupling solving (1.39) by progressively shifting the mass away from the diagonal.\n",
            "Remark 11 (Relation with iterative projections).Denoting\n",
            "C1\n",
            "adef.={P;P1m=a}andC2\n",
            "bdef.={\n",
            "P;PT1m=b}\n",
            "the rows and columns constraints, one has U(a\n",
            "Chunk 110: ,b) =C1\n",
            "a∩C2\n",
            "b. One can use Bregman iterative projections [?]\n",
            "P(ℓ+1) def.= ProjKL\n",
            "C1a(P(ℓ)) and P(ℓ+2) def.= ProjKL\n",
            "C2\n",
            "b(P(ℓ+1)). (1.52)\n",
            "Since the setsC1\n",
            "aandC2\n",
            "bare aﬃne, these iterations are known to converge to the solution of (1.44), see [?].\n",
            "These iterate are equivalent to Sinkhorn iterations (1.51) since deﬁning\n",
            "\n",
            "Chunk 111: P(2ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)),\n",
            "one has\n",
            "P(2ℓ+1) def.= diag( u(ℓ+1))Kdiag(v(ℓ))\n",
            "and P(2ℓ+2) def.= diag( u(ℓ+1))Kdiag(v(ℓ+1))\n",
            "In practice however one should prefer using (1.51) which only requires manipulating scaling vectors and\n",
            "multiplication against a Gibbs kernel, which can often be accelerated (see below Remarks??and??).\n",
            "Remark 12 (\n",
            "Chunk 112: Hilbert metric).As initially explained by [?], the global convergence analysis of Sinkhorn is\n",
            "greatly simpliﬁed using Hilbert projective metric on Rn\n",
            "+,∗(positive vectors), deﬁned as\n",
            "∀(u,u′)∈(Rn\n",
            "+,∗)2, dH(u,u′)def.= log max\n",
            "i,i′uiu′\n",
            "i′\n",
            "ui′u′\n",
            "i.\n",
            "This can be shows to be a distance on the projective cone Rn\n",
            "+,∗/∼, where u∼u′means that∃s>0,u=su′\n",
            "\n",
            "Chunk 113: (the vector are equal up to rescaling, hence the naming “projective”). This means that dHsatisﬁes the\n",
            "triangular inequality and dH(u,u′) = 0 if and only if u∼u′. This is a projective version of Hilbert’s original\n",
            "distance on bounded open convex sets [?]. The projective cone Rn\n",
            "+,∗/∼is a complete metric space for this\n",
            "distance. It was introduced independently by [?] and [?] to provide a quantitative proof of Perron-Frobenius\n",
            "theorem, which, as explained in Remark??is linked to a local linearization of Sink\n",
            "Chunk 114: horn’s iterates. They\n",
            "proved the following fundamental theorem, which shows that a positive matrix is a strict contraction on the\n",
            "cone of positive vectors.\n",
            "21\n",
            "Theorem 2. Let K∈Rn×m\n",
            "+,∗, then for (v,v′)∈(Rm\n",
            "+,∗)2\n",
            "dH(Kv,Kv′)⩽λ(K)dH(v,v′)where\n",
            "\n",
            "λ(K)def.=√\n",
            "η(K)−1√\n",
            "η(K)+1<1\n",
            "η(K\n",
            "Chunk 115: )def.= max\n",
            "i,j,k,ℓKi,kKj,ℓ\n",
            "Kj,kKi,ℓ.\n",
            "Remark 13 (Global convergence).The following theorem, proved by [?], makes use of this Theorem 2 to\n",
            "show the linear convergence of Sinkhorn’s iterations.\n",
            "Theorem 3. One has (u(ℓ),v(ℓ))→(u⋆,v⋆)and\n",
            "dH(u(ℓ),u⋆) =O(λ(K)2ℓ), dH(v(ℓ),v⋆\n",
            "Chunk 116: ) =O(λ(K)2ℓ). (1.53)\n",
            "One also has\n",
            "dH(u(ℓ),u⋆)⩽dH(P(ℓ)1m,a)\n",
            "1−λ(K)\n",
            "dH(v(ℓ),v⋆)⩽dH(P(ℓ),⊤1n,b)\n",
            "1−λ(K)(1.54)\n",
            "where we denoted P(ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)). Lastly, one has\n",
            "∥log(P\n",
            "Chunk 117: (ℓ))−log(P⋆)∥∞⩽dH(u(ℓ),u⋆) +dH(v(ℓ),v⋆) (1.55)\n",
            "where P⋆is the unique solution of (1.39).\n",
            "Proof. One notice that for any ( v,v′)∈(Rm\n",
            "+,∗)2, one has\n",
            "dH(v,v′) =dH(v/v′,1m) =dH(1m/v,1m/v′).\n",
            "This shows that\n",
            "dH(u(ℓ+1\n",
            "Chunk 118: ),u⋆) =dH(a\n",
            "Kv(ℓ),a\n",
            "Kv⋆)\n",
            "=dH(Kv(ℓ),Kv⋆)⩽λ(K)dH(v(ℓ),v⋆).\n",
            "where we used Theorem 2. This shows (1.53). One also has, using the triangular inequality\n",
            "dH(u(ℓ),u⋆)⩽dH(u(ℓ+1),u(ℓ)) +dH(u(ℓ+1),u⋆)\n",
            "⩽dH(a\n",
            "\n",
            "Chunk 119: Kv(ℓ),u(ℓ))\n",
            "+λ(K)dH(u(ℓ),u⋆)\n",
            "=dH(\n",
            "a,u(ℓ)⊙(Kv(ℓ)))\n",
            "+λ(K)dH(u(ℓ),u⋆),\n",
            "which gives the ﬁrst part of (1.54) since u(ℓ)⊙(Kv(ℓ)) =P(ℓ)1m(the second one being similar). The proof\n",
            "of (1.55) follows from [?, Lemma 3]\n",
            "The bound (\n",
            "Chunk 120: 1.54) shows that some error measures on the marginal constraints violation, for instance\n",
            "∥P(ℓ)1m−a∥1and∥P(ℓ)T1n−b∥1, are useful stopping criteria to monitor the convergence.\n",
            "Figure 1.14, bottom row, highlights this linear rate on the constraint violation, and shows how this rate\n",
            "degrades as ε→0. These results are proved in [?] and are tightly connected to nonlinear Perron-Frobenius\n",
            "Theory [?]. Perron-Frobenius theory corresponds to the linearization of the iterations, see (??). This\n",
            "convergence analysis is extended\n",
            "Chunk 121:  in [?], who shows that each iteration of Sinkhorn increases the permanent\n",
            "of the scaled coupling matrix.\n",
            "22\n",
            "Regularized Dual and Log-domain Computations The following proposition details the dual problem\n",
            "associated to (1.39).\n",
            "Proposition 8. One has\n",
            "Lε\n",
            "C(a,b) = max\n",
            "f∈Rn,g∈Rm⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩. (1.56)\n",
            "The optimal (f,g)are linked to scalings (u,v)appearing in (1.48) through\n",
            "\n",
            "Chunk 122: (u,v) = (ef/ε,eg/ε). (1.57)\n",
            "Proof. We start from the end of the proof of Proposition 7, which links the optimal primal solution P\n",
            "and dual multipliers fandgfor the marginal constraints as Pi,j=efi/εe−Ci,j/εegj/ε. Substituting in the\n",
            "LagrangianE(P,f,g) of Equation (1.5) the optimal Pas a function of fandg, we obtain that the Lagrange\n",
            "dual function equals\n",
            "f,g↦→⟨ef/ε,(K⊙C)eg/ε⟩\n",
            "Chunk 123: −εH(diag(ef/ε)Kdiag(eg/ε)). (1.58)\n",
            "The entropy of Pscaled byε, namelyε⟨P,logP−1n×m⟩can be stated explicitly as a function of f,g,C\n",
            "⟨diag(ef/ε)Kdiag(eg/ε),f1mT+1ngT−C−ε1n×m⟩\n",
            "=−⟨ef/ε,(K⊙C)eg/ε⟩+⟨f,a⟩+⟨g,b⟩−ε⟨\n",
            "Chunk 124: ef/ε,Keg/ε⟩\n",
            "therefore, the ﬁrst term in (1.58) cancels out with the ﬁrst term in the entropy above. The remaining times\n",
            "are those displayed in (1.56).\n",
            "Remark 14.Dual for generic measures For generic (non-necessarily discrete) input measures ( α,β), the dual\n",
            "problem (1.56) reads\n",
            "sup\n",
            "f,g∈C(X)×C(Y)∫\n",
            "Xf(x)dα(x) +∫\n",
            "Yg(x)dβ(x)−ε∫\n",
            "X×Ye−c(x,y\n",
            "Chunk 125: )+f(x)+g(y)\n",
            "ε dα(x)dβ(y)\n",
            "This corresponds to a smoothing of the constraint R(c) appearing in the original problem (1.21), which\n",
            "is retrieved in the limit ε→0. Proving existence ( i.e. the sup is actually a max) of these Kantorovich\n",
            "potentials ( f,g) in the case of entropic transport is less easy than for classical OT (because one cannot\n",
            "usec-transform and potentials are not automatically Lipschitz). Proof of existence can be done using the\n",
            "convergence of Sinkhorn iterations, see [?] for more details.\n",
            "Remark 15\n",
            "Chunk 126:  (Sinkhorn as a Block Coordinate Ascent on the Dual Problem).A simple approach to solve the\n",
            "unconstrained maximization problem (1.56) is to use an exact block coordinate ascent strategy, namely to\n",
            "update alternatively fandgto cancel their gradients with respect to the objective of (1.56). Indeed, one\n",
            "can easily notice that, writing Q(f,g) for the objective of (1.56) that\n",
            "∇|fQ(f,g) =a−ef/ε⊙(\n",
            "Keg/ε)\n",
            ", (1.59)\n",
            "∇|gQ(f,g) =b−eg/ε⊙\n",
            "Chunk 127: (\n",
            "KTef/ε)\n",
            ". (1.60)\n",
            "Block coordinate ascent can therefore be implemented in a closed form by applying successively the following\n",
            "updates, starting from any arbitrary g(0), forl⩾0,\n",
            "f(ℓ+1)=εloga−εlog(\n",
            "Keg(ℓ)/ε)\n",
            ", (1.61)\n",
            "g(ℓ+1)=εlogb−εlog(\n",
            "KTef(ℓ+1)/ε)\n",
            ". (1.62)\n",
            "Such iterations are mathematically equivalent to the Sinkhorn iterations (1.51) when considering the primal-\n",
            "dual relations highlighted in (1\n",
            "Chunk 128: .57). Indeed, we recover that at any iteration\n",
            "(f(ℓ),g(ℓ)) =ε(log(u(ℓ)),log(v(ℓ))).\n",
            "23\n",
            "Remark 16 (Soft-min rewriting).Iterations (1.61) and (1.62) can be given an alternative interpretation,\n",
            "using the following notation. Given a vector zof real numbers we write min εzfor the soft-minimum of its\n",
            "coordinates, namely\n",
            "minεz=−εlog∑\n",
            "ie−zi/ε.\n",
            "Note that min ε(z) converges to min zfor any vector zasε→0. Indeed\n",
            "Chunk 129: , min εcan be interpreted as a\n",
            "diﬀerentiable approximation of the min function. Using these notations, Equations (1.61) and (1.62) can be\n",
            "rewritten\n",
            "(f(ℓ+1))i= minε(Cij−g(ℓ)\n",
            "j)j+εlogai, (1.63)\n",
            "(g(ℓ+1))j= minε(Cij−f(ℓ)\n",
            "i)i+εlogbj. (1.64)\n",
            "Here the term min ε(Cij−g(ℓ)\n",
            "j)jdenotes the soft-minimum of all\n",
            "Chunk 130:  values of the j-th column of matrix\n",
            "(C−1n(g(ℓ))⊤). To simplify notations, we introduce an operator that takes a matrix as input and outputs\n",
            "now a column vector of the soft-minimum values of its columns or rows. Namely, for any matrix A∈Rn×m,\n",
            "we deﬁne\n",
            "Minrow\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)j)\n",
            "i∈Rn,\n",
            "Mincol\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)i)\n",
            "j∈Rm.\n",
            "Note that these operations are equivalent to the ent\n",
            "Chunk 131: ropic c-transform introduced in §??(see in particu-\n",
            "lar (??)). Using these notations, Sinkhorn’s iterates read\n",
            "f(ℓ+1)= Minrow\n",
            "ε(C−1ng(ℓ)T) +εloga, (1.65)\n",
            "g(ℓ+1)= Mincol\n",
            "ε(C−f(ℓ)1mT) +εlogb. (1.66)\n",
            "Note that as ε→0, minεconverges to min, but the iterations do not converge anymore in the limit ε= 0,\n",
            "because alternate minimization does not converge for constrained problems (which\n",
            "Chunk 132:  is the case for the un-\n",
            "regularized dual (1.17)).\n",
            "Remark 17 (Log-domain Sinkhorn).While mathematically equivalent to the Sinkhorn updates (1.51), itera-\n",
            "tions (1.63) and (1.64) suggest to use the log-sum-exp stabilization trick to avoid underﬂow for small values\n",
            "ofε. Writing z = min z, that trick suggests to evaluate min εzas\n",
            "minεz= z−εlog∑\n",
            "ie−(zi−z)/ε. (1.67)\n",
            "Instead of substracting z to stabilize the log domain iterations as in (1.67), one can actually\n",
            "Chunk 133:  substract the\n",
            "previously computed scalings. This leads to the following stabilized iteration\n",
            "f(ℓ+1)= Minrow\n",
            "ε(S(f(ℓ),g(ℓ)))−f(ℓ)+εlog(a) (1.68)\n",
            "g(ℓ+1)= Mincol\n",
            "ε(S(f(ℓ+1),g(ℓ)))−g(ℓ)+εlog(b), (1.69)\n",
            "where we deﬁned\n",
            "S(f,g) =(\n",
            "Ci,j−fi−gj)\n",
            "i,j.\n",
            "In contrast to the original iterations (\n",
            "Chunk 134: 1.51), these log-domain iterations (1.68) and (1.69) are stable for\n",
            "arbitraryε >0, because the quantity S(f,g) stays bounded during the iterations. The downside is that it\n",
            "requiresnmcomputations of exp at each step. Computing a Minrow\n",
            "εor Mincol\n",
            "εis typically substantially\n",
            "slower than matrix multiplications, and requires computing line by line soft-minima of matrices S. There is\n",
            "therefore no eﬃcient way to parallelize the application of Sinkhorn maps for several marginals simultaneously.\n",
            "In Euclidean domain of small dimension, it is possible to develop eﬃcient multisc\n",
            "Chunk 135: ale solvers with a decaying\n",
            "εstrategy to signiﬁcantly speed up the computation using sparse grids [?].\n",
            "24\n",
            "1.6 Extensions\n",
            "Wasserstein Barycenters. Given input histogram {bs}S\n",
            "s=1, wherebs∈Σns, and weights λ∈ΣS, a\n",
            "Wasserstein barycenter is computed by minimizing\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsLCs(a,bs) (1.70)\n",
            "where the cost matrices Cs∈Rn×nsneed to be speciﬁed. A typical setup is “Eulerian\n",
            "Chunk 136: ”, so that all the\n",
            "barycenters are deﬁned on the same grid, ns=n,Cs=C=Dpis set to be a distance matrix, so that one\n",
            "solves\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsWp\n",
            "p(a,bs).\n",
            "This barycenter problem (1.70) was originally introduced by [?] following earlier ideas of [?]. They proved\n",
            "in particular uniqueness of the barycenter for c(x,y) =||x−y||2overX=Rd, if one of the input measure\n",
            "has a density with respect to the Lebesgue measure (and\n",
            "Chunk 137:  more generally under the same hypothesis as the\n",
            "one guaranteeing the existence of a Monge map, see Remark??).\n",
            "The barycenter problem for histograms (1.70) is in fact a linear program, since one can look for the S\n",
            "couplings ( Ps)sbetween each input and the barycenter itself\n",
            "min\n",
            "a∈Σn,(Ps∈Rn×ns)s{S∑\n",
            "s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "s1ns=a,P⊤\n",
            "s1n=bs}\n",
            ".\n",
            "Although this problem is an LP, its scale forbids the use\n",
            "Chunk 138:  generic solvers for medium scale problems. One\n",
            "can therefore resort to using ﬁrst order methods such as subgradient descent on the dual [?].\n",
            "Remark 18.Barycenter of arbitrary measures Given a set of input measure ( βs)sdeﬁned on some space X,\n",
            "the barycenter problem becomes\n",
            "min\n",
            "α∈M1\n",
            "+(X)S∑\n",
            "s=1λsLc(α,βs). (1.71)\n",
            "In the case where X=Rdandc(x,y) =||x−y||2, [?] shows that if one of the input measures has a density,\n",
            "then this barycenter\n",
            "Chunk 139:  is unique. Problem (1.71) can be viewed as a generalization of the problem of computing\n",
            "barycenters of points ( xs)S\n",
            "s=1∈XSto arbitrary measures. Indeed, if βs=δxsis a single Dirac mass, then a\n",
            "solution to (1.71) is δx⋆wherex⋆is a Fr´ echet mean solving (??). Note that for c(x,y) =||x−y||2, the mean\n",
            "of the barycenter α⋆is necessarily the barycenter of the mean, i.e.\n",
            "∫\n",
            "Xxdα⋆(x\n",
            "Chunk 140: ) =∑\n",
            "sλs∫\n",
            "Xxdαs(x),\n",
            "and the support of α⋆is located in the convex hull of the supports of the ( αs)s. The consistency of the\n",
            "approximation of the inﬁnite dimensional optimization (1.71) when approximating the input distribution\n",
            "using discrete ones (and thus solving (1.70) in place) is studied in [?]. Let us also note that it is possible to\n",
            "re-cast (1.71) as a multi-marginal OT problem, see Remark??.\n",
            "One can use entropic smoothing and approximate the solution of (1.70) using\n",
            "min\n",
            "Chunk 141: \n",
            "a∈ΣnS∑\n",
            "s=1λsLε\n",
            "Cs(a,bs) (1.72)\n",
            "for someε > 0. This is a smooth convex minimization problem, which can be tackled using gradient\n",
            "descent [?]. An alternative is to use descent method (typically quasi-Newton) on the semi-dual [?], which is\n",
            "25\n",
            "useful to integrate additional regularizations on the barycenter (e.g. to impose some smoothness). A simple\n",
            "but eﬀective approach, as remarked in [?] is to rewrite (1.72) as a (weighted) KL projection problem\n",
            "min\n",
            "(Ps)\n",
            "Chunk 142: s{∑\n",
            "sλsKL(Ps|Ks) ;∀s,PsT1m=bs,P111=...=PS1S}\n",
            "(1.73)\n",
            "where we denoted Ksdef.=e−Cs/ε. Here, the barycenter ais implicitly encoded in the row marginals of all\n",
            "the couplings Ps∈Rn×nsasa=P111=...=PS1S. As detailed in [?], one can generalize Sinkhorn to\n",
            "this problem, which also corresponds to iterative projection. This can also be seen as a special case of the\n",
            "generalized Sinkhorn detailed in §??. The optimal couplings\n",
            "Chunk 143:  ( Ps)ssolving (1.73) are computed in scaling\n",
            "form as\n",
            "Ps= diag( us)Kdiag(vs), (1.74)\n",
            "and the scalings are sequentially updated as\n",
            "∀s∈J1,SK,v(ℓ+1)\n",
            "sdef.=bs\n",
            "KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Ksv(ℓ+1)\n",
            "s, (1.76)\n",
            "where a(ℓ+1)def.\n",
            "Chunk 144: =∏\n",
            "s(Ksv(ℓ+1)\n",
            "s)λs. (1.77)\n",
            "An alternative way to derive these iterations is to perform alternate minimization on the variables of a dual\n",
            "problem, which detailed in the following proposition.\n",
            "Proposition 9. The optimal (us,vs)appearing in (1.74) can be written as (us,vs) = (efs/ε,egs/ε)where\n",
            "(fs,gs)sare the solutions of the following program (whose value matches the one of (1.72) )\n",
            "max\n",
            "(fs,gs)s{∑\n",
            "sλs(\n",
            "⟨gs,bs�\n",
            "Chunk 145: ��−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "sλsfs= 0}\n",
            ". (1.78)\n",
            "Proof. Introducing Lagrange multipliers in (1.73) leads to\n",
            "min\n",
            "(Ps)s,amax\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "εKL(Ps|Ks) +⟨a−Ps1m,fs⟩\n",
            "+⟨bs−PsT1m,gs⟩)\n",
            ".\n",
            "Strong duality holds, so that one can exchange the min and the max, and gets\n",
            "max\n",
            "(fs,gs\n",
            "Chunk 146: )s∑\n",
            "sλs(\n",
            "⟨gs,bs⟩+ min\n",
            "PsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\n",
            "+ min\n",
            "a⟨∑\n",
            "sλsfs,a⟩.\n",
            "The explicit minimization on agives the constraint∑\n",
            "sλsfs= 0 together with\n",
            "max\n",
            "(fs,gs)s∑\n",
            "sλs⟨gs,bs⟩−εKL∗(fs⊕gs\n",
            "ε|Ks)\n",
            "where KL∗(·|Ks) is the Legendre transform (??)\n",
            "Chunk 147:  of the function KL∗(·|Ks). This Legendre transform reads\n",
            "KL∗(U|K) =∑\n",
            "i,jKi,j(eUi,j−1), (1.79)\n",
            "26\n",
            "Figure 1.15: Barycenters between 4 input 3-D shapes using entropic regularization (1.72). The weights\n",
            "(λs)sare bilinear with respect to the four corners of the square. Shapes are represented as measures that\n",
            "are uniform within the boundaries of the shape and null outside.\n",
            "which shows the desired formula. To show (1.79), since this function is separable, one needs to compute\n",
            "\n",
            "Chunk 148: ∀(u,k)∈R2\n",
            "+,KL∗(u|k)def.= max\n",
            "rur−(rlog(r/k)−r+k)\n",
            "whose optimality condition reads u= log(r/k), i.e.r=keu, hence the result.\n",
            "Minimizing (1.78) with respect to each gs, while keeping all the other variable ﬁxed, is obtained in closed\n",
            "form by (1.75). Minimizing (1.78) with respect to all the ( fs)srequires to solve for ausing (1.77) and leads\n",
            "to the expression (1.76).\n",
            "\n",
            "Chunk 149: Figures??and??show applications to 2-D and 3-D shapes interpolation. Figure??shows a computation\n",
            "of barycenters on a surface, where the ground cost is the square of the geodesic distance. For this ﬁgure,\n",
            "the computations are performed using the geodesic in heat approximation detailed in Remark??. We refer\n",
            "to [?] for more details and other applications to computer graphics and imaging sciences.\n",
            "Wasserstein Loss. In statistics, text processing or imaging, one must usually compare a probability\n",
            "distribution βarising from measurements to a model, namely a parameterized family of distributions {αθ,θ∈\n",
            "Θ}where Θ\n",
            "Chunk 150:  is a subset of an Euclidean space. Such a comparison is done through a “loss” or a “ﬁdelity”\n",
            "term, which, in this section, is the Wasserstein distance. In the simplest scenario, the computation of a\n",
            "suitable parameter θis obtained by minimizing directly\n",
            "min\n",
            "θ∈ΘE(θ)def.=Lc(αθ,β). (1.80)\n",
            "Of course, one can consider more complicated problems: for instance, the barycenter problem described\n",
            "in§??consists in a sum of such terms. However, most of these more advanced problems can be usually\n",
            "solved by adapting tools\n",
            "Chunk 151:  deﬁned for basic case: either using the chain rule to compute explicitly derivatives,\n",
            "or using automatic diﬀerentiation.\n",
            "The Wasserstein distance between two histograms or two densities is convex with respect to these inputs,\n",
            "as shown by (1.17) and (1.21) respectively. Therefore, when the parameter θis itself a histogram, namely Θ =\n",
            "Σnandαθ=θ, or more generally when θdescribesKweights in the simplex, Θ = Σ K, andαθ=∑K\n",
            "i=1θiαi\n",
            "is a convex combination of known atoms α1,...\n",
            "Chunk 152: ,αKin ΣN, Problem (1.80) remains convex (the ﬁrst case\n",
            "corresponds to the barycenter problem, the second to one iteration of the dictionary learning problem with\n",
            "a Wasserstein loss [?]). However, for more general parameterizations θ↦→αθ, Problem (1.80) is in general\n",
            "not convex.\n",
            "27\n",
            "g✓XZ⇣xz\u0000↵✓Figure 1.16: Schematic display of the density ﬁtting problem 1.81.\n",
            "A practical problem of paramount importance in statistic and machine learning is density ﬁtting. Given\n",
            "some discrete samples (\n",
            "Chunk 153:  xi)n\n",
            "i=1⊂X from some unknown distribution, the goal is to ﬁt a parametric model\n",
            "θ↦→αθ∈M (X) to the observed empirical input measure β\n",
            "min\n",
            "θ∈ΘL(αθ,β) where β=1\n",
            "n∑\n",
            "iδxi, (1.81)\n",
            "whereLis some “loss” function between a discrete and a “continuous” (arbitrary) distribution (see Fig-\n",
            "ure 1.16).\n",
            "In the case where αθas a densify ρθdef.=ραθwith respect\n",
            "Chunk 154:  to the Lebesgue measure (or any other ﬁxed\n",
            "reference measure), the maximum likelihood estimator (MLE) is obtained by solving\n",
            "min\n",
            "θLMLE(αθ,β)def.=−∑\n",
            "ilog(ρθ(xi)).\n",
            "This corresponds to using an empirical counterpart of a Kullback-Leibler loss since, assuming the xiare i.i.d.\n",
            "samples of some ¯β, then\n",
            "LMLE(α,β)n→+∞−→ KL(α|¯β)\n",
            "This MLE approach is known to lead to optimal estimation procedures in many cases (see for instance [?]).\n",
            "However,\n",
            "Chunk 155:  it fails to work when estimating singular distributions, typically when the αθdoes not has a density\n",
            "(so thatLMLE(αθ,β) = +∞) or when ( xi)iare samples from some singular ¯β(so that the αθshould share\n",
            "the same support as βfor KL(α|¯β) to be ﬁnite, but this support is usually unknown). Another issue is that\n",
            "in several cases of practical interest, the density ρθis inaccessible (or too hard to compute).\n",
            "A typical setup where both problems (singular and unknown densities) occur is for so-called generative\n",
            "models, where the parametric measure is written\n",
            "Chunk 156:  as a push-forward of a ﬁxed reference measure ζ∈M (Z)\n",
            "αθ=hθ,♯ζwherehθ:Z→X\n",
            "where the push-forward operator is introduced in Deﬁnition 1. The space Zis usually low-dimensional, so\n",
            "that the support of αθis localized along a low-dimensional “manifold” and the resulting density is highly\n",
            "singular (it does not have a density with respect to Lebesgue measure). Furthermore, computing this density\n",
            "is usually intractable, while generating i.i.d. samples from αθis achieved by computing xi=h\n",
            "Chunk 157: θ(zi) where\n",
            "(zi)iare i.i.d. samples from ζ.\n",
            "In order to cope with such diﬃcult scenario, one has to use weak metrics in place of the MLE functional\n",
            "LMLE, which needs to be written in dual form as\n",
            "L(α,β)def.= max\n",
            "(f,g)∈C(X)2{∫\n",
            "Xf(x)dα(x) +∫\n",
            "Xg(x)dβ(x) ; (f,g)∈R}\n",
            ". (1.82)\n",
            "Dual norms exposed in §??correspond to imposing R={(f,−f\n",
            "Chunk 158: ) ;f∈B}, while optimal transport (1.21)\n",
            "setsR=R(c) as deﬁned in (1.22).\n",
            "28\n",
            "For a ﬁxed θ, evaluating the energy to be minimized in (1.81) using such a loss function corresponds to\n",
            "solving a semi-discrete optimal transport, which is the focus of Chapter??. Minimizing the energy with\n",
            "respect toθis much more involved, and is typically highly non-convex.\n",
            "The class of estimators obtained using L=Lc, often called “Minimum Kantorovitch Estimators” (MKE),\n",
            "was initially introduced in [?\n",
            "Chunk 159: ], see also [?].\n",
            "Gromov-Wasserstein. Optimal transport needs a ground cost Cto compare histograms ( a,b), it can\n",
            "thus not be used if the histograms are not deﬁned on the same underlying space, or if one cannot pre-register\n",
            "these spaces to deﬁne a ground cost. To address this issue, one can instead only assume a weaker assumption,\n",
            "namely that one has at its disposal two matrices D∈Rn×nandD′∈Rm×mthat represent some relationship\n",
            "between the points on which the histograms are deﬁned. A typical scenario is when these matrices are (power\n",
            "\n",
            "Chunk 160: of) distance matrices. The Gromov-Wasserstein problem reads\n",
            "GW(( a,D),(b,D′))2def.= min\n",
            "P∈U(a,b)ED,D′(P)def.=∑\n",
            "i,j,i′,j′|Di,i′−D′\n",
            "j,j′|2Pi,jPi′,j′. (1.83)\n",
            "This is a non-convex problem, which can be recast as a Quadratic Assignment Problem (QAP) [?] and is in\n",
            "full generality NP-hard to solve for arbitrary inputs. It is in fact equivalent to a graph matching\n",
            "Chunk 161:  problem [?]\n",
            "for a particular cost.\n",
            "One can show that GW satisﬁes the triangular inequality, and in fact it deﬁnes a distance between\n",
            "metric spaces equipped with a probability distribution (here assumed to be discrete in deﬁnition (1.83))\n",
            "up to isometries preserving the measures. This distance was introduced and studied in details by Memoli\n",
            "in [?]. An in-depth mathematical exposition (in particular, its geodesic structure and gradient ﬂows) is given\n",
            "in [?]. See also [?] for applications in computer vision. This distance is also tightly connected with the\n",
            "Gromov-Hausdorﬀ\n",
            "Chunk 162:  distance [?] between metric spaces, which have been used for shape matching [?,?].\n",
            "Remark 19.Gromov-Wasserstein distance The general setting corresponds to computing couplings between\n",
            "metric measure spaces ( X,dX,αX) and (Y,dY,αY) where (dX,dY) are distances and ( αX,αY) are measures\n",
            "on their respective spaces. One deﬁnes\n",
            "GW((αX,dX),(αY,dY))2def.= min\n",
            "π∈U(αX,αY)∫\n",
            "X2×Y2|dX(x,x′)−d\n",
            "Chunk 163: Y(y,y′)|2dπ(x,y)dπ(x′,y′). (1.84)\n",
            "GW deﬁnes a distance between metric measure spaces up to isometries, where one says that ( αX,dX) and\n",
            "(αY,dY) are isometric if there exists ϕ:X→Y such thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′)) =dX(x,x′).\n",
            "Remark 20.Gromov-Wasserstein geodesics The space of metric spaces (up to isometries) endowed with\n",
            "thisGW distance (1\n",
            "Chunk 164: .84) has a geodesic structure. [?] shows that the geodesic between ( X0,dX0,α0) and\n",
            "(X1,dX1,α1) can be chosen to be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is a solution of (1.84) and for all\n",
            "((x0,x1),(x′\n",
            "0,x′\n",
            "1))∈(X0×X 1)2,\n",
            "dt((x0,x1),(x′\n",
            "0,x′\n",
            "1))def.= (1−t)d\n",
            "Chunk 165: X0(x0,x′\n",
            "0) +tdX1(x1,x′\n",
            "1).\n",
            "This formula allows one to deﬁne and analyze gradient ﬂows which minimize functionals involving metric\n",
            "spaces, see [?]. It is however diﬃcult to handle numerically, because it involves computations over the product\n",
            "spaceX0×X 1. A heuristic approach is used in [?] to deﬁne geodesics and barycenters of metric measure\n",
            "spaces while imposing the cardinality of the involved spaces and making use of the entropic smoothing (1.85)\n",
            "detailed below.\n",
            "To approximate the computation of\n",
            "Chunk 166:  GW, and to help convergence of minimization schemes to better\n",
            "minima, one can consider the entropic regularized variant\n",
            "min\n",
            "P∈U(a,b)ED,D′(P)−εH(P). (1.85)\n",
            "29\n",
            "Figure 1.17: Example of fuzzy correspondences computed by solving GW problem (1.85) with Sinkhorn\n",
            "iterations (1.86). Extracted from [?].\n",
            "As proposed initially in [?,?], and later revisited in [?] for applications in graphics, one can use iteratively\n",
            "Sinkhorn’s algorithm to progressively compute a stationary point of (1.85). Indeed, successive linearizations\n",
            "Chunk 167: \n",
            "of the objective function lead to consider the succession of updates\n",
            "P(ℓ+1) def.= min\n",
            "P∈U(a,b)⟨P,C(ℓ)⟩−εH(P) where (1.86)\n",
            "C(ℓ)def.=∇ED,D′(P(ℓ)) =−D′TP(ℓ)D,\n",
            "which can be interpreted as a mirror-descent scheme [?]. Each update can thus be solved using Sinkhorn\n",
            "iterations (1.51) with cost C(ℓ). Figure (1.17) illustrates the use of this entrop\n",
            "Chunk 168: ic Gromov-Wasserstein to\n",
            "compute soft maps between domains.\n",
            "30\n",
            "Bibliography\n",
            "[1] Amir Beck. Introduction to Nonlinear Optimization: Theory, Algorithms, and Applications with MAT-\n",
            "LAB. SIAM, 2014.\n",
            "[2] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization\n",
            "and statistical learning via the alternating direction method of multipliers. Foundations and Trends R⃝\n",
            "in Machine Learning, 3(1):1–122, 2011.\n",
            "[3] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.\n",
            "[4] E. Cand\n",
            "Chunk 169: ` es and D. Donoho. New tight frames of curvelets and optimal representations of objects with\n",
            "piecewise C2singularities. Commun. on Pure and Appl. Math., 57(2):219–266, 2004.\n",
            "[5] E. J. Cand` es, L. Demanet, D. L. Donoho, and L. Ying. Fast discrete curvelet transforms. SIAM\n",
            "Multiscale Modeling and Simulation, 5:861–899, 2005.\n",
            "[6] A. Chambolle. An algorithm for total variation minimization and applications. J. Math. Imaging Vis.,\n",
            "20:89–97, 2004.\n",
            "[7] Antonin Ch\n",
            "Chunk 170: ambolle, Vicent Caselles, Daniel Cremers, Matteo Novaga, and Thomas Pock. An intro-\n",
            "duction to total variation for image analysis. Theoretical foundations and numerical methods for sparse\n",
            "recovery, 9(263-340):227, 2010.\n",
            "[8] Antonin Chambolle and Thomas Pock. An introduction to continuous optimization for imaging. Acta\n",
            "Numerica, 25:161–319, 2016.\n",
            "[9] S.S. Chen, D.L. Donoho, and M.A. Saunders. Atomic decomposition by basis pursuit. SIAM Journal\n",
            "on Scientiﬁc Computing, 20(1):33–61\n",
            "Chunk 171: , 1999.\n",
            "[10] Philippe G Ciarlet. Introduction ` a l’analyse num´ erique matricielle et ` a l’optimisation. 1982.\n",
            "[11] P. L. Combettes and V. R. Wajs. Signal recovery by proximal forward-backward splitting. SIAM\n",
            "Multiscale Modeling and Simulation, 4(4), 2005.\n",
            "[12] I. Daubechies, M. Defrise, and C. De Mol. An iterative thresholding algorithm for linear inverse problems\n",
            "with a sparsity constraint. Commun. on Pure and Appl. Math., 57:1413–1541, 2004.\n",
            "[13]\n",
            "Chunk 172:  D. Donoho and I. Johnstone. Ideal spatial adaptation via wavelet shrinkage. Biometrika, 81:425–455,\n",
            "Dec 1994.\n",
            "[14] Heinz Werner Engl, Martin Hanke, and Andreas Neubauer. Regularization of inverse problems, volume\n",
            "375. Springer Science & Business Media, 1996.\n",
            "[15] M. Figueiredo and R. Nowak. An EM Algorithm for Wavelet-Based Image Restoration. IEEE Trans.\n",
            "Image Proc., 12(8):906–916, 2003.\n",
            "[16] Simon Foucart and Holger Rauhut. A mathematical introduction to compressive sensing, volume 1.\n",
            "Birkh¨ a\n",
            "Chunk 173: user Basel, 2013.\n",
            "31\n",
            "[17] Stephane Mallat. A wavelet tour of signal processing: the sparse way. Academic press, 2008.\n",
            "[18] D. Mumford and J. Shah. Optimal approximation by piecewise smooth functions and associated varia-\n",
            "tional problems. Commun. on Pure and Appl. Math., 42:577–685, 1989.\n",
            "[19] Neal Parikh, Stephen Boyd, et al. Proximal algorithms. Foundations and Trends R⃝in Optimization,\n",
            "1(3):127–239, 2014.\n",
            "[20] Gabriel Peyr´ e. L’alg` ebre discr` ete de la transform\n",
            "Chunk 174: ´ ee de Fourier. Ellipses, 2004.\n",
            "[21] J. Portilla, V. Strela, M.J. Wainwright, and Simoncelli E.P. Image denoising using scale mixtures of\n",
            "Gaussians in the wavelet domain. IEEE Trans. Image Proc., 12(11):1338–1351, November 2003.\n",
            "[22] L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear total variation based noise removal algorithms. Phys.\n",
            "D, 60(1-4):259–268, 1992.\n",
            "[23] Otmar Scherzer, Markus Grasmair, Harald Grossauer,\n",
            "Chunk 175:  Markus Haltmeier, Frank Lenzen, and L Sirovich.\n",
            "Variational methods in imaging. Springer, 2009.\n",
            "[24] C. E. Shannon. A mathematical theory of communication. The Bell System Technical Journal,\n",
            "27(3):379–423, 1948.\n",
            "[25] Jean-Luc Starck, Fionn Murtagh, and Jalal Fadili. Sparse image and signal processing: Wavelets and\n",
            "related geometric multiscale analysis. Cambridge university press, 2015.\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOQGLmOo2-Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using bert\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model  = BertModel.from_pretrained(model_name)\n",
        "text_chunker = TextChunker(model_name= model_name, tokenizer = tokenizer, model = model)\n",
        "\n",
        "chunks_char_count = text_chunker.char_count_chunking(text, chunk_size=50, chunk_overlap=40)\n",
        "print(\"Char count chunking:\")\n",
        "for i, chunk in enumerate(chunks_char_count):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")\n",
        "\n",
        "chunks_char_count = text_chunker.char_count_chunking(text, chunk_size=50, chunk_overlap=0)\n",
        "print(\"Char count chunking non overlap:\")\n",
        "for i, chunk in enumerate(chunks_char_count):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")\n",
        "\n",
        "chunks_custom_delimiter = text_chunker.char_count_chunking_with_custom_delimiter(text, chunk_size=200, chunk_overlap=50, delimiter=\"@\")\n",
        "print(\"\\nChar count chunking with custom delimiter:\")\n",
        "for i, chunk in enumerate(chunks_custom_delimiter):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0ae861cf7a844cd7b685592058af2df3",
            "6d3ab8f6c14042f9b90a12c9f90e34b1",
            "0955fda0bf164a82ad43af078892a9ca",
            "aed4b13353fe4283ba9532942c36a9e5",
            "a5015f6308504604b5e40744248fd339",
            "f79a9aae91d6415ca4b10bbf8c4b4c8e",
            "9846fc9bd82c4da28d127d9b24485b99",
            "fad1bdeb28c54d7cafc9b17e6839c569",
            "72581da74ebd4bbdaa8cf5a93915c442",
            "7dab9ff59ff94b48b656b7b835add042",
            "a3bf467317d341f7821e58d40e9595d0",
            "1066d70bce0a4f79ae9ba822d42bb52d",
            "34a10475a1344790abadf7ff6283f827",
            "94a5c1133379459cbeb8519a71d2b11b",
            "7071d7376965474483a1818a894a185d",
            "2bf1840f2ef34c7e9768f59790e13db9",
            "80002f6222b0441799edb2efde0c1350",
            "78615bbe2634433e884e5adec33868da",
            "9303deba06f9454885edcbff08cc6601",
            "6b182fa3c143466fb504b51e724eb6bb",
            "c84ff0fb44b141488e052298b7b8c2da",
            "4c2e6d6a9cb64bc3b60a1612350e285a",
            "45503582a56240aa865686c382485a95",
            "8e94bd1a2b524b189906a5475c69c05b",
            "73d218c99d704df684940ec15ef747fc",
            "6dc3b671588d4117baa02c54e73cfed2",
            "fc35c0ad4ff04b64be2f747739da1d7c",
            "3a27b3565b4b49bd99bc24b34e5af636",
            "adf2c8c6c1fd4e0caebe04bf09f3860f",
            "af9252d3e883479486dc219b5fc08958",
            "126da52849e7415a888d03e38904ecf3",
            "c90b93d6dd124253b00b6c098e33b56e",
            "d3356ef12f1f4d58bb697fb45e05a2bc",
            "d5157b318f2e4bfd8edee6d4265de13f",
            "9fb3bf251f2d473dae15377fcfab3956",
            "5228e28c524847e18f8e55f4843cde45",
            "3a91d6e728eb4349851aa5841ee76986",
            "d00a6475a3e14f1786f26c9a0e6c3845",
            "57de7e129c584d3cb5b7c1c8e224033b",
            "91e9310d68514d278465d38d07b7052d",
            "aa803a0320e74bdcb7548f96bd5d8fc3",
            "ab0e3f450a9444beb7a4e4543dcd24fd",
            "301bbbbbeb704706ae858a1efbff0e79",
            "e3bf6958320c49d0a409b1c05a6a7168",
            "07761961ae994ab2a1b7660901f65541",
            "008a085867b842788fc95e6d783b575a",
            "1ee4a5d7569049ac817ae4264a0e549a",
            "1f54d71b849d41ff8810d690d1f95ff7",
            "ca44bc423d844dd7a1045d629ef1668c",
            "4b7f55c653dc4566b8fdf69216731b6a",
            "60cecea8d26849348b88bf24b4deaad0",
            "78251ebb013843d4873e45c0cea022dd",
            "2e5712598e694bbabf31e63799c4c35a",
            "ce5d0893059c49d58e0ef719fba3858b",
            "bcd1861e67454738800d837e065017c5"
          ]
        },
        "id": "Q42dWEkQ2-hP",
        "outputId": "6f9f5f08-d81e-4024-d217-7e3eb31ab5ee"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ae861cf7a844cd7b685592058af2df3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1066d70bce0a4f79ae9ba822d42bb52d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45503582a56240aa865686c382485a95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5157b318f2e4bfd8edee6d4265de13f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07761961ae994ab2a1b7660901f65541"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Chunk 2836: lar (??)). Using these notations, Sinkhorn’s\n",
            "Chunk 2837: Using these notations, Sinkhorn’s iterates read\n",
            "Chunk 2838: f(ℓ+1)= Minrow\n",
            "ε(C−1ng(ℓ)T) +εloga, (1.65)\n",
            "Chunk 2839: ε(C−1ng(ℓ)T) +εloga, (1.65)\n",
            "g(ℓ+1)= Mincol\n",
            "Chunk 2840: g(ℓ+1)= Mincol\n",
            "ε(C−f(ℓ)1mT) +εlogb. (1.66)\n",
            "Chunk 2841: Note that as ε→0, minεconverges to min, but the\n",
            "Chunk 2842: as ε→0, minεconverges to min, but the iterations\n",
            "Chunk 2843: to min, but the iterations do not converge\n",
            "Chunk 2844: min, but the iterations do not converge anymore\n",
            "Chunk 2845: the iterations do not converge anymore in the\n",
            "Chunk 2846: do not converge anymore in the limit ε= 0,\n",
            "Chunk 2847: because alternate minimization does not converge\n",
            "Chunk 2848: minimization does not converge for constrained\n",
            "Chunk 2849: does not converge for constrained problems (which\n",
            "Chunk 2850: for constrained problems (which is the case for\n",
            "Chunk 2851: problems (which is the case for the un-\n",
            "Chunk 2852: regularized dual (1.17)).\n",
            "Chunk 2853: Remark 17 (Log-domain Sinkhorn) .While\n",
            "Chunk 2854: 17 (Log-domain Sinkhorn) .While mathematically\n",
            "Chunk 2855: Sinkhorn) .While mathematically equivalent to the\n",
            "Chunk 2856: .While mathematically equivalent to the Sinkhorn\n",
            "Chunk 2857: equivalent to the Sinkhorn updates (1.51), itera-\n",
            "Chunk 2858: tions (1.63) and (1.64) suggest to use the\n",
            "Chunk 2859: (1.63) and (1.64) suggest to use the log-sum-exp\n",
            "Chunk 2860: suggest to use the log-sum-exp stabilization\n",
            "Chunk 2861: to use the log-sum-exp stabilization trick to\n",
            "Chunk 2862: the log-sum-exp stabilization trick to avoid\n",
            "Chunk 2863: stabilization trick to avoid underﬂow for small\n",
            "Chunk 2864: trick to avoid underﬂow for small values\n",
            "Chunk 2865: ofε. Writing z = min z, that trick suggests to\n",
            "Chunk 2866: z = min z, that trick suggests to evaluate min\n",
            "Chunk 2867: z, that trick suggests to evaluate min εzas\n",
            "Chunk 2868: minεz= z−εlog∑\n",
            "ie−(zi−z)/ε. (1.67)\n",
            "Chunk 2869: Instead of substracting z to stabilize the log\n",
            "Chunk 2870: of substracting z to stabilize the log domain\n",
            "Chunk 2871: z to stabilize the log domain iterations as in\n",
            "Chunk 2872: the log domain iterations as in (1.67), one can\n",
            "Chunk 2873: domain iterations as in (1.67), one can actually\n",
            "Chunk 2874: as in (1.67), one can actually substract the\n",
            "Chunk 2875: previously computed scalings. This leads to the\n",
            "Chunk 2876: computed scalings. This leads to the following\n",
            "Chunk 2877: scalings. This leads to the following stabilized\n",
            "Chunk 2878: This leads to the following stabilized iteration\n",
            "Chunk 2879: f(ℓ+1)= Minrow\n",
            "Chunk 2880: ε(S(f(ℓ),g(ℓ)))−f(ℓ)+εlog(a) (1.68)\n",
            "Chunk 2881: g(ℓ+1)= Mincol\n",
            "Chunk 2882: ε(S(f(ℓ+1),g(ℓ)))−g(ℓ)+εlog(b), (1.69)\n",
            "Chunk 2883: where we deﬁned\n",
            "S(f,g) =(\n",
            "Ci,j−fi−gj)\n",
            "i,j.\n",
            "Chunk 2884: In contrast to the original iterations (1.51),\n",
            "Chunk 2885: to the original iterations (1.51), these\n",
            "Chunk 2886: the original iterations (1.51), these log-domain\n",
            "Chunk 2887: iterations (1.51), these log-domain iterations\n",
            "Chunk 2888: (1.51), these log-domain iterations (1.68) and\n",
            "Chunk 2889: these log-domain iterations (1.68) and (1.69) are\n",
            "Chunk 2890: iterations (1.68) and (1.69) are stable for\n",
            "Chunk 2891: arbitraryε >0, because the quantity S(f,g) stays\n",
            "Chunk 2892: >0, because the quantity S(f,g) stays bounded\n",
            "Chunk 2893: the quantity S(f,g) stays bounded during the\n",
            "Chunk 2894: S(f,g) stays bounded during the iterations. The\n",
            "Chunk 2895: bounded during the iterations. The downside is\n",
            "Chunk 2896: during the iterations. The downside is that it\n",
            "Chunk 2897: requiresnmcomputations of exp at each step.\n",
            "Chunk 2898: of exp at each step. Computing a Minrow\n",
            "Chunk 2899: εor Mincol\n",
            "εis typically substantially\n",
            "Chunk 2900: slower than matrix multiplications, and requires\n",
            "Chunk 2901: matrix multiplications, and requires computing\n",
            "Chunk 2902: multiplications, and requires computing line by\n",
            "Chunk 2903: and requires computing line by line soft-minima\n",
            "Chunk 2904: computing line by line soft-minima of matrices S.\n",
            "Chunk 2905: line by line soft-minima of matrices S. There is\n",
            "Chunk 2906: therefore no eﬃcient way to parallelize the\n",
            "Chunk 2907: no eﬃcient way to parallelize the application of\n",
            "Chunk 2908: way to parallelize the application of Sinkhorn\n",
            "Chunk 2909: parallelize the application of Sinkhorn maps for\n",
            "Chunk 2910: the application of Sinkhorn maps for several\n",
            "Chunk 2911: of Sinkhorn maps for several marginals\n",
            "Chunk 2912: maps for several marginals simultaneously.\n",
            "Chunk 2913: In Euclidean domain of small dimension, it is\n",
            "Chunk 2914: domain of small dimension, it is possible to\n",
            "Chunk 2915: of small dimension, it is possible to develop\n",
            "Chunk 2916: dimension, it is possible to develop eﬃcient\n",
            "Chunk 2917: it is possible to develop eﬃcient multiscale\n",
            "Chunk 2918: possible to develop eﬃcient multiscale solvers\n",
            "Chunk 2919: to develop eﬃcient multiscale solvers with a\n",
            "Chunk 2920: eﬃcient multiscale solvers with a decaying\n",
            "Chunk 2921: εstrategy to signiﬁcantly speed up the\n",
            "Chunk 2922: to signiﬁcantly speed up the computation using\n",
            "Chunk 2923: speed up the computation using sparse grids [ ?].\n",
            "Chunk 2924: 24\n",
            "1.6 Extensions\n",
            "Chunk 2925: Wasserstein Barycenters. Given input histogram\n",
            "Chunk 2926: Barycenters. Given input histogram {bs}S\n",
            "Chunk 2927: s=1, wherebs∈Σns, and weights λ∈ΣS, a\n",
            "Chunk 2928: Wasserstein barycenter is computed by minimizing\n",
            "Chunk 2929: min\n",
            "a∈ΣnS∑\n",
            "s=1λsLCs(a,bs) (1.70)\n",
            "Chunk 2930: where the cost matrices Cs∈Rn×nsneed to be\n",
            "Chunk 2931: the cost matrices Cs∈Rn×nsneed to be speciﬁed. A\n",
            "Chunk 2932: matrices Cs∈Rn×nsneed to be speciﬁed. A typical\n",
            "Chunk 2933: Cs∈Rn×nsneed to be speciﬁed. A typical setup is\n",
            "Chunk 2934: to be speciﬁed. A typical setup is “Eulerian”, so\n",
            "Chunk 2935: A typical setup is “Eulerian”, so that all the\n",
            "Chunk 2936: barycenters are deﬁned on the same grid,\n",
            "Chunk 2937: are deﬁned on the same grid, ns=n,Cs=C=Dpis set\n",
            "Chunk 2938: on the same grid, ns=n,Cs=C=Dpis set to be a\n",
            "Chunk 2939: same grid, ns=n,Cs=C=Dpis set to be a distance\n",
            "Chunk 2940: ns=n,Cs=C=Dpis set to be a distance matrix, so\n",
            "Chunk 2941: set to be a distance matrix, so that one\n",
            "Chunk 2942: solves\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsWp\n",
            "p(a,bs).\n",
            "Chunk 2943: This barycenter problem (1.70) was originally\n",
            "Chunk 2944: problem (1.70) was originally introduced by [ ?]\n",
            "Chunk 2945: was originally introduced by [ ?] following\n",
            "Chunk 2946: originally introduced by [ ?] following earlier\n",
            "Chunk 2947: introduced by [ ?] following earlier ideas of [\n",
            "Chunk 2948: by [ ?] following earlier ideas of [ ?]. They\n",
            "Chunk 2949: following earlier ideas of [ ?]. They proved\n",
            "Chunk 2950: in particular uniqueness of the barycenter for\n",
            "Chunk 2951: uniqueness of the barycenter for c(x,y)\n",
            "Chunk 2952: of the barycenter for c(x,y) =||x−y||2overX=Rd,\n",
            "Chunk 2953: for c(x,y) =||x−y||2overX=Rd, if one of the input\n",
            "Chunk 2954: =||x−y||2overX=Rd, if one of the input measure\n",
            "Chunk 2955: has a density with respect to the Lebesgue\n",
            "Chunk 2956: a density with respect to the Lebesgue measure\n",
            "Chunk 2957: with respect to the Lebesgue measure (and more\n",
            "Chunk 2958: to the Lebesgue measure (and more generally under\n",
            "Chunk 2959: measure (and more generally under the same\n",
            "Chunk 2960: (and more generally under the same hypothesis as\n",
            "Chunk 2961: generally under the same hypothesis as the\n",
            "Chunk 2962: one guaranteeing the existence of a Monge map,\n",
            "Chunk 2963: the existence of a Monge map, see Remark ??).\n",
            "Chunk 2964: The barycenter problem for histograms (1.70) is\n",
            "Chunk 2965: problem for histograms (1.70) is in fact a linear\n",
            "Chunk 2966: histograms (1.70) is in fact a linear program,\n",
            "Chunk 2967: (1.70) is in fact a linear program, since one can\n",
            "Chunk 2968: in fact a linear program, since one can look for\n",
            "Chunk 2969: linear program, since one can look for the S\n",
            "Chunk 2970: couplings ( Ps)sbetween each input and the\n",
            "Chunk 2971: ( Ps)sbetween each input and the barycenter\n",
            "Chunk 2972: each input and the barycenter itself\n",
            "Chunk 2973: min\n",
            "a∈Σn,(Ps∈Rn×ns)s{S∑\n",
            "s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "Chunk 2974: a∈Σn,(Ps∈Rn×ns)s{S∑\n",
            "s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "s1ns=a,P⊤\n",
            "Chunk 2975: s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "s1ns=a,P⊤\n",
            "s1n=bs}\n",
            ".\n",
            "Chunk 2976: Although this problem is an LP, its scale forbids\n",
            "Chunk 2977: problem is an LP, its scale forbids the use\n",
            "Chunk 2978: is an LP, its scale forbids the use generic\n",
            "Chunk 2979: LP, its scale forbids the use generic solvers for\n",
            "Chunk 2980: forbids the use generic solvers for medium scale\n",
            "Chunk 2981: use generic solvers for medium scale problems.\n",
            "Chunk 2982: solvers for medium scale problems. One\n",
            "Chunk 2983: can therefore resort to using ﬁrst order methods\n",
            "Chunk 2984: resort to using ﬁrst order methods such as\n",
            "Chunk 2985: to using ﬁrst order methods such as subgradient\n",
            "Chunk 2986: ﬁrst order methods such as subgradient descent on\n",
            "Chunk 2987: methods such as subgradient descent on the dual [\n",
            "Chunk 2988: as subgradient descent on the dual [ ?].\n",
            "Chunk 2989: Remark 18.Barycenter of arbitrary measures Given\n",
            "Chunk 2990: of arbitrary measures Given a set of input\n",
            "Chunk 2991: arbitrary measures Given a set of input measure (\n",
            "Chunk 2992: Given a set of input measure ( βs)sdeﬁned on some\n",
            "Chunk 2993: of input measure ( βs)sdeﬁned on some space X,\n",
            "Chunk 2994: the barycenter problem becomes\n",
            "min\n",
            "α∈M1\n",
            "+(X)S∑\n",
            "Chunk 2995: min\n",
            "α∈M1\n",
            "+(X)S∑\n",
            "s=1λsLc(α,βs). (1.71)\n",
            "Chunk 2996: In the case where X=Rdandc(x,y) =||x−y||2, [?]\n",
            "Chunk 2997: case where X=Rdandc(x,y) =||x−y||2, [?] shows\n",
            "Chunk 2998: X=Rdandc(x,y) =||x−y||2, [?] shows that if one of\n",
            "Chunk 2999: =||x−y||2, [?] shows that if one of the input\n",
            "Chunk 3000: [?] shows that if one of the input measures has a\n",
            "Chunk 3001: that if one of the input measures has a density,\n",
            "Chunk 3002: then this barycenter is unique. Problem (1.71)\n",
            "Chunk 3003: barycenter is unique. Problem (1.71) can be\n",
            "Chunk 3004: is unique. Problem (1.71) can be viewed as a\n",
            "Chunk 3005: Problem (1.71) can be viewed as a generalization\n",
            "Chunk 3006: can be viewed as a generalization of the problem\n",
            "Chunk 3007: as a generalization of the problem of computing\n",
            "Chunk 3008: barycenters of points ( xs)S\n",
            "Chunk 3009: s=1∈XSto arbitrary measures. Indeed, if βs=δxsis\n",
            "Chunk 3010: arbitrary measures. Indeed, if βs=δxsis a single\n",
            "Chunk 3011: measures. Indeed, if βs=δxsis a single Dirac\n",
            "Chunk 3012: Indeed, if βs=δxsis a single Dirac mass, then a\n",
            "Chunk 3013: solution to (1.71) is δx⋆wherex⋆is a Fr´ echet\n",
            "Chunk 3014: to (1.71) is δx⋆wherex⋆is a Fr´ echet mean\n",
            "Chunk 3015: (1.71) is δx⋆wherex⋆is a Fr´ echet mean solving (\n",
            "Chunk 3016: δx⋆wherex⋆is a Fr´ echet mean solving ( ??). Note\n",
            "Chunk 3017: a Fr´ echet mean solving ( ??). Note that for\n",
            "Chunk 3018: echet mean solving ( ??). Note that for c(x,y)\n",
            "Chunk 3019: solving ( ??). Note that for c(x,y) =||x−y||2,\n",
            "Chunk 3020: ( ??). Note that for c(x,y) =||x−y||2, the mean\n",
            "Chunk 3021: of the barycenter α⋆is necessarily the barycenter\n",
            "Chunk 3022: α⋆is necessarily the barycenter of the mean, i.e.\n",
            "Chunk 3023: ∫\n",
            "Xxdα⋆(x) =∑\n",
            "sλs∫\n",
            "Xxdαs(x),\n",
            "Chunk 3024: and the support of α⋆is located in the convex\n",
            "Chunk 3025: support of α⋆is located in the convex hull of the\n",
            "Chunk 3026: α⋆is located in the convex hull of the supports\n",
            "Chunk 3027: in the convex hull of the supports of the ( αs)s.\n",
            "Chunk 3028: hull of the supports of the ( αs)s. The\n",
            "Chunk 3029: of the supports of the ( αs)s. The consistency of\n",
            "Chunk 3030: of the ( αs)s. The consistency of the\n",
            "Chunk 3031: approximation of the inﬁnite dimensional\n",
            "Chunk 3032: of the inﬁnite dimensional optimization (1.71)\n",
            "Chunk 3033: inﬁnite dimensional optimization (1.71) when\n",
            "Chunk 3034: optimization (1.71) when approximating the input\n",
            "Chunk 3035: (1.71) when approximating the input distribution\n",
            "Chunk 3036: using discrete ones (and thus solving (1.70) in\n",
            "Chunk 3037: ones (and thus solving (1.70) in place) is\n",
            "Chunk 3038: (and thus solving (1.70) in place) is studied in\n",
            "Chunk 3039: solving (1.70) in place) is studied in [ ?]. Let\n",
            "Chunk 3040: in place) is studied in [ ?]. Let us also note\n",
            "Chunk 3041: is studied in [ ?]. Let us also note that it is\n",
            "Chunk 3042: in [ ?]. Let us also note that it is possible to\n",
            "Chunk 3043: re-cast (1.71) as a multi-marginal OT problem,\n",
            "Chunk 3044: (1.71) as a multi-marginal OT problem, see Remark\n",
            "Chunk 3045: a multi-marginal OT problem, see Remark ??.\n",
            "Chunk 3046: One can use entropic smoothing and approximate\n",
            "Chunk 3047: use entropic smoothing and approximate the\n",
            "Chunk 3048: entropic smoothing and approximate the solution\n",
            "Chunk 3049: smoothing and approximate the solution of (1.70)\n",
            "Chunk 3050: and approximate the solution of (1.70) using\n",
            "Chunk 3051: min\n",
            "a∈ΣnS∑\n",
            "s=1λsLε\n",
            "Cs(a,bs) (1.72)\n",
            "Chunk 3052: for someε > 0. This is a smooth convex\n",
            "Chunk 3053: someε > 0. This is a smooth convex minimization\n",
            "Chunk 3054: 0. This is a smooth convex minimization problem,\n",
            "Chunk 3055: a smooth convex minimization problem, which can\n",
            "Chunk 3056: convex minimization problem, which can be tackled\n",
            "Chunk 3057: problem, which can be tackled using gradient\n",
            "Chunk 3058: descent [ ?]. An alternative is to use descent\n",
            "Chunk 3059: [ ?]. An alternative is to use descent method\n",
            "Chunk 3060: alternative is to use descent method (typically\n",
            "Chunk 3061: is to use descent method (typically quasi-Newton)\n",
            "Chunk 3062: descent method (typically quasi-Newton) on the\n",
            "Chunk 3063: method (typically quasi-Newton) on the semi-dual\n",
            "Chunk 3064: quasi-Newton) on the semi-dual [ ?], which is\n",
            "Chunk 3065: 25\n",
            "Chunk 3066: useful to integrate additional regularizations on\n",
            "Chunk 3067: integrate additional regularizations on the\n",
            "Chunk 3068: additional regularizations on the barycenter\n",
            "Chunk 3069: regularizations on the barycenter (e.g. to impose\n",
            "Chunk 3070: on the barycenter (e.g. to impose some\n",
            "Chunk 3071: the barycenter (e.g. to impose some smoothness).\n",
            "Chunk 3072: (e.g. to impose some smoothness). A simple\n",
            "Chunk 3073: but eﬀective approach, as remarked in [ ?] is to\n",
            "Chunk 3074: approach, as remarked in [ ?] is to rewrite\n",
            "Chunk 3075: as remarked in [ ?] is to rewrite (1.72) as a\n",
            "Chunk 3076: in [ ?] is to rewrite (1.72) as a (weighted) KL\n",
            "Chunk 3077: to rewrite (1.72) as a (weighted) KL projection\n",
            "Chunk 3078: (1.72) as a (weighted) KL projection problem\n",
            "Chunk 3079: min\n",
            "(Ps)s{∑\n",
            "Chunk 3080: (Ps)s{∑\n",
            "sλsKL(Ps|Ks) ;∀s,PsT1m=bs,P111=...=PS1S}\n",
            "Chunk 3081: (1.73)\n",
            "Chunk 3082: where we denoted Ksdef.=e−Cs/ε. Here, the\n",
            "Chunk 3083: we denoted Ksdef.=e−Cs/ε. Here, the barycenter\n",
            "Chunk 3084: Ksdef.=e−Cs/ε. Here, the barycenter ais\n",
            "Chunk 3085: Here, the barycenter ais implicitly encoded in\n",
            "Chunk 3086: barycenter ais implicitly encoded in the row\n",
            "Chunk 3087: ais implicitly encoded in the row marginals of\n",
            "Chunk 3088: encoded in the row marginals of all\n",
            "Chunk 3089: the couplings Ps∈Rn×nsasa=P111=...=PS1S. As\n",
            "Chunk 3090: couplings Ps∈Rn×nsasa=P111=...=PS1S. As detailed\n",
            "Chunk 3091: Ps∈Rn×nsasa=P111=...=PS1S. As detailed in [ ?],\n",
            "Chunk 3092: As detailed in [ ?], one can generalize Sinkhorn\n",
            "Chunk 3093: in [ ?], one can generalize Sinkhorn to\n",
            "Chunk 3094: this problem, which also corresponds to iterative\n",
            "Chunk 3095: which also corresponds to iterative projection.\n",
            "Chunk 3096: corresponds to iterative projection. This can\n",
            "Chunk 3097: to iterative projection. This can also be seen as\n",
            "Chunk 3098: projection. This can also be seen as a special\n",
            "Chunk 3099: This can also be seen as a special case of the\n",
            "Chunk 3100: generalized Sinkhorn detailed in §??. The optimal\n",
            "Chunk 3101: Sinkhorn detailed in §??. The optimal couplings (\n",
            "Chunk 3102: in §??. The optimal couplings ( Ps)ssolving\n",
            "Chunk 3103: The optimal couplings ( Ps)ssolving (1.73) are\n",
            "Chunk 3104: couplings ( Ps)ssolving (1.73) are computed in\n",
            "Chunk 3105: ( Ps)ssolving (1.73) are computed in scaling\n",
            "Chunk 3106: form as\n",
            "Ps= diag( us)Kdiag(vs), (1.74)\n",
            "Chunk 3107: and the scalings are sequentially updated as\n",
            "Chunk 3108: ∀s∈J1,SK,v(ℓ+1)\n",
            "sdef.=bs\n",
            "KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "Chunk 3109: sdef.=bs\n",
            "KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "∀s∈J1,SK,u(ℓ+1)\n",
            "Chunk 3110: KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Chunk 3111: s, (1.75)\n",
            "∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Ksv(ℓ+1)\n",
            "Chunk 3112: ∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Ksv(ℓ+1)\n",
            "s, (1.76)\n",
            "Chunk 3113: Ksv(ℓ+1)\n",
            "s, (1.76)\n",
            "where a(ℓ+1)def.=∏\n",
            "s(Ksv(ℓ+1)\n",
            "Chunk 3114: where a(ℓ+1)def.=∏\n",
            "s(Ksv(ℓ+1)\n",
            "s)λs. (1.77)\n",
            "Chunk 3115: An alternative way to derive these iterations is\n",
            "Chunk 3116: way to derive these iterations is to perform\n",
            "Chunk 3117: derive these iterations is to perform alternate\n",
            "Chunk 3118: iterations is to perform alternate minimization\n",
            "Chunk 3119: is to perform alternate minimization on the\n",
            "Chunk 3120: perform alternate minimization on the variables\n",
            "Chunk 3121: alternate minimization on the variables of a dual\n",
            "Chunk 3122: problem, which detailed in the following\n",
            "Chunk 3123: which detailed in the following proposition.\n",
            "Chunk 3124: Proposition 9. The optimal (us,vs)appearing in\n",
            "Chunk 3125: 9. The optimal (us,vs)appearing in (1.74) can be\n",
            "Chunk 3126: (us,vs)appearing in (1.74) can be written as\n",
            "Chunk 3127: in (1.74) can be written as (us,vs) =\n",
            "Chunk 3128: can be written as (us,vs) = (efs/ε,egs/ε)where\n",
            "Chunk 3129: (fs,gs)sare the solutions of the following\n",
            "Chunk 3130: the solutions of the following program (whose\n",
            "Chunk 3131: of the following program (whose value matches the\n",
            "Chunk 3132: program (whose value matches the one of (1.72) )\n",
            "Chunk 3133: max\n",
            "(fs,gs)s{∑\n",
            "sλs(\n",
            "⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "Chunk 3134: sλs(\n",
            "⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "sλsfs= 0}\n",
            "Chunk 3135: ⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "sλsfs= 0}\n",
            ". (1.78)\n",
            "Chunk 3136: Proof. Introducing Lagrange multipliers in (1.73)\n",
            "Chunk 3137: Lagrange multipliers in (1.73) leads to\n",
            "Chunk 3138: min\n",
            "(Ps)s,amax\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "Chunk 3139: (Ps)s,amax\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "εKL(Ps|Ks) +⟨a−Ps1m,fs⟩\n",
            "Chunk 3140: sλs(\n",
            "εKL(Ps|Ks) +⟨a−Ps1m,fs⟩\n",
            "+⟨bs−PsT1m,gs⟩)\n",
            ".\n",
            "Chunk 3141: Strong duality holds, so that one can exchange\n",
            "Chunk 3142: duality holds, so that one can exchange the min\n",
            "Chunk 3143: holds, so that one can exchange the min and the\n",
            "Chunk 3144: that one can exchange the min and the max, and\n",
            "Chunk 3145: can exchange the min and the max, and gets\n",
            "Chunk 3146: max\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "⟨gs,bs⟩+ min\n",
            "Chunk 3147: sλs(\n",
            "⟨gs,bs⟩+ min\n",
            "PsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\n",
            "+ min\n",
            "Chunk 3148: PsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\n",
            "+ min\n",
            "a⟨∑\n",
            "sλsfs,a⟩.\n",
            "Chunk 3149: The explicit minimization on agives the\n",
            "Chunk 3150: explicit minimization on agives the constraint∑\n",
            "Chunk 3151: sλsfs= 0 together with\n",
            "max\n",
            "(fs,gs)s∑\n",
            "Chunk 3152: max\n",
            "(fs,gs)s∑\n",
            "sλs⟨gs,bs⟩−εKL∗(fs⊕gs\n",
            "ε|Ks)\n",
            "Chunk 3153: where KL∗(·|Ks) is the Legendre transform ( ??)\n",
            "Chunk 3154: is the Legendre transform ( ??) of the function\n",
            "Chunk 3155: transform ( ??) of the function KL∗(·|Ks). This\n",
            "Chunk 3156: ( ??) of the function KL∗(·|Ks). This Legendre\n",
            "Chunk 3157: the function KL∗(·|Ks). This Legendre transform\n",
            "Chunk 3158: KL∗(·|Ks). This Legendre transform reads\n",
            "Chunk 3159: KL∗(U|K) =∑\n",
            "i,jKi,j(eUi,j−1), (1.79)\n",
            "26\n",
            "Chunk 3160: Figure 1.15: Barycenters between 4 input 3-D\n",
            "Chunk 3161: 1.15: Barycenters between 4 input 3-D shapes\n",
            "Chunk 3162: Barycenters between 4 input 3-D shapes using\n",
            "Chunk 3163: between 4 input 3-D shapes using entropic\n",
            "Chunk 3164: 4 input 3-D shapes using entropic regularization\n",
            "Chunk 3165: shapes using entropic regularization (1.72). The\n",
            "Chunk 3166: entropic regularization (1.72). The weights\n",
            "Chunk 3167: (λs)sare bilinear with respect to the four\n",
            "Chunk 3168: bilinear with respect to the four corners of the\n",
            "Chunk 3169: with respect to the four corners of the square.\n",
            "Chunk 3170: to the four corners of the square. Shapes are\n",
            "Chunk 3171: corners of the square. Shapes are represented as\n",
            "Chunk 3172: the square. Shapes are represented as measures\n",
            "Chunk 3173: Shapes are represented as measures that\n",
            "Chunk 3174: are uniform within the boundaries of the shape\n",
            "Chunk 3175: within the boundaries of the shape and null\n",
            "Chunk 3176: the boundaries of the shape and null outside.\n",
            "Chunk 3177: which shows the desired formula. To show (1.79),\n",
            "Chunk 3178: the desired formula. To show (1.79), since this\n",
            "Chunk 3179: formula. To show (1.79), since this function is\n",
            "Chunk 3180: To show (1.79), since this function is separable,\n",
            "Chunk 3181: since this function is separable, one needs to\n",
            "Chunk 3182: function is separable, one needs to compute\n",
            "Chunk 3183: ∀(u,k)∈R2\n",
            "+,KL∗(u|k)def.= max\n",
            "rur−(rlog(r/k)−r+k)\n",
            "Chunk 3184: whose optimality condition reads u= log(r/k),\n",
            "Chunk 3185: condition reads u= log(r/k), i.e.r=keu, hence the\n",
            "Chunk 3186: reads u= log(r/k), i.e.r=keu, hence the result.\n",
            "Chunk 3187: Minimizing (1.78) with respect to each gs, while\n",
            "Chunk 3188: (1.78) with respect to each gs, while keeping all\n",
            "Chunk 3189: respect to each gs, while keeping all the other\n",
            "Chunk 3190: to each gs, while keeping all the other variable\n",
            "Chunk 3191: while keeping all the other variable ﬁxed, is\n",
            "Chunk 3192: keeping all the other variable ﬁxed, is obtained\n",
            "Chunk 3193: the other variable ﬁxed, is obtained in closed\n",
            "Chunk 3194: form by (1.75). Minimizing (1.78) with respect to\n",
            "Chunk 3195: Minimizing (1.78) with respect to all the (\n",
            "Chunk 3196: (1.78) with respect to all the ( fs)srequires to\n",
            "Chunk 3197: respect to all the ( fs)srequires to solve for\n",
            "Chunk 3198: to all the ( fs)srequires to solve for ausing\n",
            "Chunk 3199: the ( fs)srequires to solve for ausing (1.77) and\n",
            "Chunk 3200: to solve for ausing (1.77) and leads\n",
            "Chunk 3201: to the expression (1.76).\n",
            "Chunk 3202: Figures ??and??show applications to 2-D and 3-D\n",
            "Chunk 3203: ??and??show applications to 2-D and 3-D shapes\n",
            "Chunk 3204: applications to 2-D and 3-D shapes interpolation.\n",
            "Chunk 3205: to 2-D and 3-D shapes interpolation. Figure\n",
            "Chunk 3206: and 3-D shapes interpolation. Figure ??shows a\n",
            "Chunk 3207: interpolation. Figure ??shows a computation\n",
            "Chunk 3208: of barycenters on a surface, where the ground\n",
            "Chunk 3209: on a surface, where the ground cost is the square\n",
            "Chunk 3210: where the ground cost is the square of the\n",
            "Chunk 3211: the ground cost is the square of the geodesic\n",
            "Chunk 3212: cost is the square of the geodesic distance. For\n",
            "Chunk 3213: square of the geodesic distance. For this ﬁgure,\n",
            "Chunk 3214: the computations are performed using the geodesic\n",
            "Chunk 3215: are performed using the geodesic in heat\n",
            "Chunk 3216: using the geodesic in heat approximation detailed\n",
            "Chunk 3217: geodesic in heat approximation detailed in Remark\n",
            "Chunk 3218: heat approximation detailed in Remark ??. We\n",
            "Chunk 3219: approximation detailed in Remark ??. We refer\n",
            "Chunk 3220: to [?] for more details and other applications to\n",
            "Chunk 3221: more details and other applications to computer\n",
            "Chunk 3222: and other applications to computer graphics and\n",
            "Chunk 3223: applications to computer graphics and imaging\n",
            "Chunk 3224: to computer graphics and imaging sciences.\n",
            "Chunk 3225: Wasserstein Loss. In statistics, text processing\n",
            "Chunk 3226: Loss. In statistics, text processing or imaging,\n",
            "Chunk 3227: statistics, text processing or imaging, one must\n",
            "Chunk 3228: text processing or imaging, one must usually\n",
            "Chunk 3229: processing or imaging, one must usually compare a\n",
            "Chunk 3230: imaging, one must usually compare a probability\n",
            "Chunk 3231: distribution βarising from measurements to a\n",
            "Chunk 3232: βarising from measurements to a model, namely a\n",
            "Chunk 3233: measurements to a model, namely a parameterized\n",
            "Chunk 3234: to a model, namely a parameterized family of\n",
            "Chunk 3235: namely a parameterized family of distributions\n",
            "Chunk 3236: a parameterized family of distributions {αθ,θ∈\n",
            "Chunk 3237: Θ}where Θ is a subset of an Euclidean space. Such\n",
            "Chunk 3238: is a subset of an Euclidean space. Such a\n",
            "Chunk 3239: a subset of an Euclidean space. Such a comparison\n",
            "Chunk 3240: an Euclidean space. Such a comparison is done\n",
            "Chunk 3241: space. Such a comparison is done through a “loss”\n",
            "Chunk 3242: a comparison is done through a “loss” or a\n",
            "Chunk 3243: is done through a “loss” or a “ﬁdelity”\n",
            "Chunk 3244: term, which, in this section, is the Wasserstein\n",
            "Chunk 3245: in this section, is the Wasserstein distance. In\n",
            "Chunk 3246: is the Wasserstein distance. In the simplest\n",
            "Chunk 3247: Wasserstein distance. In the simplest scenario,\n",
            "Chunk 3248: distance. In the simplest scenario, the\n",
            "Chunk 3249: In the simplest scenario, the computation of a\n",
            "Chunk 3250: suitable parameter θis obtained by minimizing\n",
            "Chunk 3251: parameter θis obtained by minimizing directly\n",
            "Chunk 3252: min\n",
            "θ∈ΘE(θ)def.=Lc(αθ,β). (1.80)\n",
            "Chunk 3253: Of course, one can consider more complicated\n",
            "Chunk 3254: one can consider more complicated problems: for\n",
            "Chunk 3255: consider more complicated problems: for instance,\n",
            "Chunk 3256: complicated problems: for instance, the\n",
            "Chunk 3257: problems: for instance, the barycenter problem\n",
            "Chunk 3258: for instance, the barycenter problem described\n",
            "Chunk 3259: in§??consists in a sum of such terms. However,\n",
            "Chunk 3260: in a sum of such terms. However, most of these\n",
            "Chunk 3261: of such terms. However, most of these more\n",
            "Chunk 3262: such terms. However, most of these more advanced\n",
            "Chunk 3263: However, most of these more advanced problems can\n",
            "Chunk 3264: of these more advanced problems can be usually\n",
            "Chunk 3265: solved by adapting tools deﬁned for basic case:\n",
            "Chunk 3266: adapting tools deﬁned for basic case: either\n",
            "Chunk 3267: tools deﬁned for basic case: either using the\n",
            "Chunk 3268: deﬁned for basic case: either using the chain\n",
            "Chunk 3269: for basic case: either using the chain rule to\n",
            "Chunk 3270: case: either using the chain rule to compute\n",
            "Chunk 3271: either using the chain rule to compute explicitly\n",
            "Chunk 3272: the chain rule to compute explicitly derivatives,\n",
            "Chunk 3273: or using automatic diﬀerentiation.\n",
            "Chunk 3274: The Wasserstein distance between two histograms\n",
            "Chunk 3275: distance between two histograms or two densities\n",
            "Chunk 3276: between two histograms or two densities is convex\n",
            "Chunk 3277: histograms or two densities is convex with\n",
            "Chunk 3278: or two densities is convex with respect to these\n",
            "Chunk 3279: is convex with respect to these inputs,\n",
            "Chunk 3280: as shown by (1.17) and (1.21) respectively.\n",
            "Chunk 3281: by (1.17) and (1.21) respectively. Therefore,\n",
            "Chunk 3282: and (1.21) respectively. Therefore, when the\n",
            "Chunk 3283: respectively. Therefore, when the parameter θis\n",
            "Chunk 3284: Therefore, when the parameter θis itself a\n",
            "Chunk 3285: when the parameter θis itself a histogram, namely\n",
            "Chunk 3286: θis itself a histogram, namely Θ =\n",
            "Chunk 3287: Σnandαθ=θ, or more generally when\n",
            "Chunk 3288: or more generally when θdescribesKweights in the\n",
            "Chunk 3289: when θdescribesKweights in the simplex, Θ = Σ K,\n",
            "Chunk 3290: in the simplex, Θ = Σ K, andαθ=∑K\n",
            "Chunk 3291: i=1θiαi\n",
            "Chunk 3292: is a convex combination of known atoms\n",
            "Chunk 3293: a convex combination of known atoms α1,...,αKin\n",
            "Chunk 3294: combination of known atoms α1,...,αKin ΣN,\n",
            "Chunk 3295: of known atoms α1,...,αKin ΣN, Problem (1.80)\n",
            "Chunk 3296: atoms α1,...,αKin ΣN, Problem (1.80) remains\n",
            "Chunk 3297: α1,...,αKin ΣN, Problem (1.80) remains convex\n",
            "Chunk 3298: ΣN, Problem (1.80) remains convex (the ﬁrst case\n",
            "Chunk 3299: corresponds to the barycenter problem, the second\n",
            "Chunk 3300: to the barycenter problem, the second to one\n",
            "Chunk 3301: barycenter problem, the second to one iteration\n",
            "Chunk 3302: problem, the second to one iteration of the\n",
            "Chunk 3303: the second to one iteration of the dictionary\n",
            "Chunk 3304: to one iteration of the dictionary learning\n",
            "Chunk 3305: iteration of the dictionary learning problem with\n",
            "Chunk 3306: a Wasserstein loss [ ?]). However, for more\n",
            "Chunk 3307: loss [ ?]). However, for more general\n",
            "Chunk 3308: ?]). However, for more general parameterizations\n",
            "Chunk 3309: for more general parameterizations θ↦→αθ, Problem\n",
            "Chunk 3310: parameterizations θ↦→αθ, Problem (1.80) is in\n",
            "Chunk 3311: θ↦→αθ, Problem (1.80) is in general\n",
            "Chunk 3312: not convex.\n",
            "27\n",
            "Chunk 3313: g✓XZ⇣xz\u0000↵✓Figure 1.16: Schematic display of the\n",
            "Chunk 3314: 1.16: Schematic display of the density ﬁtting\n",
            "Chunk 3315: Schematic display of the density ﬁtting problem\n",
            "Chunk 3316: display of the density ﬁtting problem 1.81.\n",
            "Chunk 3317: A practical problem of paramount importance in\n",
            "Chunk 3318: problem of paramount importance in statistic and\n",
            "Chunk 3319: paramount importance in statistic and machine\n",
            "Chunk 3320: importance in statistic and machine learning is\n",
            "Chunk 3321: in statistic and machine learning is density\n",
            "Chunk 3322: and machine learning is density ﬁtting. Given\n",
            "Chunk 3323: some discrete samples ( xi)n\n",
            "Chunk 3324: i=1⊂X from some unknown distribution, the goal is\n",
            "Chunk 3325: some unknown distribution, the goal is to ﬁt a\n",
            "Chunk 3326: distribution, the goal is to ﬁt a parametric\n",
            "Chunk 3327: the goal is to ﬁt a parametric model\n",
            "Chunk 3328: θ↦→αθ∈M (X) to the observed empirical input\n",
            "Chunk 3329: (X) to the observed empirical input measure β\n",
            "Chunk 3330: min\n",
            "θ∈ΘL(αθ,β) where β=1\n",
            "n∑\n",
            "iδxi, (1.81)\n",
            "Chunk 3331: whereLis some “loss” function between a discrete\n",
            "Chunk 3332: some “loss” function between a discrete and a\n",
            "Chunk 3333: function between a discrete and a “continuous”\n",
            "Chunk 3334: between a discrete and a “continuous” (arbitrary)\n",
            "Chunk 3335: and a “continuous” (arbitrary) distribution (see\n",
            "Chunk 3336: (arbitrary) distribution (see Fig-\n",
            "Chunk 3337: ure 1.16).\n",
            "Chunk 3338: In the case where αθas a densify ρθdef.=ραθwith\n",
            "Chunk 3339: where αθas a densify ρθdef.=ραθwith respect to\n",
            "Chunk 3340: a densify ρθdef.=ραθwith respect to the Lebesgue\n",
            "Chunk 3341: ρθdef.=ραθwith respect to the Lebesgue measure\n",
            "Chunk 3342: respect to the Lebesgue measure (or any other\n",
            "Chunk 3343: to the Lebesgue measure (or any other ﬁxed\n",
            "Chunk 3344: reference measure), the maximum likelihood\n",
            "Chunk 3345: measure), the maximum likelihood estimator (MLE)\n",
            "Chunk 3346: the maximum likelihood estimator (MLE) is\n",
            "Chunk 3347: maximum likelihood estimator (MLE) is obtained by\n",
            "Chunk 3348: estimator (MLE) is obtained by solving\n",
            "Chunk 3349: min\n",
            "θLMLE(αθ,β)def.=−∑\n",
            "ilog(ρθ(xi)).\n",
            "Chunk 3350: This corresponds to using an empirical\n",
            "Chunk 3351: corresponds to using an empirical counterpart of\n",
            "Chunk 3352: to using an empirical counterpart of a\n",
            "Chunk 3353: an empirical counterpart of a Kullback-Leibler\n",
            "Chunk 3354: counterpart of a Kullback-Leibler loss since,\n",
            "Chunk 3355: of a Kullback-Leibler loss since, assuming the\n",
            "Chunk 3356: loss since, assuming the xiare i.i.d.\n",
            "Chunk 3357: samples of some ¯β, then\n",
            "LMLE(α,β)n→+∞−→ KL(α|¯β)\n",
            "Chunk 3358: This MLE approach is known to lead to optimal\n",
            "Chunk 3359: approach is known to lead to optimal estimation\n",
            "Chunk 3360: is known to lead to optimal estimation procedures\n",
            "Chunk 3361: lead to optimal estimation procedures in many\n",
            "Chunk 3362: optimal estimation procedures in many cases (see\n",
            "Chunk 3363: procedures in many cases (see for instance [ ?]).\n",
            "Chunk 3364: However, it fails to work when estimating\n",
            "Chunk 3365: it fails to work when estimating singular\n",
            "Chunk 3366: to work when estimating singular distributions,\n",
            "Chunk 3367: when estimating singular distributions, typically\n",
            "Chunk 3368: singular distributions, typically when the αθdoes\n",
            "Chunk 3369: typically when the αθdoes not has a density\n",
            "Chunk 3370: (so thatLMLE(αθ,β) = +∞) or when ( xi)iare\n",
            "Chunk 3371: thatLMLE(αθ,β) = +∞) or when ( xi)iare samples\n",
            "Chunk 3372: = +∞) or when ( xi)iare samples from some\n",
            "Chunk 3373: +∞) or when ( xi)iare samples from some singular\n",
            "Chunk 3374: ( xi)iare samples from some singular ¯β(so that\n",
            "Chunk 3375: samples from some singular ¯β(so that the\n",
            "Chunk 3376: from some singular ¯β(so that the αθshould share\n",
            "Chunk 3377: the same support as βfor KL(α|¯β) to be ﬁnite,\n",
            "Chunk 3378: support as βfor KL(α|¯β) to be ﬁnite, but this\n",
            "Chunk 3379: as βfor KL(α|¯β) to be ﬁnite, but this support is\n",
            "Chunk 3380: to be ﬁnite, but this support is usually\n",
            "Chunk 3381: be ﬁnite, but this support is usually unknown).\n",
            "Chunk 3382: but this support is usually unknown). Another\n",
            "Chunk 3383: support is usually unknown). Another issue is\n",
            "Chunk 3384: is usually unknown). Another issue is that\n",
            "Chunk 3385: in several cases of practical interest, the\n",
            "Chunk 3386: cases of practical interest, the density ρθis\n",
            "Chunk 3387: practical interest, the density ρθis inaccessible\n",
            "Chunk 3388: interest, the density ρθis inaccessible (or too\n",
            "Chunk 3389: the density ρθis inaccessible (or too hard to\n",
            "Chunk 3390: ρθis inaccessible (or too hard to compute).\n",
            "Chunk 3391: A typical setup where both problems (singular and\n",
            "Chunk 3392: setup where both problems (singular and unknown\n",
            "Chunk 3393: both problems (singular and unknown densities)\n",
            "Chunk 3394: (singular and unknown densities) occur is for\n",
            "Chunk 3395: and unknown densities) occur is for so-called\n",
            "Chunk 3396: densities) occur is for so-called generative\n",
            "Chunk 3397: models, where the parametric measure is written\n",
            "Chunk 3398: where the parametric measure is written as a\n",
            "Chunk 3399: parametric measure is written as a push-forward\n",
            "Chunk 3400: measure is written as a push-forward of a ﬁxed\n",
            "Chunk 3401: is written as a push-forward of a ﬁxed reference\n",
            "Chunk 3402: as a push-forward of a ﬁxed reference measure ζ∈M\n",
            "Chunk 3403: of a ﬁxed reference measure ζ∈M (Z)\n",
            "Chunk 3404: αθ=hθ,♯ζwherehθ:Z→X\n",
            "Chunk 3405: where the push-forward operator is introduced in\n",
            "Chunk 3406: push-forward operator is introduced in Deﬁnition\n",
            "Chunk 3407: operator is introduced in Deﬁnition 1. The space\n",
            "Chunk 3408: is introduced in Deﬁnition 1. The space Zis\n",
            "Chunk 3409: in Deﬁnition 1. The space Zis usually\n",
            "Chunk 3410: 1. The space Zis usually low-dimensional, so\n",
            "Chunk 3411: that the support of αθis localized along a\n",
            "Chunk 3412: support of αθis localized along a low-dimensional\n",
            "Chunk 3413: αθis localized along a low-dimensional “manifold”\n",
            "Chunk 3414: along a low-dimensional “manifold” and the\n",
            "Chunk 3415: a low-dimensional “manifold” and the resulting\n",
            "Chunk 3416: “manifold” and the resulting density is highly\n",
            "Chunk 3417: singular (it does not have a density with respect\n",
            "Chunk 3418: does not have a density with respect to Lebesgue\n",
            "Chunk 3419: have a density with respect to Lebesgue measure).\n",
            "Chunk 3420: with respect to Lebesgue measure). Furthermore,\n",
            "Chunk 3421: to Lebesgue measure). Furthermore, computing this\n",
            "Chunk 3422: measure). Furthermore, computing this density\n",
            "Chunk 3423: is usually intractable, while generating i.i.d.\n",
            "Chunk 3424: intractable, while generating i.i.d. samples from\n",
            "Chunk 3425: while generating i.i.d. samples from αθis\n",
            "Chunk 3426: generating i.i.d. samples from αθis achieved by\n",
            "Chunk 3427: i.i.d. samples from αθis achieved by computing\n",
            "Chunk 3428: samples from αθis achieved by computing xi=hθ(zi)\n",
            "Chunk 3429: αθis achieved by computing xi=hθ(zi) where\n",
            "Chunk 3430: (zi)iare i.i.d. samples from ζ.\n",
            "Chunk 3431: In order to cope with such diﬃcult scenario, one\n",
            "Chunk 3432: to cope with such diﬃcult scenario, one has to\n",
            "Chunk 3433: with such diﬃcult scenario, one has to use weak\n",
            "Chunk 3434: diﬃcult scenario, one has to use weak metrics in\n",
            "Chunk 3435: one has to use weak metrics in place of the MLE\n",
            "Chunk 3436: use weak metrics in place of the MLE functional\n",
            "Chunk 3437: LMLE, which needs to be written in dual form as\n",
            "Chunk 3438: L(α,β)def.= max\n",
            "(f,g)∈C(X)2{∫\n",
            "Xf(x)dα(x) +∫\n",
            "Chunk 3439: (f,g)∈C(X)2{∫\n",
            "Xf(x)dα(x) +∫\n",
            "Xg(x)dβ(x) ; (f,g)∈R}\n",
            "Chunk 3440: Xf(x)dα(x) +∫\n",
            "Xg(x)dβ(x) ; (f,g)∈R}\n",
            ". (1.82)\n",
            "Chunk 3441: Dual norms exposed in §??correspond to imposing\n",
            "Chunk 3442: exposed in §??correspond to imposing R={(f,−f)\n",
            "Chunk 3443: in §??correspond to imposing R={(f,−f) ;f∈B},\n",
            "Chunk 3444: to imposing R={(f,−f) ;f∈B}, while optimal\n",
            "Chunk 3445: imposing R={(f,−f) ;f∈B}, while optimal transport\n",
            "Chunk 3446: ;f∈B}, while optimal transport (1.21)\n",
            "Chunk 3447: setsR=R(c) as deﬁned in (1.22).\n",
            "28\n",
            "Chunk 3448: For a ﬁxed θ, evaluating the energy to be\n",
            "Chunk 3449: a ﬁxed θ, evaluating the energy to be minimized\n",
            "Chunk 3450: evaluating the energy to be minimized in (1.81)\n",
            "Chunk 3451: the energy to be minimized in (1.81) using such a\n",
            "Chunk 3452: to be minimized in (1.81) using such a loss\n",
            "Chunk 3453: minimized in (1.81) using such a loss function\n",
            "Chunk 3454: in (1.81) using such a loss function corresponds\n",
            "Chunk 3455: using such a loss function corresponds to\n",
            "Chunk 3456: solving a semi-discrete optimal transport, which\n",
            "Chunk 3457: semi-discrete optimal transport, which is the\n",
            "Chunk 3458: optimal transport, which is the focus of Chapter\n",
            "Chunk 3459: which is the focus of Chapter ??. Minimizing the\n",
            "Chunk 3460: the focus of Chapter ??. Minimizing the energy\n",
            "Chunk 3461: of Chapter ??. Minimizing the energy with\n",
            "Chunk 3462: respect toθis much more involved, and is\n",
            "Chunk 3463: toθis much more involved, and is typically highly\n",
            "Chunk 3464: involved, and is typically highly non-convex.\n",
            "Chunk 3465: The class of estimators obtained using L=Lc,\n",
            "Chunk 3466: of estimators obtained using L=Lc, often called\n",
            "Chunk 3467: obtained using L=Lc, often called “Minimum\n",
            "Chunk 3468: using L=Lc, often called “Minimum Kantorovitch\n",
            "Chunk 3469: often called “Minimum Kantorovitch Estimators”\n",
            "Chunk 3470: “Minimum Kantorovitch Estimators” (MKE),\n",
            "Chunk 3471: was initially introduced in [ ?], see also [ ?].\n",
            "Chunk 3472: Gromov-Wasserstein. Optimal transport needs a\n",
            "Chunk 3473: Optimal transport needs a ground cost Cto compare\n",
            "Chunk 3474: needs a ground cost Cto compare histograms (\n",
            "Chunk 3475: a ground cost Cto compare histograms ( a,b), it\n",
            "Chunk 3476: cost Cto compare histograms ( a,b), it can\n",
            "Chunk 3477: thus not be used if the histograms are not deﬁned\n",
            "Chunk 3478: used if the histograms are not deﬁned on the same\n",
            "Chunk 3479: histograms are not deﬁned on the same underlying\n",
            "Chunk 3480: are not deﬁned on the same underlying space, or\n",
            "Chunk 3481: deﬁned on the same underlying space, or if one\n",
            "Chunk 3482: on the same underlying space, or if one cannot\n",
            "Chunk 3483: underlying space, or if one cannot pre-register\n",
            "Chunk 3484: these spaces to deﬁne a ground cost. To address\n",
            "Chunk 3485: to deﬁne a ground cost. To address this issue,\n",
            "Chunk 3486: a ground cost. To address this issue, one can\n",
            "Chunk 3487: cost. To address this issue, one can instead only\n",
            "Chunk 3488: this issue, one can instead only assume a weaker\n",
            "Chunk 3489: one can instead only assume a weaker assumption,\n",
            "Chunk 3490: namely that one has at its disposal two matrices\n",
            "Chunk 3491: at its disposal two matrices D∈Rn×nandD′∈Rm×mthat\n",
            "Chunk 3492: two matrices D∈Rn×nandD′∈Rm×mthat represent some\n",
            "Chunk 3493: D∈Rn×nandD′∈Rm×mthat represent some relationship\n",
            "Chunk 3494: between the points on which the histograms are\n",
            "Chunk 3495: the points on which the histograms are deﬁned. A\n",
            "Chunk 3496: on which the histograms are deﬁned. A typical\n",
            "Chunk 3497: the histograms are deﬁned. A typical scenario is\n",
            "Chunk 3498: are deﬁned. A typical scenario is when these\n",
            "Chunk 3499: A typical scenario is when these matrices are\n",
            "Chunk 3500: scenario is when these matrices are (power\n",
            "Chunk 3501: of) distance matrices. The Gromov-Wasserstein\n",
            "Chunk 3502: matrices. The Gromov-Wasserstein problem reads\n",
            "Chunk 3503: GW(( a,D),(b,D′))2def.= min\n",
            "Chunk 3504: P∈U(a,b)ED,D′(P)def.=∑\n",
            "i,j,i′,j′|Di,i′−D′\n",
            "Chunk 3505: i,j,i′,j′|Di,i′−D′\n",
            "j,j′|2Pi,jPi′,j′. (1.83)\n",
            "Chunk 3506: This is a non-convex problem, which can be recast\n",
            "Chunk 3507: non-convex problem, which can be recast as a\n",
            "Chunk 3508: problem, which can be recast as a Quadratic\n",
            "Chunk 3509: which can be recast as a Quadratic Assignment\n",
            "Chunk 3510: can be recast as a Quadratic Assignment Problem\n",
            "Chunk 3511: as a Quadratic Assignment Problem (QAP) [ ?] and\n",
            "Chunk 3512: Assignment Problem (QAP) [ ?] and is in\n",
            "Chunk 3513: full generality NP-hard to solve for arbitrary\n",
            "Chunk 3514: NP-hard to solve for arbitrary inputs. It is in\n",
            "Chunk 3515: to solve for arbitrary inputs. It is in fact\n",
            "Chunk 3516: for arbitrary inputs. It is in fact equivalent to\n",
            "Chunk 3517: inputs. It is in fact equivalent to a graph\n",
            "Chunk 3518: It is in fact equivalent to a graph matching\n",
            "Chunk 3519: in fact equivalent to a graph matching problem [\n",
            "Chunk 3520: to a graph matching problem [ ?]\n",
            "Chunk 3521: for a particular cost.\n",
            "Chunk 3522: One can show that GW satisﬁes the triangular\n",
            "Chunk 3523: show that GW satisﬁes the triangular inequality,\n",
            "Chunk 3524: GW satisﬁes the triangular inequality, and in\n",
            "Chunk 3525: the triangular inequality, and in fact it deﬁnes\n",
            "Chunk 3526: inequality, and in fact it deﬁnes a distance\n",
            "Chunk 3527: and in fact it deﬁnes a distance between\n",
            "Chunk 3528: metric spaces equipped with a probability\n",
            "Chunk 3529: spaces equipped with a probability distribution\n",
            "Chunk 3530: with a probability distribution (here assumed to\n",
            "Chunk 3531: distribution (here assumed to be discrete in\n",
            "Chunk 3532: (here assumed to be discrete in deﬁnition (1.83))\n",
            "Chunk 3533: up to isometries preserving the measures. This\n",
            "Chunk 3534: preserving the measures. This distance was\n",
            "Chunk 3535: the measures. This distance was introduced and\n",
            "Chunk 3536: This distance was introduced and studied in\n",
            "Chunk 3537: distance was introduced and studied in details by\n",
            "Chunk 3538: introduced and studied in details by Memoli\n",
            "Chunk 3539: in [?]. An in-depth mathematical exposition (in\n",
            "Chunk 3540: in-depth mathematical exposition (in particular,\n",
            "Chunk 3541: mathematical exposition (in particular, its\n",
            "Chunk 3542: exposition (in particular, its geodesic structure\n",
            "Chunk 3543: (in particular, its geodesic structure and\n",
            "Chunk 3544: particular, its geodesic structure and gradient\n",
            "Chunk 3545: its geodesic structure and gradient ﬂows) is\n",
            "Chunk 3546: structure and gradient ﬂows) is given\n",
            "Chunk 3547: in [?]. See also [ ?] for applications in\n",
            "Chunk 3548: [?]. See also [ ?] for applications in computer\n",
            "Chunk 3549: also [ ?] for applications in computer vision.\n",
            "Chunk 3550: ?] for applications in computer vision. This\n",
            "Chunk 3551: applications in computer vision. This distance is\n",
            "Chunk 3552: in computer vision. This distance is also tightly\n",
            "Chunk 3553: vision. This distance is also tightly connected\n",
            "Chunk 3554: This distance is also tightly connected with the\n",
            "Chunk 3555: Gromov-Hausdorﬀ distance [ ?] between metric\n",
            "Chunk 3556: distance [ ?] between metric spaces, which have\n",
            "Chunk 3557: [ ?] between metric spaces, which have been used\n",
            "Chunk 3558: metric spaces, which have been used for shape\n",
            "Chunk 3559: spaces, which have been used for shape matching [\n",
            "Chunk 3560: have been used for shape matching [ ?,?].\n",
            "Chunk 3561: Remark 19.Gromov-Wasserstein distance The general\n",
            "Chunk 3562: distance The general setting corresponds to\n",
            "Chunk 3563: The general setting corresponds to computing\n",
            "Chunk 3564: setting corresponds to computing couplings\n",
            "Chunk 3565: corresponds to computing couplings between\n",
            "Chunk 3566: metric measure spaces ( X,dX,αX) and (Y,dY,αY)\n",
            "Chunk 3567: measure spaces ( X,dX,αX) and (Y,dY,αY) where\n",
            "Chunk 3568: spaces ( X,dX,αX) and (Y,dY,αY) where (dX,dY) are\n",
            "Chunk 3569: and (Y,dY,αY) where (dX,dY) are distances and (\n",
            "Chunk 3570: where (dX,dY) are distances and ( αX,αY) are\n",
            "Chunk 3571: (dX,dY) are distances and ( αX,αY) are measures\n",
            "Chunk 3572: on their respective spaces. One deﬁnes\n",
            "Chunk 3573: GW((αX,dX),(αY,dY))2def.= min\n",
            "π∈U(αX,αY)∫\n",
            "Chunk 3574: X2×Y2|dX(x,x′)−dY(y,y′)|2dπ(x,y)dπ(x′,y′). (1.84)\n",
            "Chunk 3575: GW deﬁnes a distance between metric measure\n",
            "Chunk 3576: a distance between metric measure spaces up to\n",
            "Chunk 3577: between metric measure spaces up to isometries,\n",
            "Chunk 3578: metric measure spaces up to isometries, where one\n",
            "Chunk 3579: spaces up to isometries, where one says that (\n",
            "Chunk 3580: up to isometries, where one says that ( αX,dX)\n",
            "Chunk 3581: where one says that ( αX,dX) and\n",
            "Chunk 3582: (αY,dY) are isometric if there exists ϕ:X→Y such\n",
            "Chunk 3583: exists ϕ:X→Y such thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′))\n",
            "Chunk 3584: such thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′)) =dX(x,x′).\n",
            "Chunk 3585: Remark 20.Gromov-Wasserstein geodesics The space\n",
            "Chunk 3586: geodesics The space of metric spaces (up to\n",
            "Chunk 3587: The space of metric spaces (up to isometries)\n",
            "Chunk 3588: of metric spaces (up to isometries) endowed with\n",
            "Chunk 3589: thisGW distance (1.84) has a geodesic structure.\n",
            "Chunk 3590: (1.84) has a geodesic structure. [ ?] shows that\n",
            "Chunk 3591: a geodesic structure. [ ?] shows that the\n",
            "Chunk 3592: geodesic structure. [ ?] shows that the geodesic\n",
            "Chunk 3593: structure. [ ?] shows that the geodesic between (\n",
            "Chunk 3594: [ ?] shows that the geodesic between ( X0,dX0,α0)\n",
            "Chunk 3595: that the geodesic between ( X0,dX0,α0) and\n",
            "Chunk 3596: (X1,dX1,α1) can be chosen to be t∈[0,1]↦→(X0×X\n",
            "Chunk 3597: can be chosen to be t∈[0,1]↦→(X0×X 1,dt,π⋆)\n",
            "Chunk 3598: be chosen to be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is\n",
            "Chunk 3599: to be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is a\n",
            "Chunk 3600: be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is a solution\n",
            "Chunk 3601: 1,dt,π⋆) whereπ⋆is a solution of (1.84) and for\n",
            "Chunk 3602: whereπ⋆is a solution of (1.84) and for all\n",
            "Chunk 3603: ((x0,x1),(x′\n",
            "0,x′\n",
            "1))∈(X0×X 1)2,\n",
            "dt((x0,x1),(x′\n",
            "Chunk 3604: 0,x′\n",
            "1))∈(X0×X 1)2,\n",
            "dt((x0,x1),(x′\n",
            "0,x′\n",
            "Chunk 3605: dt((x0,x1),(x′\n",
            "0,x′\n",
            "1))def.= (1−t)dX0(x0,x′\n",
            "Chunk 3606: 0,x′\n",
            "1))def.= (1−t)dX0(x0,x′\n",
            "0) +tdX1(x1,x′\n",
            "1).\n",
            "Chunk 3607: This formula allows one to deﬁne and analyze\n",
            "Chunk 3608: formula allows one to deﬁne and analyze gradient\n",
            "Chunk 3609: one to deﬁne and analyze gradient ﬂows which\n",
            "Chunk 3610: deﬁne and analyze gradient ﬂows which minimize\n",
            "Chunk 3611: analyze gradient ﬂows which minimize functionals\n",
            "Chunk 3612: ﬂows which minimize functionals involving metric\n",
            "Chunk 3613: spaces, see [ ?]. It is however diﬃcult to handle\n",
            "Chunk 3614: ?]. It is however diﬃcult to handle numerically,\n",
            "Chunk 3615: however diﬃcult to handle numerically, because it\n",
            "Chunk 3616: to handle numerically, because it involves\n",
            "Chunk 3617: numerically, because it involves computations\n",
            "Chunk 3618: because it involves computations over the product\n",
            "Chunk 3619: spaceX0×X 1. A heuristic approach is used in [ ?]\n",
            "Chunk 3620: 1. A heuristic approach is used in [ ?] to deﬁne\n",
            "Chunk 3621: approach is used in [ ?] to deﬁne geodesics and\n",
            "Chunk 3622: used in [ ?] to deﬁne geodesics and barycenters\n",
            "Chunk 3623: [ ?] to deﬁne geodesics and barycenters of metric\n",
            "Chunk 3624: geodesics and barycenters of metric measure\n",
            "Chunk 3625: spaces while imposing the cardinality of the\n",
            "Chunk 3626: while imposing the cardinality of the involved\n",
            "Chunk 3627: the cardinality of the involved spaces and making\n",
            "Chunk 3628: of the involved spaces and making use of the\n",
            "Chunk 3629: involved spaces and making use of the entropic\n",
            "Chunk 3630: spaces and making use of the entropic smoothing\n",
            "Chunk 3631: making use of the entropic smoothing (1.85)\n",
            "Chunk 3632: detailed below.\n",
            "Chunk 3633: To approximate the computation of GW, and to help\n",
            "Chunk 3634: the computation of GW, and to help convergence of\n",
            "Chunk 3635: of GW, and to help convergence of minimization\n",
            "Chunk 3636: and to help convergence of minimization schemes\n",
            "Chunk 3637: convergence of minimization schemes to better\n",
            "Chunk 3638: minima, one can consider the entropic regularized\n",
            "Chunk 3639: can consider the entropic regularized variant\n",
            "Chunk 3640: min\n",
            "P∈U(a,b)ED,D′(P)−εH(P). (1.85)\n",
            "29\n",
            "Chunk 3641: Figure 1.17: Example of fuzzy correspondences\n",
            "Chunk 3642: 1.17: Example of fuzzy correspondences computed\n",
            "Chunk 3643: of fuzzy correspondences computed by solving GW\n",
            "Chunk 3644: correspondences computed by solving GW problem\n",
            "Chunk 3645: computed by solving GW problem (1.85) with\n",
            "Chunk 3646: by solving GW problem (1.85) with Sinkhorn\n",
            "Chunk 3647: iterations (1.86). Extracted from [ ?].\n",
            "Chunk 3648: As proposed initially in [ ?,?], and later\n",
            "Chunk 3649: proposed initially in [ ?,?], and later revisited\n",
            "Chunk 3650: in [ ?,?], and later revisited in [ ?] for\n",
            "Chunk 3651: and later revisited in [ ?] for applications in\n",
            "Chunk 3652: revisited in [ ?] for applications in graphics,\n",
            "Chunk 3653: in [ ?] for applications in graphics, one can use\n",
            "Chunk 3654: applications in graphics, one can use iteratively\n",
            "Chunk 3655: Sinkhorn’s algorithm to progressively compute a\n",
            "Chunk 3656: algorithm to progressively compute a stationary\n",
            "Chunk 3657: to progressively compute a stationary point of\n",
            "Chunk 3658: compute a stationary point of (1.85). Indeed,\n",
            "Chunk 3659: a stationary point of (1.85). Indeed, successive\n",
            "Chunk 3660: of (1.85). Indeed, successive linearizations\n",
            "Chunk 3661: of the objective function lead to consider the\n",
            "Chunk 3662: function lead to consider the succession of\n",
            "Chunk 3663: lead to consider the succession of updates\n",
            "Chunk 3664: P(ℓ+1) def.= min\n",
            "Chunk 3665: P∈U(a,b)⟨P,C(ℓ)⟩−εH(P) where (1.86)\n",
            "Chunk 3666: C(ℓ)def.=∇ED,D′(P(ℓ)) =−D′TP(ℓ)D,\n",
            "Chunk 3667: which can be interpreted as a mirror-descent\n",
            "Chunk 3668: can be interpreted as a mirror-descent scheme [\n",
            "Chunk 3669: as a mirror-descent scheme [ ?]. Each update can\n",
            "Chunk 3670: scheme [ ?]. Each update can thus be solved using\n",
            "Chunk 3671: Each update can thus be solved using Sinkhorn\n",
            "Chunk 3672: iterations (1.51) with cost C(ℓ). Figure (1.17)\n",
            "Chunk 3673: (1.51) with cost C(ℓ). Figure (1.17) illustrates\n",
            "Chunk 3674: cost C(ℓ). Figure (1.17) illustrates the use of\n",
            "Chunk 3675: Figure (1.17) illustrates the use of this\n",
            "Chunk 3676: (1.17) illustrates the use of this entropic\n",
            "Chunk 3677: the use of this entropic Gromov-Wasserstein to\n",
            "Chunk 3678: compute soft maps between domains.\n",
            "30\n",
            "Chunk 3679: 30\n",
            "Bibliography\n",
            "Chunk 3680: [1] Amir Beck. Introduction to Nonlinear\n",
            "Chunk 3681: Beck. Introduction to Nonlinear Optimization:\n",
            "Chunk 3682: Introduction to Nonlinear Optimization: Theory,\n",
            "Chunk 3683: to Nonlinear Optimization: Theory, Algorithms,\n",
            "Chunk 3684: Optimization: Theory, Algorithms, and\n",
            "Chunk 3685: Theory, Algorithms, and Applications with MAT-\n",
            "Chunk 3686: LAB. SIAM, 2014.\n",
            "Chunk 3687: [2] Stephen Boyd, Neal Parikh, Eric Chu, Borja\n",
            "Chunk 3688: Boyd, Neal Parikh, Eric Chu, Borja Peleato, and\n",
            "Chunk 3689: Parikh, Eric Chu, Borja Peleato, and Jonathan\n",
            "Chunk 3690: Eric Chu, Borja Peleato, and Jonathan Eckstein.\n",
            "Chunk 3691: Borja Peleato, and Jonathan Eckstein. Distributed\n",
            "Chunk 3692: and Jonathan Eckstein. Distributed optimization\n",
            "Chunk 3693: and statistical learning via the alternating\n",
            "Chunk 3694: learning via the alternating direction method of\n",
            "Chunk 3695: the alternating direction method of multipliers.\n",
            "Chunk 3696: direction method of multipliers. Foundations and\n",
            "Chunk 3697: method of multipliers. Foundations and Trends R⃝\n",
            "Chunk 3698: in Machine Learning , 3(1):1–122, 2011.\n",
            "Chunk 3699: [3] Stephen Boyd and Lieven Vandenberghe. Convex\n",
            "Chunk 3700: Boyd and Lieven Vandenberghe. Convex optimization\n",
            "Chunk 3701: Vandenberghe. Convex optimization . Cambridge\n",
            "Chunk 3702: Convex optimization . Cambridge university press,\n",
            "Chunk 3703: . Cambridge university press, 2004.\n",
            "Chunk 3704: [4] E. Cand` es and D. Donoho. New tight frames\n",
            "Chunk 3705: es and D. Donoho. New tight frames of curvelets\n",
            "Chunk 3706: Donoho. New tight frames of curvelets and optimal\n",
            "Chunk 3707: frames of curvelets and optimal representations\n",
            "Chunk 3708: curvelets and optimal representations of objects\n",
            "Chunk 3709: and optimal representations of objects with\n",
            "Chunk 3710: piecewise C2singularities. Commun. on Pure and\n",
            "Chunk 3711: C2singularities. Commun. on Pure and Appl. Math.\n",
            "Chunk 3712: Commun. on Pure and Appl. Math. , 57(2):219–266,\n",
            "Chunk 3713: Pure and Appl. Math. , 57(2):219–266, 2004.\n",
            "Chunk 3714: [5] E. J. Cand` es, L. Demanet, D. L. Donoho, and\n",
            "Chunk 3715: Cand` es, L. Demanet, D. L. Donoho, and L. Ying.\n",
            "Chunk 3716: L. Demanet, D. L. Donoho, and L. Ying. Fast\n",
            "Chunk 3717: D. L. Donoho, and L. Ying. Fast discrete curvelet\n",
            "Chunk 3718: and L. Ying. Fast discrete curvelet transforms.\n",
            "Chunk 3719: Fast discrete curvelet transforms. SIAM\n",
            "Chunk 3720: Multiscale Modeling and Simulation , 5:861–899,\n",
            "Chunk 3721: Modeling and Simulation , 5:861–899, 2005.\n",
            "Chunk 3722: [6] A. Chambolle. An algorithm for total\n",
            "Chunk 3723: A. Chambolle. An algorithm for total variation\n",
            "Chunk 3724: An algorithm for total variation minimization and\n",
            "Chunk 3725: total variation minimization and applications. J.\n",
            "Chunk 3726: minimization and applications. J. Math. Imaging\n",
            "Chunk 3727: and applications. J. Math. Imaging Vis. ,\n",
            "Chunk 3728: 20:89–97, 2004.\n",
            "Chunk 3729: [7] Antonin Chambolle, Vicent Caselles, Daniel\n",
            "Chunk 3730: Chambolle, Vicent Caselles, Daniel Cremers,\n",
            "Chunk 3731: Vicent Caselles, Daniel Cremers, Matteo Novaga,\n",
            "Chunk 3732: Daniel Cremers, Matteo Novaga, and Thomas Pock.\n",
            "Chunk 3733: Matteo Novaga, and Thomas Pock. An intro-\n",
            "Chunk 3734: duction to total variation for image analysis.\n",
            "Chunk 3735: total variation for image analysis. Theoretical\n",
            "Chunk 3736: for image analysis. Theoretical foundations and\n",
            "Chunk 3737: analysis. Theoretical foundations and numerical\n",
            "Chunk 3738: Theoretical foundations and numerical methods for\n",
            "Chunk 3739: foundations and numerical methods for sparse\n",
            "Chunk 3740: recovery , 9(263-340):227, 2010.\n",
            "Chunk 3741: [8] Antonin Chambolle and Thomas Pock. An\n",
            "Chunk 3742: Chambolle and Thomas Pock. An introduction to\n",
            "Chunk 3743: and Thomas Pock. An introduction to continuous\n",
            "Chunk 3744: Pock. An introduction to continuous optimization\n",
            "Chunk 3745: introduction to continuous optimization for\n",
            "Chunk 3746: to continuous optimization for imaging. Acta\n",
            "Chunk 3747: Numerica , 25:161–319, 2016.\n",
            "Chunk 3748: [9] S.S. Chen, D.L. Donoho, and M.A. Saunders.\n",
            "Chunk 3749: Chen, D.L. Donoho, and M.A. Saunders. Atomic\n",
            "Chunk 3750: Donoho, and M.A. Saunders. Atomic decomposition\n",
            "Chunk 3751: and M.A. Saunders. Atomic decomposition by basis\n",
            "Chunk 3752: Saunders. Atomic decomposition by basis pursuit.\n",
            "Chunk 3753: Atomic decomposition by basis pursuit. SIAM\n",
            "Chunk 3754: decomposition by basis pursuit. SIAM Journal\n",
            "Chunk 3755: on Scientiﬁc Computing , 20(1):33–61, 1999.\n",
            "Chunk 3756: [10] Philippe G Ciarlet. Introduction ` a\n",
            "Chunk 3757: Philippe G Ciarlet. Introduction ` a l’analyse\n",
            "Chunk 3758: G Ciarlet. Introduction ` a l’analyse num´ erique\n",
            "Chunk 3759: ` a l’analyse num´ erique matricielle et ` a\n",
            "Chunk 3760: num´ erique matricielle et ` a l’optimisation.\n",
            "Chunk 3761: matricielle et ` a l’optimisation. 1982.\n",
            "Chunk 3762: [11] P. L. Combettes and V. R. Wajs. Signal\n",
            "Chunk 3763: P. L. Combettes and V. R. Wajs. Signal recovery\n",
            "Chunk 3764: and V. R. Wajs. Signal recovery by proximal\n",
            "Chunk 3765: Signal recovery by proximal forward-backward\n",
            "Chunk 3766: recovery by proximal forward-backward splitting.\n",
            "Chunk 3767: by proximal forward-backward splitting. SIAM\n",
            "Chunk 3768: Multiscale Modeling and Simulation , 4(4), 2005.\n",
            "Chunk 3769: [12] I. Daubechies, M. Defrise, and C. De Mol. An\n",
            "Chunk 3770: M. Defrise, and C. De Mol. An iterative\n",
            "Chunk 3771: Defrise, and C. De Mol. An iterative thresholding\n",
            "Chunk 3772: C. De Mol. An iterative thresholding algorithm\n",
            "Chunk 3773: An iterative thresholding algorithm for linear\n",
            "Chunk 3774: thresholding algorithm for linear inverse\n",
            "Chunk 3775: algorithm for linear inverse problems\n",
            "Chunk 3776: with a sparsity constraint. Commun. on Pure and\n",
            "Chunk 3777: constraint. Commun. on Pure and Appl. Math. ,\n",
            "Chunk 3778: Commun. on Pure and Appl. Math. , 57:1413–1541,\n",
            "Chunk 3779: on Pure and Appl. Math. , 57:1413–1541, 2004.\n",
            "Chunk 3780: [13] D. Donoho and I. Johnstone. Ideal spatial\n",
            "Chunk 3781: Donoho and I. Johnstone. Ideal spatial adaptation\n",
            "Chunk 3782: I. Johnstone. Ideal spatial adaptation via\n",
            "Chunk 3783: Johnstone. Ideal spatial adaptation via wavelet\n",
            "Chunk 3784: Ideal spatial adaptation via wavelet shrinkage.\n",
            "Chunk 3785: adaptation via wavelet shrinkage. Biometrika ,\n",
            "Chunk 3786: via wavelet shrinkage. Biometrika , 81:425–455,\n",
            "Chunk 3787: Dec 1994.\n",
            "Chunk 3788: [14] Heinz Werner Engl, Martin Hanke, and Andreas\n",
            "Chunk 3789: Werner Engl, Martin Hanke, and Andreas Neubauer.\n",
            "Chunk 3790: Hanke, and Andreas Neubauer. Regularization of\n",
            "Chunk 3791: and Andreas Neubauer. Regularization of inverse\n",
            "Chunk 3792: Neubauer. Regularization of inverse problems ,\n",
            "Chunk 3793: Regularization of inverse problems , volume\n",
            "Chunk 3794: 375. Springer Science & Business Media, 1996.\n",
            "Chunk 3795: [15] M. Figueiredo and R. Nowak. An EM Algorithm\n",
            "Chunk 3796: and R. Nowak. An EM Algorithm for Wavelet-Based\n",
            "Chunk 3797: An EM Algorithm for Wavelet-Based Image\n",
            "Chunk 3798: EM Algorithm for Wavelet-Based Image Restoration.\n",
            "Chunk 3799: for Wavelet-Based Image Restoration. IEEE Trans.\n",
            "Chunk 3800: Image Proc. , 12(8):906–916, 2003.\n",
            "Chunk 3801: [16] Simon Foucart and Holger Rauhut. A\n",
            "Chunk 3802: Simon Foucart and Holger Rauhut. A mathematical\n",
            "Chunk 3803: and Holger Rauhut. A mathematical introduction to\n",
            "Chunk 3804: A mathematical introduction to compressive\n",
            "Chunk 3805: introduction to compressive sensing , volume 1.\n",
            "Chunk 3806: Birkh¨ auser Basel, 2013.\n",
            "31\n",
            "Chunk 3807: [17] Stephane Mallat. A wavelet tour of signal\n",
            "Chunk 3808: Mallat. A wavelet tour of signal processing: the\n",
            "Chunk 3809: wavelet tour of signal processing: the sparse way\n",
            "Chunk 3810: of signal processing: the sparse way . Academic\n",
            "Chunk 3811: processing: the sparse way . Academic press,\n",
            "Chunk 3812: the sparse way . Academic press, 2008.\n",
            "Chunk 3813: [18] D. Mumford and J. Shah. Optimal\n",
            "Chunk 3814: D. Mumford and J. Shah. Optimal approximation by\n",
            "Chunk 3815: and J. Shah. Optimal approximation by piecewise\n",
            "Chunk 3816: Optimal approximation by piecewise smooth\n",
            "Chunk 3817: approximation by piecewise smooth functions and\n",
            "Chunk 3818: by piecewise smooth functions and associated\n",
            "Chunk 3819: smooth functions and associated varia-\n",
            "Chunk 3820: tional problems. Commun. on Pure and Appl. Math.\n",
            "Chunk 3821: Commun. on Pure and Appl. Math. , 42:577–685,\n",
            "Chunk 3822: on Pure and Appl. Math. , 42:577–685, 1989.\n",
            "Chunk 3823: [19] Neal Parikh, Stephen Boyd, et al. Proximal\n",
            "Chunk 3824: Parikh, Stephen Boyd, et al. Proximal algorithms.\n",
            "Chunk 3825: Boyd, et al. Proximal algorithms. Foundations and\n",
            "Chunk 3826: Proximal algorithms. Foundations and Trends R⃝in\n",
            "Chunk 3827: Foundations and Trends R⃝in Optimization ,\n",
            "Chunk 3828: 1(3):127–239, 2014.\n",
            "Chunk 3829: [20] Gabriel Peyr´ e. L’alg` ebre discr` ete de\n",
            "Chunk 3830: Peyr´ e. L’alg` ebre discr` ete de la transform´\n",
            "Chunk 3831: L’alg` ebre discr` ete de la transform´ ee de\n",
            "Chunk 3832: ebre discr` ete de la transform´ ee de Fourier .\n",
            "Chunk 3833: ete de la transform´ ee de Fourier . Ellipses,\n",
            "Chunk 3834: la transform´ ee de Fourier . Ellipses, 2004.\n",
            "Chunk 3835: [21] J. Portilla, V. Strela, M.J. Wainwright, and\n",
            "Chunk 3836: V. Strela, M.J. Wainwright, and Simoncelli E.P.\n",
            "Chunk 3837: M.J. Wainwright, and Simoncelli E.P. Image\n",
            "Chunk 3838: Wainwright, and Simoncelli E.P. Image denoising\n",
            "Chunk 3839: and Simoncelli E.P. Image denoising using scale\n",
            "Chunk 3840: E.P. Image denoising using scale mixtures of\n",
            "Chunk 3841: Gaussians in the wavelet domain. IEEE Trans.\n",
            "Chunk 3842: in the wavelet domain. IEEE Trans. Image Proc. ,\n",
            "Chunk 3843: IEEE Trans. Image Proc. , 12(11):1338–1351,\n",
            "Chunk 3844: Trans. Image Proc. , 12(11):1338–1351, November\n",
            "Chunk 3845: Proc. , 12(11):1338–1351, November 2003.\n",
            "Chunk 3846: [22] L. I. Rudin, S. Osher, and E. Fatemi.\n",
            "Chunk 3847: L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear\n",
            "Chunk 3848: S. Osher, and E. Fatemi. Nonlinear total\n",
            "Chunk 3849: Osher, and E. Fatemi. Nonlinear total variation\n",
            "Chunk 3850: E. Fatemi. Nonlinear total variation based noise\n",
            "Chunk 3851: Nonlinear total variation based noise removal\n",
            "Chunk 3852: total variation based noise removal algorithms.\n",
            "Chunk 3853: based noise removal algorithms. Phys.\n",
            "Chunk 3854: D, 60(1-4):259–268, 1992.\n",
            "Chunk 3855: [23] Otmar Scherzer, Markus Grasmair, Harald\n",
            "Chunk 3856: Scherzer, Markus Grasmair, Harald Grossauer,\n",
            "Chunk 3857: Markus Grasmair, Harald Grossauer, Markus\n",
            "Chunk 3858: Grasmair, Harald Grossauer, Markus Haltmeier,\n",
            "Chunk 3859: Harald Grossauer, Markus Haltmeier, Frank Lenzen,\n",
            "Chunk 3860: Markus Haltmeier, Frank Lenzen, and L Sirovich.\n",
            "Chunk 3861: Variational methods in imaging . Springer, 2009.\n",
            "Chunk 3862: [24] C. E. Shannon. A mathematical theory of\n",
            "Chunk 3863: Shannon. A mathematical theory of communication.\n",
            "Chunk 3864: A mathematical theory of communication. The Bell\n",
            "Chunk 3865: theory of communication. The Bell System\n",
            "Chunk 3866: of communication. The Bell System Technical\n",
            "Chunk 3867: The Bell System Technical Journal ,\n",
            "Chunk 3868: 27(3):379–423, 1948.\n",
            "Chunk 3869: [25] Jean-Luc Starck, Fionn Murtagh, and Jalal\n",
            "Chunk 3870: Starck, Fionn Murtagh, and Jalal Fadili. Sparse\n",
            "Chunk 3871: Fionn Murtagh, and Jalal Fadili. Sparse image and\n",
            "Chunk 3872: and Jalal Fadili. Sparse image and signal\n",
            "Chunk 3873: Jalal Fadili. Sparse image and signal processing:\n",
            "Chunk 3874: Sparse image and signal processing: Wavelets and\n",
            "Chunk 3875: related geometric multiscale analysis . Cambridge\n",
            "Chunk 3876: multiscale analysis . Cambridge university press,\n",
            "Chunk 3877: analysis . Cambridge university press, 2015.\n",
            "Chunk 3878: 32\n",
            "Char count chunking non overlap:\n",
            "Chunk 1: Mathematical Foundations of Data Sciences\n",
            "Chunk 2: Gabriel Peyr´ e\n",
            "CNRS & DMA\n",
            "Chunk 3: ´Ecole Normale Sup´ erieure\n",
            "gabriel.peyre@ens.fr\n",
            "Chunk 4: https://mathematical-tours.github.io\n",
            "Chunk 5: www.numerical-tours.com\n",
            "August 14, 2019\n",
            "2\n",
            "Chunk 6: Chapter 1\n",
            "Optimal Transport\n",
            "1.1 Radon Measures\n",
            "Chunk 7: Measures. We will interchangeably the term\n",
            "Chunk 8: histogram or probability vector for any element\n",
            "Chunk 9: a∈Σnthat\n",
            "Chunk 10: belongs to the probability simplex\n",
            "Σndef.={\n",
            "a∈Rn\n",
            "Chunk 11: +;n∑\n",
            "i=1ai= 1}\n",
            ".\n",
            "Chunk 12: A discrete measure with weights aand locations\n",
            "Chunk 13: x1,...,xn∈X reads\n",
            "Chunk 14: α=n∑\n",
            "i=1aiδxi (1.1)\n",
            "Chunk 15: whereδxis the Dirac at position x, intuitively a\n",
            "Chunk 16: unit of mass which is inﬁnitely concentrated at\n",
            "Chunk 17: location\n",
            "Chunk 18: x. Such as measure describes a probability\n",
            "Chunk 19: measure if, additionally, a∈Σn, and more\n",
            "Chunk 20: generally a positive\n",
            "Chunk 21: measure if each of the “weights” described in\n",
            "Chunk 22: vector ais positive itself.\n",
            "Chunk 23: Remark 1 (General measures) .A convenient feature\n",
            "Chunk 24: of OT is that it can deal with discrete and\n",
            "Chunk 25: continuous\n",
            "Chunk 26: “objects” within the same framework. Such objects\n",
            "Chunk 27: only need to be modelled as measures. This\n",
            "Chunk 28: corresponds\n",
            "Chunk 29: to the notion of Radon measures M(X) on the\n",
            "Chunk 30: spaceX. The formal deﬁnition of that set requires\n",
            "Chunk 31: that Xis\n",
            "Chunk 32: equipped with a distance, usually denoted d,\n",
            "Chunk 33: because one can only access a measure by\n",
            "Chunk 34: “testing” (integrating)\n",
            "Chunk 35: it against continuous functions, denoted f∈C(X).\n",
            "Chunk 36: Integration of f∈C(X) against a discrete measure\n",
            "Chunk 37: αcomputes a sum\n",
            "Chunk 38: ∫\n",
            "Xf(x)dα(x) =n∑\n",
            "i=1aif(xi).\n",
            "Chunk 39: More general measures, for instance on\n",
            "Chunk 40: X=Rd(whered∈N∗is the dimension), can have a\n",
            "Chunk 41: density\n",
            "Chunk 42: dα(x) =ρα(x)dxw.r.t. the Lebesgue measure, often\n",
            "Chunk 43: denoted ρα=dα\n",
            "Chunk 44: dx, which means that\n",
            "∀h∈C(Rd),∫\n",
            "Rdh(x)dα(x) =∫\n",
            "Chunk 45: Rdh(x)ρα(x)dx.\n",
            "Chunk 46: An arbitrary measure α∈M (X) (which needs not to\n",
            "Chunk 47: have a density nor be a sum of Diracs) is deﬁned\n",
            "Chunk 48: by\n",
            "Chunk 49: the fact that it can be integrated agains any\n",
            "Chunk 50: continuous function f∈C(X) and obtain∫\n",
            "Chunk 51: Xf(x)dα(x)∈R.\n",
            "Chunk 52: IfXis not compact, one should also impose that\n",
            "Chunk 53: fhas compact support or at least as 0 limit at\n",
            "Chunk 54: inﬁnity.\n",
            "Chunk 55: Measure as thus in some sense “less regular” than\n",
            "Chunk 56: functions, but more regular than distributions\n",
            "Chunk 57: (which are\n",
            "Chunk 58: dual to smooth functions). For instance, the\n",
            "Chunk 59: derivative of a Dirac is not a measure. We denote\n",
            "Chunk 60: M+(X) the\n",
            "Chunk 61: set of all positive measures on X. The set of\n",
            "Chunk 62: probability measures is denoted M1\n",
            "Chunk 63: +(X), which means that\n",
            "anyα∈M1\n",
            "Chunk 64: +(X) is positive, and that α(X) =∫\n",
            "Chunk 65: Xdα= 1. Figure 1.1 oﬀers a visualization of the\n",
            "Chunk 66: diﬀerent\n",
            "Chunk 67: classes of measures, beyond histograms,\n",
            "Chunk 68: considered in this work.\n",
            "Chunk 69: 3\n",
            "Chunk 70: Discreted= 1 Discrete d= 2 Density d= 1 Density\n",
            "Chunk 71: d= 2\n",
            "Chunk 72: Figure 1.1: Schematic display of discrete\n",
            "Chunk 73: distributions α=∑n\n",
            "Chunk 74: i=1aiδxi(red corresponds to empirical uniform\n",
            "Chunk 75: distribution ai= 1/n, and blue to arbitrary\n",
            "Chunk 76: distributions) and densities d α(x) =ρα(x)dx(in\n",
            "Chunk 77: violet), in both\n",
            "Chunk 78: 1-D and 2-D. Discrete distributions in 1-D are\n",
            "Chunk 79: displayed using vertical segments (with length\n",
            "Chunk 80: equal to ai)\n",
            "Chunk 81: and in 2-D using point clouds (radius equal to\n",
            "Chunk 82: ai).\n",
            "Chunk 83: Operators on measures. For some continuous map\n",
            "Chunk 84: T:X →Y , we deﬁne the pushforward operator\n",
            "Chunk 85: T♯:M(X)→M (Y). For discrete measures (1.1), the\n",
            "Chunk 86: pushforward operation consists simply in moving\n",
            "Chunk 87: the\n",
            "Chunk 88: positions of all the points in the support of the\n",
            "Chunk 89: measure\n",
            "Chunk 90: T♯αdef.=∑\n",
            "iaiδT(xi).\n",
            "Chunk 91: For more general measures, for instance for those\n",
            "Chunk 92: with a density, the notion of push-forward plays\n",
            "Chunk 93: a funda-\n",
            "Chunk 94: mental to describe spatial modiﬁcations of\n",
            "Chunk 95: probability measures. The formal deﬁnition reads\n",
            "Chunk 96: as follow.\n",
            "Chunk 97: Deﬁnition 1 (Push-forward) .ForT:X → Y , the push\n",
            "Chunk 98: forward measure β=T♯α∈ M (Y)of some\n",
            "Chunk 99: α∈M (X)reads\n",
            "∀h∈C(Y),∫\n",
            "Yh(y)dβ(y) =∫\n",
            "Chunk 100: Xh(T(x))dα(x). (1.2)\n",
            "Chunk 101: Equivalently, for any measurable set B⊂Y, one has\n",
            "Chunk 102: β(B) =α({x∈X;T(x)∈B}). (1.3)\n",
            "Chunk 103: Note thatT♯preserves positivity and total mass,\n",
            "Chunk 104: so that if α∈M1\n",
            "Chunk 105: +(X)thenT♯α∈M1\n",
            "+(Y).\n",
            "Chunk 106: Intuitively, a measurable map T:X→Y , can be\n",
            "Chunk 107: interpreted as a function “moving” a single point\n",
            "Chunk 108: from a\n",
            "Chunk 109: measurable space to another. The more general\n",
            "Chunk 110: extension T♯can now “move” an entire probability\n",
            "Chunk 111: measure\n",
            "Chunk 112: onXtowards a new probability measure on Y. The\n",
            "Chunk 113: operator T♯“pushes forward” each elementary mass\n",
            "Chunk 114: of\n",
            "Chunk 115: a measureαonXby applying the map Tto obtain then\n",
            "Chunk 116: an elementary mass in Y, to build on aggregate a\n",
            "Chunk 117: new measure onY) writtenT♯α. Note that such a\n",
            "Chunk 118: push-forward T♯:M1\n",
            "Chunk 119: +(X)→M1\n",
            "+(Y) is a linear operator\n",
            "Chunk 120: between measures in the sense that for two\n",
            "Chunk 121: measures α1,α2onX,T♯(α1+α2) =T♯α1+T♯α2.\n",
            "Chunk 122: Remark 2 (Push-forward for densities) .Explicitly\n",
            "Chunk 123: doing the change of variable in formula (1.2) for\n",
            "Chunk 124: measures\n",
            "Chunk 125: with densities ( ρα,ρβ) onRd(assumingTis smooth\n",
            "Chunk 126: and a bijection) shows that a push-forward acts\n",
            "Chunk 127: on\n",
            "Chunk 128: densities linearly as a change of variables in\n",
            "Chunk 129: the integration formula, indeed\n",
            "Chunk 130: ρα(x) =|det(T′(x))|ρβ(T(x)) (1.4)\n",
            "Chunk 131: whereT′(x)∈Rd×dis the Jacobian matrix of T(the\n",
            "Chunk 132: matrix formed by taking the gradient of each\n",
            "Chunk 133: coordinate\n",
            "Chunk 134: ofT). This implies, denoting y=T(x)\n",
            "Chunk 135: |det(T′(x))|=ρα(x)\n",
            "ρβ(y).\n",
            "4\n",
            "Chunk 136: =Pi\u0000xiT↵T]↵def.=Pi\u0000T(xi)\n",
            "Chunk 137: TT]gdef.=g\u0000TgPush-forward of measures Pull-back\n",
            "Chunk 138: of functions\n",
            "Chunk 139: Figure 1.2: Comparison of push-forward T♯and\n",
            "Chunk 140: pull-back T♯.\n",
            "Chunk 141: Remark 3 (Push-forward vs. pull-back) .The\n",
            "Chunk 142: push-forward T♯of measures should not be\n",
            "Chunk 143: confounded with\n",
            "Chunk 144: the pull-back of function T♯:C(Y)→C(X) which\n",
            "Chunk 145: corresponds to the “warping” of functions. It is\n",
            "Chunk 146: the linear\n",
            "Chunk 147: map deﬁned, for g∈C(Y) byT♯g=g◦T. Push-forward\n",
            "Chunk 148: and pull-back are actually adjoint one from each\n",
            "Chunk 149: others, in the sense that\n",
            "∀(α,g)∈M (X)×C(Y),∫\n",
            "Chunk 150: Ygd(T♯α) =∫\n",
            "X(T♯g)dα.\n",
            "Chunk 151: It is important to realize that even if ( α,β)\n",
            "Chunk 152: have densities ( ρα,ρβ),T♯αis not equal to T♯ρβ,\n",
            "Chunk 153: because of\n",
            "Chunk 154: the presence of the Jacobian in (1.4). This\n",
            "Chunk 155: explains why OT should be used with caution to\n",
            "Chunk 156: perform image\n",
            "Chunk 157: registration, because it does not operate as an\n",
            "Chunk 158: image warping method. Figure 1.2 illustrate the\n",
            "Chunk 159: distinction\n",
            "Chunk 160: between these push-forward and pull-back\n",
            "Chunk 161: operators.\n",
            "Chunk 162: Remark 4 (Measures and random variables) .Radon\n",
            "Chunk 163: measures can also be viewed as representing the\n",
            "Chunk 164: distri-\n",
            "Chunk 165: butions of random variables. A random variable\n",
            "Chunk 166: XonXis actually a map X: Ω→X from some abstract\n",
            "Chunk 167: (often un-speciﬁed) probabized space (Ω ,P), and\n",
            "Chunk 168: its distribution αis the Radon measure X∈M1\n",
            "Chunk 169: +(X) such\n",
            "thatP(X∈A) =α(A) =∫\n",
            "Chunk 170: Adα(x). Equivalently, it is the push-forward of\n",
            "Chunk 171: PbyX,α=X♯P. Applying\n",
            "Chunk 172: another push-forward β=T♯αforT:X →Y , following\n",
            "Chunk 173: (1.2), is equivalent to deﬁning another random\n",
            "Chunk 174: variableY=T(X) :ω∈Ω→T(X(ω))∈Y, so thatβis the\n",
            "Chunk 175: distribution of Y. Drawing a random sample\n",
            "Chunk 176: yfromYis thus simply achieved by computing y=T(x)\n",
            "Chunk 177: wherexis drawn from X.\n",
            "Chunk 178: Convergence of random variable. Convergence of\n",
            "Chunk 179: random variable (in probability, almost sure, in\n",
            "Chunk 180: law),\n",
            "Chunk 181: convergence of measures (strong, weak).\n",
            "Chunk 182: 1.2 Monge Problem\n",
            "Chunk 183: Given a cost matrix ( Ci,j)i∈JnK,j∈JmK, assuming\n",
            "Chunk 184: n=m, the optimal assignment problem seeks for a\n",
            "Chunk 185: bijectionσin the set Perm( n) of permutations of\n",
            "Chunk 186: nelements solving\n",
            "Chunk 187: min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i). (1.5)\n",
            "Chunk 188: One could naively evaluate the cost function\n",
            "Chunk 189: above using all permutations in the set Perm( n).\n",
            "Chunk 190: However,\n",
            "Chunk 191: that set has size n!, which is gigantic even for\n",
            "Chunk 192: small n. Consider for instance that such a set\n",
            "Chunk 193: has more than\n",
            "Chunk 194: 10100elements [ ?] whennis as small as 70. That\n",
            "Chunk 195: problem can therefore only be solved if there\n",
            "Chunk 196: exist eﬃcient\n",
            "Chunk 197: algorithms to optimize that cost function over\n",
            "Chunk 198: the set of permutations, which will be the\n",
            "Chunk 199: subject of §??.\n",
            "Chunk 200: 5\n",
            "Chunk 201: x1x2y1y2x1x2y1y2x4x5x6x3y3x7Figure 1.3: (left)\n",
            "Chunk 202: blue dots from measure αand red dots from measure\n",
            "Chunk 203: βare pairwise equidistant. Hence,\n",
            "Chunk 204: either matching σ= (1,2) (full line) or σ= (2,1)\n",
            "Chunk 205: (dotted line) is optimal. (right) a Monge map can\n",
            "Chunk 206: associate\n",
            "Chunk 207: the blue measure αto the red measure β. The\n",
            "Chunk 208: weights αiare displayed proportionally to the\n",
            "Chunk 209: area of the\n",
            "Chunk 210: disk marked at each location. The mapping here is\n",
            "Chunk 211: such that T(x1) =T(x2) =y2,T(x3) =y3, whereas for\n",
            "Chunk 212: 4⩽i⩽7 we haveT(xi) =y1.\n",
            "Chunk 213: Remark 5 (Uniqueness) .Note that the optimal\n",
            "Chunk 214: assignment problem may have several optimal\n",
            "Chunk 215: solutions.\n",
            "Chunk 216: Suppose for instance that n=m= 2 and that the\n",
            "Chunk 217: matrix Cis the pairwise distance matrix between\n",
            "Chunk 218: the 4\n",
            "Chunk 219: corners of a 2-dimensional square of side length\n",
            "Chunk 220: 1, as represented in the left plot in Figure 1.3.\n",
            "Chunk 221: In that case\n",
            "Chunk 222: only two assignments exist, and they share the\n",
            "Chunk 223: same cost.\n",
            "Chunk 224: For discrete measures\n",
            "α=n∑\n",
            "i=1aiδxiandβ=m∑\n",
            "Chunk 225: j=1bjδyj (1.6)\n",
            "Chunk 226: the Monge problem [ ?] seeks for a map that\n",
            "Chunk 227: associates to each point xia single point yj, and\n",
            "Chunk 228: which must\n",
            "Chunk 229: push the mass of αtoward the mass of β, which is\n",
            "Chunk 230: to say that such a map T:{x1,...,xn}→{y1,...,ym}\n",
            "Chunk 231: must verify that\n",
            "∀j∈JmK,bj=∑\n",
            "i:T(xi)=yjai (1.7)\n",
            "Chunk 232: which we write in compact form as T♯α=β. This map\n",
            "Chunk 233: should minimize some transportation cost, which\n",
            "Chunk 234: is\n",
            "Chunk 235: parameterized by a function c(x,y) deﬁned for\n",
            "Chunk 236: points ( x,y)∈X×Y\n",
            "Chunk 237: min\n",
            "T{∑\n",
            "ic(xi,T(xi)) ;T♯α=β}\n",
            ". (1.8)\n",
            "Chunk 238: Such a map between discrete points can be of\n",
            "Chunk 239: course encoded, assuming all x’s andy’s are\n",
            "Chunk 240: distinct, using\n",
            "Chunk 241: indicesσ:JnK→JmKso thatj=σ(i), and the mass\n",
            "Chunk 242: conservation is written as\n",
            "Chunk 243: ∑\n",
            "i∈σ−1(j)ai=bj.\n",
            "Chunk 244: In the special case when n=mand all weights are\n",
            "Chunk 245: uniform, that is ai=bj= 1/n, then the mass\n",
            "Chunk 246: conservation\n",
            "Chunk 247: constraint implies that Tis a bijection, such\n",
            "Chunk 248: that T(xi) =yσ(i), and the Monge problem is\n",
            "Chunk 249: equivalent to the\n",
            "Chunk 250: optimal matching problem (1.5) where the cost\n",
            "Chunk 251: matrix is\n",
            "Chunk 252: Ci,jdef.=c(xi,yj).\n",
            "Chunk 253: Whenn̸=m, note that, optimality aside, Monge maps\n",
            "Chunk 254: may not even exist between an empirical measure\n",
            "Chunk 255: to another. This happens when their weight\n",
            "Chunk 256: vectors are not compatible, which is always the\n",
            "Chunk 257: case when the\n",
            "Chunk 258: target measure has more points than the source\n",
            "Chunk 259: measure. For instance, the right plot in Figure\n",
            "Chunk 260: 1.3 shows\n",
            "Chunk 261: an (optimal) Monge map between αandβ, but there\n",
            "Chunk 262: is no Monge map from βtoα.\n",
            "Chunk 263: 6\n",
            "Chunk 264: Monge problem (1.8) is extended to the setting of\n",
            "Chunk 265: two arbitrary probability measures ( α,β) on two\n",
            "Chunk 266: spaces\n",
            "Chunk 267: (X,Y) as ﬁnding a map T:X→Y that minimizes\n",
            "min\n",
            "Chunk 268: T{∫\n",
            "Xc(x,T(x))dα(x) ;T♯α=β}\n",
            "(1.9)\n",
            "Chunk 269: The constraint T♯α=βmeans that Tpushes forward\n",
            "Chunk 270: the mass of αtoβ, and makes use of the\n",
            "Chunk 271: push-forward\n",
            "Chunk 272: operator (1.2).\n",
            "1.3 Kantorovitch Problem\n",
            "Chunk 273: The assignment problem has several limitations in\n",
            "Chunk 274: practical settings, also encountered when using\n",
            "Chunk 275: the\n",
            "Chunk 276: Monge problem. Indeed, because the assignment\n",
            "Chunk 277: problem is formulated as a permutation problem,\n",
            "Chunk 278: it can only\n",
            "Chunk 279: be used to compare two points clouds of the same\n",
            "Chunk 280: size. A direct generalization to discrete\n",
            "Chunk 281: measures with non-\n",
            "Chunk 282: uniform weights can be carried out using Monge’s\n",
            "Chunk 283: formalism of pushforward maps, but that\n",
            "Chunk 284: formulation may\n",
            "Chunk 285: also be degenerate it there does not exist\n",
            "Chunk 286: feasible solutions satisfying the mass\n",
            "Chunk 287: conservation constraint (1.7)\n",
            "Chunk 288: (see the end of Remark ??). Additionally, the\n",
            "Chunk 289: assignment Problem (1.8) is combinatorial,\n",
            "Chunk 290: whereas the feasible\n",
            "Chunk 291: set for the Monge Problem (1.9), consisting in\n",
            "Chunk 292: all push-forward measures that satisfy the mass\n",
            "Chunk 293: conservation\n",
            "Chunk 294: constraint, is non-convex . Both are therefore\n",
            "Chunk 295: diﬃcult to solve in their original formulation.\n",
            "Chunk 296: Kantorovitch formulation for discrete measures.\n",
            "Chunk 297: The key idea of [ ?] is to relax the\n",
            "Chunk 298: deterministic na-\n",
            "Chunk 299: ture of transportation, namely the fact that a\n",
            "Chunk 300: source point xican only be assigned to another,\n",
            "Chunk 301: or transported\n",
            "Chunk 302: to one and one location T(xi) only. Kantorovich\n",
            "Chunk 303: proposes instead that the mass at any point xibe\n",
            "Chunk 304: potentially\n",
            "Chunk 305: dispatched across several locations. Kantorovich\n",
            "Chunk 306: moves away from the idea that mass transportation\n",
            "Chunk 307: should\n",
            "Chunk 308: be “deterministic” to consider instead a\n",
            "Chunk 309: “probabilistic” (or “fuzzy”) transportation,\n",
            "Chunk 310: which allows what is\n",
            "Chunk 311: commonly known now as “mass splitting” from a\n",
            "Chunk 312: source towards several targets. This ﬂexibility\n",
            "Chunk 313: is encoded\n",
            "Chunk 314: using, in place of a permutation σor a mapT, a\n",
            "Chunk 315: coupling matrix P∈Rn×m\n",
            "Chunk 316: +, where Pi,jdescribes the\n",
            "Chunk 317: amount of mass ﬂowing from bin i(or pointxi)\n",
            "Chunk 318: towards bin j(or pointxj),xitowardsyjin the\n",
            "Chunk 319: formalism\n",
            "Chunk 320: of discrete measures (1.6). Admissible couplings\n",
            "Chunk 321: admit a far simpler characterization than Monge\n",
            "Chunk 322: maps:\n",
            "Chunk 323: U(a,b)def.={\n",
            "P∈Rn×m\n",
            "+ ;P1m=aand PT1n=b}\n",
            ", (1.10)\n",
            "Chunk 324: where we used the following matrix-vector\n",
            "Chunk 325: notation\n",
            "Chunk 326: P1m=\n",
            "∑\n",
            "jPi,j\n",
            "\n",
            "i∈Rnand PT1n=(∑\n",
            "iPi,j)\n",
            "j∈Rm.\n",
            "Chunk 327: The set of matrices U(a,b) is bounded, deﬁned by\n",
            "Chunk 328: n+mequality constraints, and therefore a convex\n",
            "Chunk 329: polytope (the convex hull of a ﬁnite set of\n",
            "Chunk 330: matrices).\n",
            "Chunk 331: Additionally, whereas the Monge formulation (as\n",
            "Chunk 332: illustrated in the right plot of Figure 1.3) was\n",
            "Chunk 333: intrisically\n",
            "Chunk 334: asymmetric, Kantorovich’s relaxed formulation is\n",
            "Chunk 335: always symmetric, in the sense that a coupling\n",
            "Chunk 336: Pis in\n",
            "Chunk 337: U(a,b) if and only if PTis inU(b,a).\n",
            "Chunk 338: Kantorovich’s optimal transport problem now reads\n",
            "Chunk 339: LC(a,b)def.= min\n",
            "P∈U(a,b)⟨C,P⟩def.=∑\n",
            "Chunk 340: i,jCi,jPi,j. (1.11)\n",
            "Chunk 341: This is a linear program (see Chapter ??), and as\n",
            "Chunk 342: is usually the case with such programs, its\n",
            "Chunk 343: solutions are\n",
            "Chunk 344: not necessarily unique.\n",
            "7\n",
            "↵\u0000\n",
            "Chunk 345: ↵\u0000Figure 1.4: Comparison of optimal matching and\n",
            "Chunk 346: generic couplings. A black segment between\n",
            "Chunk 347: xiandyj\n",
            "Chunk 348: indicates a non-zero element in the displayed\n",
            "Chunk 349: optimal coupling Pi,jsolving (1.11). Left:\n",
            "Chunk 350: optimal matching,\n",
            "Chunk 351: corresponding to the setting of Proposition (1)\n",
            "Chunk 352: (empirical measures with the same number n=mof\n",
            "Chunk 353: points).\n",
            "Chunk 354: Right: these two weighted point clouds cannot be\n",
            "Chunk 355: matched; instead a Kantorovich coupling can be\n",
            "Chunk 356: used to\n",
            "Chunk 357: associate two arbitrary discrete measures.\n",
            "Chunk 358: Permutation Matrices as Couplings For a\n",
            "Chunk 359: permutation σ∈Perm(n), we write Pσfor the\n",
            "Chunk 360: correspond-\n",
            "Chunk 361: ing permutation matrix,\n",
            "Chunk 362: ∀(i,j)∈JnK2,(Pσ)i,j={1/n ifj=σi,\n",
            "Chunk 363: 0 otherwise.(1.12)\n",
            "Chunk 364: One can check that in that case\n",
            "⟨C,Pσ⟩=1\n",
            "nn∑\n",
            "Chunk 365: i=1Ci,σi,\n",
            "Chunk 366: which shows that the assignment problem (1.5) can\n",
            "Chunk 367: be recast as a Kantorovich problem (1.11) where\n",
            "Chunk 368: the\n",
            "Chunk 369: couplings Pare restricted to be exactly\n",
            "Chunk 370: permutation matrices:\n",
            "Chunk 371: min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i)= min\n",
            "Chunk 372: σ∈Perm(n)⟨C,Pσ⟩.\n",
            "Chunk 373: Next, one can easily check that the set of\n",
            "Chunk 374: permutation matrices is strictly included in the\n",
            "Chunk 375: so-called Birkhoﬀ\n",
            "Chunk 376: polytope U(1n/n,1n,n). Indeed, for any\n",
            "Chunk 377: permutation σwe have Pσ1=1nandPσT1=1n, whereas\n",
            "Chunk 378: 1n1nT/n2is a valid coupling but not a permutation\n",
            "Chunk 379: matrix. Therefore, one has naturally that\n",
            "Chunk 380: min\n",
            "σ∈Perm(n)⟨C,Pσ⟩⩽LC(1n/n,1n/n).\n",
            "Chunk 381: The following proposition shows that these\n",
            "Chunk 382: problems result in fact in the same optimum,\n",
            "Chunk 383: namely that\n",
            "Chunk 384: one can always ﬁnd a permutation matrix that\n",
            "Chunk 385: minimizes Kantorovich’s problem (1.11) between\n",
            "Chunk 386: two uniform\n",
            "Chunk 387: measures a=b=1n/n, which shows that the\n",
            "Chunk 388: Kantorovich relaxation is tight when considered\n",
            "Chunk 389: on assignment\n",
            "Chunk 390: problems. Figure 1.4 shows on the left a 2-D\n",
            "Chunk 391: example of optimal matching corresponding to this\n",
            "Chunk 392: special\n",
            "Chunk 393: case.\n",
            "Chunk 394: Proposition 1 (Kantorovich for matching)\n",
            "Chunk 395: .Ifm=nanda=b=1n/n, then there exists an optimal\n",
            "Chunk 396: solution for Problem (1.11) Pσ⋆, which is a\n",
            "Chunk 397: permutation matrix associated to an optimal\n",
            "Chunk 398: permutation σ⋆∈\n",
            "Chunk 399: Perm(n)for Problem (1.5) .\n",
            "Chunk 400: Proof. Birkhoﬀ’s theorem states that the set of\n",
            "Chunk 401: extremal points of U(1n/n,1n/n) is equal to the\n",
            "Chunk 402: set of\n",
            "Chunk 403: permutation matrices. A fundamental theorem of\n",
            "Chunk 404: linear programming [ ?, Theorem 2.7] states that\n",
            "Chunk 405: the\n",
            "Chunk 406: minimum of a linear objective in a non-empty\n",
            "Chunk 407: polyhedron, if ﬁnite, is reached at an extremal\n",
            "Chunk 408: point of the\n",
            "Chunk 409: polyhedron.\n",
            "8\n",
            "⇡\u0000↵\u0000↵\n",
            "⇡\u0000↵\u0000↵\n",
            "⇡\u0000↵\u0000↵\n",
            "Chunk 410: Discrete Semi-discrete Continuous\n",
            "Chunk 411: Figure 1.5: Schematic viewed of input measures (\n",
            "Chunk 412: α,β) and couplingsU(α,β) encountered in the three\n",
            "Chunk 413: main\n",
            "Chunk 414: scenario for Kantorovich OT. Chapter ??is\n",
            "Chunk 415: dedicated to the semi-discrete setup.\n",
            "Chunk 416: ⇡\u0000↵\n",
            "⇡\u0000↵\n",
            "Chunk 417: Figure 1.6: Left: “continuous” coupling πsolving\n",
            "Chunk 418: (1.13) between two 1-D measure with density. The\n",
            "Chunk 419: coupling is localized along the graph of the\n",
            "Chunk 420: Monge map ( x,T(x)) (displayed in black). Right:\n",
            "Chunk 421: “discrete”\n",
            "Chunk 422: couplingTsolving (1.11) between two discrete\n",
            "Chunk 423: measures of the form (1.6). The non-zero entries\n",
            "Chunk 424: Ti,jare\n",
            "Chunk 425: display with a black disk at position ( i,j) with\n",
            "Chunk 426: radius proportional to Ti,j.\n",
            "Chunk 427: Kantorovitch formulation for arbitrary measures.\n",
            "Chunk 428: The deﬁnition of Lcin (??) can be extended to\n",
            "Chunk 429: arbitrary measures by considering couplings π∈M1\n",
            "Chunk 430: +(X×Y ) which are joint distributions over the\n",
            "Chunk 431: product\n",
            "Chunk 432: space. The discrete case is a special situation\n",
            "Chunk 433: where one imposes this product measure to be of\n",
            "Chunk 434: the form\n",
            "Chunk 435: π=∑\n",
            "Chunk 436: i,jPi,jδ(xi,yj). In the general case, the mass\n",
            "Chunk 437: conservation constraint (1.10) should be\n",
            "Chunk 438: rewritten as a\n",
            "Chunk 439: marginal constraint on joint probability\n",
            "Chunk 440: distributions\n",
            "Chunk 441: U(α,β)def.={\n",
            "π∈M1\n",
            "+(X×Y ) ;PX♯π=αandPY♯π=β}\n",
            "Chunk 442: . (1.13)\n",
            "Chunk 443: HerePX♯andPY♯are the push-forward (see Deﬁnition\n",
            "Chunk 444: 1) by the projections PX(x,y) =xandPY(x,y) =y.\n",
            "Chunk 445: Figure 1.5 shows a schematic visualization of the\n",
            "Chunk 446: coupling constraints for diﬀerent class of\n",
            "Chunk 447: problem (discrete\n",
            "Chunk 448: measures and densities). Using (1.3), these\n",
            "Chunk 449: marginal constraints are equivalent to imposing\n",
            "Chunk 450: that π(A×Y) =\n",
            "Chunk 451: α(A) andπ(X×B) =β(B) for setsA⊂X andB⊂Y.\n",
            "Chunk 452: The Kantorovich problem (1.11) is then\n",
            "Chunk 453: generalized as\n",
            "Chunk 454: Lc(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "Chunk 455: X×Yc(x,y)dπ(x,y). (1.14)\n",
            "Chunk 456: This is an inﬁnite-dimensional linear program\n",
            "Chunk 457: over a space of measures. Figure 1.6 shows\n",
            "Chunk 458: examples of discrete\n",
            "Chunk 459: and continuous optimal coupling solving (1.14).\n",
            "Chunk 460: Figure 1.7 shows other examples of optimal 1-D\n",
            "Chunk 461: couplings,\n",
            "Chunk 462: involving discrete and continuous marginals.\n",
            "Chunk 463: On compact domain ( X,Y), (1.14) always has a\n",
            "Chunk 464: solution, because using the weak-* topology (so\n",
            "Chunk 465: called\n",
            "Chunk 466: weak topology of measures), the set of measure is\n",
            "Chunk 467: compact, and a linear function with a continuous\n",
            "Chunk 468: c(x,y)\n",
            "Chunk 469: 9\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "Chunk 470: ↵\u0000↵⇡\u0000Figure 1.7: Four simple examples of optimal\n",
            "Chunk 471: couplings between 1-D distributions, represented\n",
            "Chunk 472: as maps\n",
            "Chunk 473: above (arrows) and couplings below. Inspired by [\n",
            "Chunk 474: ?].\n",
            "Chunk 475: is weak-* continuous. And the set of constraint\n",
            "Chunk 476: is non empty, taking α⊗β. On non compact domain,\n",
            "Chunk 477: needs\n",
            "Chunk 478: to impose moment condition on αandβ.\n",
            "Chunk 479: Wasserstein distances. An important feature of OT\n",
            "Chunk 480: is that it deﬁnes a distance between histograms\n",
            "Chunk 481: and probability measures as soon as the cost\n",
            "Chunk 482: matrix satisﬁes certain suitable properties.\n",
            "Chunk 483: Indeed, OT can be\n",
            "Chunk 484: understood as a canonical way to lift a ground\n",
            "Chunk 485: distance between points to a distance between\n",
            "Chunk 486: histogram or\n",
            "Chunk 487: measures.\n",
            "Chunk 488: We ﬁrst consider the case where, using a term\n",
            "Chunk 489: ﬁrst introduce by [ ?], the “ground metric”\n",
            "Chunk 490: matrix C\n",
            "Chunk 491: is ﬁxed, representing substitution costs between\n",
            "Chunk 492: bins, and shared across several histograms we\n",
            "Chunk 493: would like\n",
            "Chunk 494: to compare. The following proposition states that\n",
            "Chunk 495: OT provides a meaningful distance between\n",
            "Chunk 496: histograms\n",
            "Chunk 497: supported on these bins.\n",
            "Chunk 498: Proposition 2. We suppose n=m, and that for some\n",
            "Chunk 499: p⩾1,C=Dp= (Dp\n",
            "Chunk 500: i,j)i,j∈Rn×nwhere D∈Rn×n\n",
            "+\n",
            "Chunk 501: is a distance on JnK,i.e.\n",
            "1.D∈Rn×n\n",
            "Chunk 502: + is symmetric;\n",
            "2.Di,j= 0if and only if i=j;\n",
            "Chunk 503: 3.∀(i,j,k )∈JnK3,Di,k⩽Di,j+Dj,k.\n",
            "Then\n",
            "Chunk 504: Wp(a,b)def.= LDp(a,b)1/p(1.15)\n",
            "Chunk 505: (note that Wpdepends on D) deﬁnes the\n",
            "Chunk 506: p-Wasserstein distance on Σn,i.e. Wpis symmetric,\n",
            "Chunk 507: positive,\n",
            "Chunk 508: Wp(a,b) = 0 if and only if a=b, and it satisﬁes\n",
            "Chunk 509: the triangle inequality\n",
            "Chunk 510: ∀a,a′,b∈Σn,Wp(a,b)⩽Wp(a,a′) + Wp(a′,b).\n",
            "Chunk 511: Proof. Symmetry and deﬁniteness of the distance\n",
            "Chunk 512: are easy to prove: since C=Dphas a null diagonal,\n",
            "Chunk 513: Wp(a,a) = 0, with corresponding optimal transport\n",
            "Chunk 514: matrix P⋆= diag( a); by the positivity of all\n",
            "Chunk 515: oﬀ-diagonal\n",
            "Chunk 516: elements of Dp, Wp(a,b)>0 whenever a̸=b(because\n",
            "Chunk 517: in this case, an admissible coupling necessarily\n",
            "Chunk 518: has\n",
            "Chunk 519: a non-zero element outside the diagonal); by\n",
            "Chunk 520: symmetry of Dp, Wp(a,b) = 0 is itself a symmetric\n",
            "Chunk 521: function.\n",
            "Chunk 522: To prove the triangle inequality of Wasserstein\n",
            "Chunk 523: distances for arbitrary measures, [ ?, Theorem\n",
            "Chunk 524: 7.3] uses the\n",
            "Chunk 525: gluing lemma, which stresses the existence of\n",
            "Chunk 526: couplings with a prescribed structure. In the\n",
            "Chunk 527: discrete setting,\n",
            "Chunk 528: the explicit constuction of this glued coupling\n",
            "Chunk 529: is simple. Let a,b,c∈Σn. Let PandQbe two optimal\n",
            "Chunk 530: solutions of the transport problems between\n",
            "Chunk 531: aandb, and bandcrespectively. We deﬁne\n",
            "Chunk 532: ¯bjdef.=bjifbj>0\n",
            "Chunk 533: and set otherwise ¯bj= 1 (or actually any other\n",
            "Chunk 534: value). We then deﬁne\n",
            "Chunk 535: Sdef.=Pdiag(1/¯b)Q∈Rn×n\n",
            "+.\n",
            "10\n",
            "Chunk 536: We remark that S∈U(a,c) because\n",
            "Chunk 537: S1n=Pdiag(1/¯b)Q1n=P(b/¯b) =P1Supp( b)=a\n",
            "Chunk 538: where we denoted 1Supp( b)the indicator of the\n",
            "Chunk 539: support of b, and we use the fact that P1Supp(\n",
            "Chunk 540: b)=P1=b\n",
            "Chunk 541: because necessarily Pi,j= 0 forj /∈Supp( b).\n",
            "Chunk 542: Similarly one veriﬁes that S⊤1n=c.\n",
            "Chunk 543: The triangle inequality follows from\n",
            "Wp(a,c) =(\n",
            "Chunk 544: min\n",
            "P∈U(a,c)⟨P,Dp⟩)1/p\n",
            "⩽⟨S,Dp⟩1/p\n",
            "=\n",
            "∑\n",
            "ikDp\n",
            "ik∑\n",
            "Chunk 545: jPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "⩽\n",
            "∑\n",
            "ijk(Dij+Djk)pPijQjk\n",
            "¯bj\n",
            "Chunk 546: 1/p\n",
            "⩽\n",
            "∑\n",
            "ijkDp\n",
            "ijPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "ijkDp\n",
            "Chunk 547: jkPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "ijDp\n",
            "ijPij∑\n",
            "kQjk\n",
            "¯bj\n",
            "Chunk 548: 1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk∑\n",
            "iPij\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "ijDp\n",
            "Chunk 549: ijPij\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk\n",
            "1/p\n",
            "Chunk 550: = Wp(a,b) + Wp(b,b).\n",
            "Chunk 551: The ﬁrst inequality is due to the suboptimality\n",
            "Chunk 552: of S, the second is the usual triangle inequality\n",
            "Chunk 553: for elements\n",
            "Chunk 554: inD, and the third comes from Minkowski’s\n",
            "Chunk 555: inequality.\n",
            "Chunk 556: Proposition 2 generalizes from histogram to\n",
            "Chunk 557: arbitrary measures that need not be discrete.\n",
            "Chunk 558: Proposition 3. We assumeX=Y, and that for some\n",
            "Chunk 559: p⩾1,c(x,y) =d(x,y)pwheredis a distance on\n",
            "Chunk 560: X,i.e.\n",
            "(i)d(x,y) =d(y,x)⩾0;\n",
            "Chunk 561: (ii)d(x,y) = 0 if and only if x=y;\n",
            "Chunk 562: (ii)∀(x,y,z )∈X3,d(x,z)⩽d(x,y) +d(y,z).\n",
            "Then\n",
            "Chunk 563: Wp(α,β)def.=Ldp(α,β)1/p(1.16)\n",
            "Chunk 564: (note thatWpdepends on d) deﬁnes the\n",
            "Chunk 565: p-Wasserstein distance on X,i.e.Wpis symmetric,\n",
            "Chunk 566: positive,\n",
            "Chunk 567: Wp(α,β) = 0 if and only if α=β, and it satisﬁes\n",
            "Chunk 568: the triangle inequality\n",
            "Chunk 569: ∀(α,β,γ )∈M1\n",
            "+(X)3,Wp(α,γ)⩽Wp(α,β) +Wp(β,γ).\n",
            "Chunk 570: Proof. The proof follows the same approach as\n",
            "Chunk 571: that for Proposition 2 and relies on the\n",
            "Chunk 572: existence of a coupling\n",
            "Chunk 573: between (α,γ) obtained by “guying” optimal\n",
            "Chunk 574: couplings between ( α,β) and (β,γ).\n",
            "Chunk 575: The Wasserstein distance Wphas many important\n",
            "Chunk 576: properties, the most important one being that it\n",
            "Chunk 577: is a\n",
            "Chunk 578: weak distance, i.e.it allows to compare singular\n",
            "Chunk 579: distributions (for instance discrete ones) and to\n",
            "Chunk 580: quantify\n",
            "Chunk 581: spatial shift between the supports of the\n",
            "Chunk 582: distributions. In particular, “classical”\n",
            "Chunk 583: distances (or divergences)\n",
            "Chunk 584: are not even deﬁned between discrete\n",
            "Chunk 585: distributions (the L2norm can only be applied to\n",
            "Chunk 586: continuous measures\n",
            "Chunk 587: with a density with respect to a base measure,\n",
            "Chunk 588: and the discrete ℓ2norm requires the positions (\n",
            "Chunk 589: xi,yj) to\n",
            "Chunk 590: be ﬁxed to work). In sharp contrast, one has that\n",
            "Chunk 591: for any p >0,Wp\n",
            "Chunk 592: p(δx,δy) =d(x,y). Indeed, it suﬃces\n",
            "Chunk 593: to notice thatU(δx,δy) ={δx,y}and therefore the\n",
            "Chunk 594: Kantorovich problem having only one feasible\n",
            "Chunk 595: solution,\n",
            "Chunk 596: Wp\n",
            "Chunk 597: p(δx,δy) is necessarily ( d(x,y)p)1/p=d(x,y).\n",
            "Chunk 598: This shows that Wp(δx,δy)→0 ifx→y. This property\n",
            "Chunk 599: corresponds to the fact that Wpis a way to\n",
            "Chunk 600: quantify the weak convergence as we now deﬁne.\n",
            "Chunk 601: 11\n",
            "Chunk 602: Deﬁnition 2 (Weak convergence) .(αk)kconverges\n",
            "Chunk 603: weakly to αinM1\n",
            "Chunk 604: +(X)(denotedαk⇀α ) if and only if\n",
            "Chunk 605: for any continuous function g∈C(X),∫\n",
            "Xgdαk→∫\n",
            "Chunk 606: Xgdα. This notion of weak convergence corresponds\n",
            "Chunk 607: to\n",
            "Chunk 608: the convergence in law of random vectors.\n",
            "Chunk 609: This convergence can be shown to be equivalent to\n",
            "Chunk 610: Wp(αk,α)→0 [?, Theorem 6.8] (together with a\n",
            "Chunk 611: convergence of the moments up to order pfor\n",
            "Chunk 612: unbounded metric spaces).\n",
            "Chunk 613: Note that there exists alternative distances\n",
            "Chunk 614: which also metrize weak convergence. The simplest\n",
            "Chunk 615: one are\n",
            "Chunk 616: Hilbertian norms, deﬁned as\n",
            "||α||2\n",
            "Chunk 617: kdef.=Eα⊗α(k) =∫\n",
            "X×Xk(x,y)dα(x)dα(y)\n",
            "Chunk 618: for a suitable choice of kernel k:X2→R. The most\n",
            "Chunk 619: famous of such kernel is the Gaussian one k(x,y)\n",
            "Chunk 620: =\n",
            "Chunk 621: e−||x−y||2\n",
            "2σ2for some choice of bandwidth σ>0.\n",
            "Chunk 622: This convergence should not be confounded with\n",
            "Chunk 623: the strong convergence of measures, which is\n",
            "Chunk 624: metrized\n",
            "Chunk 625: by the TV norm ||α||TVdef.=|α|(X), which is the\n",
            "Chunk 626: total mass of the absolute value of the measure.\n",
            "Chunk 627: Algorithms Since ( ??)ˆA is a linear program, it\n",
            "Chunk 628: is possible to use any classical linear program\n",
            "Chunk 629: solver, such\n",
            "Chunk 630: as interior point methods or simplex. In\n",
            "Chunk 631: practice, the network simplex is an eﬃcient\n",
            "Chunk 632: option, and it used\n",
            "Chunk 633: pivoting rule adapted to the OT constraint set.\n",
            "Chunk 634: In the case of the assignment problem, a=b=1n/n,\n",
            "Chunk 635: there\n",
            "Chunk 636: exists faster combinatorial optimization scheme,\n",
            "Chunk 637: the most famous ones being the Hungarian\n",
            "Chunk 638: algorithm and\n",
            "Chunk 639: the auction algorithm, which have roughly O(n3)\n",
            "Chunk 640: complexity. Section 1.5 details an approximate\n",
            "Chunk 641: algorithm,\n",
            "Chunk 642: which is typically faster, and amenable to\n",
            "Chunk 643: parallelisation, but do not compute exactly the\n",
            "Chunk 644: solution to the\n",
            "Chunk 645: OT problem.\n",
            "1.4 Duality\n",
            "Chunk 646: The Kantorovich problem (1.11) is a constrained\n",
            "Chunk 647: convex minimization problem, and as such, it can\n",
            "Chunk 648: be\n",
            "Chunk 649: naturally paired with a so-called dual problem,\n",
            "Chunk 650: which is a constrained concave maximization\n",
            "Chunk 651: problem. The\n",
            "Chunk 652: following fundamental proposition, which is a\n",
            "Chunk 653: special case of Fenchel-Rockafellar duality\n",
            "Chunk 654: theory, explains the\n",
            "Chunk 655: relationship between the primal and dual\n",
            "Chunk 656: problems.\n",
            "Chunk 657: Proposition 4. One has\n",
            "LC(a,b) = max\n",
            "Chunk 658: (f,g)∈R(a,b)⟨f,a⟩+⟨g,b⟩ (1.17)\n",
            "Chunk 659: where the set of admissible potentials is\n",
            "Chunk 660: R(a,b)def.={(f,g)∈Rn×Rm;∀(i,j)∈JnK×JmK,f⊕g⩽C}\n",
            "Chunk 661: (1.18)\n",
            "Chunk 662: Proof. This result is a direct consequence of the\n",
            "Chunk 663: more general result on the strong duality for\n",
            "Chunk 664: linear pro-\n",
            "Chunk 665: grams [ ?, p.148,Theo.4.4]. The easier part of\n",
            "Chunk 666: that result, namely that the right-hand side of\n",
            "Chunk 667: Equation (1.17)\n",
            "Chunk 668: is a lower bound on L C(a,b) is discussed in ??.\n",
            "Chunk 669: For the sake of completeness, let us derive this\n",
            "Chunk 670: dual problem\n",
            "Chunk 671: with the use of Lagrangian duality. The Lagangian\n",
            "Chunk 672: associate to (1.11) reads\n",
            "Chunk 673: min\n",
            "P⩾0max\n",
            "Chunk 674: (f,g)∈Rn×Rm⟨C,P⟩+⟨a−P1m,f⟩+⟨b−P⊤1n,g⟩. (1.19)\n",
            "Chunk 675: For linear program, one can always exchange the\n",
            "Chunk 676: min and the max and get the same value of the\n",
            "Chunk 677: linear\n",
            "Chunk 678: program, and one thus consider\n",
            "max\n",
            "Chunk 679: (f,g)∈Rn×Rm⟨a,f⟩+⟨b,g⟩+ min\n",
            "P⩾0⟨C−f1⊤\n",
            "m−1ng⊤,P⟩.\n",
            "Chunk 680: We conclude by remarking that\n",
            "min\n",
            "Chunk 681: P⩾0⟨Q,P⟩={0 if Q⩾0\n",
            "−∞ otherwise\n",
            "Chunk 682: so that the constraint reads C−f1⊤\n",
            "Chunk 683: m−1ng⊤=C−f⊕g⩾0.\n",
            "12\n",
            "Chunk 684: The primal-dual optimality relation for the\n",
            "Chunk 685: Lagrangian (1.19) allows to locate the support of\n",
            "Chunk 686: the optimal\n",
            "Chunk 687: transport plan\n",
            "Supp( P)⊂{\n",
            "Chunk 688: (i,j)∈JnK×JmK;fi+gj=Ci,j}\n",
            ". (1.20)\n",
            "Chunk 689: To extend this primal-dual construction to\n",
            "Chunk 690: arbitrary measures, it is important to realize\n",
            "Chunk 691: that measures\n",
            "Chunk 692: are naturally paired in duality with continuous\n",
            "Chunk 693: functions (a measure can only be accessed through\n",
            "Chunk 694: integration\n",
            "Chunk 695: against continuous functions). The duality is\n",
            "Chunk 696: formalized in the following proposition, which\n",
            "Chunk 697: boils down to\n",
            "Chunk 698: Proposition 4 when dealing with discrete\n",
            "Chunk 699: measures.\n",
            "Chunk 700: Proposition 5. One has\n",
            "Lc(α,β) = max\n",
            "(f,g)∈R(c)∫\n",
            "Chunk 701: Xf(x)dα(x) +∫\n",
            "Yg(y)dβ(y), (1.21)\n",
            "Chunk 702: where the set of admissible dual potentials is\n",
            "Chunk 703: R(c)def.={(f,g)∈C(X)×C(Y) ;∀(x,y),f(x)\n",
            "Chunk 704: +g(y)⩽c(x,y)}. (1.22)\n",
            "Chunk 705: Here, (f,g)is a pair of continuous functions, and\n",
            "Chunk 706: are often called “Kantorovich potentials”.\n",
            "Chunk 707: The discrete case (1.17) corresponds to the dual\n",
            "Chunk 708: vectors being samples of the continuous\n",
            "Chunk 709: potentials, i.e.\n",
            "Chunk 710: (fi,gj) = (f(xi),g(yj)). The primal-dual\n",
            "Chunk 711: optimality conditions allow to track the support\n",
            "Chunk 712: of optimal plan,\n",
            "Chunk 713: and (1.20) is generalized as\n",
            "Chunk 714: Supp(π)⊂{(x,y)∈X×Y ;f(x) +g(y) =c(x,y)}. (1.23)\n",
            "Chunk 715: Note that in contrast to the primal problem\n",
            "Chunk 716: (1.14), showing the existence of solutions to\n",
            "Chunk 717: (1.21) is non-\n",
            "Chunk 718: trivial, because the constraint set R(c) is not\n",
            "Chunk 719: compact and the function to minimize\n",
            "Chunk 720: non-coercive. Using the\n",
            "Chunk 721: machinery of c-transform detailed in Section ??,\n",
            "Chunk 722: one can however show that optimal ( f,g) are\n",
            "Chunk 723: necessarily\n",
            "Chunk 724: Lipschitz regular, which enable to replace the\n",
            "Chunk 725: constraint by a compact one.\n",
            "Chunk 726: Benier’s Theorem and Monge-Amp` ere PDE The\n",
            "Chunk 727: following celebrated theorem of [ ?] ensures that\n",
            "Chunk 728: in\n",
            "Chunk 729: Rdforp= 2, if at least one of the two inputs\n",
            "Chunk 730: measures has a density, then Kantorovitch and\n",
            "Chunk 731: Monge problems\n",
            "Chunk 732: are equivalent.\n",
            "Chunk 733: Theorem 1 (Brenier) .In the caseX=Y=Rdandc(x,y)\n",
            "Chunk 734: =||x−y||2, if at least one of the two inputs\n",
            "Chunk 735: measures (denoted α) has a density ραwith respect\n",
            "Chunk 736: to the Lebesgue measure, then the optimal πin the\n",
            "Chunk 737: Kantorovich formulation (1.14) is unique, and is\n",
            "Chunk 738: supported on the graph (x,T(x))of a “Monge map”\n",
            "Chunk 739: T:\n",
            "Chunk 740: Rd→Rd. This means that π= (Id,T)♯µ,i.e.\n",
            "Chunk 741: ∀h∈C(X×Y ),∫\n",
            "X×Yh(x,y)dπ(x,y) =∫\n",
            "Chunk 742: Xh(x,T(x))dµ(x). (1.24)\n",
            "Chunk 743: Furthermore, this map Tis uniquely deﬁned as the\n",
            "Chunk 744: gradient of a convex function ϕ,T(x) =∇ϕ(x),\n",
            "Chunk 745: where\n",
            "Chunk 746: ϕis the unique (up to an additive constant)\n",
            "Chunk 747: convex function such that (∇ϕ)♯µ=ν. This convex\n",
            "Chunk 748: function is\n",
            "Chunk 749: related to the dual potential fsolving (1.21)\n",
            "Chunk 750: asϕ(x) =||x||2\n",
            "Chunk 751: 2−f(x).\n",
            "Chunk 752: Proof. We sketch the main ingredients of the\n",
            "Chunk 753: proof, more details can be found for instance in\n",
            "Chunk 754: [ ?]. We remark\n",
            "Chunk 755: that∫\n",
            "cdπ=Cα,β−2∫\n",
            "Chunk 756: ⟨x, y⟩dπ(x,y) where the constant is Cα,β=∫\n",
            "Chunk 757: ||x||2dα(x) +∫\n",
            "||y||2dβ(y). Instead of\n",
            "Chunk 758: solving (1.14), one can thus consider the\n",
            "Chunk 759: following problem\n",
            "Chunk 760: max\n",
            "π∈U(α,β)∫\n",
            "X×Y⟨x, y⟩dπ(x,y),\n",
            "whose dual reads\n",
            "Chunk 761: min\n",
            "(ϕ,ψ){∫\n",
            "Xϕdα+∫\n",
            "Chunk 762: Yψdβ;∀(x,y), ϕ (x) +ψ(y)⩾⟨x, y⟩}\n",
            ". (1.25)\n",
            "13\n",
            "Chunk 763: The relation between these variables and those of\n",
            "Chunk 764: (1.22) is ( ϕ,ψ) = (||·||2\n",
            "Chunk 765: 2−f,||·||2\n",
            "2−g). One can replace the\n",
            "Chunk 766: constraint by\n",
            "∀y, ψ (y)⩾ϕ∗(y)def.= sup\n",
            "Chunk 767: x⟨x, y⟩−ϕ(x). (1.26)\n",
            "Chunk 768: Hereϕ∗is the Legendre transform of ϕand is a\n",
            "Chunk 769: convex function as a supremum of linear forms\n",
            "Chunk 770: (see\n",
            "Chunk 771: also ( ??)). Since the objective appearing in\n",
            "Chunk 772: (1.27) is linear and the integrating measures\n",
            "Chunk 773: positive, one can\n",
            "Chunk 774: minimize explicitly with respect to ϕand\n",
            "Chunk 775: setψ=ϕ∗in order to consider the unconstraint\n",
            "Chunk 776: problem\n",
            "Chunk 777: min\n",
            "ϕ∫\n",
            "Xϕdα+∫\n",
            "Yϕ∗dβ, (1.27)\n",
            "Chunk 778: see also Section ??for a generalization of this\n",
            "Chunk 779: idea to generic costs c(x,y). By iterating this\n",
            "Chunk 780: argument\n",
            "Chunk 781: twice, one can replace ϕbyϕ∗∗, which is a convex\n",
            "Chunk 782: function, and thus impose in (1.27) that ϕis\n",
            "Chunk 783: convex.\n",
            "Chunk 784: Condition (1.23) shows that an optimal πis\n",
            "Chunk 785: supported on{(x,y) ;ϕ(x) +ϕ∗(y) =⟨x, y⟩}which\n",
            "Chunk 786: shows that\n",
            "Chunk 787: such anyis optimal for the minimization (1.26) of\n",
            "Chunk 788: the Legendre transform, whose optimality\n",
            "Chunk 789: condition reads\n",
            "Chunk 790: y∈∂ϕ(x). Sinceϕis convex, it is diﬀerentiable\n",
            "Chunk 791: almost everywhere, and since αhas a density, it\n",
            "Chunk 792: is also\n",
            "Chunk 793: diﬀerentiable α-almost everywhere. This shows\n",
            "Chunk 794: that for each x, the associated yis uniquely\n",
            "Chunk 795: deﬁned α-almost\n",
            "Chunk 796: everywhere as y=∇ϕ(x), and shows that necessarily\n",
            "Chunk 797: π= (Id,∇ϕ)♯α.\n",
            "Chunk 798: This results shows that in the setting of W2with\n",
            "Chunk 799: non-singular densities, the Monge problem (1.9)\n",
            "Chunk 800: and its Kantorovich relaxation (1.14) are equal\n",
            "Chunk 801: (the relaxation is tight). This is the continuous\n",
            "Chunk 802: analog\n",
            "Chunk 803: of Proposition 1 for the assignment case (1),\n",
            "Chunk 804: which states that the minimum of the optimal\n",
            "Chunk 805: transport\n",
            "Chunk 806: problem is achieved, when the marginals are equal\n",
            "Chunk 807: and uniform, at a permutation matrix (a discrete\n",
            "Chunk 808: map).\n",
            "Chunk 809: Brenier’s theorem, stating that an optimal\n",
            "Chunk 810: transport map must be the gradient of a convex\n",
            "Chunk 811: function, should\n",
            "Chunk 812: be examined under the light that a convex\n",
            "Chunk 813: function is the natural generalization of the\n",
            "Chunk 814: notion of increasing\n",
            "Chunk 815: functions in dimension more than one. Optimal\n",
            "Chunk 816: transport can thus plays an important role to\n",
            "Chunk 817: deﬁne quantile\n",
            "Chunk 818: functions in arbitrary dimensions, which in turn\n",
            "Chunk 819: is useful for applications to quantile regression\n",
            "Chunk 820: problems [ ?].\n",
            "Chunk 821: Note also that this theorem can be extended in\n",
            "Chunk 822: many directions. The condition that αhas a\n",
            "Chunk 823: density can\n",
            "Chunk 824: be weakened to the condition that it does not\n",
            "Chunk 825: give mass to “small sets” having Hausdorﬀ\n",
            "Chunk 826: dimension smaller\n",
            "Chunk 827: thand−1 (e.g. hypersurfaces). One can also\n",
            "Chunk 828: consider costs of the form c(x,y) =h(x−y)\n",
            "Chunk 829: wherehis a\n",
            "Chunk 830: strictly convex function.\n",
            "Chunk 831: For measures with densities, using (1.4), one\n",
            "Chunk 832: obtains that ϕis the unique (up to the addition\n",
            "Chunk 833: of a\n",
            "Chunk 834: constant) convex function which solves the\n",
            "Chunk 835: following Monge-Amp ˜A¨re-type equation\n",
            "Chunk 836: det(∂2ϕ(x))ρβ(∇ϕ(x)) =ρα(x) (1.28)\n",
            "Chunk 837: where∂2ϕ(x)∈Rd×dis the hessian of ϕ. The\n",
            "Chunk 838: Monge-Amp` ere operator det( ∂2ϕ(x)) can be\n",
            "Chunk 839: understood as a\n",
            "Chunk 840: non-linear degenerate Laplacian. In the limit of\n",
            "Chunk 841: small displacements, ϕ= Id +εϕ, one indeed\n",
            "Chunk 842: recovers the\n",
            "Chunk 843: Laplacian ∆ as a linearization since for smooth\n",
            "Chunk 844: maps\n",
            "Chunk 845: det(∂2ϕ(x)) = 1 +ε∆ϕ(x) +o(ε).\n",
            "Chunk 846: The convexity constraint forces det( ∂2ϕ(x))⩾0\n",
            "Chunk 847: and is necessary for this equation to have a\n",
            "Chunk 848: solution.\n",
            "Chunk 849: Special cases In general, computing OT distances\n",
            "Chunk 850: is numerically involved. We review special\n",
            "Chunk 851: favorable\n",
            "Chunk 852: cases where the resolution of the OT problem is\n",
            "Chunk 853: easy.\n",
            "Chunk 854: Remark 6 (Binary Cost Matrix and 1-Norm) .One can\n",
            "Chunk 855: easily check that when the cost matrix Cis zero\n",
            "Chunk 856: on\n",
            "Chunk 857: the diagonal and 1 elsewhere, namely when\n",
            "Chunk 858: C=1n×n−In, the OT distance between aandbis equal\n",
            "Chunk 859: to\n",
            "Chunk 860: the 1-norm of their diﬀerence, L C(a,b)\n",
            "Chunk 861: =||a−b||1. One can also easily check that this\n",
            "Chunk 862: result extends to\n",
            "Chunk 863: discrete and discrete measures in the case where\n",
            "Chunk 864: c(x,y) is 0 ifx=yand 1 when x̸=y. The OT distance\n",
            "Chunk 865: between two discrete measures αandβis equal to\n",
            "Chunk 866: their total variation distance.\n",
            "Chunk 867: 14\n",
            "Chunk 868: \u0000\u0000↵Figure 1.8: 1-D optimal couplings: each arrow\n",
            "Chunk 869: xi→yjindicate a non-zero Pi,jin the optimal\n",
            "Chunk 870: coupling.\n",
            "Chunk 871: Top: empirical measures with same number of\n",
            "Chunk 872: points (optimal matching). Bottom: generic case.\n",
            "Chunk 873: This\n",
            "Chunk 874: corresponds to monotone rearrangements, if\n",
            "Chunk 875: xi⩽xi′are such that Pi,j̸= 0,Pi′,j′̸= 0, then\n",
            "Chunk 876: necessarily\n",
            "Chunk 877: yj⩽yj′.\n",
            "Chunk 878: Remark 7 (1-D case – Empirical measures)\n",
            "Chunk 879: .HereX=R. Assuming α=1\n",
            "Chunk 880: n∑n\n",
            "i=1δxiandβ=1\n",
            "n∑n\n",
            "j=1δyj,\n",
            "Chunk 881: and assuming (without loss of generality) that\n",
            "Chunk 882: the points are ordered, i.e.x1⩽x2⩽...⩽xnand\n",
            "Chunk 883: y1⩽y2⩽...⩽yn, then one has the simple formula\n",
            "Chunk 884: Wp(α,β)p=p∑\n",
            "i=1|xi−yi|p, (1.29)\n",
            "Chunk 885: i.e.locally (if one assumes distinct points),\n",
            "Chunk 886: Wp(α,β) is theℓpnorm between two vectors of\n",
            "Chunk 887: ordered values of\n",
            "Chunk 888: αandβ. That statement is only valid locally, in\n",
            "Chunk 889: the sense that the order (and those vector\n",
            "Chunk 890: representations)\n",
            "Chunk 891: might change whenever some of the values change.\n",
            "Chunk 892: That formula is a simple consequence of the more\n",
            "Chunk 893: general\n",
            "Chunk 894: remark given below. Figure 1.8, top row,\n",
            "Chunk 895: illustrates the 1-D transportation map between\n",
            "Chunk 896: empirical measures\n",
            "Chunk 897: with the same number of points. The bottom row\n",
            "Chunk 898: shows how this monotone map generalizes to\n",
            "Chunk 899: arbitrary\n",
            "Chunk 900: discrete measures. It is possible to leverage\n",
            "Chunk 901: this 1-D computation to also compute eﬃciently OT\n",
            "Chunk 902: on the\n",
            "Chunk 903: circle, see [ ?]. Note that in the case of\n",
            "Chunk 904: concave cost of the distance, for instance when\n",
            "Chunk 905: p<1, the behaviour\n",
            "Chunk 906: of the optimal transport plan is very diﬀerent,\n",
            "Chunk 907: see [ ?], which describes an eﬃcient solver in\n",
            "Chunk 908: this case.\n",
            "Chunk 909: Remark 8 (1-D case – Generic case) .For a measure\n",
            "Chunk 910: αonR, we introduce the cumulative function\n",
            "Chunk 911: ∀x∈R,Cα(x)def.=∫x\n",
            "−∞dα, (1.30)\n",
            "Chunk 912: which is a function Cα:R→[0,1], and its\n",
            "Chunk 913: pseudo-inverse C−1\n",
            "Chunk 914: α: [0,1]→R∪{−∞}\n",
            "∀r∈[0,1],C−1\n",
            "α(r) = min\n",
            "Chunk 915: x{x∈R∪{−∞} ;Cα(x)⩾r}.\n",
            "Chunk 916: That function is also called the generalized\n",
            "Chunk 917: quantile function of α. For anyp⩾1, one has\n",
            "Chunk 918: Wp(α,β)p=||C−1\n",
            "α−C−1\n",
            "β||p\n",
            "Lp([0,1])=∫1\n",
            "0|C−1\n",
            "Chunk 919: α(r)−C−1\n",
            "β(r)|pdr. (1.31)\n",
            "Chunk 920: This means that through the map α↦→C−1\n",
            "Chunk 921: α, the Wasserstein distance is isometric to a\n",
            "Chunk 922: linear space equipped\n",
            "Chunk 923: with theLpnorm, or, equivalently, that the\n",
            "Chunk 924: Wasserstein distance for measures on the real\n",
            "Chunk 925: line is a Hilbertian\n",
            "Chunk 926: metric. This makes the geometry of 1-D optimal\n",
            "Chunk 927: transport very simple, but also very diﬀerent\n",
            "Chunk 928: from its\n",
            "Chunk 929: geometry in higher dimensions, which is not\n",
            "Chunk 930: Hilbertian as discussed in Proposition ??and more\n",
            "Chunk 931: generally\n",
            "Chunk 932: in§??. Forp= 1, one even has the simpler formula\n",
            "Chunk 933: W1(α,β) =||Cα−Cβ||L1(R)=∫\n",
            "R|Cα(x)−Cβ(x)|dx (1.32)\n",
            "Chunk 934: =∫\n",
            "R⏐⏐⏐⏐∫x\n",
            "−∞d(α−β)⏐⏐⏐⏐dx. (1.33)\n",
            "15\n",
            "Chunk 935: µ ν (tT+ (1−t)Id)♯µ\n",
            "0 0.5 10.5Cµ\n",
            "Cν\n",
            "0 0.5 100.51\n",
            "Chunk 936: Cµ-1\n",
            "Cν-1\n",
            "0 0.5 100.51\n",
            "T\n",
            "T-1\n",
            "0 0.5 100.51\n",
            "Chunk 937: (Cα,Cβ) (C−1\n",
            "α,C−1\n",
            "β) ( T,T−1) (1−t)C−1\n",
            "α+tC−1\n",
            "β\n",
            "Chunk 938: Figure 1.9: Computation of OT and displacement\n",
            "Chunk 939: interpolation between two 1-D measures, using\n",
            "Chunk 940: cumulant\n",
            "Chunk 941: function as detailed in (1.34).\n",
            "Chunk 942: which shows that W1is a norm (see§??for the\n",
            "Chunk 943: generalization to arbitrary dimensions). An\n",
            "Chunk 944: optimal Monge\n",
            "Chunk 945: mapTsuch thatT♯α=βis then deﬁned by\n",
            "T=C−1\n",
            "Chunk 946: β◦Cα. (1.34)\n",
            "Chunk 947: Figure 1.9 illustrates the computation of 1-D OT\n",
            "Chunk 948: through cumulative functions. It also displays\n",
            "Chunk 949: displacement\n",
            "Chunk 950: interpolations, computed as detailed in ( ??),\n",
            "Chunk 951: see also Remark ??. For a detailed survey of the\n",
            "Chunk 952: properties of\n",
            "Chunk 953: optimal transport in 1-D, we refer the reader to\n",
            "Chunk 954: [ ?, Chapter 2].\n",
            "Chunk 955: Remark 9 (Distance between Gaussians)\n",
            "Chunk 956: .Ifα=N(mα,Σα) andβ=N(mβ,Σβ) are two Gaussians in\n",
            "Chunk 957: Rd,\n",
            "Chunk 958: then one can show that the following map\n",
            "Chunk 959: T:x↦→mβ+A(x−mα), (1.35)\n",
            "where\n",
            "A=Σ−1\n",
            "2α(\n",
            "Σ1\n",
            "2αΣβΣ1\n",
            "Chunk 960: 2α)1\n",
            "2Σ−1\n",
            "2α=AT,\n",
            "Chunk 961: is such that T♯ρα=ρβ. Indeed, one simply has to\n",
            "Chunk 962: notice that the change of variables formula (1.4)\n",
            "Chunk 963: is satisﬁed\n",
            "Chunk 964: since\n",
            "ρβ(T(x)) = det(2πΣβ)−1\n",
            "2exp(−⟨T(x)−mβ,Σ−1\n",
            "Chunk 965: β(T(x)−mβ)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα, ATΣ−1\n",
            "Chunk 966: βA(x−mα)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα,Σ−1\n",
            "Chunk 967: α(x−mα)⟩),\n",
            "and sinceTis a linear map we have that\n",
            "Chunk 968: |detT′(x)|= detA=(detΣβ\n",
            "detΣα)1\n",
            "2\n",
            "Chunk 969: and we therefore recover\n",
            "Chunk 970: ρα=|detT′|ρβmeaningT♯α=β. Notice now that Tis the\n",
            "Chunk 971: gradient of the convex\n",
            "Chunk 972: functionψ:x↦→1\n",
            "Chunk 973: 2⟨x−mα, A(x−mα)⟩+⟨mβ, x⟩to conclude, using\n",
            "Chunk 974: Brenier’s theorem [ ?] (see Remark ??)\n",
            "Chunk 975: thatTis optimal. Both that map Tand the\n",
            "Chunk 976: corresponding potential ψare illustrated in\n",
            "Chunk 977: Figures 1.10 and ??\n",
            "Chunk 978: 16\n",
            "-4 -2 0 2 4 6-3-2-101234\n",
            "Chunk 979: ρβραFigure 1.10: Two Gaussians ραandρβ,\n",
            "Chunk 980: represented using the contour plots of their\n",
            "Chunk 981: densities, with respective\n",
            "Chunk 982: mean and variance matrices mα= (−2,0),Σα=1\n",
            "2(\n",
            "1−1\n",
            "Chunk 983: 2;−1\n",
            "21)\n",
            "andmβ= (3,1),Σβ=(\n",
            "2,1\n",
            "2;1\n",
            "2,1)\n",
            ". The\n",
            "Chunk 984: arrows originate at random points xtaken on the\n",
            "Chunk 985: plane and end at the corresponding mappings of\n",
            "Chunk 986: those\n",
            "Chunk 987: pointsT(x) =mβ+A(x−mα).\n",
            "\u0000m\n",
            "Chunk 988: Figure 1.11: Computation of displacement\n",
            "Chunk 989: interpolation between two 1-D Gaussians. Denoting\n",
            "Chunk 990: Gm,σ(x)def.=\n",
            "Chunk 991: 1√\n",
            "2πse−(x−m)2\n",
            "Chunk 992: 2s2the Gaussian density, it thus shows the\n",
            "Chunk 993: interpolation G(1−t)m0+tm1,(1−t)σ0+tσ1.\n",
            "Chunk 994: With additional calculations involving ﬁrst and\n",
            "Chunk 995: second order moments of ρα, we obtain that the\n",
            "Chunk 996: transport\n",
            "Chunk 997: cost of that map is\n",
            "W2\n",
            "Chunk 998: 2(α,β) =||mα−mβ||2+B(Σα,Σβ)2(1.36)\n",
            "Chunk 999: whereBis the so-called Bures’ metric [ ?] between\n",
            "Chunk 1000: positive deﬁnite matrices (see also [ ?,?]),\n",
            "Chunk 1001: B(Σα,Σβ)2def.= tr(\n",
            "Σα+Σβ−2(Σ1/2\n",
            "αΣβΣ1/2\n",
            "α)1/2)\n",
            "Chunk 1002: , (1.37)\n",
            "Chunk 1003: where Σ1/2is the matrix square root. One can show\n",
            "Chunk 1004: that Bis a distance on covariance matrices, and\n",
            "Chunk 1005: that\n",
            "Chunk 1006: B2is convex with respect to both its arguments.\n",
            "Chunk 1007: In the case where Σα= diag(ri)iandΣβ=\n",
            "Chunk 1008: diag(si)iare\n",
            "Chunk 1009: diagonals, the Bures metric is the Hellinger\n",
            "Chunk 1010: distance\n",
            "Chunk 1011: B(Σα,Σβ) =||√r−√s||2.\n",
            "Chunk 1012: For 1-D Gaussians, W2is thus the Euclidean\n",
            "Chunk 1013: distance on the 2-D plane ( m,√\n",
            "Chunk 1014: Σ), as illustrated in Figure 1.11.\n",
            "Chunk 1015: For a detailed treatment of the Wasserstein\n",
            "Chunk 1016: geometry of Gaussian distributions, we refer to [\n",
            "Chunk 1017: ?].\n",
            "Chunk 1018: 1.5 Sinkhorn\n",
            "Chunk 1019: This section introduces a family of numerical\n",
            "Chunk 1020: scheme to approximate solutions to Kantorovich\n",
            "Chunk 1021: formulation\n",
            "Chunk 1022: of optimal transport and its many\n",
            "Chunk 1023: generalizations. It operates by adding an\n",
            "Chunk 1024: entropic regularization penalty to\n",
            "Chunk 1025: the original problem. This regularization has\n",
            "Chunk 1026: several important advantages, but a few stand out\n",
            "Chunk 1027: particularly:\n",
            "Chunk 1028: The minimization of the regularized problen can\n",
            "Chunk 1029: be solved using a simple alternate minimization\n",
            "Chunk 1030: scheme;\n",
            "Chunk 1031: that scheme translates into iterations that are\n",
            "Chunk 1032: simple matrix products, making them particularly\n",
            "Chunk 1033: suited to\n",
            "Chunk 1034: execution of GPU; the resulting approximate\n",
            "Chunk 1035: distance is smooth with respect to input\n",
            "Chunk 1036: histogram weights\n",
            "Chunk 1037: and positions of the Diracs.\n",
            "17\n",
            "Chunk 1038: c\"P\"Figure 1.12: Impact of εon the optimization\n",
            "Chunk 1039: of a linear function on the simplex, solving Pε=\n",
            "Chunk 1040: argminP∈Σ3⟨C,P⟩−εH(P) for a varying ε.\n",
            "Chunk 1041: Entropic Regularization. The discrete entropy of\n",
            "Chunk 1042: a coupling matrix is deﬁned as\n",
            "Chunk 1043: H(P)def.=−∑\n",
            "i,jPi,j(log(Pi,j)−1), (1.38)\n",
            "Chunk 1044: with an analogous deﬁnition for vectors, with the\n",
            "Chunk 1045: convention that H(a) =−∞ if one of the entries\n",
            "Chunk 1046: ajis\n",
            "Chunk 1047: 0 or negative. The function His 1-strongly\n",
            "Chunk 1048: concave, because its hessian is ∂2H(P)\n",
            "Chunk 1049: =−diag(1/Pi,j) and\n",
            "Chunk 1050: Pi,j⩽1. The idea of the entropic regularization\n",
            "Chunk 1051: of optimal transport is to use −Has a\n",
            "Chunk 1052: regularizing function\n",
            "Chunk 1053: to obtain approximate solutions to the original\n",
            "Chunk 1054: transport problem (1.11):\n",
            "Chunk 1055: Lε\n",
            "C(a,b)def.= min\n",
            "P∈U(a,b)⟨P,C⟩−εH(P). (1.39)\n",
            "Chunk 1056: Since the objective is a ε-strongly convex\n",
            "Chunk 1057: function, problem 1.39 has a unique optimal\n",
            "Chunk 1058: solution. The idea\n",
            "Chunk 1059: to regularize the optimal transport problem by an\n",
            "Chunk 1060: entropic term can be traced back to modeling\n",
            "Chunk 1061: ideas in\n",
            "Chunk 1062: transportation theory [ ?]: Actual traﬃc patterns\n",
            "Chunk 1063: in a network do not agree with those predicted by\n",
            "Chunk 1064: the\n",
            "Chunk 1065: solution of the optimal transport problem.\n",
            "Chunk 1066: Indeed, the former are more diﬀuse than the\n",
            "Chunk 1067: latter, which tend\n",
            "Chunk 1068: to rely on a few routes as a result of the\n",
            "Chunk 1069: sparsity of optimal couplings to the solution of\n",
            "Chunk 1070: 1.11. To balance for\n",
            "Chunk 1071: that, researchers in transportation proposed a\n",
            "Chunk 1072: model, called the “gravity” model [ ?], that is\n",
            "Chunk 1073: able to form a\n",
            "Chunk 1074: more “blurred” traﬃc prediction.\n",
            "Chunk 1075: Figure 1.12 illustrates the eﬀect of the entropy\n",
            "Chunk 1076: to regularize a linear program over the simples Σ\n",
            "Chunk 1077: 3(which\n",
            "Chunk 1078: can thus be visualized as a triangle in 2-D).\n",
            "Chunk 1079: Note how the entropy pushes the original LP\n",
            "Chunk 1080: solution away\n",
            "Chunk 1081: from the boundary of the triangle. The optimal\n",
            "Chunk 1082: Pεprogressively moves toward an “entropic center”\n",
            "Chunk 1083: of the\n",
            "Chunk 1084: triangle. This is further detailed in the\n",
            "Chunk 1085: proposition below. The convergence of the\n",
            "Chunk 1086: solution of that regularized\n",
            "Chunk 1087: problem towards an optimal solution of the\n",
            "Chunk 1088: original linear program has been studied by [ ?].\n",
            "Chunk 1089: Proposition 6 (Convergence with ε).The unique\n",
            "Chunk 1090: solution Pεof(1.39) converges to the optimal\n",
            "Chunk 1091: solution\n",
            "Chunk 1092: with maximal entropy within the set of all\n",
            "Chunk 1093: optimal solutions of the Kantorovich problem,\n",
            "Chunk 1094: namely\n",
            "Chunk 1095: Pεε→0−→argmin\n",
            "Chunk 1096: P{−H(P) ;P∈U(a,b),⟨P,C⟩= LC(a,b)} (1.40)\n",
            "Chunk 1097: so that in particular\n",
            "Lε\n",
            "C(a,b)ε→0−→LC(a,b).\n",
            "Chunk 1098: One has\n",
            "Pεε→∞−→abT= (aibj)i,j. (1.41)\n",
            "Chunk 1099: Proof. We consider a sequence ( εℓ)ℓsuch thatεℓ→0\n",
            "Chunk 1100: andεℓ>0. We denote Pℓthe solution of (1.39) for\n",
            "Chunk 1101: ε=εℓ. Since U(a,b) is bounded, we can extract a\n",
            "Chunk 1102: sequence (that we do not relabel for sake of\n",
            "Chunk 1103: simplicity)\n",
            "Chunk 1104: such that Pℓ→P⋆. Since U(a,b) is closed,\n",
            "Chunk 1105: P⋆∈U(a,b). We consider any Psuch that⟨C,P⟩=\n",
            "Chunk 1106: LC(a,b).\n",
            "Chunk 1107: By optimality of PandPℓfor their respective\n",
            "Chunk 1108: optimization problems (for ε= 0 andε=εℓ), one has\n",
            "Chunk 1109: 0⩽⟨C,Pℓ⟩−⟨C,P⟩⩽εℓ(H(Pℓ)−H(P)). (1.42)\n",
            "18\n",
            "⇡\"↵\u0000\n",
            "Chunk 1110: \"\u0000↵Figure 1.13: Impact of εon coupling between\n",
            "Chunk 1111: densities and discrete distributions,\n",
            "Chunk 1112: illustrating Proposition 6.\n",
            "Chunk 1113: Left: between two 1-D densities. Right: between\n",
            "Chunk 1114: two 2-D discrete empirical densities with same\n",
            "Chunk 1115: number\n",
            "Chunk 1116: n=mof points (only entries of the optimal (\n",
            "Chunk 1117: Pi,j)i,jabove a small threshold are displayed as\n",
            "Chunk 1118: segments\n",
            "Chunk 1119: betweenxiandyj).\n",
            "Chunk 1120: Since His continuous, taking the limit ℓ→+∞in\n",
            "Chunk 1121: this expression shows that ⟨C,P⋆⟩=⟨C,P⟩so that\n",
            "Chunk 1122: P⋆is a feasible point of (1.40). Furthermore,\n",
            "Chunk 1123: dividing by εℓin (1.42) and taking the limit\n",
            "Chunk 1124: shows that\n",
            "Chunk 1125: H(P)⩽H(P⋆), which shows that P⋆is a solution of\n",
            "Chunk 1126: (1.40). Since the solution P⋆\n",
            "Chunk 1127: 0to this program is unique\n",
            "Chunk 1128: by strict convexity of −H, one has P⋆=P⋆\n",
            "Chunk 1129: 0, and the whole sequence is converging.\n",
            "Chunk 1130: Formula (1.40) states that for low\n",
            "Chunk 1131: regularization, the solution converges to the\n",
            "Chunk 1132: maximum entropy optimal\n",
            "Chunk 1133: transport coupling. In sharp contrast, (1.41)\n",
            "Chunk 1134: shows that for large regularization, the solution\n",
            "Chunk 1135: converges to the\n",
            "Chunk 1136: coupling with maximal entropy between two\n",
            "Chunk 1137: prescribed marginals a,b, namely the joint\n",
            "Chunk 1138: probability between\n",
            "Chunk 1139: two independent random variables with prescribed\n",
            "Chunk 1140: distributions. A reﬁned analysis of this\n",
            "Chunk 1141: convergence is\n",
            "Chunk 1142: performed in [ ?], including a ﬁrst order\n",
            "Chunk 1143: expansion in ε(resp. 1/ε) nearε= 0 (respε= +∞).\n",
            "Chunk 1144: Figure 1.13\n",
            "Chunk 1145: shows visually the eﬀect of these two\n",
            "Chunk 1146: convergence. A key insight is that, as\n",
            "Chunk 1147: εincreases, the optimal coupling\n",
            "Chunk 1148: becomes less and less sparse (in the sense of\n",
            "Chunk 1149: having entries larger than a prescribed\n",
            "Chunk 1150: thresholds), which in\n",
            "Chunk 1151: turn as the eﬀect of both accelerating\n",
            "Chunk 1152: computational algorithms (as we study in §1.5)\n",
            "Chunk 1153: but also leading to\n",
            "Chunk 1154: faster statistical convergence (as exposed in\n",
            "Chunk 1155: §??).\n",
            "Chunk 1156: Deﬁning the Kullback-Leibler divergence between\n",
            "Chunk 1157: couplings as\n",
            "Chunk 1158: KL(P|K)def.=∑\n",
            "i,jPi,jlog(Pi,j\n",
            "Ki,j)\n",
            "Chunk 1159: −Pi,j+Ki,j, (1.43)\n",
            "Chunk 1160: the unique solution Pεof (1.39) is a projection\n",
            "Chunk 1161: onto U(a,b) of the Gibbs kernel associated to the\n",
            "Chunk 1162: cost matrix\n",
            "Chunk 1163: Cas\n",
            "Ki,jdef.=e−Ci,j\n",
            "ε\n",
            "Chunk 1164: Indeed one has that using the deﬁnition above\n",
            "Chunk 1165: Pε= ProjKL\n",
            "U(a,b)(K)def.= argmin\n",
            "Chunk 1166: P∈U(a,b)KL(P|K). (1.44)\n",
            "Chunk 1167: Remark 10 (General formulation) .One can consider\n",
            "Chunk 1168: arbitrary measures by replacing the discrete\n",
            "Chunk 1169: entropy\n",
            "Chunk 1170: by the relative entropy with respect to the\n",
            "Chunk 1171: product measure d α⊗dβ(x,y)def.= dα(x)dβ(y), and\n",
            "Chunk 1172: propose a\n",
            "Chunk 1173: regularized counterpart to (1.14) using\n",
            "Lε\n",
            "Chunk 1174: c(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "Chunk 1175: X×Yc(x,y)dπ(x,y) +εKL(π|α⊗β) (1.45)\n",
            "Chunk 1176: where the relative entropy is a generalization of\n",
            "Chunk 1177: the discrete Kullback-Leibler divergence (1.43)\n",
            "Chunk 1178: KL(π|ξ)def.=∫\n",
            "X×Ylog(dπ\n",
            "dξ(x,y))\n",
            "dπ(x,y)+\n",
            "∫\n",
            "Chunk 1179: X×Y(dξ(x,y)−dπ(x,y)),(1.46)\n",
            "19\n",
            "Chunk 1180: and by convention KL( π|ξ) = +∞ifπdoes not have a\n",
            "Chunk 1181: densitydπ\n",
            "Chunk 1182: dξwith respect to ξ. It is important to\n",
            "Chunk 1183: realize that the reference measure α⊗βchosen in\n",
            "Chunk 1184: (1.45) to deﬁne the entropic regularizing term\n",
            "Chunk 1185: KL( ·|α⊗β)\n",
            "Chunk 1186: plays no speciﬁc role, only its support matters.\n",
            "Chunk 1187: Formula (1.45) can be re-factored as a projection\n",
            "Chunk 1188: problem\n",
            "Chunk 1189: min\n",
            "π∈U(α,β)KL(π|K) (1.47)\n",
            "Chunk 1190: whereKis the Gibbs distributions d\n",
            "Chunk 1191: K(x,y)def.=e−c(x,y)\n",
            "Chunk 1192: εdµ(x)dν(y). This problem is often referred to as\n",
            "Chunk 1193: the\n",
            "Chunk 1194: “static Schr¨ odinger problem” [ ?,?], since it\n",
            "Chunk 1195: was initially considered by Schr¨ odinger in\n",
            "Chunk 1196: statistical physics [ ?].\n",
            "Chunk 1197: Asε→0, the unique solution to (1.47) converges to\n",
            "Chunk 1198: the maximum entropy solution to (1.14), see [\n",
            "Chunk 1199: ?,?].§??\n",
            "Chunk 1200: details an alternate “dynamic” formulation of the\n",
            "Chunk 1201: Schr¨ odinger problem over the space of paths\n",
            "Chunk 1202: connecting\n",
            "Chunk 1203: the points of two measures.\n",
            "Chunk 1204: Sinkhorn’s Algorithm The following proposition\n",
            "Chunk 1205: shows that the solution of (1.39) has a speciﬁc\n",
            "Chunk 1206: form,\n",
            "Chunk 1207: which can be parameterized using n+mvariables.\n",
            "Chunk 1208: That parameterization is therefore essentially\n",
            "Chunk 1209: dual, in\n",
            "Chunk 1210: the sense that a coupling PinU(a,b)\n",
            "Chunk 1211: hasnmvariables but n+mconstraints.\n",
            "Chunk 1212: Proposition 7. The solution to (1.39) is unique\n",
            "Chunk 1213: and has the form\n",
            "Chunk 1214: ∀(i,j)∈JnK×JmK,Pi,j=uiKi,jvj (1.48)\n",
            "Chunk 1215: for two (unknown) scaling variable (u,v)∈Rn\n",
            "+×Rm\n",
            "Chunk 1216: +.\n",
            "Chunk 1217: Proof. Introducing two dual variables\n",
            "Chunk 1218: f∈Rn,g∈Rmfor each marginal constraint, the\n",
            "Chunk 1219: Lagrangian of (1.39)\n",
            "Chunk 1220: reads\n",
            "E(P,f,g) =⟨P,C⟩−εH(P)−⟨f,P1m−a⟩−⟨g,PT1n−b⟩.\n",
            "Chunk 1221: Considering ﬁrst order conditions, we have\n",
            "Chunk 1222: ∂E(P,f,g)\n",
            "∂Pi,j=Ci,j−εlog(Pi,j)−fi−gj.\n",
            "Chunk 1223: which results, for an optimal Pcoupling to the\n",
            "Chunk 1224: regularized problem, in the expression\n",
            "Chunk 1225: Pi,j=efi/εe−Ci,j/εegj/ε\n",
            "Chunk 1226: which can be rewritten in the form provided in\n",
            "Chunk 1227: the proposition using non-negative vectors uandv.\n",
            "Chunk 1228: The factorization of the optimal solution\n",
            "Chunk 1229: exhibited in Equation (1.48) can be conveniently\n",
            "Chunk 1230: rewritten in\n",
            "Chunk 1231: matrix form as P= diag( u)Kdiag(v).u,vmust\n",
            "Chunk 1232: therefore satisfy the following non-linear\n",
            "Chunk 1233: equations which\n",
            "Chunk 1234: correspond to the mass conservation constraints\n",
            "Chunk 1235: inherent to U(a,b),\n",
            "Chunk 1236: diag(u)Kdiag(v)1m=a,and diag( v)K⊤diag(u)1n=b,\n",
            "Chunk 1237: (1.49)\n",
            "Chunk 1238: These two equations can be further simpliﬁed,\n",
            "Chunk 1239: since diag( v)1mis simply v, and the\n",
            "Chunk 1240: multiplication of diag( u)\n",
            "Chunk 1241: times Kvis\n",
            "u⊙(Kv) =aand v⊙(KTu) =b (1.50)\n",
            "Chunk 1242: where⊙corresponds to entry-wise multiplication of\n",
            "Chunk 1243: vectors. That problem is known in the numerical\n",
            "Chunk 1244: analysis\n",
            "Chunk 1245: community as the matrix scaling problem (see [ ?]\n",
            "Chunk 1246: and references therein). An intuitive way to try\n",
            "Chunk 1247: to solve\n",
            "Chunk 1248: these equations is to solve them iteratively, by\n",
            "Chunk 1249: modifying ﬁrst uso that it satisﬁes the left-hand\n",
            "Chunk 1250: side of\n",
            "Chunk 1251: Equation (1.50) and then vto satisfy its\n",
            "Chunk 1252: right-hand side. These two updates deﬁne\n",
            "Chunk 1253: Sinkhorn’s algorithm:\n",
            "Chunk 1254: u(ℓ+1)def.=a\n",
            "Kv(ℓ)and v(ℓ+1)def.=b\n",
            "Chunk 1255: KTu(ℓ+1), (1.51)\n",
            "Chunk 1256: initialized with an arbitrary positive vector\n",
            "Chunk 1257: v(0)=1m. The division operator used above between\n",
            "Chunk 1258: two\n",
            "Chunk 1259: vectors is to be understood entry-wise. Note that\n",
            "Chunk 1260: a diﬀerent initialization will likely lead to a\n",
            "Chunk 1261: diﬀerent\n",
            "Chunk 1262: 20\n",
            "`⇡(`)\"\n",
            "Chunk 1263: 1000 2000 3000 4000 5000-2-1.5-1-0.50`Figure\n",
            "Chunk 1264: 1.14: Left: evolution of the coupling πℓ\n",
            "Chunk 1265: ε= diag( U(ℓ))Kdiag(V(ℓ)) computed at iteration\n",
            "Chunk 1266: ℓof\n",
            "Chunk 1267: Sinkhorn’s iterations, for 1-D densities. Right:\n",
            "Chunk 1268: impact of εthe convergence rate of Sinkhorn, as\n",
            "Chunk 1269: measured\n",
            "Chunk 1270: in term of marginal constraint violation log(\n",
            "Chunk 1271: ||πℓ\n",
            "Chunk 1272: ε1m−b||1).\n",
            "Chunk 1273: solution for u,v, since u,vare only deﬁned up to\n",
            "Chunk 1274: a multiplicative constant (if u,vsatisfy (1.49)\n",
            "Chunk 1275: then\n",
            "Chunk 1276: so doλu,v/λfor anyλ > 0). It turns out however\n",
            "Chunk 1277: that these iterations converge (see Remark 11 for\n",
            "Chunk 1278: a justiﬁcation using iterative projections, and\n",
            "Chunk 1279: Remark 13 for a strict contraction result) and\n",
            "Chunk 1280: all result in\n",
            "Chunk 1281: the same optimal coupling diag( u)Kdiag(v).\n",
            "Chunk 1282: Figure 1.14, top row, shows the evolution of the\n",
            "Chunk 1283: coupling\n",
            "Chunk 1284: diag(U(ℓ))Kdiag(V(ℓ)) computed by Sinkhorn\n",
            "Chunk 1285: iterations. It evolves from the Gibbs kernel\n",
            "Chunk 1286: Ktowards the\n",
            "Chunk 1287: optimal coupling solving (1.39) by progressively\n",
            "Chunk 1288: shifting the mass away from the diagonal.\n",
            "Chunk 1289: Remark 11 (Relation with iterative projections)\n",
            "Chunk 1290: .Denoting\n",
            "Chunk 1291: C1\n",
            "adef.={P;P1m=a}andC2\n",
            "bdef.={\n",
            "P;PT1m=b}\n",
            "Chunk 1292: the rows and columns constraints, one has U(a,b)\n",
            "Chunk 1293: =C1\n",
            "Chunk 1294: a∩C2\n",
            "Chunk 1295: b. One can use Bregman iterative projections [ ?]\n",
            "Chunk 1296: P(ℓ+1) def.= ProjKL\n",
            "Chunk 1297: C1a(P(ℓ)) and P(ℓ+2) def.= ProjKL\n",
            "C2\n",
            "Chunk 1298: b(P(ℓ+1)). (1.52)\n",
            "Since the setsC1\n",
            "aandC2\n",
            "Chunk 1299: bare aﬃne, these iterations are known to converge\n",
            "Chunk 1300: to the solution of (1.44), see [ ?].\n",
            "Chunk 1301: These iterate are equivalent to Sinkhorn\n",
            "Chunk 1302: iterations (1.51) since deﬁning\n",
            "Chunk 1303: P(2ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)),\n",
            "one has\n",
            "Chunk 1304: P(2ℓ+1) def.= diag( u(ℓ+1))Kdiag(v(ℓ))\n",
            "Chunk 1305: and P(2ℓ+2) def.= diag( u(ℓ+1))Kdiag(v(ℓ+1))\n",
            "Chunk 1306: In practice however one should prefer using\n",
            "Chunk 1307: (1.51) which only requires manipulating scaling\n",
            "Chunk 1308: vectors and\n",
            "Chunk 1309: multiplication against a Gibbs kernel, which can\n",
            "Chunk 1310: often be accelerated (see below Remarks ??and??).\n",
            "Chunk 1311: Remark 12 (Hilbert metric) .As initially\n",
            "Chunk 1312: explained by [ ?], the global convergence\n",
            "Chunk 1313: analysis of Sinkhorn is\n",
            "Chunk 1314: greatly simpliﬁed using Hilbert projective metric\n",
            "Chunk 1315: on Rn\n",
            "Chunk 1316: +,∗(positive vectors), deﬁned as\n",
            "∀(u,u′)∈(Rn\n",
            "Chunk 1317: +,∗)2, dH(u,u′)def.= log max\n",
            "i,i′uiu′\n",
            "i′\n",
            "ui′u′\n",
            "i.\n",
            "Chunk 1318: This can be shows to be a distance on the\n",
            "Chunk 1319: projective cone Rn\n",
            "Chunk 1320: +,∗/∼, where u∼u′means that∃s>0,u=su′\n",
            "Chunk 1321: (the vector are equal up to rescaling, hence the\n",
            "Chunk 1322: naming “projective”). This means that dHsatisﬁes\n",
            "Chunk 1323: the\n",
            "Chunk 1324: triangular inequality and dH(u,u′) = 0 if and\n",
            "Chunk 1325: only if u∼u′. This is a projective version of\n",
            "Chunk 1326: Hilbert’s original\n",
            "Chunk 1327: distance on bounded open convex sets [ ?]. The\n",
            "Chunk 1328: projective cone Rn\n",
            "Chunk 1329: +,∗/∼is a complete metric space for this\n",
            "Chunk 1330: distance. It was introduced independently by [ ?]\n",
            "Chunk 1331: and [ ?] to provide a quantitative proof of\n",
            "Chunk 1332: Perron-Frobenius\n",
            "Chunk 1333: theorem, which, as explained in Remark ??is\n",
            "Chunk 1334: linked to a local linearization of Sinkhorn’s\n",
            "Chunk 1335: iterates. They\n",
            "Chunk 1336: proved the following fundamental theorem, which\n",
            "Chunk 1337: shows that a positive matrix is a strict\n",
            "Chunk 1338: contraction on the\n",
            "Chunk 1339: cone of positive vectors.\n",
            "21\n",
            "Chunk 1340: Theorem 2. Let K∈Rn×m\n",
            "+,∗, then for (v,v′)∈(Rm\n",
            "Chunk 1341: +,∗)2\n",
            "dH(Kv,Kv′)⩽λ(K)dH(v,v′)where\n",
            "\n",
            "Chunk 1342: λ(K)def.=√\n",
            "η(K)−1√\n",
            "η(K)+1<1\n",
            "η(K)def.= max\n",
            "Chunk 1343: i,j,k,ℓKi,kKj,ℓ\n",
            "Kj,kKi,ℓ.\n",
            "Chunk 1344: Remark 13 (Global convergence) .The following\n",
            "Chunk 1345: theorem, proved by [ ?], makes use of this\n",
            "Chunk 1346: Theorem 2 to\n",
            "Chunk 1347: show the linear convergence of Sinkhorn’s\n",
            "Chunk 1348: iterations.\n",
            "Chunk 1349: Theorem 3. One has (u(ℓ),v(ℓ))→(u⋆,v⋆)and\n",
            "Chunk 1350: dH(u(ℓ),u⋆) =O(λ(K)2ℓ), dH(v(ℓ),v⋆) =O(λ(K)2ℓ).\n",
            "Chunk 1351: (1.53)\n",
            "Chunk 1352: One also has\n",
            "dH(u(ℓ),u⋆)⩽dH(P(ℓ)1m,a)\n",
            "1−λ(K)\n",
            "Chunk 1353: dH(v(ℓ),v⋆)⩽dH(P(ℓ),⊤1n,b)\n",
            "1−λ(K)(1.54)\n",
            "Chunk 1354: where we denoted P(ℓ)def.= diag(\n",
            "Chunk 1355: u(ℓ))Kdiag(v(ℓ)). Lastly, one has\n",
            "Chunk 1356: ∥log(P(ℓ))−log(P⋆)∥∞⩽dH(u(ℓ),u⋆) +dH(v(ℓ),v⋆)\n",
            "Chunk 1357: (1.55)\n",
            "Chunk 1358: where P⋆is the unique solution of (1.39) .\n",
            "Chunk 1359: Proof. One notice that for any ( v,v′)∈(Rm\n",
            "Chunk 1360: +,∗)2, one has\n",
            "Chunk 1361: dH(v,v′) =dH(v/v′,1m) =dH(1m/v,1m/v′).\n",
            "Chunk 1362: This shows that\n",
            "dH(u(ℓ+1),u⋆) =dH(a\n",
            "Kv(ℓ),a\n",
            "Kv⋆)\n",
            "Chunk 1363: =dH(Kv(ℓ),Kv⋆)⩽λ(K)dH(v(ℓ),v⋆).\n",
            "Chunk 1364: where we used Theorem 2. This shows (1.53). One\n",
            "Chunk 1365: also has, using the triangular inequality\n",
            "Chunk 1366: dH(u(ℓ),u⋆)⩽dH(u(ℓ+1),u(ℓ)) +dH(u(ℓ+1),u⋆)\n",
            "⩽dH(a\n",
            "Chunk 1367: Kv(ℓ),u(ℓ))\n",
            "+λ(K)dH(u(ℓ),u⋆)\n",
            "=dH(\n",
            "a,u(ℓ)⊙(Kv(ℓ)))\n",
            "Chunk 1368: +λ(K)dH(u(ℓ),u⋆),\n",
            "Chunk 1369: which gives the ﬁrst part of (1.54) since\n",
            "Chunk 1370: u(ℓ)⊙(Kv(ℓ)) =P(ℓ)1m(the second one being\n",
            "Chunk 1371: similar). The proof\n",
            "Chunk 1372: of (1.55) follows from [ ?, Lemma 3]\n",
            "Chunk 1373: The bound (1.54) shows that some error measures\n",
            "Chunk 1374: on the marginal constraints violation, for\n",
            "Chunk 1375: instance\n",
            "Chunk 1376: ∥P(ℓ)1m−a∥1and∥P(ℓ)T1n−b∥1, are useful stopping\n",
            "Chunk 1377: criteria to monitor the convergence.\n",
            "Chunk 1378: Figure 1.14, bottom row, highlights this linear\n",
            "Chunk 1379: rate on the constraint violation, and shows how\n",
            "Chunk 1380: this rate\n",
            "Chunk 1381: degrades as ε→0. These results are proved in [ ?]\n",
            "Chunk 1382: and are tightly connected to nonlinear\n",
            "Chunk 1383: Perron-Frobenius\n",
            "Chunk 1384: Theory [ ?]. Perron-Frobenius theory corresponds\n",
            "Chunk 1385: to the linearization of the iterations, see (\n",
            "Chunk 1386: ??). This\n",
            "Chunk 1387: convergence analysis is extended in [ ?], who\n",
            "Chunk 1388: shows that each iteration of Sinkhorn increases\n",
            "Chunk 1389: the permanent\n",
            "Chunk 1390: of the scaled coupling matrix.\n",
            "22\n",
            "Chunk 1391: Regularized Dual and Log-domain Computations The\n",
            "Chunk 1392: following proposition details the dual problem\n",
            "Chunk 1393: associated to (1.39).\n",
            "Proposition 8. One has\n",
            "Lε\n",
            "Chunk 1394: C(a,b) = max\n",
            "Chunk 1395: f∈Rn,g∈Rm⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩. (1.56)\n",
            "Chunk 1396: The optimal (f,g)are linked to scalings\n",
            "Chunk 1397: (u,v)appearing in (1.48) through\n",
            "Chunk 1398: (u,v) = (ef/ε,eg/ε). (1.57)\n",
            "Chunk 1399: Proof. We start from the end of the proof of\n",
            "Chunk 1400: Proposition 7, which links the optimal primal\n",
            "Chunk 1401: solution P\n",
            "Chunk 1402: and dual multipliers fandgfor the marginal\n",
            "Chunk 1403: constraints as Pi,j=efi/εe−Ci,j/εegj/ε.\n",
            "Chunk 1404: Substituting in the\n",
            "Chunk 1405: LagrangianE(P,f,g) of Equation (1.5) the optimal\n",
            "Chunk 1406: Pas a function of fandg, we obtain that the\n",
            "Chunk 1407: Lagrange\n",
            "Chunk 1408: dual function equals\n",
            "Chunk 1409: f,g↦→⟨ef/ε,(K⊙C)eg/ε⟩−εH(diag(ef/ε)Kdiag(eg/ε)).\n",
            "Chunk 1410: (1.58)\n",
            "Chunk 1411: The entropy of Pscaled byε,\n",
            "Chunk 1412: namelyε⟨P,logP−1n×m⟩can be stated explicitly as a\n",
            "Chunk 1413: function of f,g,C\n",
            "Chunk 1414: ⟨diag(ef/ε)Kdiag(eg/ε),f1mT+1ngT−C−ε1n×m⟩\n",
            "Chunk 1415: =−⟨ef/ε,(K⊙C)eg/ε⟩+⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩\n",
            "Chunk 1416: therefore, the ﬁrst term in (1.58) cancels out\n",
            "Chunk 1417: with the ﬁrst term in the entropy above. The\n",
            "Chunk 1418: remaining times\n",
            "Chunk 1419: are those displayed in (1.56).\n",
            "Chunk 1420: Remark 14.Dual for generic measures For generic\n",
            "Chunk 1421: (non-necessarily discrete) input measures ( α,β),\n",
            "Chunk 1422: the dual\n",
            "Chunk 1423: problem (1.56) reads\n",
            "sup\n",
            "f,g∈C(X)×C(Y)∫\n",
            "Chunk 1424: Xf(x)dα(x) +∫\n",
            "Yg(x)dβ(x)−ε∫\n",
            "X×Ye−c(x,y)+f(x)+g(y)\n",
            "Chunk 1425: ε dα(x)dβ(y)\n",
            "Chunk 1426: This corresponds to a smoothing of the constraint\n",
            "Chunk 1427: R(c) appearing in the original problem (1.21),\n",
            "Chunk 1428: which\n",
            "Chunk 1429: is retrieved in the limit ε→0. Proving existence\n",
            "Chunk 1430: ( i.e. the sup is actually a max) of these\n",
            "Chunk 1431: Kantorovich\n",
            "Chunk 1432: potentials ( f,g) in the case of entropic\n",
            "Chunk 1433: transport is less easy than for classical OT\n",
            "Chunk 1434: (because one cannot\n",
            "Chunk 1435: usec-transform and potentials are not\n",
            "Chunk 1436: automatically Lipschitz). Proof of existence can\n",
            "Chunk 1437: be done using the\n",
            "Chunk 1438: convergence of Sinkhorn iterations, see [ ?] for\n",
            "Chunk 1439: more details.\n",
            "Chunk 1440: Remark 15 (Sinkhorn as a Block Coordinate Ascent\n",
            "Chunk 1441: on the Dual Problem) .A simple approach to solve\n",
            "Chunk 1442: the\n",
            "Chunk 1443: unconstrained maximization problem (1.56) is to\n",
            "Chunk 1444: use an exact block coordinate ascent strategy,\n",
            "Chunk 1445: namely to\n",
            "Chunk 1446: update alternatively fandgto cancel their\n",
            "Chunk 1447: gradients with respect to the objective of\n",
            "Chunk 1448: (1.56). Indeed, one\n",
            "Chunk 1449: can easily notice that, writing Q(f,g) for the\n",
            "Chunk 1450: objective of (1.56) that\n",
            "Chunk 1451: ∇|fQ(f,g) =a−ef/ε⊙(\n",
            "Keg/ε)\n",
            ", (1.59)\n",
            "Chunk 1452: ∇|gQ(f,g) =b−eg/ε⊙(\n",
            "KTef/ε)\n",
            ". (1.60)\n",
            "Chunk 1453: Block coordinate ascent can therefore be\n",
            "Chunk 1454: implemented in a closed form by applying\n",
            "Chunk 1455: successively the following\n",
            "Chunk 1456: updates, starting from any arbitrary g(0),\n",
            "Chunk 1457: forl⩾0,\n",
            "Chunk 1458: f(ℓ+1)=εloga−εlog(\n",
            "Keg(ℓ)/ε)\n",
            ", (1.61)\n",
            "Chunk 1459: g(ℓ+1)=εlogb−εlog(\n",
            "KTef(ℓ+1)/ε)\n",
            ". (1.62)\n",
            "Chunk 1460: Such iterations are mathematically equivalent to\n",
            "Chunk 1461: the Sinkhorn iterations (1.51) when considering\n",
            "Chunk 1462: the primal-\n",
            "Chunk 1463: dual relations highlighted in (1.57). Indeed, we\n",
            "Chunk 1464: recover that at any iteration\n",
            "Chunk 1465: (f(ℓ),g(ℓ)) =ε(log(u(ℓ)),log(v(ℓ))).\n",
            "23\n",
            "Chunk 1466: Remark 16 (Soft-min rewriting) .Iterations (1.61)\n",
            "Chunk 1467: and (1.62) can be given an alternative\n",
            "Chunk 1468: interpretation,\n",
            "Chunk 1469: using the following notation. Given a vector zof\n",
            "Chunk 1470: real numbers we write min εzfor the soft-minimum\n",
            "Chunk 1471: of its\n",
            "Chunk 1472: coordinates, namely\n",
            "minεz=−εlog∑\n",
            "ie−zi/ε.\n",
            "Chunk 1473: Note that min ε(z) converges to min zfor any\n",
            "Chunk 1474: vector zasε→0. Indeed, min εcan be interpreted as\n",
            "Chunk 1475: a\n",
            "Chunk 1476: diﬀerentiable approximation of the min function.\n",
            "Chunk 1477: Using these notations, Equations (1.61) and\n",
            "Chunk 1478: (1.62) can be\n",
            "Chunk 1479: rewritten\n",
            "(f(ℓ+1))i= minε(Cij−g(ℓ)\n",
            "Chunk 1480: j)j+εlogai, (1.63)\n",
            "(g(ℓ+1))j= minε(Cij−f(ℓ)\n",
            "Chunk 1481: i)i+εlogbj. (1.64)\n",
            "Here the term min ε(Cij−g(ℓ)\n",
            "Chunk 1482: j)jdenotes the soft-minimum of all values of the\n",
            "Chunk 1483: j-th column of matrix\n",
            "Chunk 1484: (C−1n(g(ℓ))⊤). To simplify notations, we\n",
            "Chunk 1485: introduce an operator that takes a matrix as\n",
            "Chunk 1486: input and outputs\n",
            "Chunk 1487: now a column vector of the soft-minimum values of\n",
            "Chunk 1488: its columns or rows. Namely, for any matrix\n",
            "Chunk 1489: A∈Rn×m,\n",
            "Chunk 1490: we deﬁne\n",
            "Minrow\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)j)\n",
            "i∈Rn,\n",
            "Chunk 1491: Mincol\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)i)\n",
            "j∈Rm.\n",
            "Chunk 1492: Note that these operations are equivalent to the\n",
            "Chunk 1493: entropic c-transform introduced in §??(see in\n",
            "Chunk 1494: particu-\n",
            "Chunk 1495: lar (??)). Using these notations, Sinkhorn’s\n",
            "Chunk 1496: iterates read\n",
            "Chunk 1497: f(ℓ+1)= Minrow\n",
            "ε(C−1ng(ℓ)T) +εloga, (1.65)\n",
            "Chunk 1498: g(ℓ+1)= Mincol\n",
            "ε(C−f(ℓ)1mT) +εlogb. (1.66)\n",
            "Chunk 1499: Note that as ε→0, minεconverges to min, but the\n",
            "Chunk 1500: iterations do not converge anymore in the limit\n",
            "Chunk 1501: ε= 0,\n",
            "Chunk 1502: because alternate minimization does not converge\n",
            "Chunk 1503: for constrained problems (which is the case for\n",
            "Chunk 1504: the un-\n",
            "Chunk 1505: regularized dual (1.17)).\n",
            "Chunk 1506: Remark 17 (Log-domain Sinkhorn) .While\n",
            "Chunk 1507: mathematically equivalent to the Sinkhorn updates\n",
            "Chunk 1508: (1.51), itera-\n",
            "Chunk 1509: tions (1.63) and (1.64) suggest to use the\n",
            "Chunk 1510: log-sum-exp stabilization trick to avoid underﬂow\n",
            "Chunk 1511: for small values\n",
            "Chunk 1512: ofε. Writing z = min z, that trick suggests to\n",
            "Chunk 1513: evaluate min εzas\n",
            "Chunk 1514: minεz= z−εlog∑\n",
            "ie−(zi−z)/ε. (1.67)\n",
            "Chunk 1515: Instead of substracting z to stabilize the log\n",
            "Chunk 1516: domain iterations as in (1.67), one can actually\n",
            "Chunk 1517: substract the\n",
            "Chunk 1518: previously computed scalings. This leads to the\n",
            "Chunk 1519: following stabilized iteration\n",
            "Chunk 1520: f(ℓ+1)= Minrow\n",
            "Chunk 1521: ε(S(f(ℓ),g(ℓ)))−f(ℓ)+εlog(a) (1.68)\n",
            "Chunk 1522: g(ℓ+1)= Mincol\n",
            "Chunk 1523: ε(S(f(ℓ+1),g(ℓ)))−g(ℓ)+εlog(b), (1.69)\n",
            "Chunk 1524: where we deﬁned\n",
            "S(f,g) =(\n",
            "Ci,j−fi−gj)\n",
            "i,j.\n",
            "Chunk 1525: In contrast to the original iterations (1.51),\n",
            "Chunk 1526: these log-domain iterations (1.68) and (1.69) are\n",
            "Chunk 1527: stable for\n",
            "Chunk 1528: arbitraryε >0, because the quantity S(f,g) stays\n",
            "Chunk 1529: bounded during the iterations. The downside is\n",
            "Chunk 1530: that it\n",
            "Chunk 1531: requiresnmcomputations of exp at each step.\n",
            "Chunk 1532: Computing a Minrow\n",
            "Chunk 1533: εor Mincol\n",
            "εis typically substantially\n",
            "Chunk 1534: slower than matrix multiplications, and requires\n",
            "Chunk 1535: computing line by line soft-minima of matrices S.\n",
            "Chunk 1536: There is\n",
            "Chunk 1537: therefore no eﬃcient way to parallelize the\n",
            "Chunk 1538: application of Sinkhorn maps for several\n",
            "Chunk 1539: marginals simultaneously.\n",
            "Chunk 1540: In Euclidean domain of small dimension, it is\n",
            "Chunk 1541: possible to develop eﬃcient multiscale solvers\n",
            "Chunk 1542: with a decaying\n",
            "Chunk 1543: εstrategy to signiﬁcantly speed up the\n",
            "Chunk 1544: computation using sparse grids [ ?].\n",
            "Chunk 1545: 24\n",
            "1.6 Extensions\n",
            "Chunk 1546: Wasserstein Barycenters. Given input histogram\n",
            "Chunk 1547: {bs}S\n",
            "Chunk 1548: s=1, wherebs∈Σns, and weights λ∈ΣS, a\n",
            "Chunk 1549: Wasserstein barycenter is computed by minimizing\n",
            "Chunk 1550: min\n",
            "a∈ΣnS∑\n",
            "s=1λsLCs(a,bs) (1.70)\n",
            "Chunk 1551: where the cost matrices Cs∈Rn×nsneed to be\n",
            "Chunk 1552: speciﬁed. A typical setup is “Eulerian”, so that\n",
            "Chunk 1553: all the\n",
            "Chunk 1554: barycenters are deﬁned on the same grid,\n",
            "Chunk 1555: ns=n,Cs=C=Dpis set to be a distance matrix, so\n",
            "Chunk 1556: that one\n",
            "Chunk 1557: solves\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsWp\n",
            "p(a,bs).\n",
            "Chunk 1558: This barycenter problem (1.70) was originally\n",
            "Chunk 1559: introduced by [ ?] following earlier ideas of [\n",
            "Chunk 1560: ?]. They proved\n",
            "Chunk 1561: in particular uniqueness of the barycenter for\n",
            "Chunk 1562: c(x,y) =||x−y||2overX=Rd, if one of the input\n",
            "Chunk 1563: measure\n",
            "Chunk 1564: has a density with respect to the Lebesgue\n",
            "Chunk 1565: measure (and more generally under the same\n",
            "Chunk 1566: hypothesis as the\n",
            "Chunk 1567: one guaranteeing the existence of a Monge map,\n",
            "Chunk 1568: see Remark ??).\n",
            "Chunk 1569: The barycenter problem for histograms (1.70) is\n",
            "Chunk 1570: in fact a linear program, since one can look for\n",
            "Chunk 1571: the S\n",
            "Chunk 1572: couplings ( Ps)sbetween each input and the\n",
            "Chunk 1573: barycenter itself\n",
            "Chunk 1574: min\n",
            "a∈Σn,(Ps∈Rn×ns)s{S∑\n",
            "s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "Chunk 1575: s1ns=a,P⊤\n",
            "s1n=bs}\n",
            ".\n",
            "Chunk 1576: Although this problem is an LP, its scale forbids\n",
            "Chunk 1577: the use generic solvers for medium scale\n",
            "Chunk 1578: problems. One\n",
            "Chunk 1579: can therefore resort to using ﬁrst order methods\n",
            "Chunk 1580: such as subgradient descent on the dual [ ?].\n",
            "Chunk 1581: Remark 18.Barycenter of arbitrary measures Given\n",
            "Chunk 1582: a set of input measure ( βs)sdeﬁned on some space\n",
            "Chunk 1583: X,\n",
            "Chunk 1584: the barycenter problem becomes\n",
            "min\n",
            "α∈M1\n",
            "+(X)S∑\n",
            "Chunk 1585: s=1λsLc(α,βs). (1.71)\n",
            "Chunk 1586: In the case where X=Rdandc(x,y) =||x−y||2, [?]\n",
            "Chunk 1587: shows that if one of the input measures has a\n",
            "Chunk 1588: density,\n",
            "Chunk 1589: then this barycenter is unique. Problem (1.71)\n",
            "Chunk 1590: can be viewed as a generalization of the problem\n",
            "Chunk 1591: of computing\n",
            "Chunk 1592: barycenters of points ( xs)S\n",
            "Chunk 1593: s=1∈XSto arbitrary measures. Indeed, if βs=δxsis\n",
            "Chunk 1594: a single Dirac mass, then a\n",
            "Chunk 1595: solution to (1.71) is δx⋆wherex⋆is a Fr´ echet\n",
            "Chunk 1596: mean solving ( ??). Note that for c(x,y)\n",
            "Chunk 1597: =||x−y||2, the mean\n",
            "Chunk 1598: of the barycenter α⋆is necessarily the barycenter\n",
            "Chunk 1599: of the mean, i.e.\n",
            "Chunk 1600: ∫\n",
            "Xxdα⋆(x) =∑\n",
            "sλs∫\n",
            "Xxdαs(x),\n",
            "Chunk 1601: and the support of α⋆is located in the convex\n",
            "Chunk 1602: hull of the supports of the ( αs)s. The\n",
            "Chunk 1603: consistency of the\n",
            "Chunk 1604: approximation of the inﬁnite dimensional\n",
            "Chunk 1605: optimization (1.71) when approximating the input\n",
            "Chunk 1606: distribution\n",
            "Chunk 1607: using discrete ones (and thus solving (1.70) in\n",
            "Chunk 1608: place) is studied in [ ?]. Let us also note that\n",
            "Chunk 1609: it is possible to\n",
            "Chunk 1610: re-cast (1.71) as a multi-marginal OT problem,\n",
            "Chunk 1611: see Remark ??.\n",
            "Chunk 1612: One can use entropic smoothing and approximate\n",
            "Chunk 1613: the solution of (1.70) using\n",
            "Chunk 1614: min\n",
            "a∈ΣnS∑\n",
            "s=1λsLε\n",
            "Cs(a,bs) (1.72)\n",
            "Chunk 1615: for someε > 0. This is a smooth convex\n",
            "Chunk 1616: minimization problem, which can be tackled using\n",
            "Chunk 1617: gradient\n",
            "Chunk 1618: descent [ ?]. An alternative is to use descent\n",
            "Chunk 1619: method (typically quasi-Newton) on the semi-dual\n",
            "Chunk 1620: [ ?], which is\n",
            "Chunk 1621: 25\n",
            "Chunk 1622: useful to integrate additional regularizations on\n",
            "Chunk 1623: the barycenter (e.g. to impose some smoothness).\n",
            "Chunk 1624: A simple\n",
            "Chunk 1625: but eﬀective approach, as remarked in [ ?] is to\n",
            "Chunk 1626: rewrite (1.72) as a (weighted) KL projection\n",
            "Chunk 1627: problem\n",
            "Chunk 1628: min\n",
            "(Ps)s{∑\n",
            "Chunk 1629: sλsKL(Ps|Ks) ;∀s,PsT1m=bs,P111=...=PS1S}\n",
            "(1.73)\n",
            "Chunk 1630: where we denoted Ksdef.=e−Cs/ε. Here, the\n",
            "Chunk 1631: barycenter ais implicitly encoded in the row\n",
            "Chunk 1632: marginals of all\n",
            "Chunk 1633: the couplings Ps∈Rn×nsasa=P111=...=PS1S. As\n",
            "Chunk 1634: detailed in [ ?], one can generalize Sinkhorn to\n",
            "Chunk 1635: this problem, which also corresponds to iterative\n",
            "Chunk 1636: projection. This can also be seen as a special\n",
            "Chunk 1637: case of the\n",
            "Chunk 1638: generalized Sinkhorn detailed in §??. The optimal\n",
            "Chunk 1639: couplings ( Ps)ssolving (1.73) are computed in\n",
            "Chunk 1640: scaling\n",
            "Chunk 1641: form as\n",
            "Ps= diag( us)Kdiag(vs), (1.74)\n",
            "Chunk 1642: and the scalings are sequentially updated as\n",
            "Chunk 1643: ∀s∈J1,SK,v(ℓ+1)\n",
            "sdef.=bs\n",
            "KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "Chunk 1644: ∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Ksv(ℓ+1)\n",
            "s, (1.76)\n",
            "Chunk 1645: where a(ℓ+1)def.=∏\n",
            "s(Ksv(ℓ+1)\n",
            "s)λs. (1.77)\n",
            "Chunk 1646: An alternative way to derive these iterations is\n",
            "Chunk 1647: to perform alternate minimization on the\n",
            "Chunk 1648: variables of a dual\n",
            "Chunk 1649: problem, which detailed in the following\n",
            "Chunk 1650: proposition.\n",
            "Chunk 1651: Proposition 9. The optimal (us,vs)appearing in\n",
            "Chunk 1652: (1.74) can be written as (us,vs) =\n",
            "Chunk 1653: (efs/ε,egs/ε)where\n",
            "Chunk 1654: (fs,gs)sare the solutions of the following\n",
            "Chunk 1655: program (whose value matches the one of (1.72) )\n",
            "Chunk 1656: max\n",
            "(fs,gs)s{∑\n",
            "sλs(\n",
            "⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "Chunk 1657: sλsfs= 0}\n",
            ". (1.78)\n",
            "Chunk 1658: Proof. Introducing Lagrange multipliers in (1.73)\n",
            "Chunk 1659: leads to\n",
            "Chunk 1660: min\n",
            "(Ps)s,amax\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "Chunk 1661: εKL(Ps|Ks) +⟨a−Ps1m,fs⟩\n",
            "+⟨bs−PsT1m,gs⟩)\n",
            ".\n",
            "Chunk 1662: Strong duality holds, so that one can exchange\n",
            "Chunk 1663: the min and the max, and gets\n",
            "Chunk 1664: max\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "⟨gs,bs⟩+ min\n",
            "Chunk 1665: PsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\n",
            "+ min\n",
            "a⟨∑\n",
            "sλsfs,a⟩.\n",
            "Chunk 1666: The explicit minimization on agives the\n",
            "Chunk 1667: constraint∑\n",
            "Chunk 1668: sλsfs= 0 together with\n",
            "max\n",
            "(fs,gs)s∑\n",
            "Chunk 1669: sλs⟨gs,bs⟩−εKL∗(fs⊕gs\n",
            "ε|Ks)\n",
            "Chunk 1670: where KL∗(·|Ks) is the Legendre transform ( ??)\n",
            "Chunk 1671: of the function KL∗(·|Ks). This Legendre\n",
            "Chunk 1672: transform reads\n",
            "Chunk 1673: KL∗(U|K) =∑\n",
            "i,jKi,j(eUi,j−1), (1.79)\n",
            "26\n",
            "Chunk 1674: Figure 1.15: Barycenters between 4 input 3-D\n",
            "Chunk 1675: shapes using entropic regularization (1.72). The\n",
            "Chunk 1676: weights\n",
            "Chunk 1677: (λs)sare bilinear with respect to the four\n",
            "Chunk 1678: corners of the square. Shapes are represented as\n",
            "Chunk 1679: measures that\n",
            "Chunk 1680: are uniform within the boundaries of the shape\n",
            "Chunk 1681: and null outside.\n",
            "Chunk 1682: which shows the desired formula. To show (1.79),\n",
            "Chunk 1683: since this function is separable, one needs to\n",
            "Chunk 1684: compute\n",
            "Chunk 1685: ∀(u,k)∈R2\n",
            "+,KL∗(u|k)def.= max\n",
            "rur−(rlog(r/k)−r+k)\n",
            "Chunk 1686: whose optimality condition reads u= log(r/k),\n",
            "Chunk 1687: i.e.r=keu, hence the result.\n",
            "Chunk 1688: Minimizing (1.78) with respect to each gs, while\n",
            "Chunk 1689: keeping all the other variable ﬁxed, is obtained\n",
            "Chunk 1690: in closed\n",
            "Chunk 1691: form by (1.75). Minimizing (1.78) with respect to\n",
            "Chunk 1692: all the ( fs)srequires to solve for ausing (1.77)\n",
            "Chunk 1693: and leads\n",
            "Chunk 1694: to the expression (1.76).\n",
            "Chunk 1695: Figures ??and??show applications to 2-D and 3-D\n",
            "Chunk 1696: shapes interpolation. Figure ??shows a\n",
            "Chunk 1697: computation\n",
            "Chunk 1698: of barycenters on a surface, where the ground\n",
            "Chunk 1699: cost is the square of the geodesic distance. For\n",
            "Chunk 1700: this ﬁgure,\n",
            "Chunk 1701: the computations are performed using the geodesic\n",
            "Chunk 1702: in heat approximation detailed in Remark ??. We\n",
            "Chunk 1703: refer\n",
            "Chunk 1704: to [?] for more details and other applications to\n",
            "Chunk 1705: computer graphics and imaging sciences.\n",
            "Chunk 1706: Wasserstein Loss. In statistics, text processing\n",
            "Chunk 1707: or imaging, one must usually compare a\n",
            "Chunk 1708: probability\n",
            "Chunk 1709: distribution βarising from measurements to a\n",
            "Chunk 1710: model, namely a parameterized family of\n",
            "Chunk 1711: distributions {αθ,θ∈\n",
            "Chunk 1712: Θ}where Θ is a subset of an Euclidean space. Such\n",
            "Chunk 1713: a comparison is done through a “loss” or a\n",
            "Chunk 1714: “ﬁdelity”\n",
            "Chunk 1715: term, which, in this section, is the Wasserstein\n",
            "Chunk 1716: distance. In the simplest scenario, the\n",
            "Chunk 1717: computation of a\n",
            "Chunk 1718: suitable parameter θis obtained by minimizing\n",
            "Chunk 1719: directly\n",
            "Chunk 1720: min\n",
            "θ∈ΘE(θ)def.=Lc(αθ,β). (1.80)\n",
            "Chunk 1721: Of course, one can consider more complicated\n",
            "Chunk 1722: problems: for instance, the barycenter problem\n",
            "Chunk 1723: described\n",
            "Chunk 1724: in§??consists in a sum of such terms. However,\n",
            "Chunk 1725: most of these more advanced problems can be\n",
            "Chunk 1726: usually\n",
            "Chunk 1727: solved by adapting tools deﬁned for basic case:\n",
            "Chunk 1728: either using the chain rule to compute explicitly\n",
            "Chunk 1729: derivatives,\n",
            "Chunk 1730: or using automatic diﬀerentiation.\n",
            "Chunk 1731: The Wasserstein distance between two histograms\n",
            "Chunk 1732: or two densities is convex with respect to these\n",
            "Chunk 1733: inputs,\n",
            "Chunk 1734: as shown by (1.17) and (1.21) respectively.\n",
            "Chunk 1735: Therefore, when the parameter θis itself a\n",
            "Chunk 1736: histogram, namely Θ =\n",
            "Chunk 1737: Σnandαθ=θ, or more generally when\n",
            "Chunk 1738: θdescribesKweights in the simplex, Θ = Σ K,\n",
            "Chunk 1739: andαθ=∑K\n",
            "Chunk 1740: i=1θiαi\n",
            "Chunk 1741: is a convex combination of known atoms\n",
            "Chunk 1742: α1,...,αKin ΣN, Problem (1.80) remains convex\n",
            "Chunk 1743: (the ﬁrst case\n",
            "Chunk 1744: corresponds to the barycenter problem, the second\n",
            "Chunk 1745: to one iteration of the dictionary learning\n",
            "Chunk 1746: problem with\n",
            "Chunk 1747: a Wasserstein loss [ ?]). However, for more\n",
            "Chunk 1748: general parameterizations θ↦→αθ, Problem (1.80)\n",
            "Chunk 1749: is in general\n",
            "Chunk 1750: not convex.\n",
            "27\n",
            "Chunk 1751: g✓XZ⇣xz\u0000↵✓Figure 1.16: Schematic display of the\n",
            "Chunk 1752: density ﬁtting problem 1.81.\n",
            "Chunk 1753: A practical problem of paramount importance in\n",
            "Chunk 1754: statistic and machine learning is density ﬁtting.\n",
            "Chunk 1755: Given\n",
            "Chunk 1756: some discrete samples ( xi)n\n",
            "Chunk 1757: i=1⊂X from some unknown distribution, the goal is\n",
            "Chunk 1758: to ﬁt a parametric model\n",
            "Chunk 1759: θ↦→αθ∈M (X) to the observed empirical input\n",
            "Chunk 1760: measure β\n",
            "Chunk 1761: min\n",
            "θ∈ΘL(αθ,β) where β=1\n",
            "n∑\n",
            "iδxi, (1.81)\n",
            "Chunk 1762: whereLis some “loss” function between a discrete\n",
            "Chunk 1763: and a “continuous” (arbitrary) distribution (see\n",
            "Chunk 1764: Fig-\n",
            "Chunk 1765: ure 1.16).\n",
            "Chunk 1766: In the case where αθas a densify ρθdef.=ραθwith\n",
            "Chunk 1767: respect to the Lebesgue measure (or any other\n",
            "Chunk 1768: ﬁxed\n",
            "Chunk 1769: reference measure), the maximum likelihood\n",
            "Chunk 1770: estimator (MLE) is obtained by solving\n",
            "Chunk 1771: min\n",
            "θLMLE(αθ,β)def.=−∑\n",
            "ilog(ρθ(xi)).\n",
            "Chunk 1772: This corresponds to using an empirical\n",
            "Chunk 1773: counterpart of a Kullback-Leibler loss since,\n",
            "Chunk 1774: assuming the xiare i.i.d.\n",
            "Chunk 1775: samples of some ¯β, then\n",
            "LMLE(α,β)n→+∞−→ KL(α|¯β)\n",
            "Chunk 1776: This MLE approach is known to lead to optimal\n",
            "Chunk 1777: estimation procedures in many cases (see for\n",
            "Chunk 1778: instance [ ?]).\n",
            "Chunk 1779: However, it fails to work when estimating\n",
            "Chunk 1780: singular distributions, typically when the αθdoes\n",
            "Chunk 1781: not has a density\n",
            "Chunk 1782: (so thatLMLE(αθ,β) = +∞) or when ( xi)iare\n",
            "Chunk 1783: samples from some singular ¯β(so that the\n",
            "Chunk 1784: αθshould share\n",
            "Chunk 1785: the same support as βfor KL(α|¯β) to be ﬁnite,\n",
            "Chunk 1786: but this support is usually unknown). Another\n",
            "Chunk 1787: issue is that\n",
            "Chunk 1788: in several cases of practical interest, the\n",
            "Chunk 1789: density ρθis inaccessible (or too hard to\n",
            "Chunk 1790: compute).\n",
            "Chunk 1791: A typical setup where both problems (singular and\n",
            "Chunk 1792: unknown densities) occur is for so-called\n",
            "Chunk 1793: generative\n",
            "Chunk 1794: models, where the parametric measure is written\n",
            "Chunk 1795: as a push-forward of a ﬁxed reference measure ζ∈M\n",
            "Chunk 1796: (Z)\n",
            "Chunk 1797: αθ=hθ,♯ζwherehθ:Z→X\n",
            "Chunk 1798: where the push-forward operator is introduced in\n",
            "Chunk 1799: Deﬁnition 1. The space Zis usually\n",
            "Chunk 1800: low-dimensional, so\n",
            "Chunk 1801: that the support of αθis localized along a\n",
            "Chunk 1802: low-dimensional “manifold” and the resulting\n",
            "Chunk 1803: density is highly\n",
            "Chunk 1804: singular (it does not have a density with respect\n",
            "Chunk 1805: to Lebesgue measure). Furthermore, computing this\n",
            "Chunk 1806: density\n",
            "Chunk 1807: is usually intractable, while generating i.i.d.\n",
            "Chunk 1808: samples from αθis achieved by computing xi=hθ(zi)\n",
            "Chunk 1809: where\n",
            "Chunk 1810: (zi)iare i.i.d. samples from ζ.\n",
            "Chunk 1811: In order to cope with such diﬃcult scenario, one\n",
            "Chunk 1812: has to use weak metrics in place of the MLE\n",
            "Chunk 1813: functional\n",
            "Chunk 1814: LMLE, which needs to be written in dual form as\n",
            "Chunk 1815: L(α,β)def.= max\n",
            "(f,g)∈C(X)2{∫\n",
            "Xf(x)dα(x) +∫\n",
            "Chunk 1816: Xg(x)dβ(x) ; (f,g)∈R}\n",
            ". (1.82)\n",
            "Chunk 1817: Dual norms exposed in §??correspond to imposing\n",
            "Chunk 1818: R={(f,−f) ;f∈B}, while optimal transport (1.21)\n",
            "Chunk 1819: setsR=R(c) as deﬁned in (1.22).\n",
            "28\n",
            "Chunk 1820: For a ﬁxed θ, evaluating the energy to be\n",
            "Chunk 1821: minimized in (1.81) using such a loss function\n",
            "Chunk 1822: corresponds to\n",
            "Chunk 1823: solving a semi-discrete optimal transport, which\n",
            "Chunk 1824: is the focus of Chapter ??. Minimizing the energy\n",
            "Chunk 1825: with\n",
            "Chunk 1826: respect toθis much more involved, and is\n",
            "Chunk 1827: typically highly non-convex.\n",
            "Chunk 1828: The class of estimators obtained using L=Lc,\n",
            "Chunk 1829: often called “Minimum Kantorovitch Estimators”\n",
            "Chunk 1830: (MKE),\n",
            "Chunk 1831: was initially introduced in [ ?], see also [ ?].\n",
            "Chunk 1832: Gromov-Wasserstein. Optimal transport needs a\n",
            "Chunk 1833: ground cost Cto compare histograms ( a,b), it can\n",
            "Chunk 1834: thus not be used if the histograms are not deﬁned\n",
            "Chunk 1835: on the same underlying space, or if one cannot\n",
            "Chunk 1836: pre-register\n",
            "Chunk 1837: these spaces to deﬁne a ground cost. To address\n",
            "Chunk 1838: this issue, one can instead only assume a weaker\n",
            "Chunk 1839: assumption,\n",
            "Chunk 1840: namely that one has at its disposal two matrices\n",
            "Chunk 1841: D∈Rn×nandD′∈Rm×mthat represent some relationship\n",
            "Chunk 1842: between the points on which the histograms are\n",
            "Chunk 1843: deﬁned. A typical scenario is when these matrices\n",
            "Chunk 1844: are (power\n",
            "Chunk 1845: of) distance matrices. The Gromov-Wasserstein\n",
            "Chunk 1846: problem reads\n",
            "Chunk 1847: GW(( a,D),(b,D′))2def.= min\n",
            "Chunk 1848: P∈U(a,b)ED,D′(P)def.=∑\n",
            "i,j,i′,j′|Di,i′−D′\n",
            "Chunk 1849: j,j′|2Pi,jPi′,j′. (1.83)\n",
            "Chunk 1850: This is a non-convex problem, which can be recast\n",
            "Chunk 1851: as a Quadratic Assignment Problem (QAP) [ ?] and\n",
            "Chunk 1852: is in\n",
            "Chunk 1853: full generality NP-hard to solve for arbitrary\n",
            "Chunk 1854: inputs. It is in fact equivalent to a graph\n",
            "Chunk 1855: matching problem [ ?]\n",
            "Chunk 1856: for a particular cost.\n",
            "Chunk 1857: One can show that GW satisﬁes the triangular\n",
            "Chunk 1858: inequality, and in fact it deﬁnes a distance\n",
            "Chunk 1859: between\n",
            "Chunk 1860: metric spaces equipped with a probability\n",
            "Chunk 1861: distribution (here assumed to be discrete in\n",
            "Chunk 1862: deﬁnition (1.83))\n",
            "Chunk 1863: up to isometries preserving the measures. This\n",
            "Chunk 1864: distance was introduced and studied in details by\n",
            "Chunk 1865: Memoli\n",
            "Chunk 1866: in [?]. An in-depth mathematical exposition (in\n",
            "Chunk 1867: particular, its geodesic structure and gradient\n",
            "Chunk 1868: ﬂows) is given\n",
            "Chunk 1869: in [?]. See also [ ?] for applications in\n",
            "Chunk 1870: computer vision. This distance is also tightly\n",
            "Chunk 1871: connected with the\n",
            "Chunk 1872: Gromov-Hausdorﬀ distance [ ?] between metric\n",
            "Chunk 1873: spaces, which have been used for shape matching [\n",
            "Chunk 1874: ?,?].\n",
            "Chunk 1875: Remark 19.Gromov-Wasserstein distance The general\n",
            "Chunk 1876: setting corresponds to computing couplings\n",
            "Chunk 1877: between\n",
            "Chunk 1878: metric measure spaces ( X,dX,αX) and (Y,dY,αY)\n",
            "Chunk 1879: where (dX,dY) are distances and ( αX,αY) are\n",
            "Chunk 1880: measures\n",
            "Chunk 1881: on their respective spaces. One deﬁnes\n",
            "Chunk 1882: GW((αX,dX),(αY,dY))2def.= min\n",
            "π∈U(αX,αY)∫\n",
            "Chunk 1883: X2×Y2|dX(x,x′)−dY(y,y′)|2dπ(x,y)dπ(x′,y′). (1.84)\n",
            "Chunk 1884: GW deﬁnes a distance between metric measure\n",
            "Chunk 1885: spaces up to isometries, where one says that (\n",
            "Chunk 1886: αX,dX) and\n",
            "Chunk 1887: (αY,dY) are isometric if there exists ϕ:X→Y such\n",
            "Chunk 1888: thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′)) =dX(x,x′).\n",
            "Chunk 1889: Remark 20.Gromov-Wasserstein geodesics The space\n",
            "Chunk 1890: of metric spaces (up to isometries) endowed with\n",
            "Chunk 1891: thisGW distance (1.84) has a geodesic structure.\n",
            "Chunk 1892: [ ?] shows that the geodesic between ( X0,dX0,α0)\n",
            "Chunk 1893: and\n",
            "Chunk 1894: (X1,dX1,α1) can be chosen to be t∈[0,1]↦→(X0×X\n",
            "Chunk 1895: 1,dt,π⋆) whereπ⋆is a solution of (1.84) and for\n",
            "Chunk 1896: all\n",
            "Chunk 1897: ((x0,x1),(x′\n",
            "0,x′\n",
            "1))∈(X0×X 1)2,\n",
            "dt((x0,x1),(x′\n",
            "Chunk 1898: 0,x′\n",
            "1))def.= (1−t)dX0(x0,x′\n",
            "0) +tdX1(x1,x′\n",
            "1).\n",
            "Chunk 1899: This formula allows one to deﬁne and analyze\n",
            "Chunk 1900: gradient ﬂows which minimize functionals\n",
            "Chunk 1901: involving metric\n",
            "Chunk 1902: spaces, see [ ?]. It is however diﬃcult to handle\n",
            "Chunk 1903: numerically, because it involves computations\n",
            "Chunk 1904: over the product\n",
            "Chunk 1905: spaceX0×X 1. A heuristic approach is used in [ ?]\n",
            "Chunk 1906: to deﬁne geodesics and barycenters of metric\n",
            "Chunk 1907: measure\n",
            "Chunk 1908: spaces while imposing the cardinality of the\n",
            "Chunk 1909: involved spaces and making use of the entropic\n",
            "Chunk 1910: smoothing (1.85)\n",
            "Chunk 1911: detailed below.\n",
            "Chunk 1912: To approximate the computation of GW, and to help\n",
            "Chunk 1913: convergence of minimization schemes to better\n",
            "Chunk 1914: minima, one can consider the entropic regularized\n",
            "Chunk 1915: variant\n",
            "Chunk 1916: min\n",
            "P∈U(a,b)ED,D′(P)−εH(P). (1.85)\n",
            "29\n",
            "Chunk 1917: Figure 1.17: Example of fuzzy correspondences\n",
            "Chunk 1918: computed by solving GW problem (1.85) with\n",
            "Chunk 1919: Sinkhorn\n",
            "Chunk 1920: iterations (1.86). Extracted from [ ?].\n",
            "Chunk 1921: As proposed initially in [ ?,?], and later\n",
            "Chunk 1922: revisited in [ ?] for applications in graphics,\n",
            "Chunk 1923: one can use iteratively\n",
            "Chunk 1924: Sinkhorn’s algorithm to progressively compute a\n",
            "Chunk 1925: stationary point of (1.85). Indeed, successive\n",
            "Chunk 1926: linearizations\n",
            "Chunk 1927: of the objective function lead to consider the\n",
            "Chunk 1928: succession of updates\n",
            "Chunk 1929: P(ℓ+1) def.= min\n",
            "Chunk 1930: P∈U(a,b)⟨P,C(ℓ)⟩−εH(P) where (1.86)\n",
            "Chunk 1931: C(ℓ)def.=∇ED,D′(P(ℓ)) =−D′TP(ℓ)D,\n",
            "Chunk 1932: which can be interpreted as a mirror-descent\n",
            "Chunk 1933: scheme [ ?]. Each update can thus be solved using\n",
            "Chunk 1934: Sinkhorn\n",
            "Chunk 1935: iterations (1.51) with cost C(ℓ). Figure (1.17)\n",
            "Chunk 1936: illustrates the use of this entropic\n",
            "Chunk 1937: Gromov-Wasserstein to\n",
            "Chunk 1938: compute soft maps between domains.\n",
            "30\n",
            "Chunk 1939: Bibliography\n",
            "Chunk 1940: [1] Amir Beck. Introduction to Nonlinear\n",
            "Chunk 1941: Optimization: Theory, Algorithms, and\n",
            "Chunk 1942: Applications with MAT-\n",
            "Chunk 1943: LAB. SIAM, 2014.\n",
            "Chunk 1944: [2] Stephen Boyd, Neal Parikh, Eric Chu, Borja\n",
            "Chunk 1945: Peleato, and Jonathan Eckstein. Distributed\n",
            "Chunk 1946: optimization\n",
            "Chunk 1947: and statistical learning via the alternating\n",
            "Chunk 1948: direction method of multipliers. Foundations and\n",
            "Chunk 1949: Trends R⃝\n",
            "Chunk 1950: in Machine Learning , 3(1):1–122, 2011.\n",
            "Chunk 1951: [3] Stephen Boyd and Lieven Vandenberghe. Convex\n",
            "Chunk 1952: optimization . Cambridge university press, 2004.\n",
            "Chunk 1953: [4] E. Cand` es and D. Donoho. New tight frames\n",
            "Chunk 1954: of curvelets and optimal representations of\n",
            "Chunk 1955: objects with\n",
            "Chunk 1956: piecewise C2singularities. Commun. on Pure and\n",
            "Chunk 1957: Appl. Math. , 57(2):219–266, 2004.\n",
            "Chunk 1958: [5] E. J. Cand` es, L. Demanet, D. L. Donoho, and\n",
            "Chunk 1959: L. Ying. Fast discrete curvelet transforms. SIAM\n",
            "Chunk 1960: Multiscale Modeling and Simulation , 5:861–899,\n",
            "Chunk 1961: 2005.\n",
            "Chunk 1962: [6] A. Chambolle. An algorithm for total\n",
            "Chunk 1963: variation minimization and applications. J. Math.\n",
            "Chunk 1964: Imaging Vis. ,\n",
            "Chunk 1965: 20:89–97, 2004.\n",
            "Chunk 1966: [7] Antonin Chambolle, Vicent Caselles, Daniel\n",
            "Chunk 1967: Cremers, Matteo Novaga, and Thomas Pock. An\n",
            "Chunk 1968: intro-\n",
            "Chunk 1969: duction to total variation for image analysis.\n",
            "Chunk 1970: Theoretical foundations and numerical methods for\n",
            "Chunk 1971: sparse\n",
            "Chunk 1972: recovery , 9(263-340):227, 2010.\n",
            "Chunk 1973: [8] Antonin Chambolle and Thomas Pock. An\n",
            "Chunk 1974: introduction to continuous optimization for\n",
            "Chunk 1975: imaging. Acta\n",
            "Chunk 1976: Numerica , 25:161–319, 2016.\n",
            "Chunk 1977: [9] S.S. Chen, D.L. Donoho, and M.A. Saunders.\n",
            "Chunk 1978: Atomic decomposition by basis pursuit. SIAM\n",
            "Chunk 1979: Journal\n",
            "Chunk 1980: on Scientiﬁc Computing , 20(1):33–61, 1999.\n",
            "Chunk 1981: [10] Philippe G Ciarlet. Introduction ` a\n",
            "Chunk 1982: l’analyse num´ erique matricielle et ` a\n",
            "Chunk 1983: l’optimisation. 1982.\n",
            "Chunk 1984: [11] P. L. Combettes and V. R. Wajs. Signal\n",
            "Chunk 1985: recovery by proximal forward-backward splitting.\n",
            "Chunk 1986: SIAM\n",
            "Chunk 1987: Multiscale Modeling and Simulation , 4(4), 2005.\n",
            "Chunk 1988: [12] I. Daubechies, M. Defrise, and C. De Mol. An\n",
            "Chunk 1989: iterative thresholding algorithm for linear\n",
            "Chunk 1990: inverse problems\n",
            "Chunk 1991: with a sparsity constraint. Commun. on Pure and\n",
            "Chunk 1992: Appl. Math. , 57:1413–1541, 2004.\n",
            "Chunk 1993: [13] D. Donoho and I. Johnstone. Ideal spatial\n",
            "Chunk 1994: adaptation via wavelet shrinkage. Biometrika ,\n",
            "Chunk 1995: 81:425–455,\n",
            "Chunk 1996: Dec 1994.\n",
            "Chunk 1997: [14] Heinz Werner Engl, Martin Hanke, and Andreas\n",
            "Chunk 1998: Neubauer. Regularization of inverse problems ,\n",
            "Chunk 1999: volume\n",
            "Chunk 2000: 375. Springer Science & Business Media, 1996.\n",
            "Chunk 2001: [15] M. Figueiredo and R. Nowak. An EM Algorithm\n",
            "Chunk 2002: for Wavelet-Based Image Restoration. IEEE Trans.\n",
            "Chunk 2003: Image Proc. , 12(8):906–916, 2003.\n",
            "Chunk 2004: [16] Simon Foucart and Holger Rauhut. A\n",
            "Chunk 2005: mathematical introduction to compressive sensing\n",
            "Chunk 2006: , volume 1.\n",
            "Chunk 2007: Birkh¨ auser Basel, 2013.\n",
            "31\n",
            "Chunk 2008: [17] Stephane Mallat. A wavelet tour of signal\n",
            "Chunk 2009: processing: the sparse way . Academic press,\n",
            "Chunk 2010: 2008.\n",
            "Chunk 2011: [18] D. Mumford and J. Shah. Optimal\n",
            "Chunk 2012: approximation by piecewise smooth functions and\n",
            "Chunk 2013: associated varia-\n",
            "Chunk 2014: tional problems. Commun. on Pure and Appl. Math.\n",
            "Chunk 2015: , 42:577–685, 1989.\n",
            "Chunk 2016: [19] Neal Parikh, Stephen Boyd, et al. Proximal\n",
            "Chunk 2017: algorithms. Foundations and Trends R⃝in\n",
            "Chunk 2018: Optimization ,\n",
            "Chunk 2019: 1(3):127–239, 2014.\n",
            "Chunk 2020: [20] Gabriel Peyr´ e. L’alg` ebre discr` ete de\n",
            "Chunk 2021: la transform´ ee de Fourier . Ellipses, 2004.\n",
            "Chunk 2022: [21] J. Portilla, V. Strela, M.J. Wainwright, and\n",
            "Chunk 2023: Simoncelli E.P. Image denoising using scale\n",
            "Chunk 2024: mixtures of\n",
            "Chunk 2025: Gaussians in the wavelet domain. IEEE Trans.\n",
            "Chunk 2026: Image Proc. , 12(11):1338–1351, November 2003.\n",
            "Chunk 2027: [22] L. I. Rudin, S. Osher, and E. Fatemi.\n",
            "Chunk 2028: Nonlinear total variation based noise removal\n",
            "Chunk 2029: algorithms. Phys.\n",
            "Chunk 2030: D, 60(1-4):259–268, 1992.\n",
            "Chunk 2031: [23] Otmar Scherzer, Markus Grasmair, Harald\n",
            "Chunk 2032: Grossauer, Markus Haltmeier, Frank Lenzen, and L\n",
            "Chunk 2033: Sirovich.\n",
            "Chunk 2034: Variational methods in imaging . Springer, 2009.\n",
            "Chunk 2035: [24] C. E. Shannon. A mathematical theory of\n",
            "Chunk 2036: communication. The Bell System Technical Journal\n",
            "Chunk 2037: ,\n",
            "Chunk 2038: 27(3):379–423, 1948.\n",
            "Chunk 2039: [25] Jean-Luc Starck, Fionn Murtagh, and Jalal\n",
            "Chunk 2040: Fadili. Sparse image and signal processing:\n",
            "Chunk 2041: Wavelets and\n",
            "Chunk 2042: related geometric multiscale analysis . Cambridge\n",
            "Chunk 2043: university press, 2015.\n",
            "Chunk 2044: 32\n",
            "\n",
            "Char count chunking with custom delimiter:\n",
            "Chunk 1: Mathematical Foundations of Data Sciences\n",
            "Gabriel Peyr´ e\n",
            "CNRS & DMA\n",
            "´Ecole Normale Sup´ erieure\n",
            "gabriel.peyre\n",
            "Chunk 2: ens.fr\n",
            "https://mathematical-tours.github.io\n",
            "www.numerical-tours.com\n",
            "August 14, 2019\n",
            "2\n",
            "Chapter 1\n",
            "Optimal Transport\n",
            "1.1 Radon Measures\n",
            "Measures. We will interchangeably the term histogram or probability vector for any element a∈Σnthat\n",
            "belongs to the probability simplex\n",
            "Σndef.={\n",
            "a∈Rn\n",
            "+;n∑\n",
            "i=1ai= 1}\n",
            ".\n",
            "A discrete measure with weights aand locations x1,...,xn∈X reads\n",
            "α=n∑\n",
            "i=1aiδxi (1.1)\n",
            "whereδxis the Dirac at position x, intuitively a unit of mass which is inﬁnitely concentrated at location\n",
            "x. Such as measure describes a probability measure if, additionally, a∈Σn, and more generally a positive\n",
            "measure if each of the “weights” described in vector ais positive itself.\n",
            "Remark 1 (General measures) .A convenient feature of OT is that it can deal with discrete and continuous\n",
            "“objects” within the same framework. Such objects only need to be modelled as measures. This corresponds\n",
            "to the notion of Radon measures M(X) on the spaceX. The formal deﬁnition of that set requires that Xis\n",
            "equipped with a distance, usually denoted d, because one can only access a measure by “testing” (integrating)\n",
            "it against continuous functions, denoted f∈C(X).\n",
            "Integration of f∈C(X) against a discrete measure αcomputes a sum\n",
            "∫\n",
            "Xf(x)dα(x) =n∑\n",
            "i=1aif(xi).\n",
            "More general measures, for instance on X=Rd(whered∈N∗is the dimension), can have a density\n",
            "dα(x) =ρα(x)dxw.r.t. the Lebesgue measure, often denoted ρα=dα\n",
            "dx, which means that\n",
            "∀h∈C(Rd),∫\n",
            "Rdh(x)dα(x) =∫\n",
            "Rdh(x)ρα(x)dx.\n",
            "An arbitrary measure α∈M (X) (which needs not to have a density nor be a sum of Diracs) is deﬁned by\n",
            "the fact that it can be integrated agains any continuous function f∈C(X) and obtain∫\n",
            "Xf(x)dα(x)∈R.\n",
            "IfXis not compact, one should also impose that fhas compact support or at least as 0 limit at inﬁnity.\n",
            "Measure as thus in some sense “less regular” than functions, but more regular than distributions (which are\n",
            "dual to smooth functions). For instance, the derivative of a Dirac is not a measure. We denote M+(X) the\n",
            "set of all positive measures on X. The set of probability measures is denoted M1\n",
            "+(X), which means that\n",
            "anyα∈M1\n",
            "+(X) is positive, and that α(X) =∫\n",
            "Xdα= 1. Figure 1.1 oﬀers a visualization of the diﬀerent\n",
            "classes of measures, beyond histograms, considered in this work.\n",
            "3\n",
            "Discreted= 1 Discrete d= 2 Density d= 1 Density d= 2\n",
            "Figure 1.1: Schematic display of discrete distributions α=∑n\n",
            "i=1aiδxi(red corresponds to empirical uniform\n",
            "distribution ai= 1/n, and blue to arbitrary distributions) and densities d α(x) =ρα(x)dx(in violet), in both\n",
            "1-D and 2-D. Discrete distributions in 1-D are displayed using vertical segments (with length equal to ai)\n",
            "and in 2-D using point clouds (radius equal to ai).\n",
            "Operators on measures. For some continuous map T:X →Y , we deﬁne the pushforward operator\n",
            "T♯:M(X)→M (Y). For discrete measures (1.1), the pushforward operation consists simply in moving the\n",
            "positions of all the points in the support of the measure\n",
            "T♯αdef.=∑\n",
            "iaiδT(xi).\n",
            "For more general measures, for instance for those with a density, the notion of push-forward plays a funda-\n",
            "mental to describe spatial modiﬁcations of probability measures. The formal deﬁnition reads as follow.\n",
            "Deﬁnition 1 (Push-forward) .ForT:X → Y , the push forward measure β=T♯α∈ M (Y)of some\n",
            "α∈M (X)reads\n",
            "∀h∈C(Y),∫\n",
            "Yh(y)dβ(y) =∫\n",
            "Xh(T(x))dα(x). (1.2)\n",
            "Equivalently, for any measurable set B⊂Y, one has\n",
            "β(B) =α({x∈X;T(x)∈B}). (1.3)\n",
            "Note thatT♯preserves positivity and total mass, so that if α∈M1\n",
            "+(X)thenT♯α∈M1\n",
            "+(Y).\n",
            "Intuitively, a measurable map T:X→Y , can be interpreted as a function “moving” a single point from a\n",
            "measurable space to another. The more general extension T♯can now “move” an entire probability measure\n",
            "onXtowards a new probability measure on Y. The operator T♯“pushes forward” each elementary mass of\n",
            "a measureαonXby applying the map Tto obtain then an elementary mass in Y, to build on aggregate a\n",
            "new measure onY) writtenT♯α. Note that such a push-forward T♯:M1\n",
            "+(X)→M1\n",
            "+(Y) is a linear operator\n",
            "between measures in the sense that for two measures α1,α2onX,T♯(α1+α2) =T♯α1+T♯α2.\n",
            "Remark 2 (Push-forward for densities) .Explicitly doing the change of variable in formula (1.2) for measures\n",
            "with densities ( ρα,ρβ) onRd(assumingTis smooth and a bijection) shows that a push-forward acts on\n",
            "densities linearly as a change of variables in the integration formula, indeed\n",
            "ρα(x) =|det(T′(x))|ρβ(T(x)) (1.4)\n",
            "whereT′(x)∈Rd×dis the Jacobian matrix of T(the matrix formed by taking the gradient of each coordinate\n",
            "ofT). This implies, denoting y=T(x)\n",
            "|det(T′(x))|=ρα(x)\n",
            "ρβ(y).\n",
            "4\n",
            "=Pi\u0000xiT↵T]↵def.=Pi\u0000T(xi)\n",
            "TT]gdef.=g\u0000TgPush-forward of measures Pull-back of functions\n",
            "Figure 1.2: Comparison of push-forward T♯and pull-back T♯.\n",
            "Remark 3 (Push-forward vs. pull-back) .The push-forward T♯of measures should not be confounded with\n",
            "the pull-back of function T♯:C(Y)→C(X) which corresponds to the “warping” of functions. It is the linear\n",
            "map deﬁned, for g∈C(Y) byT♯g=g◦T. Push-forward and pull-back are actually adjoint one from each\n",
            "others, in the sense that\n",
            "∀(α,g)∈M (X)×C(Y),∫\n",
            "Ygd(T♯α) =∫\n",
            "X(T♯g)dα.\n",
            "It is important to realize that even if ( α,β) have densities ( ρα,ρβ),T♯αis not equal to T♯ρβ, because of\n",
            "the presence of the Jacobian in (1.4). This explains why OT should be used with caution to perform image\n",
            "registration, because it does not operate as an image warping method. Figure 1.2 illustrate the distinction\n",
            "between these push-forward and pull-back operators.\n",
            "Remark 4 (Measures and random variables) .Radon measures can also be viewed as representing the distri-\n",
            "butions of random variables. A random variable XonXis actually a map X: Ω→X from some abstract\n",
            "(often un-speciﬁed) probabized space (Ω ,P), and its distribution αis the Radon measure X∈M1\n",
            "+(X) such\n",
            "thatP(X∈A) =α(A) =∫\n",
            "Adα(x). Equivalently, it is the push-forward of PbyX,α=X♯P. Applying\n",
            "another push-forward β=T♯αforT:X →Y , following (1.2), is equivalent to deﬁning another random\n",
            "variableY=T(X) :ω∈Ω→T(X(ω))∈Y, so thatβis the distribution of Y. Drawing a random sample\n",
            "yfromYis thus simply achieved by computing y=T(x) wherexis drawn from X.\n",
            "Convergence of random variable. Convergence of random variable (in probability, almost sure, in law),\n",
            "convergence of measures (strong, weak).\n",
            "1.2 Monge Problem\n",
            "Given a cost matrix ( Ci,j)i∈JnK,j∈JmK, assuming n=m, the optimal assignment problem seeks for a\n",
            "bijectionσin the set Perm( n) of permutations of nelements solving\n",
            "min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i). (1.5)\n",
            "One could naively evaluate the cost function above using all permutations in the set Perm( n). However,\n",
            "that set has size n!, which is gigantic even for small n. Consider for instance that such a set has more than\n",
            "10100elements [ ?] whennis as small as 70. That problem can therefore only be solved if there exist eﬃcient\n",
            "algorithms to optimize that cost function over the set of permutations, which will be the subject of §??.\n",
            "5\n",
            "x1x2y1y2x1x2y1y2x4x5x6x3y3x7Figure 1.3: (left) blue dots from measure αand red dots from measure βare pairwise equidistant. Hence,\n",
            "either matching σ= (1,2) (full line) or σ= (2,1) (dotted line) is optimal. (right) a Monge map can associate\n",
            "the blue measure αto the red measure β. The weights αiare displayed proportionally to the area of the\n",
            "disk marked at each location. The mapping here is such that T(x1) =T(x2) =y2,T(x3) =y3, whereas for\n",
            "4⩽i⩽7 we haveT(xi) =y1.\n",
            "Remark 5 (Uniqueness) .Note that the optimal assignment problem may have several optimal solutions.\n",
            "Suppose for instance that n=m= 2 and that the matrix Cis the pairwise distance matrix between the 4\n",
            "corners of a 2-dimensional square of side length 1, as represented in the left plot in Figure 1.3. In that case\n",
            "only two assignments exist, and they share the same cost.\n",
            "For discrete measures\n",
            "α=n∑\n",
            "i=1aiδxiandβ=m∑\n",
            "j=1bjδyj (1.6)\n",
            "the Monge problem [ ?] seeks for a map that associates to each point xia single point yj, and which must\n",
            "push the mass of αtoward the mass of β, which is to say that such a map T:{x1,...,xn}→{y1,...,ym}\n",
            "must verify that\n",
            "∀j∈JmK,bj=∑\n",
            "i:T(xi)=yjai (1.7)\n",
            "which we write in compact form as T♯α=β. This map should minimize some transportation cost, which is\n",
            "parameterized by a function c(x,y) deﬁned for points ( x,y)∈X×Y\n",
            "min\n",
            "T{∑\n",
            "ic(xi,T(xi)) ;T♯α=β}\n",
            ". (1.8)\n",
            "Such a map between discrete points can be of course encoded, assuming all x’s andy’s are distinct, using\n",
            "indicesσ:JnK→JmKso thatj=σ(i), and the mass conservation is written as\n",
            "∑\n",
            "i∈σ−1(j)ai=bj.\n",
            "In the special case when n=mand all weights are uniform, that is ai=bj= 1/n, then the mass conservation\n",
            "constraint implies that Tis a bijection, such that T(xi) =yσ(i), and the Monge problem is equivalent to the\n",
            "optimal matching problem (1.5) where the cost matrix is\n",
            "Ci,jdef.=c(xi,yj).\n",
            "Whenn̸=m, note that, optimality aside, Monge maps may not even exist between an empirical measure\n",
            "to another. This happens when their weight vectors are not compatible, which is always the case when the\n",
            "target measure has more points than the source measure. For instance, the right plot in Figure 1.3 shows\n",
            "an (optimal) Monge map between αandβ, but there is no Monge map from βtoα.\n",
            "6\n",
            "Monge problem (1.8) is extended to the setting of two arbitrary probability measures ( α,β) on two spaces\n",
            "(X,Y) as ﬁnding a map T:X→Y that minimizes\n",
            "min\n",
            "T{∫\n",
            "Xc(x,T(x))dα(x) ;T♯α=β}\n",
            "(1.9)\n",
            "The constraint T♯α=βmeans that Tpushes forward the mass of αtoβ, and makes use of the push-forward\n",
            "operator (1.2).\n",
            "1.3 Kantorovitch Problem\n",
            "The assignment problem has several limitations in practical settings, also encountered when using the\n",
            "Monge problem. Indeed, because the assignment problem is formulated as a permutation problem, it can only\n",
            "be used to compare two points clouds of the same size. A direct generalization to discrete measures with non-\n",
            "uniform weights can be carried out using Monge’s formalism of pushforward maps, but that formulation may\n",
            "also be degenerate it there does not exist feasible solutions satisfying the mass conservation constraint (1.7)\n",
            "(see the end of Remark ??). Additionally, the assignment Problem (1.8) is combinatorial, whereas the feasible\n",
            "set for the Monge Problem (1.9), consisting in all push-forward measures that satisfy the mass conservation\n",
            "constraint, is non-convex . Both are therefore diﬃcult to solve in their original formulation.\n",
            "Kantorovitch formulation for discrete measures. The key idea of [ ?] is to relax the deterministic na-\n",
            "ture of transportation, namely the fact that a source point xican only be assigned to another, or transported\n",
            "to one and one location T(xi) only. Kantorovich proposes instead that the mass at any point xibe potentially\n",
            "dispatched across several locations. Kantorovich moves away from the idea that mass transportation should\n",
            "be “deterministic” to consider instead a “probabilistic” (or “fuzzy”) transportation, which allows what is\n",
            "commonly known now as “mass splitting” from a source towards several targets. This ﬂexibility is encoded\n",
            "using, in place of a permutation σor a mapT, a coupling matrix P∈Rn×m\n",
            "+, where Pi,jdescribes the\n",
            "amount of mass ﬂowing from bin i(or pointxi) towards bin j(or pointxj),xitowardsyjin the formalism\n",
            "of discrete measures (1.6). Admissible couplings admit a far simpler characterization than Monge maps:\n",
            "U(a,b)def.={\n",
            "P∈Rn×m\n",
            "+ ;P1m=aand PT1n=b}\n",
            ", (1.10)\n",
            "where we used the following matrix-vector notation\n",
            "P1m=\n",
            "∑\n",
            "jPi,j\n",
            "\n",
            "i∈Rnand PT1n=(∑\n",
            "iPi,j)\n",
            "j∈Rm.\n",
            "The set of matrices U(a,b) is bounded, deﬁned by n+mequality constraints, and therefore a convex\n",
            "polytope (the convex hull of a ﬁnite set of matrices).\n",
            "Additionally, whereas the Monge formulation (as illustrated in the right plot of Figure 1.3) was intrisically\n",
            "asymmetric, Kantorovich’s relaxed formulation is always symmetric, in the sense that a coupling Pis in\n",
            "U(a,b) if and only if PTis inU(b,a).\n",
            "Kantorovich’s optimal transport problem now reads\n",
            "LC(a,b)def.= min\n",
            "P∈U(a,b)⟨C,P⟩def.=∑\n",
            "i,jCi,jPi,j. (1.11)\n",
            "This is a linear program (see Chapter ??), and as is usually the case with such programs, its solutions are\n",
            "not necessarily unique.\n",
            "7\n",
            "↵\u0000\n",
            "↵\u0000Figure 1.4: Comparison of optimal matching and generic couplings. A black segment between xiandyj\n",
            "indicates a non-zero element in the displayed optimal coupling Pi,jsolving (1.11). Left: optimal matching,\n",
            "corresponding to the setting of Proposition (1) (empirical measures with the same number n=mof points).\n",
            "Right: these two weighted point clouds cannot be matched; instead a Kantorovich coupling can be used to\n",
            "associate two arbitrary discrete measures.\n",
            "Permutation Matrices as Couplings For a permutation σ∈Perm(n), we write Pσfor the correspond-\n",
            "ing permutation matrix,\n",
            "∀(i,j)∈JnK2,(Pσ)i,j={1/n ifj=σi,\n",
            "0 otherwise.(1.12)\n",
            "One can check that in that case\n",
            "⟨C,Pσ⟩=1\n",
            "nn∑\n",
            "i=1Ci,σi,\n",
            "which shows that the assignment problem (1.5) can be recast as a Kantorovich problem (1.11) where the\n",
            "couplings Pare restricted to be exactly permutation matrices:\n",
            "min\n",
            "σ∈Perm(n)1\n",
            "nn∑\n",
            "i=1Ci,σ(i)= min\n",
            "σ∈Perm(n)⟨C,Pσ⟩.\n",
            "Next, one can easily check that the set of permutation matrices is strictly included in the so-called Birkhoﬀ\n",
            "polytope U(1n/n,1n,n). Indeed, for any permutation σwe have Pσ1=1nandPσT1=1n, whereas\n",
            "1n1nT/n2is a valid coupling but not a permutation matrix. Therefore, one has naturally that\n",
            "min\n",
            "σ∈Perm(n)⟨C,Pσ⟩⩽LC(1n/n,1n/n).\n",
            "The following proposition shows that these problems result in fact in the same optimum, namely that\n",
            "one can always ﬁnd a permutation matrix that minimizes Kantorovich’s problem (1.11) between two uniform\n",
            "measures a=b=1n/n, which shows that the Kantorovich relaxation is tight when considered on assignment\n",
            "problems. Figure 1.4 shows on the left a 2-D example of optimal matching corresponding to this special\n",
            "case.\n",
            "Proposition 1 (Kantorovich for matching) .Ifm=nanda=b=1n/n, then there exists an optimal\n",
            "solution for Problem (1.11) Pσ⋆, which is a permutation matrix associated to an optimal permutation σ⋆∈\n",
            "Perm(n)for Problem (1.5) .\n",
            "Proof. Birkhoﬀ’s theorem states that the set of extremal points of U(1n/n,1n/n) is equal to the set of\n",
            "permutation matrices. A fundamental theorem of linear programming [ ?, Theorem 2.7] states that the\n",
            "minimum of a linear objective in a non-empty polyhedron, if ﬁnite, is reached at an extremal point of the\n",
            "polyhedron.\n",
            "8\n",
            "⇡\u0000↵\u0000↵\n",
            "⇡\u0000↵\u0000↵\n",
            "⇡\u0000↵\u0000↵\n",
            "Discrete Semi-discrete Continuous\n",
            "Figure 1.5: Schematic viewed of input measures ( α,β) and couplingsU(α,β) encountered in the three main\n",
            "scenario for Kantorovich OT. Chapter ??is dedicated to the semi-discrete setup.\n",
            "⇡\u0000↵\n",
            "⇡\u0000↵\n",
            "Figure 1.6: Left: “continuous” coupling πsolving (1.13) between two 1-D measure with density. The\n",
            "coupling is localized along the graph of the Monge map ( x,T(x)) (displayed in black). Right: “discrete”\n",
            "couplingTsolving (1.11) between two discrete measures of the form (1.6). The non-zero entries Ti,jare\n",
            "display with a black disk at position ( i,j) with radius proportional to Ti,j.\n",
            "Kantorovitch formulation for arbitrary measures. The deﬁnition of Lcin (??) can be extended to\n",
            "arbitrary measures by considering couplings π∈M1\n",
            "+(X×Y ) which are joint distributions over the product\n",
            "space. The discrete case is a special situation where one imposes this product measure to be of the form\n",
            "π=∑\n",
            "i,jPi,jδ(xi,yj). In the general case, the mass conservation constraint (1.10) should be rewritten as a\n",
            "marginal constraint on joint probability distributions\n",
            "U(α,β)def.={\n",
            "π∈M1\n",
            "+(X×Y ) ;PX♯π=αandPY♯π=β}\n",
            ". (1.13)\n",
            "HerePX♯andPY♯are the push-forward (see Deﬁnition 1) by the projections PX(x,y) =xandPY(x,y) =y.\n",
            "Figure 1.5 shows a schematic visualization of the coupling constraints for diﬀerent class of problem (discrete\n",
            "measures and densities). Using (1.3), these marginal constraints are equivalent to imposing that π(A×Y) =\n",
            "α(A) andπ(X×B) =β(B) for setsA⊂X andB⊂Y.\n",
            "The Kantorovich problem (1.11) is then generalized as\n",
            "Lc(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "X×Yc(x,y)dπ(x,y). (1.14)\n",
            "This is an inﬁnite-dimensional linear program over a space of measures. Figure 1.6 shows examples of discrete\n",
            "and continuous optimal coupling solving (1.14). Figure 1.7 shows other examples of optimal 1-D couplings,\n",
            "involving discrete and continuous marginals.\n",
            "On compact domain ( X,Y), (1.14) always has a solution, because using the weak-* topology (so called\n",
            "weak topology of measures), the set of measure is compact, and a linear function with a continuous c(x,y)\n",
            "9\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "\u0000↵\u0000↵⇡\n",
            "↵\u0000↵⇡\u0000Figure 1.7: Four simple examples of optimal couplings between 1-D distributions, represented as maps\n",
            "above (arrows) and couplings below. Inspired by [ ?].\n",
            "is weak-* continuous. And the set of constraint is non empty, taking α⊗β. On non compact domain, needs\n",
            "to impose moment condition on αandβ.\n",
            "Wasserstein distances. An important feature of OT is that it deﬁnes a distance between histograms\n",
            "and probability measures as soon as the cost matrix satisﬁes certain suitable properties. Indeed, OT can be\n",
            "understood as a canonical way to lift a ground distance between points to a distance between histogram or\n",
            "measures.\n",
            "We ﬁrst consider the case where, using a term ﬁrst introduce by [ ?], the “ground metric” matrix C\n",
            "is ﬁxed, representing substitution costs between bins, and shared across several histograms we would like\n",
            "to compare. The following proposition states that OT provides a meaningful distance between histograms\n",
            "supported on these bins.\n",
            "Proposition 2. We suppose n=m, and that for some p⩾1,C=Dp= (Dp\n",
            "i,j)i,j∈Rn×nwhere D∈Rn×n\n",
            "+\n",
            "is a distance on JnK,i.e.\n",
            "1.D∈Rn×n\n",
            "+ is symmetric;\n",
            "2.Di,j= 0if and only if i=j;\n",
            "3.∀(i,j,k )∈JnK3,Di,k⩽Di,j+Dj,k.\n",
            "Then\n",
            "Wp(a,b)def.= LDp(a,b)1/p(1.15)\n",
            "(note that Wpdepends on D) deﬁnes the p-Wasserstein distance on Σn,i.e. Wpis symmetric, positive,\n",
            "Wp(a,b) = 0 if and only if a=b, and it satisﬁes the triangle inequality\n",
            "∀a,a′,b∈Σn,Wp(a,b)⩽Wp(a,a′) + Wp(a′,b).\n",
            "Proof. Symmetry and deﬁniteness of the distance are easy to prove: since C=Dphas a null diagonal,\n",
            "Wp(a,a) = 0, with corresponding optimal transport matrix P⋆= diag( a); by the positivity of all oﬀ-diagonal\n",
            "elements of Dp, Wp(a,b)>0 whenever a̸=b(because in this case, an admissible coupling necessarily has\n",
            "a non-zero element outside the diagonal); by symmetry of Dp, Wp(a,b) = 0 is itself a symmetric function.\n",
            "To prove the triangle inequality of Wasserstein distances for arbitrary measures, [ ?, Theorem 7.3] uses the\n",
            "gluing lemma, which stresses the existence of couplings with a prescribed structure. In the discrete setting,\n",
            "the explicit constuction of this glued coupling is simple. Let a,b,c∈Σn. Let PandQbe two optimal\n",
            "solutions of the transport problems between aandb, and bandcrespectively. We deﬁne ¯bjdef.=bjifbj>0\n",
            "and set otherwise ¯bj= 1 (or actually any other value). We then deﬁne\n",
            "Sdef.=Pdiag(1/¯b)Q∈Rn×n\n",
            "+.\n",
            "10\n",
            "We remark that S∈U(a,c) because\n",
            "S1n=Pdiag(1/¯b)Q1n=P(b/¯b) =P1Supp( b)=a\n",
            "where we denoted 1Supp( b)the indicator of the support of b, and we use the fact that P1Supp( b)=P1=b\n",
            "because necessarily Pi,j= 0 forj /∈Supp( b). Similarly one veriﬁes that S⊤1n=c.\n",
            "The triangle inequality follows from\n",
            "Wp(a,c) =(\n",
            "min\n",
            "P∈U(a,c)⟨P,Dp⟩)1/p\n",
            "⩽⟨S,Dp⟩1/p\n",
            "=\n",
            "∑\n",
            "ikDp\n",
            "ik∑\n",
            "jPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "⩽\n",
            "∑\n",
            "ijk(Dij+Djk)pPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "⩽\n",
            "∑\n",
            "ijkDp\n",
            "ijPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "ijkDp\n",
            "jkPijQjk\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "ijDp\n",
            "ijPij∑\n",
            "kQjk\n",
            "¯bj\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk∑\n",
            "iPij\n",
            "¯bj\n",
            "1/p\n",
            "=\n",
            "∑\n",
            "ijDp\n",
            "ijPij\n",
            "1/p\n",
            "+\n",
            "∑\n",
            "jkDp\n",
            "jkQjk\n",
            "1/p\n",
            "= Wp(a,b) + Wp(b,b).\n",
            "The ﬁrst inequality is due to the suboptimality of S, the second is the usual triangle inequality for elements\n",
            "inD, and the third comes from Minkowski’s inequality.\n",
            "Proposition 2 generalizes from histogram to arbitrary measures that need not be discrete.\n",
            "Proposition 3. We assumeX=Y, and that for some p⩾1,c(x,y) =d(x,y)pwheredis a distance on\n",
            "X,i.e.\n",
            "(i)d(x,y) =d(y,x)⩾0;\n",
            "(ii)d(x,y) = 0 if and only if x=y;\n",
            "(ii)∀(x,y,z )∈X3,d(x,z)⩽d(x,y) +d(y,z).\n",
            "Then\n",
            "Wp(α,β)def.=Ldp(α,β)1/p(1.16)\n",
            "(note thatWpdepends on d) deﬁnes the p-Wasserstein distance on X,i.e.Wpis symmetric, positive,\n",
            "Wp(α,β) = 0 if and only if α=β, and it satisﬁes the triangle inequality\n",
            "∀(α,β,γ )∈M1\n",
            "+(X)3,Wp(α,γ)⩽Wp(α,β) +Wp(β,γ).\n",
            "Proof. The proof follows the same approach as that for Proposition 2 and relies on the existence of a coupling\n",
            "between (α,γ) obtained by “guying” optimal couplings between ( α,β) and (β,γ).\n",
            "The Wasserstein distance Wphas many important properties, the most important one being that it is a\n",
            "weak distance, i.e.it allows to compare singular distributions (for instance discrete ones) and to quantify\n",
            "spatial shift between the supports of the distributions. In particular, “classical” distances (or divergences)\n",
            "are not even deﬁned between discrete distributions (the L2norm can only be applied to continuous measures\n",
            "with a density with respect to a base measure, and the discrete ℓ2norm requires the positions ( xi,yj) to\n",
            "be ﬁxed to work). In sharp contrast, one has that for any p >0,Wp\n",
            "p(δx,δy) =d(x,y). Indeed, it suﬃces\n",
            "to notice thatU(δx,δy) ={δx,y}and therefore the Kantorovich problem having only one feasible solution,\n",
            "Wp\n",
            "p(δx,δy) is necessarily ( d(x,y)p)1/p=d(x,y). This shows that Wp(δx,δy)→0 ifx→y. This property\n",
            "corresponds to the fact that Wpis a way to quantify the weak convergence as we now deﬁne.\n",
            "11\n",
            "Deﬁnition 2 (Weak convergence) .(αk)kconverges weakly to αinM1\n",
            "+(X)(denotedαk⇀α ) if and only if\n",
            "for any continuous function g∈C(X),∫\n",
            "Xgdαk→∫\n",
            "Xgdα. This notion of weak convergence corresponds to\n",
            "the convergence in law of random vectors.\n",
            "This convergence can be shown to be equivalent to Wp(αk,α)→0 [?, Theorem 6.8] (together with a\n",
            "convergence of the moments up to order pfor unbounded metric spaces).\n",
            "Note that there exists alternative distances which also metrize weak convergence. The simplest one are\n",
            "Hilbertian norms, deﬁned as\n",
            "||α||2\n",
            "kdef.=Eα⊗α(k) =∫\n",
            "X×Xk(x,y)dα(x)dα(y)\n",
            "for a suitable choice of kernel k:X2→R. The most famous of such kernel is the Gaussian one k(x,y) =\n",
            "e−||x−y||2\n",
            "2σ2for some choice of bandwidth σ>0.\n",
            "This convergence should not be confounded with the strong convergence of measures, which is metrized\n",
            "by the TV norm ||α||TVdef.=|α|(X), which is the total mass of the absolute value of the measure.\n",
            "Algorithms Since ( ??)ˆA is a linear program, it is possible to use any classical linear program solver, such\n",
            "as interior point methods or simplex. In practice, the network simplex is an eﬃcient option, and it used\n",
            "pivoting rule adapted to the OT constraint set. In the case of the assignment problem, a=b=1n/n, there\n",
            "exists faster combinatorial optimization scheme, the most famous ones being the Hungarian algorithm and\n",
            "the auction algorithm, which have roughly O(n3) complexity. Section 1.5 details an approximate algorithm,\n",
            "which is typically faster, and amenable to parallelisation, but do not compute exactly the solution to the\n",
            "OT problem.\n",
            "1.4 Duality\n",
            "The Kantorovich problem (1.11) is a constrained convex minimization problem, and as such, it can be\n",
            "naturally paired with a so-called dual problem, which is a constrained concave maximization problem. The\n",
            "following fundamental proposition, which is a special case of Fenchel-Rockafellar duality theory, explains the\n",
            "relationship between the primal and dual problems.\n",
            "Proposition 4. One has\n",
            "LC(a,b) = max\n",
            "(f,g)∈R(a,b)⟨f,a⟩+⟨g,b⟩ (1.17)\n",
            "where the set of admissible potentials is\n",
            "R(a,b)def.={(f,g)∈Rn×Rm;∀(i,j)∈JnK×JmK,f⊕g⩽C} (1.18)\n",
            "Proof. This result is a direct consequence of the more general result on the strong duality for linear pro-\n",
            "grams [ ?, p.148,Theo.4.4]. The easier part of that result, namely that the right-hand side of Equation (1.17)\n",
            "is a lower bound on L C(a,b) is discussed in ??. For the sake of completeness, let us derive this dual problem\n",
            "with the use of Lagrangian duality. The Lagangian associate to (1.11) reads\n",
            "min\n",
            "P⩾0max\n",
            "(f,g)∈Rn×Rm⟨C,P⟩+⟨a−P1m,f⟩+⟨b−P⊤1n,g⟩. (1.19)\n",
            "For linear program, one can always exchange the min and the max and get the same value of the linear\n",
            "program, and one thus consider\n",
            "max\n",
            "(f,g)∈Rn×Rm⟨a,f⟩+⟨b,g⟩+ min\n",
            "P⩾0⟨C−f1⊤\n",
            "m−1ng⊤,P⟩.\n",
            "We conclude by remarking that\n",
            "min\n",
            "P⩾0⟨Q,P⟩={0 if Q⩾0\n",
            "−∞ otherwise\n",
            "so that the constraint reads C−f1⊤\n",
            "m−1ng⊤=C−f⊕g⩾0.\n",
            "12\n",
            "The primal-dual optimality relation for the Lagrangian (1.19) allows to locate the support of the optimal\n",
            "transport plan\n",
            "Supp( P)⊂{\n",
            "(i,j)∈JnK×JmK;fi+gj=Ci,j}\n",
            ". (1.20)\n",
            "To extend this primal-dual construction to arbitrary measures, it is important to realize that measures\n",
            "are naturally paired in duality with continuous functions (a measure can only be accessed through integration\n",
            "against continuous functions). The duality is formalized in the following proposition, which boils down to\n",
            "Proposition 4 when dealing with discrete measures.\n",
            "Proposition 5. One has\n",
            "Lc(α,β) = max\n",
            "(f,g)∈R(c)∫\n",
            "Xf(x)dα(x) +∫\n",
            "Yg(y)dβ(y), (1.21)\n",
            "where the set of admissible dual potentials is\n",
            "R(c)def.={(f,g)∈C(X)×C(Y) ;∀(x,y),f(x) +g(y)⩽c(x,y)}. (1.22)\n",
            "Here, (f,g)is a pair of continuous functions, and are often called “Kantorovich potentials”.\n",
            "The discrete case (1.17) corresponds to the dual vectors being samples of the continuous potentials, i.e.\n",
            "(fi,gj) = (f(xi),g(yj)). The primal-dual optimality conditions allow to track the support of optimal plan,\n",
            "and (1.20) is generalized as\n",
            "Supp(π)⊂{(x,y)∈X×Y ;f(x) +g(y) =c(x,y)}. (1.23)\n",
            "Note that in contrast to the primal problem (1.14), showing the existence of solutions to (1.21) is non-\n",
            "trivial, because the constraint set R(c) is not compact and the function to minimize non-coercive. Using the\n",
            "machinery of c-transform detailed in Section ??, one can however show that optimal ( f,g) are necessarily\n",
            "Lipschitz regular, which enable to replace the constraint by a compact one.\n",
            "Benier’s Theorem and Monge-Amp` ere PDE The following celebrated theorem of [ ?] ensures that in\n",
            "Rdforp= 2, if at least one of the two inputs measures has a density, then Kantorovitch and Monge problems\n",
            "are equivalent.\n",
            "Theorem 1 (Brenier) .In the caseX=Y=Rdandc(x,y) =||x−y||2, if at least one of the two inputs\n",
            "measures (denoted α) has a density ραwith respect to the Lebesgue measure, then the optimal πin the\n",
            "Kantorovich formulation (1.14) is unique, and is supported on the graph (x,T(x))of a “Monge map” T:\n",
            "Rd→Rd. This means that π= (Id,T)♯µ,i.e.\n",
            "∀h∈C(X×Y ),∫\n",
            "X×Yh(x,y)dπ(x,y) =∫\n",
            "Xh(x,T(x))dµ(x). (1.24)\n",
            "Furthermore, this map Tis uniquely deﬁned as the gradient of a convex function ϕ,T(x) =∇ϕ(x), where\n",
            "ϕis the unique (up to an additive constant) convex function such that (∇ϕ)♯µ=ν. This convex function is\n",
            "related to the dual potential fsolving (1.21) asϕ(x) =||x||2\n",
            "2−f(x).\n",
            "Proof. We sketch the main ingredients of the proof, more details can be found for instance in [ ?]. We remark\n",
            "that∫\n",
            "cdπ=Cα,β−2∫\n",
            "⟨x, y⟩dπ(x,y) where the constant is Cα,β=∫\n",
            "||x||2dα(x) +∫\n",
            "||y||2dβ(y). Instead of\n",
            "solving (1.14), one can thus consider the following problem\n",
            "max\n",
            "π∈U(α,β)∫\n",
            "X×Y⟨x, y⟩dπ(x,y),\n",
            "whose dual reads\n",
            "min\n",
            "(ϕ,ψ){∫\n",
            "Xϕdα+∫\n",
            "Yψdβ;∀(x,y), ϕ (x) +ψ(y)⩾⟨x, y⟩}\n",
            ". (1.25)\n",
            "13\n",
            "The relation between these variables and those of (1.22) is ( ϕ,ψ) = (||·||2\n",
            "2−f,||·||2\n",
            "2−g). One can replace the\n",
            "constraint by\n",
            "∀y, ψ (y)⩾ϕ∗(y)def.= sup\n",
            "x⟨x, y⟩−ϕ(x). (1.26)\n",
            "Hereϕ∗is the Legendre transform of ϕand is a convex function as a supremum of linear forms (see\n",
            "also ( ??)). Since the objective appearing in (1.27) is linear and the integrating measures positive, one can\n",
            "minimize explicitly with respect to ϕand setψ=ϕ∗in order to consider the unconstraint problem\n",
            "min\n",
            "ϕ∫\n",
            "Xϕdα+∫\n",
            "Yϕ∗dβ, (1.27)\n",
            "see also Section ??for a generalization of this idea to generic costs c(x,y). By iterating this argument\n",
            "twice, one can replace ϕbyϕ∗∗, which is a convex function, and thus impose in (1.27) that ϕis convex.\n",
            "Condition (1.23) shows that an optimal πis supported on{(x,y) ;ϕ(x) +ϕ∗(y) =⟨x, y⟩}which shows that\n",
            "such anyis optimal for the minimization (1.26) of the Legendre transform, whose optimality condition reads\n",
            "y∈∂ϕ(x). Sinceϕis convex, it is diﬀerentiable almost everywhere, and since αhas a density, it is also\n",
            "diﬀerentiable α-almost everywhere. This shows that for each x, the associated yis uniquely deﬁned α-almost\n",
            "everywhere as y=∇ϕ(x), and shows that necessarily π= (Id,∇ϕ)♯α.\n",
            "This results shows that in the setting of W2with non-singular densities, the Monge problem (1.9)\n",
            "and its Kantorovich relaxation (1.14) are equal (the relaxation is tight). This is the continuous analog\n",
            "of Proposition 1 for the assignment case (1), which states that the minimum of the optimal transport\n",
            "problem is achieved, when the marginals are equal and uniform, at a permutation matrix (a discrete map).\n",
            "Brenier’s theorem, stating that an optimal transport map must be the gradient of a convex function, should\n",
            "be examined under the light that a convex function is the natural generalization of the notion of increasing\n",
            "functions in dimension more than one. Optimal transport can thus plays an important role to deﬁne quantile\n",
            "functions in arbitrary dimensions, which in turn is useful for applications to quantile regression problems [ ?].\n",
            "Note also that this theorem can be extended in many directions. The condition that αhas a density can\n",
            "be weakened to the condition that it does not give mass to “small sets” having Hausdorﬀ dimension smaller\n",
            "thand−1 (e.g. hypersurfaces). One can also consider costs of the form c(x,y) =h(x−y) wherehis a\n",
            "strictly convex function.\n",
            "For measures with densities, using (1.4), one obtains that ϕis the unique (up to the addition of a\n",
            "constant) convex function which solves the following Monge-Amp ˜A¨re-type equation\n",
            "det(∂2ϕ(x))ρβ(∇ϕ(x)) =ρα(x) (1.28)\n",
            "where∂2ϕ(x)∈Rd×dis the hessian of ϕ. The Monge-Amp` ere operator det( ∂2ϕ(x)) can be understood as a\n",
            "non-linear degenerate Laplacian. In the limit of small displacements, ϕ= Id +εϕ, one indeed recovers the\n",
            "Laplacian ∆ as a linearization since for smooth maps\n",
            "det(∂2ϕ(x)) = 1 +ε∆ϕ(x) +o(ε).\n",
            "The convexity constraint forces det( ∂2ϕ(x))⩾0 and is necessary for this equation to have a solution.\n",
            "Special cases In general, computing OT distances is numerically involved. We review special favorable\n",
            "cases where the resolution of the OT problem is easy.\n",
            "Remark 6 (Binary Cost Matrix and 1-Norm) .One can easily check that when the cost matrix Cis zero on\n",
            "the diagonal and 1 elsewhere, namely when C=1n×n−In, the OT distance between aandbis equal to\n",
            "the 1-norm of their diﬀerence, L C(a,b) =||a−b||1. One can also easily check that this result extends to\n",
            "discrete and discrete measures in the case where c(x,y) is 0 ifx=yand 1 when x̸=y. The OT distance\n",
            "between two discrete measures αandβis equal to their total variation distance.\n",
            "14\n",
            "\u0000\u0000↵Figure 1.8: 1-D optimal couplings: each arrow xi→yjindicate a non-zero Pi,jin the optimal coupling.\n",
            "Top: empirical measures with same number of points (optimal matching). Bottom: generic case. This\n",
            "corresponds to monotone rearrangements, if xi⩽xi′are such that Pi,j̸= 0,Pi′,j′̸= 0, then necessarily\n",
            "yj⩽yj′.\n",
            "Remark 7 (1-D case – Empirical measures) .HereX=R. Assuming α=1\n",
            "n∑n\n",
            "i=1δxiandβ=1\n",
            "n∑n\n",
            "j=1δyj,\n",
            "and assuming (without loss of generality) that the points are ordered, i.e.x1⩽x2⩽...⩽xnand\n",
            "y1⩽y2⩽...⩽yn, then one has the simple formula\n",
            "Wp(α,β)p=p∑\n",
            "i=1|xi−yi|p, (1.29)\n",
            "i.e.locally (if one assumes distinct points), Wp(α,β) is theℓpnorm between two vectors of ordered values of\n",
            "αandβ. That statement is only valid locally, in the sense that the order (and those vector representations)\n",
            "might change whenever some of the values change. That formula is a simple consequence of the more general\n",
            "remark given below. Figure 1.8, top row, illustrates the 1-D transportation map between empirical measures\n",
            "with the same number of points. The bottom row shows how this monotone map generalizes to arbitrary\n",
            "discrete measures. It is possible to leverage this 1-D computation to also compute eﬃciently OT on the\n",
            "circle, see [ ?]. Note that in the case of concave cost of the distance, for instance when p<1, the behaviour\n",
            "of the optimal transport plan is very diﬀerent, see [ ?], which describes an eﬃcient solver in this case.\n",
            "Remark 8 (1-D case – Generic case) .For a measure αonR, we introduce the cumulative function\n",
            "∀x∈R,Cα(x)def.=∫x\n",
            "−∞dα, (1.30)\n",
            "which is a function Cα:R→[0,1], and its pseudo-inverse C−1\n",
            "α: [0,1]→R∪{−∞}\n",
            "∀r∈[0,1],C−1\n",
            "α(r) = min\n",
            "x{x∈R∪{−∞} ;Cα(x)⩾r}.\n",
            "That function is also called the generalized quantile function of α. For anyp⩾1, one has\n",
            "Wp(α,β)p=||C−1\n",
            "α−C−1\n",
            "β||p\n",
            "Lp([0,1])=∫1\n",
            "0|C−1\n",
            "α(r)−C−1\n",
            "β(r)|pdr. (1.31)\n",
            "This means that through the map α↦→C−1\n",
            "α, the Wasserstein distance is isometric to a linear space equipped\n",
            "with theLpnorm, or, equivalently, that the Wasserstein distance for measures on the real line is a Hilbertian\n",
            "metric. This makes the geometry of 1-D optimal transport very simple, but also very diﬀerent from its\n",
            "geometry in higher dimensions, which is not Hilbertian as discussed in Proposition ??and more generally\n",
            "in§??. Forp= 1, one even has the simpler formula\n",
            "W1(α,β) =||Cα−Cβ||L1(R)=∫\n",
            "R|Cα(x)−Cβ(x)|dx (1.32)\n",
            "=∫\n",
            "R⏐⏐⏐⏐∫x\n",
            "−∞d(α−β)⏐⏐⏐⏐dx. (1.33)\n",
            "15\n",
            "µ ν (tT+ (1−t)Id)♯µ\n",
            "0 0.5 10.5Cµ\n",
            "Cν\n",
            "0 0.5 100.51\n",
            "Cµ-1\n",
            "Cν-1\n",
            "0 0.5 100.51\n",
            "T\n",
            "T-1\n",
            "0 0.5 100.51\n",
            "(Cα,Cβ) (C−1\n",
            "α,C−1\n",
            "β) ( T,T−1) (1−t)C−1\n",
            "α+tC−1\n",
            "β\n",
            "Figure 1.9: Computation of OT and displacement interpolation between two 1-D measures, using cumulant\n",
            "function as detailed in (1.34).\n",
            "which shows that W1is a norm (see§??for the generalization to arbitrary dimensions). An optimal Monge\n",
            "mapTsuch thatT♯α=βis then deﬁned by\n",
            "T=C−1\n",
            "β◦Cα. (1.34)\n",
            "Figure 1.9 illustrates the computation of 1-D OT through cumulative functions. It also displays displacement\n",
            "interpolations, computed as detailed in ( ??), see also Remark ??. For a detailed survey of the properties of\n",
            "optimal transport in 1-D, we refer the reader to [ ?, Chapter 2].\n",
            "Remark 9 (Distance between Gaussians) .Ifα=N(mα,Σα) andβ=N(mβ,Σβ) are two Gaussians in Rd,\n",
            "then one can show that the following map\n",
            "T:x↦→mβ+A(x−mα), (1.35)\n",
            "where\n",
            "A=Σ−1\n",
            "2α(\n",
            "Σ1\n",
            "2αΣβΣ1\n",
            "2α)1\n",
            "2Σ−1\n",
            "2α=AT,\n",
            "is such that T♯ρα=ρβ. Indeed, one simply has to notice that the change of variables formula (1.4) is satisﬁed\n",
            "since\n",
            "ρβ(T(x)) = det(2πΣβ)−1\n",
            "2exp(−⟨T(x)−mβ,Σ−1\n",
            "β(T(x)−mβ)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα, ATΣ−1\n",
            "βA(x−mα)⟩)\n",
            "= det(2πΣβ)−1\n",
            "2exp(−⟨x−mα,Σ−1\n",
            "α(x−mα)⟩),\n",
            "and sinceTis a linear map we have that\n",
            "|detT′(x)|= detA=(detΣβ\n",
            "detΣα)1\n",
            "2\n",
            "and we therefore recover ρα=|detT′|ρβmeaningT♯α=β. Notice now that Tis the gradient of the convex\n",
            "functionψ:x↦→1\n",
            "2⟨x−mα, A(x−mα)⟩+⟨mβ, x⟩to conclude, using Brenier’s theorem [ ?] (see Remark ??)\n",
            "thatTis optimal. Both that map Tand the corresponding potential ψare illustrated in Figures 1.10 and ??\n",
            "16\n",
            "-4 -2 0 2 4 6-3-2-101234\n",
            "ρβραFigure 1.10: Two Gaussians ραandρβ, represented using the contour plots of their densities, with respective\n",
            "mean and variance matrices mα= (−2,0),Σα=1\n",
            "2(\n",
            "1−1\n",
            "2;−1\n",
            "21)\n",
            "andmβ= (3,1),Σβ=(\n",
            "2,1\n",
            "2;1\n",
            "2,1)\n",
            ". The\n",
            "arrows originate at random points xtaken on the plane and end at the corresponding mappings of those\n",
            "pointsT(x) =mβ+A(x−mα).\n",
            "\u0000m\n",
            "Figure 1.11: Computation of displacement interpolation between two 1-D Gaussians. Denoting Gm,σ(x)def.=\n",
            "1√\n",
            "2πse−(x−m)2\n",
            "2s2the Gaussian density, it thus shows the interpolation G(1−t)m0+tm1,(1−t)σ0+tσ1.\n",
            "With additional calculations involving ﬁrst and second order moments of ρα, we obtain that the transport\n",
            "cost of that map is\n",
            "W2\n",
            "2(α,β) =||mα−mβ||2+B(Σα,Σβ)2(1.36)\n",
            "whereBis the so-called Bures’ metric [ ?] between positive deﬁnite matrices (see also [ ?,?]),\n",
            "B(Σα,Σβ)2def.= tr(\n",
            "Σα+Σβ−2(Σ1/2\n",
            "αΣβΣ1/2\n",
            "α)1/2)\n",
            ", (1.37)\n",
            "where Σ1/2is the matrix square root. One can show that Bis a distance on covariance matrices, and that\n",
            "B2is convex with respect to both its arguments. In the case where Σα= diag(ri)iandΣβ= diag(si)iare\n",
            "diagonals, the Bures metric is the Hellinger distance\n",
            "B(Σα,Σβ) =||√r−√s||2.\n",
            "For 1-D Gaussians, W2is thus the Euclidean distance on the 2-D plane ( m,√\n",
            "Σ), as illustrated in Figure 1.11.\n",
            "For a detailed treatment of the Wasserstein geometry of Gaussian distributions, we refer to [ ?].\n",
            "1.5 Sinkhorn\n",
            "This section introduces a family of numerical scheme to approximate solutions to Kantorovich formulation\n",
            "of optimal transport and its many generalizations. It operates by adding an entropic regularization penalty to\n",
            "the original problem. This regularization has several important advantages, but a few stand out particularly:\n",
            "The minimization of the regularized problen can be solved using a simple alternate minimization scheme;\n",
            "that scheme translates into iterations that are simple matrix products, making them particularly suited to\n",
            "execution of GPU; the resulting approximate distance is smooth with respect to input histogram weights\n",
            "and positions of the Diracs.\n",
            "17\n",
            "c\"P\"Figure 1.12: Impact of εon the optimization of a linear function on the simplex, solving Pε=\n",
            "argminP∈Σ3⟨C,P⟩−εH(P) for a varying ε.\n",
            "Entropic Regularization. The discrete entropy of a coupling matrix is deﬁned as\n",
            "H(P)def.=−∑\n",
            "i,jPi,j(log(Pi,j)−1), (1.38)\n",
            "with an analogous deﬁnition for vectors, with the convention that H(a) =−∞ if one of the entries ajis\n",
            "0 or negative. The function His 1-strongly concave, because its hessian is ∂2H(P) =−diag(1/Pi,j) and\n",
            "Pi,j⩽1. The idea of the entropic regularization of optimal transport is to use −Has a regularizing function\n",
            "to obtain approximate solutions to the original transport problem (1.11):\n",
            "Lε\n",
            "C(a,b)def.= min\n",
            "P∈U(a,b)⟨P,C⟩−εH(P). (1.39)\n",
            "Since the objective is a ε-strongly convex function, problem 1.39 has a unique optimal solution. The idea\n",
            "to regularize the optimal transport problem by an entropic term can be traced back to modeling ideas in\n",
            "transportation theory [ ?]: Actual traﬃc patterns in a network do not agree with those predicted by the\n",
            "solution of the optimal transport problem. Indeed, the former are more diﬀuse than the latter, which tend\n",
            "to rely on a few routes as a result of the sparsity of optimal couplings to the solution of 1.11. To balance for\n",
            "that, researchers in transportation proposed a model, called the “gravity” model [ ?], that is able to form a\n",
            "more “blurred” traﬃc prediction.\n",
            "Figure 1.12 illustrates the eﬀect of the entropy to regularize a linear program over the simples Σ 3(which\n",
            "can thus be visualized as a triangle in 2-D). Note how the entropy pushes the original LP solution away\n",
            "from the boundary of the triangle. The optimal Pεprogressively moves toward an “entropic center” of the\n",
            "triangle. This is further detailed in the proposition below. The convergence of the solution of that regularized\n",
            "problem towards an optimal solution of the original linear program has been studied by [ ?].\n",
            "Proposition 6 (Convergence with ε).The unique solution Pεof(1.39) converges to the optimal solution\n",
            "with maximal entropy within the set of all optimal solutions of the Kantorovich problem, namely\n",
            "Pεε→0−→argmin\n",
            "P{−H(P) ;P∈U(a,b),⟨P,C⟩= LC(a,b)} (1.40)\n",
            "so that in particular\n",
            "Lε\n",
            "C(a,b)ε→0−→LC(a,b).\n",
            "One has\n",
            "Pεε→∞−→abT= (aibj)i,j. (1.41)\n",
            "Proof. We consider a sequence ( εℓ)ℓsuch thatεℓ→0 andεℓ>0. We denote Pℓthe solution of (1.39) for\n",
            "ε=εℓ. Since U(a,b) is bounded, we can extract a sequence (that we do not relabel for sake of simplicity)\n",
            "such that Pℓ→P⋆. Since U(a,b) is closed, P⋆∈U(a,b). We consider any Psuch that⟨C,P⟩= LC(a,b).\n",
            "By optimality of PandPℓfor their respective optimization problems (for ε= 0 andε=εℓ), one has\n",
            "0⩽⟨C,Pℓ⟩−⟨C,P⟩⩽εℓ(H(Pℓ)−H(P)). (1.42)\n",
            "18\n",
            "⇡\"↵\u0000\n",
            "\"\u0000↵Figure 1.13: Impact of εon coupling between densities and discrete distributions, illustrating Proposition 6.\n",
            "Left: between two 1-D densities. Right: between two 2-D discrete empirical densities with same number\n",
            "n=mof points (only entries of the optimal ( Pi,j)i,jabove a small threshold are displayed as segments\n",
            "betweenxiandyj).\n",
            "Since His continuous, taking the limit ℓ→+∞in this expression shows that ⟨C,P⋆⟩=⟨C,P⟩so that\n",
            "P⋆is a feasible point of (1.40). Furthermore, dividing by εℓin (1.42) and taking the limit shows that\n",
            "H(P)⩽H(P⋆), which shows that P⋆is a solution of (1.40). Since the solution P⋆\n",
            "0to this program is unique\n",
            "by strict convexity of −H, one has P⋆=P⋆\n",
            "0, and the whole sequence is converging.\n",
            "Formula (1.40) states that for low regularization, the solution converges to the maximum entropy optimal\n",
            "transport coupling. In sharp contrast, (1.41) shows that for large regularization, the solution converges to the\n",
            "coupling with maximal entropy between two prescribed marginals a,b, namely the joint probability between\n",
            "two independent random variables with prescribed distributions. A reﬁned analysis of this convergence is\n",
            "performed in [ ?], including a ﬁrst order expansion in ε(resp. 1/ε) nearε= 0 (respε= +∞). Figure 1.13\n",
            "shows visually the eﬀect of these two convergence. A key insight is that, as εincreases, the optimal coupling\n",
            "becomes less and less sparse (in the sense of having entries larger than a prescribed thresholds), which in\n",
            "turn as the eﬀect of both accelerating computational algorithms (as we study in §1.5) but also leading to\n",
            "faster statistical convergence (as exposed in §??).\n",
            "Deﬁning the Kullback-Leibler divergence between couplings as\n",
            "KL(P|K)def.=∑\n",
            "i,jPi,jlog(Pi,j\n",
            "Ki,j)\n",
            "−Pi,j+Ki,j, (1.43)\n",
            "the unique solution Pεof (1.39) is a projection onto U(a,b) of the Gibbs kernel associated to the cost matrix\n",
            "Cas\n",
            "Ki,jdef.=e−Ci,j\n",
            "ε\n",
            "Indeed one has that using the deﬁnition above\n",
            "Pε= ProjKL\n",
            "U(a,b)(K)def.= argmin\n",
            "P∈U(a,b)KL(P|K). (1.44)\n",
            "Remark 10 (General formulation) .One can consider arbitrary measures by replacing the discrete entropy\n",
            "by the relative entropy with respect to the product measure d α⊗dβ(x,y)def.= dα(x)dβ(y), and propose a\n",
            "regularized counterpart to (1.14) using\n",
            "Lε\n",
            "c(α,β)def.= min\n",
            "π∈U(α,β)∫\n",
            "X×Yc(x,y)dπ(x,y) +εKL(π|α⊗β) (1.45)\n",
            "where the relative entropy is a generalization of the discrete Kullback-Leibler divergence (1.43)\n",
            "KL(π|ξ)def.=∫\n",
            "X×Ylog(dπ\n",
            "dξ(x,y))\n",
            "dπ(x,y)+\n",
            "∫\n",
            "X×Y(dξ(x,y)−dπ(x,y)),(1.46)\n",
            "19\n",
            "and by convention KL( π|ξ) = +∞ifπdoes not have a densitydπ\n",
            "dξwith respect to ξ. It is important to\n",
            "realize that the reference measure α⊗βchosen in (1.45) to deﬁne the entropic regularizing term KL( ·|α⊗β)\n",
            "plays no speciﬁc role, only its support matters.\n",
            "Formula (1.45) can be re-factored as a projection problem\n",
            "min\n",
            "π∈U(α,β)KL(π|K) (1.47)\n",
            "whereKis the Gibbs distributions d K(x,y)def.=e−c(x,y)\n",
            "εdµ(x)dν(y). This problem is often referred to as the\n",
            "“static Schr¨ odinger problem” [ ?,?], since it was initially considered by Schr¨ odinger in statistical physics [ ?].\n",
            "Asε→0, the unique solution to (1.47) converges to the maximum entropy solution to (1.14), see [ ?,?].§??\n",
            "details an alternate “dynamic” formulation of the Schr¨ odinger problem over the space of paths connecting\n",
            "the points of two measures.\n",
            "Sinkhorn’s Algorithm The following proposition shows that the solution of (1.39) has a speciﬁc form,\n",
            "which can be parameterized using n+mvariables. That parameterization is therefore essentially dual, in\n",
            "the sense that a coupling PinU(a,b) hasnmvariables but n+mconstraints.\n",
            "Proposition 7. The solution to (1.39) is unique and has the form\n",
            "∀(i,j)∈JnK×JmK,Pi,j=uiKi,jvj (1.48)\n",
            "for two (unknown) scaling variable (u,v)∈Rn\n",
            "+×Rm\n",
            "+.\n",
            "Proof. Introducing two dual variables f∈Rn,g∈Rmfor each marginal constraint, the Lagrangian of (1.39)\n",
            "reads\n",
            "E(P,f,g) =⟨P,C⟩−εH(P)−⟨f,P1m−a⟩−⟨g,PT1n−b⟩.\n",
            "Considering ﬁrst order conditions, we have\n",
            "∂E(P,f,g)\n",
            "∂Pi,j=Ci,j−εlog(Pi,j)−fi−gj.\n",
            "which results, for an optimal Pcoupling to the regularized problem, in the expression Pi,j=efi/εe−Ci,j/εegj/ε\n",
            "which can be rewritten in the form provided in the proposition using non-negative vectors uandv.\n",
            "The factorization of the optimal solution exhibited in Equation (1.48) can be conveniently rewritten in\n",
            "matrix form as P= diag( u)Kdiag(v).u,vmust therefore satisfy the following non-linear equations which\n",
            "correspond to the mass conservation constraints inherent to U(a,b),\n",
            "diag(u)Kdiag(v)1m=a,and diag( v)K⊤diag(u)1n=b, (1.49)\n",
            "These two equations can be further simpliﬁed, since diag( v)1mis simply v, and the multiplication of diag( u)\n",
            "times Kvis\n",
            "u⊙(Kv) =aand v⊙(KTu) =b (1.50)\n",
            "where⊙corresponds to entry-wise multiplication of vectors. That problem is known in the numerical analysis\n",
            "community as the matrix scaling problem (see [ ?] and references therein). An intuitive way to try to solve\n",
            "these equations is to solve them iteratively, by modifying ﬁrst uso that it satisﬁes the left-hand side of\n",
            "Equation (1.50) and then vto satisfy its right-hand side. These two updates deﬁne Sinkhorn’s algorithm:\n",
            "u(ℓ+1)def.=a\n",
            "Kv(ℓ)and v(ℓ+1)def.=b\n",
            "KTu(ℓ+1), (1.51)\n",
            "initialized with an arbitrary positive vector v(0)=1m. The division operator used above between two\n",
            "vectors is to be understood entry-wise. Note that a diﬀerent initialization will likely lead to a diﬀerent\n",
            "20\n",
            "`⇡(`)\"\n",
            "1000 2000 3000 4000 5000-2-1.5-1-0.50`Figure 1.14: Left: evolution of the coupling πℓ\n",
            "ε= diag( U(ℓ))Kdiag(V(ℓ)) computed at iteration ℓof\n",
            "Sinkhorn’s iterations, for 1-D densities. Right: impact of εthe convergence rate of Sinkhorn, as measured\n",
            "in term of marginal constraint violation log( ||πℓ\n",
            "ε1m−b||1).\n",
            "solution for u,v, since u,vare only deﬁned up to a multiplicative constant (if u,vsatisfy (1.49) then\n",
            "so doλu,v/λfor anyλ > 0). It turns out however that these iterations converge (see Remark 11 for\n",
            "a justiﬁcation using iterative projections, and Remark 13 for a strict contraction result) and all result in\n",
            "the same optimal coupling diag( u)Kdiag(v). Figure 1.14, top row, shows the evolution of the coupling\n",
            "diag(U(ℓ))Kdiag(V(ℓ)) computed by Sinkhorn iterations. It evolves from the Gibbs kernel Ktowards the\n",
            "optimal coupling solving (1.39) by progressively shifting the mass away from the diagonal.\n",
            "Remark 11 (Relation with iterative projections) .Denoting\n",
            "C1\n",
            "adef.={P;P1m=a}andC2\n",
            "bdef.={\n",
            "P;PT1m=b}\n",
            "the rows and columns constraints, one has U(a,b) =C1\n",
            "a∩C2\n",
            "b. One can use Bregman iterative projections [ ?]\n",
            "P(ℓ+1) def.= ProjKL\n",
            "C1a(P(ℓ)) and P(ℓ+2) def.= ProjKL\n",
            "C2\n",
            "b(P(ℓ+1)). (1.52)\n",
            "Since the setsC1\n",
            "aandC2\n",
            "bare aﬃne, these iterations are known to converge to the solution of (1.44), see [ ?].\n",
            "These iterate are equivalent to Sinkhorn iterations (1.51) since deﬁning\n",
            "P(2ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)),\n",
            "one has\n",
            "P(2ℓ+1) def.= diag( u(ℓ+1))Kdiag(v(ℓ))\n",
            "and P(2ℓ+2) def.= diag( u(ℓ+1))Kdiag(v(ℓ+1))\n",
            "In practice however one should prefer using (1.51) which only requires manipulating scaling vectors and\n",
            "multiplication against a Gibbs kernel, which can often be accelerated (see below Remarks ??and??).\n",
            "Remark 12 (Hilbert metric) .As initially explained by [ ?], the global convergence analysis of Sinkhorn is\n",
            "greatly simpliﬁed using Hilbert projective metric on Rn\n",
            "+,∗(positive vectors), deﬁned as\n",
            "∀(u,u′)∈(Rn\n",
            "+,∗)2, dH(u,u′)def.= log max\n",
            "i,i′uiu′\n",
            "i′\n",
            "ui′u′\n",
            "i.\n",
            "This can be shows to be a distance on the projective cone Rn\n",
            "+,∗/∼, where u∼u′means that∃s>0,u=su′\n",
            "(the vector are equal up to rescaling, hence the naming “projective”). This means that dHsatisﬁes the\n",
            "triangular inequality and dH(u,u′) = 0 if and only if u∼u′. This is a projective version of Hilbert’s original\n",
            "distance on bounded open convex sets [ ?]. The projective cone Rn\n",
            "+,∗/∼is a complete metric space for this\n",
            "distance. It was introduced independently by [ ?] and [ ?] to provide a quantitative proof of Perron-Frobenius\n",
            "theorem, which, as explained in Remark ??is linked to a local linearization of Sinkhorn’s iterates. They\n",
            "proved the following fundamental theorem, which shows that a positive matrix is a strict contraction on the\n",
            "cone of positive vectors.\n",
            "21\n",
            "Theorem 2. Let K∈Rn×m\n",
            "+,∗, then for (v,v′)∈(Rm\n",
            "+,∗)2\n",
            "dH(Kv,Kv′)⩽λ(K)dH(v,v′)where\n",
            "\n",
            "λ(K)def.=√\n",
            "η(K)−1√\n",
            "η(K)+1<1\n",
            "η(K)def.= max\n",
            "i,j,k,ℓKi,kKj,ℓ\n",
            "Kj,kKi,ℓ.\n",
            "Remark 13 (Global convergence) .The following theorem, proved by [ ?], makes use of this Theorem 2 to\n",
            "show the linear convergence of Sinkhorn’s iterations.\n",
            "Theorem 3. One has (u(ℓ),v(ℓ))→(u⋆,v⋆)and\n",
            "dH(u(ℓ),u⋆) =O(λ(K)2ℓ), dH(v(ℓ),v⋆) =O(λ(K)2ℓ). (1.53)\n",
            "One also has\n",
            "dH(u(ℓ),u⋆)⩽dH(P(ℓ)1m,a)\n",
            "1−λ(K)\n",
            "dH(v(ℓ),v⋆)⩽dH(P(ℓ),⊤1n,b)\n",
            "1−λ(K)(1.54)\n",
            "where we denoted P(ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)). Lastly, one has\n",
            "∥log(P(ℓ))−log(P⋆)∥∞⩽dH(u(ℓ),u⋆) +dH(v(ℓ),v⋆) (1.55)\n",
            "where P⋆is the unique solution of (1.39) .\n",
            "Proof. One notice that for any ( v,v′)∈(Rm\n",
            "+,∗)2, one has\n",
            "dH(v,v′) =dH(v/v′,1m) =dH(1m/v,1m/v′).\n",
            "This shows that\n",
            "dH(u(ℓ+1),u⋆) =dH(a\n",
            "Kv(ℓ),a\n",
            "Kv⋆)\n",
            "=dH(Kv(ℓ),Kv⋆)⩽λ(K)dH(v(ℓ),v⋆).\n",
            "where we used Theorem 2. This shows (1.53). One also has, using the triangular inequality\n",
            "dH(u(ℓ),u⋆)⩽dH(u(ℓ+1),u(ℓ)) +dH(u(ℓ+1),u⋆)\n",
            "⩽dH(a\n",
            "Kv(ℓ),u(ℓ))\n",
            "+λ(K)dH(u(ℓ),u⋆)\n",
            "=dH(\n",
            "a,u(ℓ)⊙(Kv(ℓ)))\n",
            "+λ(K)dH(u(ℓ),u⋆),\n",
            "which gives the ﬁrst part of (1.54) since u(ℓ)⊙(Kv(ℓ)) =P(ℓ)1m(the second one being similar). The proof\n",
            "of (1.55) follows from [ ?, Lemma 3]\n",
            "The bound (1.54) shows that some error measures on the marginal constraints violation, for instance\n",
            "∥P(ℓ)1m−a∥1and∥P(ℓ)T1n−b∥1, are useful stopping criteria to monitor the convergence.\n",
            "Figure 1.14, bottom row, highlights this linear rate on the constraint violation, and shows how this rate\n",
            "degrades as ε→0. These results are proved in [ ?] and are tightly connected to nonlinear Perron-Frobenius\n",
            "Theory [ ?]. Perron-Frobenius theory corresponds to the linearization of the iterations, see ( ??). This\n",
            "convergence analysis is extended in [ ?], who shows that each iteration of Sinkhorn increases the permanent\n",
            "of the scaled coupling matrix.\n",
            "22\n",
            "Regularized Dual and Log-domain Computations The following proposition details the dual problem\n",
            "associated to (1.39).\n",
            "Proposition 8. One has\n",
            "Lε\n",
            "C(a,b) = max\n",
            "f∈Rn,g∈Rm⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩. (1.56)\n",
            "The optimal (f,g)are linked to scalings (u,v)appearing in (1.48) through\n",
            "(u,v) = (ef/ε,eg/ε). (1.57)\n",
            "Proof. We start from the end of the proof of Proposition 7, which links the optimal primal solution P\n",
            "and dual multipliers fandgfor the marginal constraints as Pi,j=efi/εe−Ci,j/εegj/ε. Substituting in the\n",
            "LagrangianE(P,f,g) of Equation (1.5) the optimal Pas a function of fandg, we obtain that the Lagrange\n",
            "dual function equals\n",
            "f,g↦→⟨ef/ε,(K⊙C)eg/ε⟩−εH(diag(ef/ε)Kdiag(eg/ε)). (1.58)\n",
            "The entropy of Pscaled byε, namelyε⟨P,logP−1n×m⟩can be stated explicitly as a function of f,g,C\n",
            "⟨diag(ef/ε)Kdiag(eg/ε),f1mT+1ngT−C−ε1n×m⟩\n",
            "=−⟨ef/ε,(K⊙C)eg/ε⟩+⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩\n",
            "therefore, the ﬁrst term in (1.58) cancels out with the ﬁrst term in the entropy above. The remaining times\n",
            "are those displayed in (1.56).\n",
            "Remark 14.Dual for generic measures For generic (non-necessarily discrete) input measures ( α,β), the dual\n",
            "problem (1.56) reads\n",
            "sup\n",
            "f,g∈C(X)×C(Y)∫\n",
            "Xf(x)dα(x) +∫\n",
            "Yg(x)dβ(x)−ε∫\n",
            "X×Ye−c(x,y)+f(x)+g(y)\n",
            "ε dα(x)dβ(y)\n",
            "This corresponds to a smoothing of the constraint R(c) appearing in the original problem (1.21), which\n",
            "is retrieved in the limit ε→0. Proving existence ( i.e. the sup is actually a max) of these Kantorovich\n",
            "potentials ( f,g) in the case of entropic transport is less easy than for classical OT (because one cannot\n",
            "usec-transform and potentials are not automatically Lipschitz). Proof of existence can be done using the\n",
            "convergence of Sinkhorn iterations, see [ ?] for more details.\n",
            "Remark 15 (Sinkhorn as a Block Coordinate Ascent on the Dual Problem) .A simple approach to solve the\n",
            "unconstrained maximization problem (1.56) is to use an exact block coordinate ascent strategy, namely to\n",
            "update alternatively fandgto cancel their gradients with respect to the objective of (1.56). Indeed, one\n",
            "can easily notice that, writing Q(f,g) for the objective of (1.56) that\n",
            "∇|fQ(f,g) =a−ef/ε⊙(\n",
            "Keg/ε)\n",
            ", (1.59)\n",
            "∇|gQ(f,g) =b−eg/ε⊙(\n",
            "KTef/ε)\n",
            ". (1.60)\n",
            "Block coordinate ascent can therefore be implemented in a closed form by applying successively the following\n",
            "updates, starting from any arbitrary g(0), forl⩾0,\n",
            "f(ℓ+1)=εloga−εlog(\n",
            "Keg(ℓ)/ε)\n",
            ", (1.61)\n",
            "g(ℓ+1)=εlogb−εlog(\n",
            "KTef(ℓ+1)/ε)\n",
            ". (1.62)\n",
            "Such iterations are mathematically equivalent to the Sinkhorn iterations (1.51) when considering the primal-\n",
            "dual relations highlighted in (1.57). Indeed, we recover that at any iteration\n",
            "(f(ℓ),g(ℓ)) =ε(log(u(ℓ)),log(v(ℓ))).\n",
            "23\n",
            "Remark 16 (Soft-min rewriting) .Iterations (1.61) and (1.62) can be given an alternative interpretation,\n",
            "using the following notation. Given a vector zof real numbers we write min εzfor the soft-minimum of its\n",
            "coordinates, namely\n",
            "minεz=−εlog∑\n",
            "ie−zi/ε.\n",
            "Note that min ε(z) converges to min zfor any vector zasε→0. Indeed, min εcan be interpreted as a\n",
            "diﬀerentiable approximation of the min function. Using these notations, Equations (1.61) and (1.62) can be\n",
            "rewritten\n",
            "(f(ℓ+1))i= minε(Cij−g(ℓ)\n",
            "j)j+εlogai, (1.63)\n",
            "(g(ℓ+1))j= minε(Cij−f(ℓ)\n",
            "i)i+εlogbj. (1.64)\n",
            "Here the term min ε(Cij−g(ℓ)\n",
            "j)jdenotes the soft-minimum of all values of the j-th column of matrix\n",
            "(C−1n(g(ℓ))⊤). To simplify notations, we introduce an operator that takes a matrix as input and outputs\n",
            "now a column vector of the soft-minimum values of its columns or rows. Namely, for any matrix A∈Rn×m,\n",
            "we deﬁne\n",
            "Minrow\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)j)\n",
            "i∈Rn,\n",
            "Mincol\n",
            "ε(A)def.=(\n",
            "minε(Ai,j)i)\n",
            "j∈Rm.\n",
            "Note that these operations are equivalent to the entropic c-transform introduced in §??(see in particu-\n",
            "lar (??)). Using these notations, Sinkhorn’s iterates read\n",
            "f(ℓ+1)= Minrow\n",
            "ε(C−1ng(ℓ)T) +εloga, (1.65)\n",
            "g(ℓ+1)= Mincol\n",
            "ε(C−f(ℓ)1mT) +εlogb. (1.66)\n",
            "Note that as ε→0, minεconverges to min, but the iterations do not converge anymore in the limit ε= 0,\n",
            "because alternate minimization does not converge for constrained problems (which is the case for the un-\n",
            "regularized dual (1.17)).\n",
            "Remark 17 (Log-domain Sinkhorn) .While mathematically equivalent to the Sinkhorn updates (1.51), itera-\n",
            "tions (1.63) and (1.64) suggest to use the log-sum-exp stabilization trick to avoid underﬂow for small values\n",
            "ofε. Writing z = min z, that trick suggests to evaluate min εzas\n",
            "minεz= z−εlog∑\n",
            "ie−(zi−z)/ε. (1.67)\n",
            "Instead of substracting z to stabilize the log domain iterations as in (1.67), one can actually substract the\n",
            "previously computed scalings. This leads to the following stabilized iteration\n",
            "f(ℓ+1)= Minrow\n",
            "ε(S(f(ℓ),g(ℓ)))−f(ℓ)+εlog(a) (1.68)\n",
            "g(ℓ+1)= Mincol\n",
            "ε(S(f(ℓ+1),g(ℓ)))−g(ℓ)+εlog(b), (1.69)\n",
            "where we deﬁned\n",
            "S(f,g) =(\n",
            "Ci,j−fi−gj)\n",
            "i,j.\n",
            "In contrast to the original iterations (1.51), these log-domain iterations (1.68) and (1.69) are stable for\n",
            "arbitraryε >0, because the quantity S(f,g) stays bounded during the iterations. The downside is that it\n",
            "requiresnmcomputations of exp at each step. Computing a Minrow\n",
            "εor Mincol\n",
            "εis typically substantially\n",
            "slower than matrix multiplications, and requires computing line by line soft-minima of matrices S. There is\n",
            "therefore no eﬃcient way to parallelize the application of Sinkhorn maps for several marginals simultaneously.\n",
            "In Euclidean domain of small dimension, it is possible to develop eﬃcient multiscale solvers with a decaying\n",
            "εstrategy to signiﬁcantly speed up the computation using sparse grids [ ?].\n",
            "24\n",
            "1.6 Extensions\n",
            "Wasserstein Barycenters. Given input histogram {bs}S\n",
            "s=1, wherebs∈Σns, and weights λ∈ΣS, a\n",
            "Wasserstein barycenter is computed by minimizing\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsLCs(a,bs) (1.70)\n",
            "where the cost matrices Cs∈Rn×nsneed to be speciﬁed. A typical setup is “Eulerian”, so that all the\n",
            "barycenters are deﬁned on the same grid, ns=n,Cs=C=Dpis set to be a distance matrix, so that one\n",
            "solves\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsWp\n",
            "p(a,bs).\n",
            "This barycenter problem (1.70) was originally introduced by [ ?] following earlier ideas of [ ?]. They proved\n",
            "in particular uniqueness of the barycenter for c(x,y) =||x−y||2overX=Rd, if one of the input measure\n",
            "has a density with respect to the Lebesgue measure (and more generally under the same hypothesis as the\n",
            "one guaranteeing the existence of a Monge map, see Remark ??).\n",
            "The barycenter problem for histograms (1.70) is in fact a linear program, since one can look for the S\n",
            "couplings ( Ps)sbetween each input and the barycenter itself\n",
            "min\n",
            "a∈Σn,(Ps∈Rn×ns)s{S∑\n",
            "s=1λs⟨Ps,Cs⟩;∀s,P⊤\n",
            "s1ns=a,P⊤\n",
            "s1n=bs}\n",
            ".\n",
            "Although this problem is an LP, its scale forbids the use generic solvers for medium scale problems. One\n",
            "can therefore resort to using ﬁrst order methods such as subgradient descent on the dual [ ?].\n",
            "Remark 18.Barycenter of arbitrary measures Given a set of input measure ( βs)sdeﬁned on some space X,\n",
            "the barycenter problem becomes\n",
            "min\n",
            "α∈M1\n",
            "+(X)S∑\n",
            "s=1λsLc(α,βs). (1.71)\n",
            "In the case where X=Rdandc(x,y) =||x−y||2, [?] shows that if one of the input measures has a density,\n",
            "then this barycenter is unique. Problem (1.71) can be viewed as a generalization of the problem of computing\n",
            "barycenters of points ( xs)S\n",
            "s=1∈XSto arbitrary measures. Indeed, if βs=δxsis a single Dirac mass, then a\n",
            "solution to (1.71) is δx⋆wherex⋆is a Fr´ echet mean solving ( ??). Note that for c(x,y) =||x−y||2, the mean\n",
            "of the barycenter α⋆is necessarily the barycenter of the mean, i.e.\n",
            "∫\n",
            "Xxdα⋆(x) =∑\n",
            "sλs∫\n",
            "Xxdαs(x),\n",
            "and the support of α⋆is located in the convex hull of the supports of the ( αs)s. The consistency of the\n",
            "approximation of the inﬁnite dimensional optimization (1.71) when approximating the input distribution\n",
            "using discrete ones (and thus solving (1.70) in place) is studied in [ ?]. Let us also note that it is possible to\n",
            "re-cast (1.71) as a multi-marginal OT problem, see Remark ??.\n",
            "One can use entropic smoothing and approximate the solution of (1.70) using\n",
            "min\n",
            "a∈ΣnS∑\n",
            "s=1λsLε\n",
            "Cs(a,bs) (1.72)\n",
            "for someε > 0. This is a smooth convex minimization problem, which can be tackled using gradient\n",
            "descent [ ?]. An alternative is to use descent method (typically quasi-Newton) on the semi-dual [ ?], which is\n",
            "25\n",
            "useful to integrate additional regularizations on the barycenter (e.g. to impose some smoothness). A simple\n",
            "but eﬀective approach, as remarked in [ ?] is to rewrite (1.72) as a (weighted) KL projection problem\n",
            "min\n",
            "(Ps)s{∑\n",
            "sλsKL(Ps|Ks) ;∀s,PsT1m=bs,P111=...=PS1S}\n",
            "(1.73)\n",
            "where we denoted Ksdef.=e−Cs/ε. Here, the barycenter ais implicitly encoded in the row marginals of all\n",
            "the couplings Ps∈Rn×nsasa=P111=...=PS1S. As detailed in [ ?], one can generalize Sinkhorn to\n",
            "this problem, which also corresponds to iterative projection. This can also be seen as a special case of the\n",
            "generalized Sinkhorn detailed in §??. The optimal couplings ( Ps)ssolving (1.73) are computed in scaling\n",
            "form as\n",
            "Ps= diag( us)Kdiag(vs), (1.74)\n",
            "and the scalings are sequentially updated as\n",
            "∀s∈J1,SK,v(ℓ+1)\n",
            "sdef.=bs\n",
            "KT\n",
            "su(ℓ)\n",
            "s, (1.75)\n",
            "∀s∈J1,SK,u(ℓ+1)\n",
            "sdef.=a(ℓ+1)\n",
            "Ksv(ℓ+1)\n",
            "s, (1.76)\n",
            "where a(ℓ+1)def.=∏\n",
            "s(Ksv(ℓ+1)\n",
            "s)λs. (1.77)\n",
            "An alternative way to derive these iterations is to perform alternate minimization on the variables of a dual\n",
            "problem, which detailed in the following proposition.\n",
            "Proposition 9. The optimal (us,vs)appearing in (1.74) can be written as (us,vs) = (efs/ε,egs/ε)where\n",
            "(fs,gs)sare the solutions of the following program (whose value matches the one of (1.72) )\n",
            "max\n",
            "(fs,gs)s{∑\n",
            "sλs(\n",
            "⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\n",
            ";∑\n",
            "sλsfs= 0}\n",
            ". (1.78)\n",
            "Proof. Introducing Lagrange multipliers in (1.73) leads to\n",
            "min\n",
            "(Ps)s,amax\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "εKL(Ps|Ks) +⟨a−Ps1m,fs⟩\n",
            "+⟨bs−PsT1m,gs⟩)\n",
            ".\n",
            "Strong duality holds, so that one can exchange the min and the max, and gets\n",
            "max\n",
            "(fs,gs)s∑\n",
            "sλs(\n",
            "⟨gs,bs⟩+ min\n",
            "PsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\n",
            "+ min\n",
            "a⟨∑\n",
            "sλsfs,a⟩.\n",
            "The explicit minimization on agives the constraint∑\n",
            "sλsfs= 0 together with\n",
            "max\n",
            "(fs,gs)s∑\n",
            "sλs⟨gs,bs⟩−εKL∗(fs⊕gs\n",
            "ε|Ks)\n",
            "where KL∗(·|Ks) is the Legendre transform ( ??) of the function KL∗(·|Ks). This Legendre transform reads\n",
            "KL∗(U|K) =∑\n",
            "i,jKi,j(eUi,j−1), (1.79)\n",
            "26\n",
            "Figure 1.15: Barycenters between 4 input 3-D shapes using entropic regularization (1.72). The weights\n",
            "(λs)sare bilinear with respect to the four corners of the square. Shapes are represented as measures that\n",
            "are uniform within the boundaries of the shape and null outside.\n",
            "which shows the desired formula. To show (1.79), since this function is separable, one needs to compute\n",
            "∀(u,k)∈R2\n",
            "+,KL∗(u|k)def.= max\n",
            "rur−(rlog(r/k)−r+k)\n",
            "whose optimality condition reads u= log(r/k), i.e.r=keu, hence the result.\n",
            "Minimizing (1.78) with respect to each gs, while keeping all the other variable ﬁxed, is obtained in closed\n",
            "form by (1.75). Minimizing (1.78) with respect to all the ( fs)srequires to solve for ausing (1.77) and leads\n",
            "to the expression (1.76).\n",
            "Figures ??and??show applications to 2-D and 3-D shapes interpolation. Figure ??shows a computation\n",
            "of barycenters on a surface, where the ground cost is the square of the geodesic distance. For this ﬁgure,\n",
            "the computations are performed using the geodesic in heat approximation detailed in Remark ??. We refer\n",
            "to [?] for more details and other applications to computer graphics and imaging sciences.\n",
            "Wasserstein Loss. In statistics, text processing or imaging, one must usually compare a probability\n",
            "distribution βarising from measurements to a model, namely a parameterized family of distributions {αθ,θ∈\n",
            "Θ}where Θ is a subset of an Euclidean space. Such a comparison is done through a “loss” or a “ﬁdelity”\n",
            "term, which, in this section, is the Wasserstein distance. In the simplest scenario, the computation of a\n",
            "suitable parameter θis obtained by minimizing directly\n",
            "min\n",
            "θ∈ΘE(θ)def.=Lc(αθ,β). (1.80)\n",
            "Of course, one can consider more complicated problems: for instance, the barycenter problem described\n",
            "in§??consists in a sum of such terms. However, most of these more advanced problems can be usually\n",
            "solved by adapting tools deﬁned for basic case: either using the chain rule to compute explicitly derivatives,\n",
            "or using automatic diﬀerentiation.\n",
            "The Wasserstein distance between two histograms or two densities is convex with respect to these inputs,\n",
            "as shown by (1.17) and (1.21) respectively. Therefore, when the parameter θis itself a histogram, namely Θ =\n",
            "Σnandαθ=θ, or more generally when θdescribesKweights in the simplex, Θ = Σ K, andαθ=∑K\n",
            "i=1θiαi\n",
            "is a convex combination of known atoms α1,...,αKin ΣN, Problem (1.80) remains convex (the ﬁrst case\n",
            "corresponds to the barycenter problem, the second to one iteration of the dictionary learning problem with\n",
            "a Wasserstein loss [ ?]). However, for more general parameterizations θ↦→αθ, Problem (1.80) is in general\n",
            "not convex.\n",
            "27\n",
            "g✓XZ⇣xz\u0000↵✓Figure 1.16: Schematic display of the density ﬁtting problem 1.81.\n",
            "A practical problem of paramount importance in statistic and machine learning is density ﬁtting. Given\n",
            "some discrete samples ( xi)n\n",
            "i=1⊂X from some unknown distribution, the goal is to ﬁt a parametric model\n",
            "θ↦→αθ∈M (X) to the observed empirical input measure β\n",
            "min\n",
            "θ∈ΘL(αθ,β) where β=1\n",
            "n∑\n",
            "iδxi, (1.81)\n",
            "whereLis some “loss” function between a discrete and a “continuous” (arbitrary) distribution (see Fig-\n",
            "ure 1.16).\n",
            "In the case where αθas a densify ρθdef.=ραθwith respect to the Lebesgue measure (or any other ﬁxed\n",
            "reference measure), the maximum likelihood estimator (MLE) is obtained by solving\n",
            "min\n",
            "θLMLE(αθ,β)def.=−∑\n",
            "ilog(ρθ(xi)).\n",
            "This corresponds to using an empirical counterpart of a Kullback-Leibler loss since, assuming the xiare i.i.d.\n",
            "samples of some ¯β, then\n",
            "LMLE(α,β)n→+∞−→ KL(α|¯β)\n",
            "This MLE approach is known to lead to optimal estimation procedures in many cases (see for instance [ ?]).\n",
            "However, it fails to work when estimating singular distributions, typically when the αθdoes not has a density\n",
            "(so thatLMLE(αθ,β) = +∞) or when ( xi)iare samples from some singular ¯β(so that the αθshould share\n",
            "the same support as βfor KL(α|¯β) to be ﬁnite, but this support is usually unknown). Another issue is that\n",
            "in several cases of practical interest, the density ρθis inaccessible (or too hard to compute).\n",
            "A typical setup where both problems (singular and unknown densities) occur is for so-called generative\n",
            "models, where the parametric measure is written as a push-forward of a ﬁxed reference measure ζ∈M (Z)\n",
            "αθ=hθ,♯ζwherehθ:Z→X\n",
            "where the push-forward operator is introduced in Deﬁnition 1. The space Zis usually low-dimensional, so\n",
            "that the support of αθis localized along a low-dimensional “manifold” and the resulting density is highly\n",
            "singular (it does not have a density with respect to Lebesgue measure). Furthermore, computing this density\n",
            "is usually intractable, while generating i.i.d. samples from αθis achieved by computing xi=hθ(zi) where\n",
            "(zi)iare i.i.d. samples from ζ.\n",
            "In order to cope with such diﬃcult scenario, one has to use weak metrics in place of the MLE functional\n",
            "LMLE, which needs to be written in dual form as\n",
            "L(α,β)def.= max\n",
            "(f,g)∈C(X)2{∫\n",
            "Xf(x)dα(x) +∫\n",
            "Xg(x)dβ(x) ; (f,g)∈R}\n",
            ". (1.82)\n",
            "Dual norms exposed in §??correspond to imposing R={(f,−f) ;f∈B}, while optimal transport (1.21)\n",
            "setsR=R(c) as deﬁned in (1.22).\n",
            "28\n",
            "For a ﬁxed θ, evaluating the energy to be minimized in (1.81) using such a loss function corresponds to\n",
            "solving a semi-discrete optimal transport, which is the focus of Chapter ??. Minimizing the energy with\n",
            "respect toθis much more involved, and is typically highly non-convex.\n",
            "The class of estimators obtained using L=Lc, often called “Minimum Kantorovitch Estimators” (MKE),\n",
            "was initially introduced in [ ?], see also [ ?].\n",
            "Gromov-Wasserstein. Optimal transport needs a ground cost Cto compare histograms ( a,b), it can\n",
            "thus not be used if the histograms are not deﬁned on the same underlying space, or if one cannot pre-register\n",
            "these spaces to deﬁne a ground cost. To address this issue, one can instead only assume a weaker assumption,\n",
            "namely that one has at its disposal two matrices D∈Rn×nandD′∈Rm×mthat represent some relationship\n",
            "between the points on which the histograms are deﬁned. A typical scenario is when these matrices are (power\n",
            "of) distance matrices. The Gromov-Wasserstein problem reads\n",
            "GW(( a,D),(b,D′))2def.= min\n",
            "P∈U(a,b)ED,D′(P)def.=∑\n",
            "i,j,i′,j′|Di,i′−D′\n",
            "j,j′|2Pi,jPi′,j′. (1.83)\n",
            "This is a non-convex problem, which can be recast as a Quadratic Assignment Problem (QAP) [ ?] and is in\n",
            "full generality NP-hard to solve for arbitrary inputs. It is in fact equivalent to a graph matching problem [ ?]\n",
            "for a particular cost.\n",
            "One can show that GW satisﬁes the triangular inequality, and in fact it deﬁnes a distance between\n",
            "metric spaces equipped with a probability distribution (here assumed to be discrete in deﬁnition (1.83))\n",
            "up to isometries preserving the measures. This distance was introduced and studied in details by Memoli\n",
            "in [?]. An in-depth mathematical exposition (in particular, its geodesic structure and gradient ﬂows) is given\n",
            "in [?]. See also [ ?] for applications in computer vision. This distance is also tightly connected with the\n",
            "Gromov-Hausdorﬀ distance [ ?] between metric spaces, which have been used for shape matching [ ?,?].\n",
            "Remark 19.Gromov-Wasserstein distance The general setting corresponds to computing couplings between\n",
            "metric measure spaces ( X,dX,αX) and (Y,dY,αY) where (dX,dY) are distances and ( αX,αY) are measures\n",
            "on their respective spaces. One deﬁnes\n",
            "GW((αX,dX),(αY,dY))2def.= min\n",
            "π∈U(αX,αY)∫\n",
            "X2×Y2|dX(x,x′)−dY(y,y′)|2dπ(x,y)dπ(x′,y′). (1.84)\n",
            "GW deﬁnes a distance between metric measure spaces up to isometries, where one says that ( αX,dX) and\n",
            "(αY,dY) are isometric if there exists ϕ:X→Y such thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′)) =dX(x,x′).\n",
            "Remark 20.Gromov-Wasserstein geodesics The space of metric spaces (up to isometries) endowed with\n",
            "thisGW distance (1.84) has a geodesic structure. [ ?] shows that the geodesic between ( X0,dX0,α0) and\n",
            "(X1,dX1,α1) can be chosen to be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is a solution of (1.84) and for all\n",
            "((x0,x1),(x′\n",
            "0,x′\n",
            "1))∈(X0×X 1)2,\n",
            "dt((x0,x1),(x′\n",
            "0,x′\n",
            "1))def.= (1−t)dX0(x0,x′\n",
            "0) +tdX1(x1,x′\n",
            "1).\n",
            "This formula allows one to deﬁne and analyze gradient ﬂows which minimize functionals involving metric\n",
            "spaces, see [ ?]. It is however diﬃcult to handle numerically, because it involves computations over the product\n",
            "spaceX0×X 1. A heuristic approach is used in [ ?] to deﬁne geodesics and barycenters of metric measure\n",
            "spaces while imposing the cardinality of the involved spaces and making use of the entropic smoothing (1.85)\n",
            "detailed below.\n",
            "To approximate the computation of GW, and to help convergence of minimization schemes to better\n",
            "minima, one can consider the entropic regularized variant\n",
            "min\n",
            "P∈U(a,b)ED,D′(P)−εH(P). (1.85)\n",
            "29\n",
            "Figure 1.17: Example of fuzzy correspondences computed by solving GW problem (1.85) with Sinkhorn\n",
            "iterations (1.86). Extracted from [ ?].\n",
            "As proposed initially in [ ?,?], and later revisited in [ ?] for applications in graphics, one can use iteratively\n",
            "Sinkhorn’s algorithm to progressively compute a stationary point of (1.85). Indeed, successive linearizations\n",
            "of the objective function lead to consider the succession of updates\n",
            "P(ℓ+1) def.= min\n",
            "P∈U(a,b)⟨P,C(ℓ)⟩−εH(P) where (1.86)\n",
            "C(ℓ)def.=∇ED,D′(P(ℓ)) =−D′TP(ℓ)D,\n",
            "which can be interpreted as a mirror-descent scheme [ ?]. Each update can thus be solved using Sinkhorn\n",
            "iterations (1.51) with cost C(ℓ). Figure (1.17) illustrates the use of this entropic Gromov-Wasserstein to\n",
            "compute soft maps between domains.\n",
            "30\n",
            "Bibliography\n",
            "[1] Amir Beck. Introduction to Nonlinear Optimization: Theory, Algorithms, and Applications with MAT-\n",
            "LAB. SIAM, 2014.\n",
            "[2] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization\n",
            "and statistical learning via the alternating direction method of multipliers. Foundations and Trends R⃝\n",
            "in Machine Learning , 3(1):1–122, 2011.\n",
            "[3] Stephen Boyd and Lieven Vandenberghe. Convex optimization . Cambridge university press, 2004.\n",
            "[4] E. Cand` es and D. Donoho. New tight frames of curvelets and optimal representations of objects with\n",
            "piecewise C2singularities. Commun. on Pure and Appl. Math. , 57(2):219–266, 2004.\n",
            "[5] E. J. Cand` es, L. Demanet, D. L. Donoho, and L. Ying. Fast discrete curvelet transforms. SIAM\n",
            "Multiscale Modeling and Simulation , 5:861–899, 2005.\n",
            "[6] A. Chambolle. An algorithm for total variation minimization and applications. J. Math. Imaging Vis. ,\n",
            "20:89–97, 2004.\n",
            "[7] Antonin Chambolle, Vicent Caselles, Daniel Cremers, Matteo Novaga, and Thomas Pock. An intro-\n",
            "duction to total variation for image analysis. Theoretical foundations and numerical methods for sparse\n",
            "recovery , 9(263-340):227, 2010.\n",
            "[8] Antonin Chambolle and Thomas Pock. An introduction to continuous optimization for imaging. Acta\n",
            "Numerica , 25:161–319, 2016.\n",
            "[9] S.S. Chen, D.L. Donoho, and M.A. Saunders. Atomic decomposition by basis pursuit. SIAM Journal\n",
            "on Scientiﬁc Computing , 20(1):33–61, 1999.\n",
            "[10] Philippe G Ciarlet. Introduction ` a l’analyse num´ erique matricielle et ` a l’optimisation. 1982.\n",
            "[11] P. L. Combettes and V. R. Wajs. Signal recovery by proximal forward-backward splitting. SIAM\n",
            "Multiscale Modeling and Simulation , 4(4), 2005.\n",
            "[12] I. Daubechies, M. Defrise, and C. De Mol. An iterative thresholding algorithm for linear inverse problems\n",
            "with a sparsity constraint. Commun. on Pure and Appl. Math. , 57:1413–1541, 2004.\n",
            "[13] D. Donoho and I. Johnstone. Ideal spatial adaptation via wavelet shrinkage. Biometrika , 81:425–455,\n",
            "Dec 1994.\n",
            "[14] Heinz Werner Engl, Martin Hanke, and Andreas Neubauer. Regularization of inverse problems , volume\n",
            "375. Springer Science & Business Media, 1996.\n",
            "[15] M. Figueiredo and R. Nowak. An EM Algorithm for Wavelet-Based Image Restoration. IEEE Trans.\n",
            "Image Proc. , 12(8):906–916, 2003.\n",
            "[16] Simon Foucart and Holger Rauhut. A mathematical introduction to compressive sensing , volume 1.\n",
            "Birkh¨ auser Basel, 2013.\n",
            "31\n",
            "[17] Stephane Mallat. A wavelet tour of signal processing: the sparse way . Academic press, 2008.\n",
            "[18] D. Mumford and J. Shah. Optimal approximation by piecewise smooth functions and associated varia-\n",
            "tional problems. Commun. on Pure and Appl. Math. , 42:577–685, 1989.\n",
            "[19] Neal Parikh, Stephen Boyd, et al. Proximal algorithms. Foundations and Trends R⃝in Optimization ,\n",
            "1(3):127–239, 2014.\n",
            "[20] Gabriel Peyr´ e. L’alg` ebre discr` ete de la transform´ ee de Fourier . Ellipses, 2004.\n",
            "[21] J. Portilla, V. Strela, M.J. Wainwright, and Simoncelli E.P. Image denoising using scale mixtures of\n",
            "Gaussians in the wavelet domain. IEEE Trans. Image Proc. , 12(11):1338–1351, November 2003.\n",
            "[22] L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear total variation based noise removal algorithms. Phys.\n",
            "D, 60(1-4):259–268, 1992.\n",
            "[23] Otmar Scherzer, Markus Grasmair, Harald Grossauer, Markus Haltmeier, Frank Lenzen, and L Sirovich.\n",
            "Variational methods in imaging . Springer, 2009.\n",
            "[24] C. E. Shannon. A mathematical theory of communication. The Bell System Technical Journal ,\n",
            "27(3):379–423, 1948.\n",
            "[25] Jean-Luc Starck, Fionn Murtagh, and Jalal Fadili. Sparse image and signal processing: Wavelets and\n",
            "related geometric multiscale analysis . Cambridge university press, 2015.\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1jXeefmM0_kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClX5CSQQ3cuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using text embeddings\n",
        "pdf_path =r\"/content/drive/MyDrive/chunking/ds (1).pdf\"\n",
        "text_chunker = TextChunker()\n",
        "text, documents  = text_chunker.extract_text_from_pdf(path = pdf_path )\n",
        "\n",
        "text_embedding_model_name = \"BAAI/bge-base-en-v1.5\"\n",
        "\n",
        "semantic_chunks = text_chunker.semantic_section_chunking_with_TextEmbedding( documents , text_embedding_model_name,  breakpoint_threshold_type = \"percentile\")\n",
        "\n",
        "\n",
        "print(\"\\nsemantic chunking with text embeddings:\")\n",
        "for i, chunk in enumerate(semantic_chunks):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d63a56aff40d415cabf70bfe39327c4f",
            "bfe320eafe644ebd86048d391e3fdc98",
            "d0f7990cb1ea4d7485ec0f81b124d4f9",
            "6435fcf4df6943b2bf132a1fb3aa6d74",
            "a64dc30335ff4fec9d3c7317286033ad",
            "4bcb8e2668d64bdea4c713d600c79ea7",
            "64714ca2dc6c43da917dab06c2355bdd",
            "ec9b1f532e974d7f9fb104e398a670bc",
            "4c23169b0a70431096209ff47090d214",
            "0c9c4abc0466440c934cc4c4b81a874c",
            "465fc92f17c64e03bc14cb558d8a6b8f",
            "8dfa0da36ea7428daaffeb84b094332e",
            "873628da40644b239e187bd38850a656",
            "9c43415c539349cea2e3bb95efc3cb29",
            "ea01b6402d2549dda5c11da39e92dd7f",
            "db38017b87134738933cb4dfe5678b6a",
            "60d6e95b2b874977a14febccfe3e3790",
            "67be254d06ef4cf28b8e1be6eb0da867",
            "2e36fbef8e84476d99414bb6e55eaa8a",
            "619a768b2cbc42efaf58db3a413f32d4",
            "5058e118fe3b4dcda6fabad76e90313f",
            "e87b7726d54a40d0b49988c409465ec2",
            "15bf7ff98a154d5698df381acaad9fb9",
            "7dceca8549b14b4380ebb20941145f65",
            "65c41a9548a84c699f4594f0cd904407",
            "b2d2bf9004e44e47924a891e38e2fbf6",
            "c94ff76f475143569c2f030e24409d97",
            "b50fa45be6514f1d9410da47cc5bad85",
            "2bf7429fe09c47e69af4ac4c967eb6b1",
            "76b9469949c5486c97c29a72ff812fb9",
            "7a1158f8a9c740d19c8922c4e5c64294",
            "7f644b5e8d0d471c83d94dcd332226a1",
            "0e0658f11a9b4e4282c7c6b0530d8ea6",
            "4582b810ba044f8aa22f93cbd4fc360a",
            "3d323e0c82f645848dcd838d00bf07af",
            "750e22e57a204aff9b92f796972864b1",
            "8d2350230ca74a15be5c87b0a6c11c7e",
            "70626758351e4835801b9b3c1c0b3b0f",
            "01020158deaf44688ebca211eda3ee89",
            "7d5b2d3f5be04e8fa5707213180fd5dd",
            "9fb61b21c70d4ea9a24cbbe1dd179d8e",
            "225c351a384347079968cf30a6d6ec5d",
            "c2e3827b36f747c49f7f99c4b49cbdd0",
            "87060c8538b24d598cd76b7822e6d5fc",
            "8a6ea0ecd2ac4632aaec256aab3afd7c",
            "ec7642e78fb94617ae5ce940b8105822",
            "7034641ae6fa43bd90b8a83ec1a8c650",
            "13b020570df24caca282a5c37535050d",
            "9576f6bfe5fe46c8b6a8bfa2529d28d9",
            "4fd0efc59d5746ed8eae1800400a41ff",
            "6fd60ba72216474d961d6c11ae7f572a",
            "cfde163b3d2d4b1db66fb1c925e06206",
            "4e1b25ce3de14fd78629472271092b31",
            "8324208d1267497583204f7ed9845900",
            "4f04dded6f1b4bddbdcd89fe3653a80c",
            "d9cbf5aacb9d4560b4f5d9856be1e4f4",
            "3cc8a522a7ff4fceb970dffad782723b",
            "592c05f603a74216ac09bfc1cab77440",
            "b4d0b374665e4b63bf5e82ceac00ce83",
            "541ddd80ecb74179ad5b7eeadef478cd",
            "474f5b8711fc47639ec8015910a08e20",
            "d68c7c56a52646a182e5adaa2cf2808a",
            "d26f02dce9434b2084ef216cd70a5eab",
            "a41114e234ee4483b9b18eae51537162",
            "07c160df6f5949fcb7715292a99d8d1c",
            "c795ba9a9b064f2e8710b616f1005e3e"
          ]
        },
        "id": "kvjvStDZ0RsF",
        "outputId": "7a477459-5d93-458b-cd83-7ec42dda4eb3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d63a56aff40d415cabf70bfe39327c4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/740 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dfa0da36ea7428daaffeb84b094332e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15bf7ff98a154d5698df381acaad9fb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4582b810ba044f8aa22f93cbd4fc360a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a6ea0ecd2ac4632aaec256aab3afd7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_optimized.onnx:   0%|          | 0.00/218M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9cbf5aacb9d4560b4f5d9856be1e4f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Mathematical Foundations of Data Sciences\\nGabriel Peyr´ e\\nCNRS & DMA\\n´Ecole Normale Sup´ erieure\\ngabriel.peyre@ens.fr\\nhttps://mathematical-tours.github.io\\nwww.numerical-tours.com\\nAugust 14, 2019'),\n",
              " Document(page_content='2'),\n",
              " Document(page_content='Chapter 1\\nOptimal Transport\\n1.1 Radon Measures\\nMeasures. We will interchangeably the term histogram or probability vector for any element a∈Σnthat\\nbelongs to the probability simplex\\nΣndef.={\\na∈Rn\\n+;n∑\\ni=1ai= 1}\\n. A discrete measure with weights aand locations x1,...,xn∈X reads\\nα=n∑\\ni=1aiδxi (1.1)\\nwhereδxis the Dirac at position x, intuitively a unit of mass which is inﬁnitely concentrated at location\\nx. Such as measure describes a probability measure if, additionally, a∈Σn, and more generally a positive\\nmeasure if each of the “weights” described in vector ais positive itself. Remark 1 (General measures) .A convenient feature of OT is that it can deal with discrete and continuous\\n“objects” within the same framework. Such objects only need to be modelled as measures. This corresponds\\nto the notion of Radon measures M(X) on the spaceX. The formal deﬁnition of that set requires that Xis\\nequipped with a distance, usually denoted d, because one can only access a measure by “testing” (integrating)\\nit against continuous functions, denoted f∈C(X). Integration of f∈C(X) against a discrete measure αcomputes a sum\\n∫\\nXf(x)dα(x) =n∑\\ni=1aif(xi). More general measures, for instance on X=Rd(whered∈N∗is the dimension), can have a density\\ndα(x) =ρα(x)dxw.r.t. the Lebesgue measure, often denoted ρα=dα\\ndx, which means that\\n∀h∈C(Rd),∫\\nRdh(x)dα(x) =∫\\nRdh(x)ρα(x)dx. An arbitrary measure α∈M (X) (which needs not to have a density nor be a sum of Diracs) is deﬁned by\\nthe fact that it can be integrated agains any continuous function f∈C(X) and obtain∫\\nXf(x)dα(x)∈R. IfXis not compact, one should also impose that fhas compact support or at least as 0 limit at inﬁnity. Measure as thus in some sense “less regular” than functions, but more regular than distributions (which are\\ndual to smooth functions). For instance, the derivative of a Dirac is not a measure. We denote M+(X) the\\nset of all positive measures on X. The set of probability measures is denoted M1\\n+(X), which means that\\nanyα∈M1\\n+(X) is positive, and that α(X) =∫\\nXdα= 1. Figure 1.1 oﬀers a visualization of the diﬀerent\\nclasses of measures, beyond histograms, considered in this work.'),\n",
              " Document(page_content='3'),\n",
              " Document(page_content='Discreted= 1 Discrete d= 2 Density d= 1 Density d= 2\\nFigure 1.1: Schematic display of discrete distributions α=∑n\\ni=1aiδxi(red corresponds to empirical uniform\\ndistribution ai= 1/n, and blue to arbitrary distributions) and densities d α(x) =ρα(x)dx(in violet), in both\\n1-D and 2-D. Discrete distributions in 1-D are displayed using vertical segments (with length equal to ai)\\nand in 2-D using point clouds (radius equal to ai). Operators on measures. For some continuous map T:X →Y , we deﬁne the pushforward operator\\nT♯:M(X)→M (Y). For discrete measures (1.1), the pushforward operation consists simply in moving the\\npositions of all the points in the support of the measure\\nT♯αdef.=∑\\niaiδT(xi). For more general measures, for instance for those with a density, the notion of push-forward plays a funda-\\nmental to describe spatial modiﬁcations of probability measures. The formal deﬁnition reads as follow. Deﬁnition 1 (Push-forward) .ForT:X → Y , the push forward measure β=T♯α∈ M (Y)of some\\nα∈M (X)reads\\n∀h∈C(Y),∫\\nYh(y)dβ(y) =∫\\nXh(T(x))dα(x). (1.2)\\nEquivalently, for any measurable set B⊂Y, one has\\nβ(B) =α({x∈X;T(x)∈B}). (1.3)\\nNote thatT♯preserves positivity and total mass, so that if α∈M1\\n+(X)thenT♯α∈M1\\n+(Y). Intuitively, a measurable map T:X→Y , can be interpreted as a function “moving” a single point from a\\nmeasurable space to another. The more general extension T♯can now “move” an entire probability measure\\nonXtowards a new probability measure on Y. The operator T♯“pushes forward” each elementary mass of\\na measureαonXby applying the map Tto obtain then an elementary mass in Y, to build on aggregate a\\nnew measure onY) writtenT♯α. Note that such a push-forward T♯:M1\\n+(X)→M1\\n+(Y) is a linear operator\\nbetween measures in the sense that for two measures α1,α2onX,T♯(α1+α2) =T♯α1+T♯α2. Remark 2 (Push-forward for densities) .Explicitly doing the change of variable in formula (1.2) for measures\\nwith densities ( ρα,ρβ) onRd(assumingTis smooth and a bijection) shows that a push-forward acts on\\ndensities linearly as a change of variables in the integration formula, indeed\\nρα(x) =|det(T′(x))|ρβ(T(x)) (1.4)\\nwhereT′(x)∈Rd×dis the Jacobian matrix of T(the matrix formed by taking the gradient of each coordinate\\nofT). This implies, denoting y=T(x)\\n|det(T′(x))|=ρα(x)\\nρβ(y).'),\n",
              " Document(page_content='4'),\n",
              " Document(page_content='=Pi\\x00xiT↵T]↵def.=Pi\\x00T(xi)\\nTT]gdef.=g\\x00TgPush-forward of measures Pull-back of functions\\nFigure 1.2: Comparison of push-forward T♯and pull-back T♯. Remark 3 (Push-forward vs. pull-back) .The push-forward T♯of measures should not be confounded with\\nthe pull-back of function T♯:C(Y)→C(X) which corresponds to the “warping” of functions. It is the linear\\nmap deﬁned, for g∈C(Y) byT♯g=g◦T. Push-forward and pull-back are actually adjoint one from each\\nothers, in the sense that\\n∀(α,g)∈M (X)×C(Y),∫\\nYgd(T♯α) =∫\\nX(T♯g)dα. It is important to realize that even if ( α,β) have densities ( ρα,ρβ),T♯αis not equal to T♯ρβ, because of\\nthe presence of the Jacobian in (1.4). This explains why OT should be used with caution to perform image\\nregistration, because it does not operate as an image warping method. Figure 1.2 illustrate the distinction\\nbetween these push-forward and pull-back operators. Remark 4 (Measures and random variables) .Radon measures can also be viewed as representing the distri-\\nbutions of random variables. A random variable XonXis actually a map X: Ω→X from some abstract\\n(often un-speciﬁed) probabized space (Ω ,P), and its distribution αis the Radon measure X∈M1\\n+(X) such\\nthatP(X∈A) =α(A) =∫\\nAdα(x). Equivalently, it is the push-forward of PbyX,α=X♯P. Applying\\nanother push-forward β=T♯αforT:X →Y , following (1.2), is equivalent to deﬁning another random\\nvariableY=T(X) :ω∈Ω→T(X(ω))∈Y, so thatβis the distribution of Y. Drawing a random sample\\nyfromYis thus simply achieved by computing y=T(x) wherexis drawn from X. Convergence of random variable.'),\n",
              " Document(page_content='Convergence of random variable (in probability, almost sure, in law),\\nconvergence of measures (strong, weak). 1.2 Monge Problem\\nGiven a cost matrix ( Ci,j)i∈JnK,j∈JmK, assuming n=m, the optimal assignment problem seeks for a\\nbijectionσin the set Perm( n) of permutations of nelements solving\\nmin\\nσ∈Perm(n)1\\nnn∑\\ni=1Ci,σ(i). (1.5)\\nOne could naively evaluate the cost function above using all permutations in the set Perm( n). However,\\nthat set has size n!, which is gigantic even for small n. Consider for instance that such a set has more than\\n10100elements [ ?] whennis as small as 70. That problem can therefore only be solved if there exist eﬃcient\\nalgorithms to optimize that cost function over the set of permutations, which will be the subject of §??. 5'),\n",
              " Document(page_content='x1x2y1y2x1x2y1y2x4x5x6x3y3x7Figure 1.3: (left) blue dots from measure αand red dots from measure βare pairwise equidistant. Hence,\\neither matching σ= (1,2) (full line) or σ= (2,1) (dotted line) is optimal. (right) a Monge map can associate\\nthe blue measure αto the red measure β. The weights αiare displayed proportionally to the area of the\\ndisk marked at each location. The mapping here is such that T(x1) =T(x2) =y2,T(x3) =y3, whereas for\\n4⩽i⩽7 we haveT(xi) =y1. Remark 5 (Uniqueness) .Note that the optimal assignment problem may have several optimal solutions. Suppose for instance that n=m= 2 and that the matrix Cis the pairwise distance matrix between the 4\\ncorners of a 2-dimensional square of side length 1, as represented in the left plot in Figure 1.3.'),\n",
              " Document(page_content='In that case\\nonly two assignments exist, and they share the same cost. For discrete measures\\nα=n∑\\ni=1aiδxiandβ=m∑\\nj=1bjδyj (1.6)\\nthe Monge problem [ ?] seeks for a map that associates to each point xia single point yj, and which must\\npush the mass of αtoward the mass of β, which is to say that such a map T:{x1,...,xn}→{y1,...,ym}\\nmust verify that\\n∀j∈JmK,bj=∑\\ni:T(xi)=yjai (1.7)\\nwhich we write in compact form as T♯α=β. This map should minimize some transportation cost, which is\\nparameterized by a function c(x,y) deﬁned for points ( x,y)∈X×Y\\nmin\\nT{∑\\nic(xi,T(xi)) ;T♯α=β}\\n. (1.8)\\nSuch a map between discrete points can be of course encoded, assuming all x’s andy’s are distinct, using\\nindicesσ:JnK→JmKso thatj=σ(i), and the mass conservation is written as\\n∑\\ni∈σ−1(j)ai=bj. In the special case when n=mand all weights are uniform, that is ai=bj= 1/n, then the mass conservation\\nconstraint implies that Tis a bijection, such that T(xi) =yσ(i), and the Monge problem is equivalent to the\\noptimal matching problem (1.5) where the cost matrix is\\nCi,jdef.=c(xi,yj). Whenn̸=m, note that, optimality aside, Monge maps may not even exist between an empirical measure\\nto another. This happens when their weight vectors are not compatible, which is always the case when the\\ntarget measure has more points than the source measure. For instance, the right plot in Figure 1.3 shows\\nan (optimal) Monge map between αandβ, but there is no Monge map from βtoα. 6'),\n",
              " Document(page_content='Monge problem (1.8) is extended to the setting of two arbitrary probability measures ( α,β) on two spaces\\n(X,Y) as ﬁnding a map T:X→Y that minimizes\\nmin\\nT{∫\\nXc(x,T(x))dα(x) ;T♯α=β}\\n(1.9)\\nThe constraint T♯α=βmeans that Tpushes forward the mass of αtoβ, and makes use of the push-forward\\noperator (1.2). 1.3 Kantorovitch Problem\\nThe assignment problem has several limitations in practical settings, also encountered when using the\\nMonge problem. Indeed, because the assignment problem is formulated as a permutation problem, it can only\\nbe used to compare two points clouds of the same size. A direct generalization to discrete measures with non-\\nuniform weights can be carried out using Monge’s formalism of pushforward maps, but that formulation may\\nalso be degenerate it there does not exist feasible solutions satisfying the mass conservation constraint (1.7)\\n(see the end of Remark ??). Additionally, the assignment Problem (1.8) is combinatorial, whereas the feasible\\nset for the Monge Problem (1.9), consisting in all push-forward measures that satisfy the mass conservation\\nconstraint, is non-convex . Both are therefore diﬃcult to solve in their original formulation.'),\n",
              " Document(page_content='Kantorovitch formulation for discrete measures. The key idea of [ ?] is to relax the deterministic na-\\nture of transportation, namely the fact that a source point xican only be assigned to another, or transported\\nto one and one location T(xi) only. Kantorovich proposes instead that the mass at any point xibe potentially\\ndispatched across several locations. Kantorovich moves away from the idea that mass transportation should\\nbe “deterministic” to consider instead a “probabilistic” (or “fuzzy”) transportation, which allows what is\\ncommonly known now as “mass splitting” from a source towards several targets. This ﬂexibility is encoded\\nusing, in place of a permutation σor a mapT, a coupling matrix P∈Rn×m\\n+, where Pi,jdescribes the\\namount of mass ﬂowing from bin i(or pointxi) towards bin j(or pointxj),xitowardsyjin the formalism\\nof discrete measures (1.6). Admissible couplings admit a far simpler characterization than Monge maps:\\nU(a,b)def.={\\nP∈Rn×m\\n+ ;P1m=aand PT1n=b}\\n, (1.10)\\nwhere we used the following matrix-vector notation\\nP1m=\\uf8eb\\n\\uf8ed∑\\njPi,j\\uf8f6\\n\\uf8f8\\ni∈Rnand PT1n=(∑\\niPi,j)\\nj∈Rm. The set of matrices U(a,b) is bounded, deﬁned by n+mequality constraints, and therefore a convex\\npolytope (the convex hull of a ﬁnite set of matrices). Additionally, whereas the Monge formulation (as illustrated in the right plot of Figure 1.3) was intrisically\\nasymmetric, Kantorovich’s relaxed formulation is always symmetric, in the sense that a coupling Pis in\\nU(a,b) if and only if PTis inU(b,a). Kantorovich’s optimal transport problem now reads\\nLC(a,b)def.= min\\nP∈U(a,b)⟨C,P⟩def.=∑\\ni,jCi,jPi,j. (1.11)\\nThis is a linear program (see Chapter ??), and as is usually the case with such programs, its solutions are\\nnot necessarily unique. 7'),\n",
              " Document(page_content='↵\\x00\\n↵\\x00Figure 1.4: Comparison of optimal matching and generic couplings. A black segment between xiandyj\\nindicates a non-zero element in the displayed optimal coupling Pi,jsolving (1.11). Left: optimal matching,\\ncorresponding to the setting of Proposition (1) (empirical measures with the same number n=mof points). Right: these two weighted point clouds cannot be matched; instead a Kantorovich coupling can be used to\\nassociate two arbitrary discrete measures. Permutation Matrices as Couplings For a permutation σ∈Perm(n), we write Pσfor the correspond-\\ning permutation matrix,\\n∀(i,j)∈JnK2,(Pσ)i,j={1/n ifj=σi,\\n0 otherwise.(1.12)\\nOne can check that in that case\\n⟨C,Pσ⟩=1\\nnn∑\\ni=1Ci,σi,\\nwhich shows that the assignment problem (1.5) can be recast as a Kantorovich problem (1.11) where the\\ncouplings Pare restricted to be exactly permutation matrices:\\nmin\\nσ∈Perm(n)1\\nnn∑\\ni=1Ci,σ(i)= min\\nσ∈Perm(n)⟨C,Pσ⟩. Next, one can easily check that the set of permutation matrices is strictly included in the so-called Birkhoﬀ\\npolytope U(1n/n,1n,n). Indeed, for any permutation σwe have Pσ1=1nandPσT1=1n, whereas\\n1n1nT/n2is a valid coupling but not a permutation matrix. Therefore, one has naturally that\\nmin\\nσ∈Perm(n)⟨C,Pσ⟩⩽LC(1n/n,1n/n). The following proposition shows that these problems result in fact in the same optimum, namely that\\none can always ﬁnd a permutation matrix that minimizes Kantorovich’s problem (1.11) between two uniform\\nmeasures a=b=1n/n, which shows that the Kantorovich relaxation is tight when considered on assignment\\nproblems. Figure 1.4 shows on the left a 2-D example of optimal matching corresponding to this special\\ncase. Proposition 1 (Kantorovich for matching) .Ifm=nanda=b=1n/n, then there exists an optimal\\nsolution for Problem (1.11) Pσ⋆, which is a permutation matrix associated to an optimal permutation σ⋆∈\\nPerm(n)for Problem (1.5) . Proof.'),\n",
              " Document(page_content='Birkhoﬀ’s theorem states that the set of extremal points of U(1n/n,1n/n) is equal to the set of\\npermutation matrices. A fundamental theorem of linear programming [ ?, Theorem 2.7] states that the\\nminimum of a linear objective in a non-empty polyhedron, if ﬁnite, is reached at an extremal point of the\\npolyhedron. 8'),\n",
              " Document(page_content='⇡\\x00↵\\x00↵\\n⇡\\x00↵\\x00↵\\n⇡\\x00↵\\x00↵\\nDiscrete Semi-discrete Continuous\\nFigure 1.5: Schematic viewed of input measures ( α,β) and couplingsU(α,β) encountered in the three main\\nscenario for Kantorovich OT. Chapter ??is dedicated to the semi-discrete setup.'),\n",
              " Document(page_content='⇡\\x00↵\\n⇡\\x00↵\\nFigure 1.6: Left: “continuous” coupling πsolving (1.13) between two 1-D measure with density. The\\ncoupling is localized along the graph of the Monge map ( x,T(x)) (displayed in black). Right: “discrete”\\ncouplingTsolving (1.11) between two discrete measures of the form (1.6). The non-zero entries Ti,jare\\ndisplay with a black disk at position ( i,j) with radius proportional to Ti,j. Kantorovitch formulation for arbitrary measures. The deﬁnition of Lcin (??) can be extended to\\narbitrary measures by considering couplings π∈M1\\n+(X×Y ) which are joint distributions over the product\\nspace. The discrete case is a special situation where one imposes this product measure to be of the form\\nπ=∑\\ni,jPi,jδ(xi,yj). In the general case, the mass conservation constraint (1.10) should be rewritten as a\\nmarginal constraint on joint probability distributions\\nU(α,β)def.={\\nπ∈M1\\n+(X×Y ) ;PX♯π=αandPY♯π=β}\\n. (1.13)\\nHerePX♯andPY♯are the push-forward (see Deﬁnition 1) by the projections PX(x,y) =xandPY(x,y) =y. Figure 1.5 shows a schematic visualization of the coupling constraints for diﬀerent class of problem (discrete\\nmeasures and densities). Using (1.3), these marginal constraints are equivalent to imposing that π(A×Y) =\\nα(A) andπ(X×B) =β(B) for setsA⊂X andB⊂Y. The Kantorovich problem (1.11) is then generalized as\\nLc(α,β)def.= min\\nπ∈U(α,β)∫\\nX×Yc(x,y)dπ(x,y). (1.14)\\nThis is an inﬁnite-dimensional linear program over a space of measures. Figure 1.6 shows examples of discrete\\nand continuous optimal coupling solving (1.14). Figure 1.7 shows other examples of optimal 1-D couplings,\\ninvolving discrete and continuous marginals. On compact domain ( X,Y), (1.14) always has a solution, because using the weak-* topology (so called\\nweak topology of measures), the set of measure is compact, and a linear function with a continuous c(x,y)\\n9'),\n",
              " Document(page_content='\\x00↵\\x00↵⇡\\n\\x00↵\\x00↵⇡\\n\\x00↵\\x00↵⇡\\n↵\\x00↵⇡\\x00Figure 1.7: Four simple examples of optimal couplings between 1-D distributions, represented as maps\\nabove (arrows) and couplings below. Inspired by [ ?].'),\n",
              " Document(page_content='is weak-* continuous. And the set of constraint is non empty, taking α⊗β. On non compact domain, needs\\nto impose moment condition on αandβ. Wasserstein distances. An important feature of OT is that it deﬁnes a distance between histograms\\nand probability measures as soon as the cost matrix satisﬁes certain suitable properties. Indeed, OT can be\\nunderstood as a canonical way to lift a ground distance between points to a distance between histogram or\\nmeasures. We ﬁrst consider the case where, using a term ﬁrst introduce by [ ?], the “ground metric” matrix C\\nis ﬁxed, representing substitution costs between bins, and shared across several histograms we would like\\nto compare. The following proposition states that OT provides a meaningful distance between histograms\\nsupported on these bins. Proposition 2. We suppose n=m, and that for some p⩾1,C=Dp= (Dp\\ni,j)i,j∈Rn×nwhere D∈Rn×n\\n+\\nis a distance on JnK,i.e. 1.D∈Rn×n\\n+ is symmetric;\\n2.Di,j= 0if and only if i=j;\\n3.∀(i,j,k )∈JnK3,Di,k⩽Di,j+Dj,k. Then\\nWp(a,b)def.= LDp(a,b)1/p(1.15)\\n(note that Wpdepends on D) deﬁnes the p-Wasserstein distance on Σn,i.e. Wpis symmetric, positive,\\nWp(a,b) = 0 if and only if a=b, and it satisﬁes the triangle inequality\\n∀a,a′,b∈Σn,Wp(a,b)⩽Wp(a,a′) + Wp(a′,b). Proof. Symmetry and deﬁniteness of the distance are easy to prove: since C=Dphas a null diagonal,\\nWp(a,a) = 0, with corresponding optimal transport matrix P⋆= diag( a); by the positivity of all oﬀ-diagonal\\nelements of Dp, Wp(a,b)>0 whenever a̸=b(because in this case, an admissible coupling necessarily has\\na non-zero element outside the diagonal); by symmetry of Dp, Wp(a,b) = 0 is itself a symmetric function. To prove the triangle inequality of Wasserstein distances for arbitrary measures, [ ?, Theorem 7.3] uses the\\ngluing lemma, which stresses the existence of couplings with a prescribed structure. In the discrete setting,\\nthe explicit constuction of this glued coupling is simple.'),\n",
              " Document(page_content='Let a,b,c∈Σn. Let PandQbe two optimal\\nsolutions of the transport problems between aandb, and bandcrespectively. We deﬁne ¯bjdef.=bjifbj>0\\nand set otherwise ¯bj= 1 (or actually any other value). We then deﬁne\\nSdef.=Pdiag(1/¯b)Q∈Rn×n\\n+. 10'),\n",
              " Document(page_content='We remark that S∈U(a,c) because\\nS1n=Pdiag(1/¯b)Q1n=P(b/¯b) =P1Supp( b)=a\\nwhere we denoted 1Supp( b)the indicator of the support of b, and we use the fact that P1Supp( b)=P1=b\\nbecause necessarily Pi,j= 0 forj /∈Supp( b). Similarly one veriﬁes that S⊤1n=c. The triangle inequality follows from\\nWp(a,c) =(\\nmin\\nP∈U(a,c)⟨P,Dp⟩)1/p\\n⩽⟨S,Dp⟩1/p\\n=\\uf8eb\\n\\uf8ed∑\\nikDp\\nik∑\\njPijQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n⩽\\uf8eb\\n\\uf8ed∑\\nijk(Dij+Djk)pPijQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n⩽\\uf8eb\\n\\uf8ed∑\\nijkDp\\nijPijQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n+\\uf8eb\\n\\uf8ed∑\\nijkDp\\njkPijQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n=\\uf8eb\\n\\uf8ed∑\\nijDp\\nijPij∑\\nkQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n+\\uf8eb\\n\\uf8ed∑\\njkDp\\njkQjk∑\\niPij\\n¯bj\\uf8f6\\n\\uf8f81/p\\n=\\uf8eb\\n\\uf8ed∑\\nijDp\\nijPij\\uf8f6\\n\\uf8f81/p\\n+\\uf8eb\\n\\uf8ed∑\\njkDp\\njkQjk\\uf8f6\\n\\uf8f81/p\\n= Wp(a,b) + Wp(b,b). The ﬁrst inequality is due to the suboptimality of S, the second is the usual triangle inequality for elements\\ninD, and the third comes from Minkowski’s inequality. Proposition 2 generalizes from histogram to arbitrary measures that need not be discrete.'),\n",
              " Document(page_content='Proposition 3. We assumeX=Y, and that for some p⩾1,c(x,y) =d(x,y)pwheredis a distance on\\nX,i.e. (i)d(x,y) =d(y,x)⩾0;\\n(ii)d(x,y) = 0 if and only if x=y;\\n(ii)∀(x,y,z )∈X3,d(x,z)⩽d(x,y) +d(y,z). Then\\nWp(α,β)def.=Ldp(α,β)1/p(1.16)\\n(note thatWpdepends on d) deﬁnes the p-Wasserstein distance on X,i.e.Wpis symmetric, positive,\\nWp(α,β) = 0 if and only if α=β, and it satisﬁes the triangle inequality\\n∀(α,β,γ )∈M1\\n+(X)3,Wp(α,γ)⩽Wp(α,β) +Wp(β,γ). Proof. The proof follows the same approach as that for Proposition 2 and relies on the existence of a coupling\\nbetween (α,γ) obtained by “guying” optimal couplings between ( α,β) and (β,γ). The Wasserstein distance Wphas many important properties, the most important one being that it is a\\nweak distance, i.e.it allows to compare singular distributions (for instance discrete ones) and to quantify\\nspatial shift between the supports of the distributions. In particular, “classical” distances (or divergences)\\nare not even deﬁned between discrete distributions (the L2norm can only be applied to continuous measures\\nwith a density with respect to a base measure, and the discrete ℓ2norm requires the positions ( xi,yj) to\\nbe ﬁxed to work). In sharp contrast, one has that for any p >0,Wp\\np(δx,δy) =d(x,y). Indeed, it suﬃces\\nto notice thatU(δx,δy) ={δx,y}and therefore the Kantorovich problem having only one feasible solution,\\nWp\\np(δx,δy) is necessarily ( d(x,y)p)1/p=d(x,y). This shows that Wp(δx,δy)→0 ifx→y. This property\\ncorresponds to the fact that Wpis a way to quantify the weak convergence as we now deﬁne. 11'),\n",
              " Document(page_content='Deﬁnition 2 (Weak convergence) .(αk)kconverges weakly to αinM1\\n+(X)(denotedαk⇀α ) if and only if\\nfor any continuous function g∈C(X),∫\\nXgdαk→∫\\nXgdα. This notion of weak convergence corresponds to\\nthe convergence in law of random vectors. This convergence can be shown to be equivalent to Wp(αk,α)→0 [?, Theorem 6.8] (together with a\\nconvergence of the moments up to order pfor unbounded metric spaces). Note that there exists alternative distances which also metrize weak convergence. The simplest one are\\nHilbertian norms, deﬁned as\\n||α||2\\nkdef.=Eα⊗α(k) =∫\\nX×Xk(x,y)dα(x)dα(y)\\nfor a suitable choice of kernel k:X2→R. The most famous of such kernel is the Gaussian one k(x,y) =\\ne−||x−y||2\\n2σ2for some choice of bandwidth σ>0. This convergence should not be confounded with the strong convergence of measures, which is metrized\\nby the TV norm ||α||TVdef.=|α|(X), which is the total mass of the absolute value of the measure. Algorithms Since ( ??)ˆA is a linear program, it is possible to use any classical linear program solver, such\\nas interior point methods or simplex.'),\n",
              " Document(page_content='In practice, the network simplex is an eﬃcient option, and it used\\npivoting rule adapted to the OT constraint set. In the case of the assignment problem, a=b=1n/n, there\\nexists faster combinatorial optimization scheme, the most famous ones being the Hungarian algorithm and\\nthe auction algorithm, which have roughly O(n3) complexity. Section 1.5 details an approximate algorithm,\\nwhich is typically faster, and amenable to parallelisation, but do not compute exactly the solution to the\\nOT problem. 1.4 Duality\\nThe Kantorovich problem (1.11) is a constrained convex minimization problem, and as such, it can be\\nnaturally paired with a so-called dual problem, which is a constrained concave maximization problem. The\\nfollowing fundamental proposition, which is a special case of Fenchel-Rockafellar duality theory, explains the\\nrelationship between the primal and dual problems. Proposition 4. One has\\nLC(a,b) = max\\n(f,g)∈R(a,b)⟨f,a⟩+⟨g,b⟩ (1.17)\\nwhere the set of admissible potentials is\\nR(a,b)def.={(f,g)∈Rn×Rm;∀(i,j)∈JnK×JmK,f⊕g⩽C} (1.18)\\nProof. This result is a direct consequence of the more general result on the strong duality for linear pro-\\ngrams [ ?, p.148,Theo.4.4]. The easier part of that result, namely that the right-hand side of Equation (1.17)\\nis a lower bound on L C(a,b) is discussed in ??. For the sake of completeness, let us derive this dual problem\\nwith the use of Lagrangian duality. The Lagangian associate to (1.11) reads\\nmin\\nP⩾0max\\n(f,g)∈Rn×Rm⟨C,P⟩+⟨a−P1m,f⟩+⟨b−P⊤1n,g⟩. (1.19)\\nFor linear program, one can always exchange the min and the max and get the same value of the linear\\nprogram, and one thus consider\\nmax\\n(f,g)∈Rn×Rm⟨a,f⟩+⟨b,g⟩+ min\\nP⩾0⟨C−f1⊤\\nm−1ng⊤,P⟩. We conclude by remarking that\\nmin\\nP⩾0⟨Q,P⟩={0 if Q⩾0\\n−∞ otherwise\\nso that the constraint reads C−f1⊤\\nm−1ng⊤=C−f⊕g⩾0. 12'),\n",
              " Document(page_content='The primal-dual optimality relation for the Lagrangian (1.19) allows to locate the support of the optimal\\ntransport plan\\nSupp( P)⊂{\\n(i,j)∈JnK×JmK;fi+gj=Ci,j}\\n. (1.20)\\nTo extend this primal-dual construction to arbitrary measures, it is important to realize that measures\\nare naturally paired in duality with continuous functions (a measure can only be accessed through integration\\nagainst continuous functions). The duality is formalized in the following proposition, which boils down to\\nProposition 4 when dealing with discrete measures. Proposition 5. One has\\nLc(α,β) = max\\n(f,g)∈R(c)∫\\nXf(x)dα(x) +∫\\nYg(y)dβ(y), (1.21)\\nwhere the set of admissible dual potentials is\\nR(c)def.={(f,g)∈C(X)×C(Y) ;∀(x,y),f(x) +g(y)⩽c(x,y)}. (1.22)\\nHere, (f,g)is a pair of continuous functions, and are often called “Kantorovich potentials”. The discrete case (1.17) corresponds to the dual vectors being samples of the continuous potentials, i.e. (fi,gj) = (f(xi),g(yj)). The primal-dual optimality conditions allow to track the support of optimal plan,\\nand (1.20) is generalized as\\nSupp(π)⊂{(x,y)∈X×Y ;f(x) +g(y) =c(x,y)}. (1.23)\\nNote that in contrast to the primal problem (1.14), showing the existence of solutions to (1.21) is non-\\ntrivial, because the constraint set R(c) is not compact and the function to minimize non-coercive. Using the\\nmachinery of c-transform detailed in Section ??, one can however show that optimal ( f,g) are necessarily\\nLipschitz regular, which enable to replace the constraint by a compact one. Benier’s Theorem and Monge-Amp` ere PDE The following celebrated theorem of [ ?] ensures that in\\nRdforp= 2, if at least one of the two inputs measures has a density, then Kantorovitch and Monge problems\\nare equivalent. Theorem 1 (Brenier) .In the caseX=Y=Rdandc(x,y) =||x−y||2, if at least one of the two inputs\\nmeasures (denoted α) has a density ραwith respect to the Lebesgue measure, then the optimal πin the\\nKantorovich formulation (1.14) is unique, and is supported on the graph (x,T(x))of a “Monge map” T:\\nRd→Rd. This means that π= (Id,T)♯µ,i.e. ∀h∈C(X×Y ),∫\\nX×Yh(x,y)dπ(x,y) =∫\\nXh(x,T(x))dµ(x). (1.24)\\nFurthermore, this map Tis uniquely deﬁned as the gradient of a convex function ϕ,T(x) =∇ϕ(x), where\\nϕis the unique (up to an additive constant) convex function such that (∇ϕ)♯µ=ν. This convex function is\\nrelated to the dual potential fsolving (1.21) asϕ(x) =||x||2\\n2−f(x). Proof.'),\n",
              " Document(page_content='We sketch the main ingredients of the proof, more details can be found for instance in [ ?]. We remark\\nthat∫\\ncdπ=Cα,β−2∫\\n⟨x, y⟩dπ(x,y) where the constant is Cα,β=∫\\n||x||2dα(x) +∫\\n||y||2dβ(y). Instead of\\nsolving (1.14), one can thus consider the following problem\\nmax\\nπ∈U(α,β)∫\\nX×Y⟨x, y⟩dπ(x,y),\\nwhose dual reads\\nmin\\n(ϕ,ψ){∫\\nXϕdα+∫\\nYψdβ;∀(x,y), ϕ (x) +ψ(y)⩾⟨x, y⟩}\\n. (1.25)\\n13'),\n",
              " Document(page_content='The relation between these variables and those of (1.22) is ( ϕ,ψ) = (||·||2\\n2−f,||·||2\\n2−g). One can replace the\\nconstraint by\\n∀y, ψ (y)⩾ϕ∗(y)def.= sup\\nx⟨x, y⟩−ϕ(x). (1.26)\\nHereϕ∗is the Legendre transform of ϕand is a convex function as a supremum of linear forms (see\\nalso ( ??)). Since the objective appearing in (1.27) is linear and the integrating measures positive, one can\\nminimize explicitly with respect to ϕand setψ=ϕ∗in order to consider the unconstraint problem\\nmin\\nϕ∫\\nXϕdα+∫\\nYϕ∗dβ, (1.27)\\nsee also Section ??for a generalization of this idea to generic costs c(x,y). By iterating this argument\\ntwice, one can replace ϕbyϕ∗∗, which is a convex function, and thus impose in (1.27) that ϕis convex. Condition (1.23) shows that an optimal πis supported on{(x,y) ;ϕ(x) +ϕ∗(y) =⟨x, y⟩}which shows that\\nsuch anyis optimal for the minimization (1.26) of the Legendre transform, whose optimality condition reads\\ny∈∂ϕ(x). Sinceϕis convex, it is diﬀerentiable almost everywhere, and since αhas a density, it is also\\ndiﬀerentiable α-almost everywhere. This shows that for each x, the associated yis uniquely deﬁned α-almost\\neverywhere as y=∇ϕ(x), and shows that necessarily π= (Id,∇ϕ)♯α. This results shows that in the setting of W2with non-singular densities, the Monge problem (1.9)\\nand its Kantorovich relaxation (1.14) are equal (the relaxation is tight). This is the continuous analog\\nof Proposition 1 for the assignment case (1), which states that the minimum of the optimal transport\\nproblem is achieved, when the marginals are equal and uniform, at a permutation matrix (a discrete map). Brenier’s theorem, stating that an optimal transport map must be the gradient of a convex function, should\\nbe examined under the light that a convex function is the natural generalization of the notion of increasing\\nfunctions in dimension more than one. Optimal transport can thus plays an important role to deﬁne quantile\\nfunctions in arbitrary dimensions, which in turn is useful for applications to quantile regression problems [ ?]. Note also that this theorem can be extended in many directions.'),\n",
              " Document(page_content='The condition that αhas a density can\\nbe weakened to the condition that it does not give mass to “small sets” having Hausdorﬀ dimension smaller\\nthand−1 (e.g. hypersurfaces).'),\n",
              " Document(page_content='One can also consider costs of the form c(x,y) =h(x−y) wherehis a\\nstrictly convex function. For measures with densities, using (1.4), one obtains that ϕis the unique (up to the addition of a\\nconstant) convex function which solves the following Monge-Amp ˜A¨re-type equation\\ndet(∂2ϕ(x))ρβ(∇ϕ(x)) =ρα(x) (1.28)\\nwhere∂2ϕ(x)∈Rd×dis the hessian of ϕ. The Monge-Amp` ere operator det( ∂2ϕ(x)) can be understood as a\\nnon-linear degenerate Laplacian. In the limit of small displacements, ϕ= Id +εϕ, one indeed recovers the\\nLaplacian ∆ as a linearization since for smooth maps\\ndet(∂2ϕ(x)) = 1 +ε∆ϕ(x) +o(ε). The convexity constraint forces det( ∂2ϕ(x))⩾0 and is necessary for this equation to have a solution. Special cases In general, computing OT distances is numerically involved. We review special favorable\\ncases where the resolution of the OT problem is easy. Remark 6 (Binary Cost Matrix and 1-Norm) .One can easily check that when the cost matrix Cis zero on\\nthe diagonal and 1 elsewhere, namely when C=1n×n−In, the OT distance between aandbis equal to\\nthe 1-norm of their diﬀerence, L C(a,b) =||a−b||1. One can also easily check that this result extends to\\ndiscrete and discrete measures in the case where c(x,y) is 0 ifx=yand 1 when x̸=y. The OT distance\\nbetween two discrete measures αandβis equal to their total variation distance. 14'),\n",
              " Document(page_content='\\x00\\x00↵Figure 1.8: 1-D optimal couplings: each arrow xi→yjindicate a non-zero Pi,jin the optimal coupling. Top: empirical measures with same number of points (optimal matching). Bottom: generic case. This\\ncorresponds to monotone rearrangements, if xi⩽xi′are such that Pi,j̸= 0,Pi′,j′̸= 0, then necessarily\\nyj⩽yj′. Remark 7 (1-D case – Empirical measures) .HereX=R. Assuming α=1\\nn∑n\\ni=1δxiandβ=1\\nn∑n\\nj=1δyj,\\nand assuming (without loss of generality) that the points are ordered, i.e.x1⩽x2⩽...⩽xnand\\ny1⩽y2⩽...⩽yn, then one has the simple formula\\nWp(α,β)p=p∑\\ni=1|xi−yi|p, (1.29)\\ni.e.locally (if one assumes distinct points), Wp(α,β) is theℓpnorm between two vectors of ordered values of\\nαandβ. That statement is only valid locally, in the sense that the order (and those vector representations)\\nmight change whenever some of the values change. That formula is a simple consequence of the more general\\nremark given below. Figure 1.8, top row, illustrates the 1-D transportation map between empirical measures\\nwith the same number of points. The bottom row shows how this monotone map generalizes to arbitrary\\ndiscrete measures. It is possible to leverage this 1-D computation to also compute eﬃciently OT on the\\ncircle, see [ ?]. Note that in the case of concave cost of the distance, for instance when p<1, the behaviour\\nof the optimal transport plan is very diﬀerent, see [ ?], which describes an eﬃcient solver in this case. Remark 8 (1-D case – Generic case) .For a measure αonR, we introduce the cumulative function\\n∀x∈R,Cα(x)def.=∫x\\n−∞dα, (1.30)\\nwhich is a function Cα:R→[0,1], and its pseudo-inverse C−1\\nα: [0,1]→R∪{−∞}\\n∀r∈[0,1],C−1\\nα(r) = min\\nx{x∈R∪{−∞} ;Cα(x)⩾r}. That function is also called the generalized quantile function of α. For anyp⩾1, one has\\nWp(α,β)p=||C−1\\nα−C−1\\nβ||p\\nLp([0,1])=∫1\\n0|C−1\\nα(r)−C−1\\nβ(r)|pdr. (1.31)\\nThis means that through the map α↦→C−1\\nα, the Wasserstein distance is isometric to a linear space equipped\\nwith theLpnorm, or, equivalently, that the Wasserstein distance for measures on the real line is a Hilbertian\\nmetric. This makes the geometry of 1-D optimal transport very simple, but also very diﬀerent from its\\ngeometry in higher dimensions, which is not Hilbertian as discussed in Proposition ??and more generally\\nin§??. Forp= 1, one even has the simpler formula\\nW1(α,β) =||Cα−Cβ||L1(R)=∫\\nR|Cα(x)−Cβ(x)|dx (1.32)\\n=∫\\nR⏐⏐⏐⏐∫x\\n−∞d(α−β)⏐⏐⏐⏐dx.'),\n",
              " Document(page_content='(1.33)\\n15'),\n",
              " Document(page_content='µ ν (tT+ (1−t)Id)♯µ\\n0 0.5 10.5Cµ\\nCν\\n0 0.5 100.51\\nCµ-1\\nCν-1\\n0 0.5 100.51\\nT\\nT-1\\n0 0.5 100.51\\n(Cα,Cβ) (C−1\\nα,C−1\\nβ) ( T,T−1) (1−t)C−1\\nα+tC−1\\nβ\\nFigure 1.9: Computation of OT and displacement interpolation between two 1-D measures, using cumulant\\nfunction as detailed in (1.34). which shows that W1is a norm (see§??for the generalization to arbitrary dimensions). An optimal Monge\\nmapTsuch thatT♯α=βis then deﬁned by\\nT=C−1\\nβ◦Cα. (1.34)\\nFigure 1.9 illustrates the computation of 1-D OT through cumulative functions. It also displays displacement\\ninterpolations, computed as detailed in ( ??), see also Remark ??. For a detailed survey of the properties of\\noptimal transport in 1-D, we refer the reader to [ ?, Chapter 2]. Remark 9 (Distance between Gaussians) .Ifα=N(mα,Σα) andβ=N(mβ,Σβ) are two Gaussians in Rd,\\nthen one can show that the following map\\nT:x↦→mβ+A(x−mα), (1.35)\\nwhere\\nA=Σ−1\\n2α(\\nΣ1\\n2αΣβΣ1\\n2α)1\\n2Σ−1\\n2α=AT,\\nis such that T♯ρα=ρβ. Indeed, one simply has to notice that the change of variables formula (1.4) is satisﬁed\\nsince\\nρβ(T(x)) = det(2πΣβ)−1\\n2exp(−⟨T(x)−mβ,Σ−1\\nβ(T(x)−mβ)⟩)\\n= det(2πΣβ)−1\\n2exp(−⟨x−mα, ATΣ−1\\nβA(x−mα)⟩)\\n= det(2πΣβ)−1\\n2exp(−⟨x−mα,Σ−1\\nα(x−mα)⟩),\\nand sinceTis a linear map we have that\\n|detT′(x)|= detA=(detΣβ\\ndetΣα)1\\n2\\nand we therefore recover ρα=|detT′|ρβmeaningT♯α=β. Notice now that Tis the gradient of the convex\\nfunctionψ:x↦→1\\n2⟨x−mα, A(x−mα)⟩+⟨mβ, x⟩to conclude, using Brenier’s theorem [ ?] (see Remark ??)\\nthatTis optimal. Both that map Tand the corresponding potential ψare illustrated in Figures 1.10 and ??'),\n",
              " Document(page_content='16'),\n",
              " Document(page_content='-4 -2 0 2 4 6-3-2-101234\\nρβραFigure 1.10: Two Gaussians ραandρβ, represented using the contour plots of their densities, with respective\\nmean and variance matrices mα= (−2,0),Σα=1\\n2(\\n1−1\\n2;−1\\n21)\\nandmβ= (3,1),Σβ=(\\n2,1\\n2;1\\n2,1)\\n. The\\narrows originate at random points xtaken on the plane and end at the corresponding mappings of those\\npointsT(x) =mβ+A(x−mα). \\x00m\\nFigure 1.11: Computation of displacement interpolation between two 1-D Gaussians. Denoting Gm,σ(x)def.=\\n1√\\n2πse−(x−m)2\\n2s2the Gaussian density, it thus shows the interpolation G(1−t)m0+tm1,(1−t)σ0+tσ1. With additional calculations involving ﬁrst and second order moments of ρα, we obtain that the transport\\ncost of that map is\\nW2\\n2(α,β) =||mα−mβ||2+B(Σα,Σβ)2(1.36)\\nwhereBis the so-called Bures’ metric [ ?] between positive deﬁnite matrices (see also [ ?,?]),\\nB(Σα,Σβ)2def.= tr(\\nΣα+Σβ−2(Σ1/2\\nαΣβΣ1/2\\nα)1/2)\\n, (1.37)\\nwhere Σ1/2is the matrix square root. One can show that Bis a distance on covariance matrices, and that\\nB2is convex with respect to both its arguments.'),\n",
              " Document(page_content='In the case where Σα= diag(ri)iandΣβ= diag(si)iare\\ndiagonals, the Bures metric is the Hellinger distance\\nB(Σα,Σβ) =||√r−√s||2. For 1-D Gaussians, W2is thus the Euclidean distance on the 2-D plane ( m,√\\nΣ), as illustrated in Figure 1.11. For a detailed treatment of the Wasserstein geometry of Gaussian distributions, we refer to [ ?]. 1.5 Sinkhorn\\nThis section introduces a family of numerical scheme to approximate solutions to Kantorovich formulation\\nof optimal transport and its many generalizations. It operates by adding an entropic regularization penalty to\\nthe original problem. This regularization has several important advantages, but a few stand out particularly:\\nThe minimization of the regularized problen can be solved using a simple alternate minimization scheme;\\nthat scheme translates into iterations that are simple matrix products, making them particularly suited to\\nexecution of GPU; the resulting approximate distance is smooth with respect to input histogram weights\\nand positions of the Diracs. 17'),\n",
              " Document(page_content='c\"P\"Figure 1.12: Impact of εon the optimization of a linear function on the simplex, solving Pε=\\nargminP∈Σ3⟨C,P⟩−εH(P) for a varying ε. Entropic Regularization. The discrete entropy of a coupling matrix is deﬁned as\\nH(P)def.=−∑\\ni,jPi,j(log(Pi,j)−1), (1.38)\\nwith an analogous deﬁnition for vectors, with the convention that H(a) =−∞ if one of the entries ajis\\n0 or negative. The function His 1-strongly concave, because its hessian is ∂2H(P) =−diag(1/Pi,j) and\\nPi,j⩽1. The idea of the entropic regularization of optimal transport is to use −Has a regularizing function\\nto obtain approximate solutions to the original transport problem (1.11):\\nLε\\nC(a,b)def.= min\\nP∈U(a,b)⟨P,C⟩−εH(P). (1.39)\\nSince the objective is a ε-strongly convex function, problem 1.39 has a unique optimal solution. The idea\\nto regularize the optimal transport problem by an entropic term can be traced back to modeling ideas in\\ntransportation theory [ ?]: Actual traﬃc patterns in a network do not agree with those predicted by the\\nsolution of the optimal transport problem. Indeed, the former are more diﬀuse than the latter, which tend\\nto rely on a few routes as a result of the sparsity of optimal couplings to the solution of 1.11. To balance for\\nthat, researchers in transportation proposed a model, called the “gravity” model [ ?], that is able to form a\\nmore “blurred” traﬃc prediction. Figure 1.12 illustrates the eﬀect of the entropy to regularize a linear program over the simples Σ 3(which\\ncan thus be visualized as a triangle in 2-D). Note how the entropy pushes the original LP solution away\\nfrom the boundary of the triangle. The optimal Pεprogressively moves toward an “entropic center” of the\\ntriangle. This is further detailed in the proposition below. The convergence of the solution of that regularized\\nproblem towards an optimal solution of the original linear program has been studied by [ ?]. Proposition 6 (Convergence with ε).The unique solution Pεof(1.39) converges to the optimal solution\\nwith maximal entropy within the set of all optimal solutions of the Kantorovich problem, namely\\nPεε→0−→argmin\\nP{−H(P) ;P∈U(a,b),⟨P,C⟩= LC(a,b)} (1.40)\\nso that in particular\\nLε\\nC(a,b)ε→0−→LC(a,b). One has\\nPεε→∞−→abT= (aibj)i,j.'),\n",
              " Document(page_content='(1.41)\\nProof. We consider a sequence ( εℓ)ℓsuch thatεℓ→0 andεℓ>0. We denote Pℓthe solution of (1.39) for\\nε=εℓ. Since U(a,b) is bounded, we can extract a sequence (that we do not relabel for sake of simplicity)\\nsuch that Pℓ→P⋆. Since U(a,b) is closed, P⋆∈U(a,b).'),\n",
              " Document(page_content='We consider any Psuch that⟨C,P⟩= LC(a,b). By optimality of PandPℓfor their respective optimization problems (for ε= 0 andε=εℓ), one has\\n0⩽⟨C,Pℓ⟩−⟨C,P⟩⩽εℓ(H(Pℓ)−H(P)). (1.42)\\n18'),\n",
              " Document(page_content='⇡\"↵\\x00\\n\"\\x00↵Figure 1.13: Impact of εon coupling between densities and discrete distributions, illustrating Proposition 6. Left: between two 1-D densities. Right: between two 2-D discrete empirical densities with same number\\nn=mof points (only entries of the optimal ( Pi,j)i,jabove a small threshold are displayed as segments\\nbetweenxiandyj). Since His continuous, taking the limit ℓ→+∞in this expression shows that ⟨C,P⋆⟩=⟨C,P⟩so that\\nP⋆is a feasible point of (1.40).'),\n",
              " Document(page_content='Furthermore, dividing by εℓin (1.42) and taking the limit shows that\\nH(P)⩽H(P⋆), which shows that P⋆is a solution of (1.40). Since the solution P⋆\\n0to this program is unique\\nby strict convexity of −H, one has P⋆=P⋆\\n0, and the whole sequence is converging. Formula (1.40) states that for low regularization, the solution converges to the maximum entropy optimal\\ntransport coupling. In sharp contrast, (1.41) shows that for large regularization, the solution converges to the\\ncoupling with maximal entropy between two prescribed marginals a,b, namely the joint probability between\\ntwo independent random variables with prescribed distributions. A reﬁned analysis of this convergence is\\nperformed in [ ?], including a ﬁrst order expansion in ε(resp. 1/ε) nearε= 0 (respε= +∞). Figure 1.13\\nshows visually the eﬀect of these two convergence. A key insight is that, as εincreases, the optimal coupling\\nbecomes less and less sparse (in the sense of having entries larger than a prescribed thresholds), which in\\nturn as the eﬀect of both accelerating computational algorithms (as we study in §1.5) but also leading to\\nfaster statistical convergence (as exposed in §??). Deﬁning the Kullback-Leibler divergence between couplings as\\nKL(P|K)def.=∑\\ni,jPi,jlog(Pi,j\\nKi,j)\\n−Pi,j+Ki,j, (1.43)\\nthe unique solution Pεof (1.39) is a projection onto U(a,b) of the Gibbs kernel associated to the cost matrix\\nCas\\nKi,jdef.=e−Ci,j\\nε\\nIndeed one has that using the deﬁnition above\\nPε= ProjKL\\nU(a,b)(K)def.= argmin\\nP∈U(a,b)KL(P|K). (1.44)\\nRemark 10 (General formulation) .One can consider arbitrary measures by replacing the discrete entropy\\nby the relative entropy with respect to the product measure d α⊗dβ(x,y)def.= dα(x)dβ(y), and propose a\\nregularized counterpart to (1.14) using\\nLε\\nc(α,β)def.= min\\nπ∈U(α,β)∫\\nX×Yc(x,y)dπ(x,y) +εKL(π|α⊗β) (1.45)\\nwhere the relative entropy is a generalization of the discrete Kullback-Leibler divergence (1.43)\\nKL(π|ξ)def.=∫\\nX×Ylog(dπ\\ndξ(x,y))\\ndπ(x,y)+\\n∫\\nX×Y(dξ(x,y)−dπ(x,y)),(1.46)\\n19'),\n",
              " Document(page_content='and by convention KL( π|ξ) = +∞ifπdoes not have a densitydπ\\ndξwith respect to ξ. It is important to\\nrealize that the reference measure α⊗βchosen in (1.45) to deﬁne the entropic regularizing term KL( ·|α⊗β)\\nplays no speciﬁc role, only its support matters. Formula (1.45) can be re-factored as a projection problem\\nmin\\nπ∈U(α,β)KL(π|K) (1.47)\\nwhereKis the Gibbs distributions d K(x,y)def.=e−c(x,y)\\nεdµ(x)dν(y). This problem is often referred to as the\\n“static Schr¨ odinger problem” [ ?,?], since it was initially considered by Schr¨ odinger in statistical physics [ ?]. Asε→0, the unique solution to (1.47) converges to the maximum entropy solution to (1.14), see [ ?,?].§?? details an alternate “dynamic” formulation of the Schr¨ odinger problem over the space of paths connecting\\nthe points of two measures. Sinkhorn’s Algorithm The following proposition shows that the solution of (1.39) has a speciﬁc form,\\nwhich can be parameterized using n+mvariables. That parameterization is therefore essentially dual, in\\nthe sense that a coupling PinU(a,b) hasnmvariables but n+mconstraints. Proposition 7. The solution to (1.39) is unique and has the form\\n∀(i,j)∈JnK×JmK,Pi,j=uiKi,jvj (1.48)\\nfor two (unknown) scaling variable (u,v)∈Rn\\n+×Rm\\n+. Proof. Introducing two dual variables f∈Rn,g∈Rmfor each marginal constraint, the Lagrangian of (1.39)\\nreads\\nE(P,f,g) =⟨P,C⟩−εH(P)−⟨f,P1m−a⟩−⟨g,PT1n−b⟩. Considering ﬁrst order conditions, we have\\n∂E(P,f,g)\\n∂Pi,j=Ci,j−εlog(Pi,j)−fi−gj. which results, for an optimal Pcoupling to the regularized problem, in the expression Pi,j=efi/εe−Ci,j/εegj/ε\\nwhich can be rewritten in the form provided in the proposition using non-negative vectors uandv. The factorization of the optimal solution exhibited in Equation (1.48) can be conveniently rewritten in\\nmatrix form as P= diag( u)Kdiag(v).u,vmust therefore satisfy the following non-linear equations which\\ncorrespond to the mass conservation constraints inherent to U(a,b),\\ndiag(u)Kdiag(v)1m=a,and diag( v)K⊤diag(u)1n=b, (1.49)\\nThese two equations can be further simpliﬁed, since diag( v)1mis simply v, and the multiplication of diag( u)\\ntimes Kvis\\nu⊙(Kv) =aand v⊙(KTu) =b (1.50)\\nwhere⊙corresponds to entry-wise multiplication of vectors. That problem is known in the numerical analysis\\ncommunity as the matrix scaling problem (see [ ?] and references therein).'),\n",
              " Document(page_content='An intuitive way to try to solve\\nthese equations is to solve them iteratively, by modifying ﬁrst uso that it satisﬁes the left-hand side of\\nEquation (1.50) and then vto satisfy its right-hand side. These two updates deﬁne Sinkhorn’s algorithm:\\nu(ℓ+1)def.=a\\nKv(ℓ)and v(ℓ+1)def.=b\\nKTu(ℓ+1), (1.51)\\ninitialized with an arbitrary positive vector v(0)=1m. The division operator used above between two\\nvectors is to be understood entry-wise. Note that a diﬀerent initialization will likely lead to a diﬀerent\\n20'),\n",
              " Document(page_content='`⇡(`)\"\\n1000 2000 3000 4000 5000-2-1.5-1-0.50`Figure 1.14: Left: evolution of the coupling πℓ\\nε= diag( U(ℓ))Kdiag(V(ℓ)) computed at iteration ℓof\\nSinkhorn’s iterations, for 1-D densities. Right: impact of εthe convergence rate of Sinkhorn, as measured\\nin term of marginal constraint violation log( ||πℓ\\nε1m−b||1). solution for u,v, since u,vare only deﬁned up to a multiplicative constant (if u,vsatisfy (1.49) then\\nso doλu,v/λfor anyλ > 0). It turns out however that these iterations converge (see Remark 11 for\\na justiﬁcation using iterative projections, and Remark 13 for a strict contraction result) and all result in\\nthe same optimal coupling diag( u)Kdiag(v). Figure 1.14, top row, shows the evolution of the coupling\\ndiag(U(ℓ))Kdiag(V(ℓ)) computed by Sinkhorn iterations. It evolves from the Gibbs kernel Ktowards the\\noptimal coupling solving (1.39) by progressively shifting the mass away from the diagonal. Remark 11 (Relation with iterative projections) .Denoting\\nC1\\nadef.={P;P1m=a}andC2\\nbdef.={\\nP;PT1m=b}\\nthe rows and columns constraints, one has U(a,b) =C1\\na∩C2\\nb.'),\n",
              " Document(page_content='One can use Bregman iterative projections [ ?]\\nP(ℓ+1) def.= ProjKL\\nC1a(P(ℓ)) and P(ℓ+2) def.= ProjKL\\nC2\\nb(P(ℓ+1)). (1.52)\\nSince the setsC1\\naandC2\\nbare aﬃne, these iterations are known to converge to the solution of (1.44), see [ ?]. These iterate are equivalent to Sinkhorn iterations (1.51) since deﬁning\\nP(2ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)),\\none has\\nP(2ℓ+1) def.= diag( u(ℓ+1))Kdiag(v(ℓ))\\nand P(2ℓ+2) def.= diag( u(ℓ+1))Kdiag(v(ℓ+1))\\nIn practice however one should prefer using (1.51) which only requires manipulating scaling vectors and\\nmultiplication against a Gibbs kernel, which can often be accelerated (see below Remarks ??and??). Remark 12 (Hilbert metric) .As initially explained by [ ?], the global convergence analysis of Sinkhorn is\\ngreatly simpliﬁed using Hilbert projective metric on Rn\\n+,∗(positive vectors), deﬁned as\\n∀(u,u′)∈(Rn\\n+,∗)2, dH(u,u′)def.= log max\\ni,i′uiu′\\ni′\\nui′u′\\ni. This can be shows to be a distance on the projective cone Rn\\n+,∗/∼, where u∼u′means that∃s>0,u=su′\\n(the vector are equal up to rescaling, hence the naming “projective”). This means that dHsatisﬁes the\\ntriangular inequality and dH(u,u′) = 0 if and only if u∼u′. This is a projective version of Hilbert’s original\\ndistance on bounded open convex sets [ ?]. The projective cone Rn\\n+,∗/∼is a complete metric space for this\\ndistance. It was introduced independently by [ ?] and [ ?] to provide a quantitative proof of Perron-Frobenius\\ntheorem, which, as explained in Remark ??is linked to a local linearization of Sinkhorn’s iterates. They\\nproved the following fundamental theorem, which shows that a positive matrix is a strict contraction on the\\ncone of positive vectors. 21'),\n",
              " Document(page_content='Theorem 2. Let K∈Rn×m\\n+,∗, then for (v,v′)∈(Rm\\n+,∗)2\\ndH(Kv,Kv′)⩽λ(K)dH(v,v′)where\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3λ(K)def.=√\\nη(K)−1√\\nη(K)+1<1\\nη(K)def.= max\\ni,j,k,ℓKi,kKj,ℓ\\nKj,kKi,ℓ. Remark 13 (Global convergence) .The following theorem, proved by [ ?], makes use of this Theorem 2 to\\nshow the linear convergence of Sinkhorn’s iterations. Theorem 3.'),\n",
              " Document(page_content='One has (u(ℓ),v(ℓ))→(u⋆,v⋆)and\\ndH(u(ℓ),u⋆) =O(λ(K)2ℓ), dH(v(ℓ),v⋆) =O(λ(K)2ℓ). (1.53)\\nOne also has\\ndH(u(ℓ),u⋆)⩽dH(P(ℓ)1m,a)\\n1−λ(K)\\ndH(v(ℓ),v⋆)⩽dH(P(ℓ),⊤1n,b)\\n1−λ(K)(1.54)\\nwhere we denoted P(ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)). Lastly, one has\\n∥log(P(ℓ))−log(P⋆)∥∞⩽dH(u(ℓ),u⋆) +dH(v(ℓ),v⋆) (1.55)\\nwhere P⋆is the unique solution of (1.39) . Proof. One notice that for any ( v,v′)∈(Rm\\n+,∗)2, one has\\ndH(v,v′) =dH(v/v′,1m) =dH(1m/v,1m/v′). This shows that\\ndH(u(ℓ+1),u⋆) =dH(a\\nKv(ℓ),a\\nKv⋆)\\n=dH(Kv(ℓ),Kv⋆)⩽λ(K)dH(v(ℓ),v⋆). where we used Theorem 2. This shows (1.53). One also has, using the triangular inequality\\ndH(u(ℓ),u⋆)⩽dH(u(ℓ+1),u(ℓ)) +dH(u(ℓ+1),u⋆)\\n⩽dH(a\\nKv(ℓ),u(ℓ))\\n+λ(K)dH(u(ℓ),u⋆)\\n=dH(\\na,u(ℓ)⊙(Kv(ℓ)))\\n+λ(K)dH(u(ℓ),u⋆),\\nwhich gives the ﬁrst part of (1.54) since u(ℓ)⊙(Kv(ℓ)) =P(ℓ)1m(the second one being similar). The proof\\nof (1.55) follows from [ ?, Lemma 3]\\nThe bound (1.54) shows that some error measures on the marginal constraints violation, for instance\\n∥P(ℓ)1m−a∥1and∥P(ℓ)T1n−b∥1, are useful stopping criteria to monitor the convergence. Figure 1.14, bottom row, highlights this linear rate on the constraint violation, and shows how this rate\\ndegrades as ε→0. These results are proved in [ ?] and are tightly connected to nonlinear Perron-Frobenius\\nTheory [ ?]. Perron-Frobenius theory corresponds to the linearization of the iterations, see ( ??). This\\nconvergence analysis is extended in [ ?], who shows that each iteration of Sinkhorn increases the permanent\\nof the scaled coupling matrix. 22'),\n",
              " Document(page_content='Regularized Dual and Log-domain Computations The following proposition details the dual problem\\nassociated to (1.39). Proposition 8.'),\n",
              " Document(page_content='One has\\nLε\\nC(a,b) = max\\nf∈Rn,g∈Rm⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩. (1.56)\\nThe optimal (f,g)are linked to scalings (u,v)appearing in (1.48) through\\n(u,v) = (ef/ε,eg/ε). (1.57)\\nProof. We start from the end of the proof of Proposition 7, which links the optimal primal solution P\\nand dual multipliers fandgfor the marginal constraints as Pi,j=efi/εe−Ci,j/εegj/ε. Substituting in the\\nLagrangianE(P,f,g) of Equation (1.5) the optimal Pas a function of fandg, we obtain that the Lagrange\\ndual function equals\\nf,g↦→⟨ef/ε,(K⊙C)eg/ε⟩−εH(diag(ef/ε)Kdiag(eg/ε)). (1.58)\\nThe entropy of Pscaled byε, namelyε⟨P,logP−1n×m⟩can be stated explicitly as a function of f,g,C\\n⟨diag(ef/ε)Kdiag(eg/ε),f1mT+1ngT−C−ε1n×m⟩\\n=−⟨ef/ε,(K⊙C)eg/ε⟩+⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩\\ntherefore, the ﬁrst term in (1.58) cancels out with the ﬁrst term in the entropy above. The remaining times\\nare those displayed in (1.56). Remark 14.Dual for generic measures For generic (non-necessarily discrete) input measures ( α,β), the dual\\nproblem (1.56) reads\\nsup\\nf,g∈C(X)×C(Y)∫\\nXf(x)dα(x) +∫\\nYg(x)dβ(x)−ε∫\\nX×Ye−c(x,y)+f(x)+g(y)\\nε dα(x)dβ(y)\\nThis corresponds to a smoothing of the constraint R(c) appearing in the original problem (1.21), which\\nis retrieved in the limit ε→0. Proving existence ( i.e. the sup is actually a max) of these Kantorovich\\npotentials ( f,g) in the case of entropic transport is less easy than for classical OT (because one cannot\\nusec-transform and potentials are not automatically Lipschitz). Proof of existence can be done using the\\nconvergence of Sinkhorn iterations, see [ ?] for more details. Remark 15 (Sinkhorn as a Block Coordinate Ascent on the Dual Problem) .A simple approach to solve the\\nunconstrained maximization problem (1.56) is to use an exact block coordinate ascent strategy, namely to\\nupdate alternatively fandgto cancel their gradients with respect to the objective of (1.56). Indeed, one\\ncan easily notice that, writing Q(f,g) for the objective of (1.56) that\\n∇|fQ(f,g) =a−ef/ε⊙(\\nKeg/ε)\\n, (1.59)\\n∇|gQ(f,g) =b−eg/ε⊙(\\nKTef/ε)\\n. (1.60)\\nBlock coordinate ascent can therefore be implemented in a closed form by applying successively the following\\nupdates, starting from any arbitrary g(0), forl⩾0,\\nf(ℓ+1)=εloga−εlog(\\nKeg(ℓ)/ε)\\n, (1.61)\\ng(ℓ+1)=εlogb−εlog(\\nKTef(ℓ+1)/ε)\\n. (1.62)\\nSuch iterations are mathematically equivalent to the Sinkhorn iterations (1.51) when considering the primal-\\ndual relations highlighted in (1.57). Indeed, we recover that at any iteration\\n(f(ℓ),g(ℓ)) =ε(log(u(ℓ)),log(v(ℓ))). 23'),\n",
              " Document(page_content='Remark 16 (Soft-min rewriting) .Iterations (1.61) and (1.62) can be given an alternative interpretation,\\nusing the following notation. Given a vector zof real numbers we write min εzfor the soft-minimum of its\\ncoordinates, namely\\nminεz=−εlog∑\\nie−zi/ε. Note that min ε(z) converges to min zfor any vector zasε→0. Indeed, min εcan be interpreted as a\\ndiﬀerentiable approximation of the min function. Using these notations, Equations (1.61) and (1.62) can be\\nrewritten\\n(f(ℓ+1))i= minε(Cij−g(ℓ)\\nj)j+εlogai, (1.63)\\n(g(ℓ+1))j= minε(Cij−f(ℓ)\\ni)i+εlogbj. (1.64)\\nHere the term min ε(Cij−g(ℓ)\\nj)jdenotes the soft-minimum of all values of the j-th column of matrix\\n(C−1n(g(ℓ))⊤). To simplify notations, we introduce an operator that takes a matrix as input and outputs\\nnow a column vector of the soft-minimum values of its columns or rows. Namely, for any matrix A∈Rn×m,\\nwe deﬁne\\nMinrow\\nε(A)def.=(\\nminε(Ai,j)j)\\ni∈Rn,\\nMincol\\nε(A)def.=(\\nminε(Ai,j)i)\\nj∈Rm. Note that these operations are equivalent to the entropic c-transform introduced in §??(see in particu-\\nlar (??)). Using these notations, Sinkhorn’s iterates read\\nf(ℓ+1)= Minrow\\nε(C−1ng(ℓ)T) +εloga, (1.65)\\ng(ℓ+1)= Mincol\\nε(C−f(ℓ)1mT) +εlogb. (1.66)\\nNote that as ε→0, minεconverges to min, but the iterations do not converge anymore in the limit ε= 0,\\nbecause alternate minimization does not converge for constrained problems (which is the case for the un-\\nregularized dual (1.17)). Remark 17 (Log-domain Sinkhorn) .While mathematically equivalent to the Sinkhorn updates (1.51), itera-\\ntions (1.63) and (1.64) suggest to use the log-sum-exp stabilization trick to avoid underﬂow for small values\\nofε. Writing z = min z, that trick suggests to evaluate min εzas\\nminεz= z−εlog∑\\nie−(zi−z)/ε. (1.67)\\nInstead of substracting z to stabilize the log domain iterations as in (1.67), one can actually substract the\\npreviously computed scalings. This leads to the following stabilized iteration\\nf(ℓ+1)= Minrow\\nε(S(f(ℓ),g(ℓ)))−f(ℓ)+εlog(a) (1.68)\\ng(ℓ+1)= Mincol\\nε(S(f(ℓ+1),g(ℓ)))−g(ℓ)+εlog(b), (1.69)\\nwhere we deﬁned\\nS(f,g) =(\\nCi,j−fi−gj)\\ni,j. In contrast to the original iterations (1.51), these log-domain iterations (1.68) and (1.69) are stable for\\narbitraryε >0, because the quantity S(f,g) stays bounded during the iterations. The downside is that it\\nrequiresnmcomputations of exp at each step.'),\n",
              " Document(page_content='Computing a Minrow\\nεor Mincol\\nεis typically substantially\\nslower than matrix multiplications, and requires computing line by line soft-minima of matrices S. There is\\ntherefore no eﬃcient way to parallelize the application of Sinkhorn maps for several marginals simultaneously. In Euclidean domain of small dimension, it is possible to develop eﬃcient multiscale solvers with a decaying\\nεstrategy to signiﬁcantly speed up the computation using sparse grids [ ?]. 24'),\n",
              " Document(page_content='1.6 Extensions\\nWasserstein Barycenters. Given input histogram {bs}S\\ns=1, wherebs∈Σns, and weights λ∈ΣS, a\\nWasserstein barycenter is computed by minimizing\\nmin\\na∈ΣnS∑\\ns=1λsLCs(a,bs) (1.70)\\nwhere the cost matrices Cs∈Rn×nsneed to be speciﬁed. A typical setup is “Eulerian”, so that all the\\nbarycenters are deﬁned on the same grid, ns=n,Cs=C=Dpis set to be a distance matrix, so that one\\nsolves\\nmin\\na∈ΣnS∑\\ns=1λsWp\\np(a,bs). This barycenter problem (1.70) was originally introduced by [ ?] following earlier ideas of [ ?]. They proved\\nin particular uniqueness of the barycenter for c(x,y) =||x−y||2overX=Rd, if one of the input measure\\nhas a density with respect to the Lebesgue measure (and more generally under the same hypothesis as the\\none guaranteeing the existence of a Monge map, see Remark ??). The barycenter problem for histograms (1.70) is in fact a linear program, since one can look for the S\\ncouplings ( Ps)sbetween each input and the barycenter itself\\nmin\\na∈Σn,(Ps∈Rn×ns)s{S∑\\ns=1λs⟨Ps,Cs⟩;∀s,P⊤\\ns1ns=a,P⊤\\ns1n=bs}\\n. Although this problem is an LP, its scale forbids the use generic solvers for medium scale problems. One\\ncan therefore resort to using ﬁrst order methods such as subgradient descent on the dual [ ?]. Remark 18.Barycenter of arbitrary measures Given a set of input measure ( βs)sdeﬁned on some space X,\\nthe barycenter problem becomes\\nmin\\nα∈M1\\n+(X)S∑\\ns=1λsLc(α,βs). (1.71)\\nIn the case where X=Rdandc(x,y) =||x−y||2, [?] shows that if one of the input measures has a density,\\nthen this barycenter is unique. Problem (1.71) can be viewed as a generalization of the problem of computing\\nbarycenters of points ( xs)S\\ns=1∈XSto arbitrary measures. Indeed, if βs=δxsis a single Dirac mass, then a\\nsolution to (1.71) is δx⋆wherex⋆is a Fr´ echet mean solving ( ??). Note that for c(x,y) =||x−y||2, the mean\\nof the barycenter α⋆is necessarily the barycenter of the mean, i.e.'),\n",
              " Document(page_content='∫\\nXxdα⋆(x) =∑\\nsλs∫\\nXxdαs(x),\\nand the support of α⋆is located in the convex hull of the supports of the ( αs)s. The consistency of the\\napproximation of the inﬁnite dimensional optimization (1.71) when approximating the input distribution\\nusing discrete ones (and thus solving (1.70) in place) is studied in [ ?]. Let us also note that it is possible to\\nre-cast (1.71) as a multi-marginal OT problem, see Remark ??. One can use entropic smoothing and approximate the solution of (1.70) using\\nmin\\na∈ΣnS∑\\ns=1λsLε\\nCs(a,bs) (1.72)\\nfor someε > 0. This is a smooth convex minimization problem, which can be tackled using gradient\\ndescent [ ?]. An alternative is to use descent method (typically quasi-Newton) on the semi-dual [ ?], which is\\n25'),\n",
              " Document(page_content='useful to integrate additional regularizations on the barycenter (e.g. to impose some smoothness). A simple\\nbut eﬀective approach, as remarked in [ ?] is to rewrite (1.72) as a (weighted) KL projection problem\\nmin\\n(Ps)s{∑\\nsλsKL(Ps|Ks) ;∀s,PsT1m=bs,P111=...=PS1S}\\n(1.73)\\nwhere we denoted Ksdef.=e−Cs/ε. Here, the barycenter ais implicitly encoded in the row marginals of all\\nthe couplings Ps∈Rn×nsasa=P111=...=PS1S. As detailed in [ ?], one can generalize Sinkhorn to\\nthis problem, which also corresponds to iterative projection. This can also be seen as a special case of the\\ngeneralized Sinkhorn detailed in §??. The optimal couplings ( Ps)ssolving (1.73) are computed in scaling\\nform as\\nPs= diag( us)Kdiag(vs), (1.74)\\nand the scalings are sequentially updated as\\n∀s∈J1,SK,v(ℓ+1)\\nsdef.=bs\\nKT\\nsu(ℓ)\\ns, (1.75)\\n∀s∈J1,SK,u(ℓ+1)\\nsdef.=a(ℓ+1)\\nKsv(ℓ+1)\\ns, (1.76)\\nwhere a(ℓ+1)def.=∏\\ns(Ksv(ℓ+1)\\ns)λs. (1.77)\\nAn alternative way to derive these iterations is to perform alternate minimization on the variables of a dual\\nproblem, which detailed in the following proposition.'),\n",
              " Document(page_content='Proposition 9. The optimal (us,vs)appearing in (1.74) can be written as (us,vs) = (efs/ε,egs/ε)where\\n(fs,gs)sare the solutions of the following program (whose value matches the one of (1.72) )\\nmax\\n(fs,gs)s{∑\\nsλs(\\n⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\\n;∑\\nsλsfs= 0}\\n. (1.78)\\nProof. Introducing Lagrange multipliers in (1.73) leads to\\nmin\\n(Ps)s,amax\\n(fs,gs)s∑\\nsλs(\\nεKL(Ps|Ks) +⟨a−Ps1m,fs⟩\\n+⟨bs−PsT1m,gs⟩)\\n. Strong duality holds, so that one can exchange the min and the max, and gets\\nmax\\n(fs,gs)s∑\\nsλs(\\n⟨gs,bs⟩+ min\\nPsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\\n+ min\\na⟨∑\\nsλsfs,a⟩. The explicit minimization on agives the constraint∑\\nsλsfs= 0 together with\\nmax\\n(fs,gs)s∑\\nsλs⟨gs,bs⟩−εKL∗(fs⊕gs\\nε|Ks)\\nwhere KL∗(·|Ks) is the Legendre transform ( ??) of the function KL∗(·|Ks). This Legendre transform reads\\nKL∗(U|K) =∑\\ni,jKi,j(eUi,j−1), (1.79)\\n26'),\n",
              " Document(page_content='Figure 1.15: Barycenters between 4 input 3-D shapes using entropic regularization (1.72). The weights\\n(λs)sare bilinear with respect to the four corners of the square. Shapes are represented as measures that\\nare uniform within the boundaries of the shape and null outside. which shows the desired formula. To show (1.79), since this function is separable, one needs to compute\\n∀(u,k)∈R2\\n+,KL∗(u|k)def.= max\\nrur−(rlog(r/k)−r+k)\\nwhose optimality condition reads u= log(r/k), i.e.r=keu, hence the result. Minimizing (1.78) with respect to each gs, while keeping all the other variable ﬁxed, is obtained in closed\\nform by (1.75). Minimizing (1.78) with respect to all the ( fs)srequires to solve for ausing (1.77) and leads\\nto the expression (1.76). Figures ??and??show applications to 2-D and 3-D shapes interpolation. Figure ??shows a computation\\nof barycenters on a surface, where the ground cost is the square of the geodesic distance. For this ﬁgure,\\nthe computations are performed using the geodesic in heat approximation detailed in Remark ??. We refer\\nto [?] for more details and other applications to computer graphics and imaging sciences. Wasserstein Loss. In statistics, text processing or imaging, one must usually compare a probability\\ndistribution βarising from measurements to a model, namely a parameterized family of distributions {αθ,θ∈\\nΘ}where Θ is a subset of an Euclidean space. Such a comparison is done through a “loss” or a “ﬁdelity”\\nterm, which, in this section, is the Wasserstein distance. In the simplest scenario, the computation of a\\nsuitable parameter θis obtained by minimizing directly\\nmin\\nθ∈ΘE(θ)def.=Lc(αθ,β). (1.80)\\nOf course, one can consider more complicated problems: for instance, the barycenter problem described\\nin§??consists in a sum of such terms.'),\n",
              " Document(page_content='However, most of these more advanced problems can be usually\\nsolved by adapting tools deﬁned for basic case: either using the chain rule to compute explicitly derivatives,\\nor using automatic diﬀerentiation. The Wasserstein distance between two histograms or two densities is convex with respect to these inputs,\\nas shown by (1.17) and (1.21) respectively. Therefore, when the parameter θis itself a histogram, namely Θ =\\nΣnandαθ=θ, or more generally when θdescribesKweights in the simplex, Θ = Σ K, andαθ=∑K\\ni=1θiαi\\nis a convex combination of known atoms α1,...,αKin ΣN, Problem (1.80) remains convex (the ﬁrst case\\ncorresponds to the barycenter problem, the second to one iteration of the dictionary learning problem with\\na Wasserstein loss [ ?]). However, for more general parameterizations θ↦→αθ, Problem (1.80) is in general\\nnot convex. 27'),\n",
              " Document(page_content='g✓XZ⇣xz\\x00↵✓Figure 1.16: Schematic display of the density ﬁtting problem 1.81. A practical problem of paramount importance in statistic and machine learning is density ﬁtting. Given\\nsome discrete samples ( xi)n\\ni=1⊂X from some unknown distribution, the goal is to ﬁt a parametric model\\nθ↦→αθ∈M (X) to the observed empirical input measure β\\nmin\\nθ∈ΘL(αθ,β) where β=1\\nn∑\\niδxi, (1.81)\\nwhereLis some “loss” function between a discrete and a “continuous” (arbitrary) distribution (see Fig-\\nure 1.16). In the case where αθas a densify ρθdef.=ραθwith respect to the Lebesgue measure (or any other ﬁxed\\nreference measure), the maximum likelihood estimator (MLE) is obtained by solving\\nmin\\nθLMLE(αθ,β)def.=−∑\\nilog(ρθ(xi)). This corresponds to using an empirical counterpart of a Kullback-Leibler loss since, assuming the xiare i.i.d. samples of some ¯β, then\\nLMLE(α,β)n→+∞−→ KL(α|¯β)\\nThis MLE approach is known to lead to optimal estimation procedures in many cases (see for instance [ ?]). However, it fails to work when estimating singular distributions, typically when the αθdoes not has a density\\n(so thatLMLE(αθ,β) = +∞) or when ( xi)iare samples from some singular ¯β(so that the αθshould share\\nthe same support as βfor KL(α|¯β) to be ﬁnite, but this support is usually unknown). Another issue is that\\nin several cases of practical interest, the density ρθis inaccessible (or too hard to compute). A typical setup where both problems (singular and unknown densities) occur is for so-called generative\\nmodels, where the parametric measure is written as a push-forward of a ﬁxed reference measure ζ∈M (Z)\\nαθ=hθ,♯ζwherehθ:Z→X\\nwhere the push-forward operator is introduced in Deﬁnition 1. The space Zis usually low-dimensional, so\\nthat the support of αθis localized along a low-dimensional “manifold” and the resulting density is highly\\nsingular (it does not have a density with respect to Lebesgue measure). Furthermore, computing this density\\nis usually intractable, while generating i.i.d. samples from αθis achieved by computing xi=hθ(zi) where\\n(zi)iare i.i.d.'),\n",
              " Document(page_content='samples from ζ. In order to cope with such diﬃcult scenario, one has to use weak metrics in place of the MLE functional\\nLMLE, which needs to be written in dual form as\\nL(α,β)def.= max\\n(f,g)∈C(X)2{∫\\nXf(x)dα(x) +∫\\nXg(x)dβ(x) ; (f,g)∈R}\\n. (1.82)\\nDual norms exposed in §??correspond to imposing R={(f,−f) ;f∈B}, while optimal transport (1.21)\\nsetsR=R(c) as deﬁned in (1.22). 28'),\n",
              " Document(page_content='For a ﬁxed θ, evaluating the energy to be minimized in (1.81) using such a loss function corresponds to\\nsolving a semi-discrete optimal transport, which is the focus of Chapter ??. Minimizing the energy with\\nrespect toθis much more involved, and is typically highly non-convex. The class of estimators obtained using L=Lc, often called “Minimum Kantorovitch Estimators” (MKE),\\nwas initially introduced in [ ?], see also [ ?]. Gromov-Wasserstein. Optimal transport needs a ground cost Cto compare histograms ( a,b), it can\\nthus not be used if the histograms are not deﬁned on the same underlying space, or if one cannot pre-register\\nthese spaces to deﬁne a ground cost. To address this issue, one can instead only assume a weaker assumption,\\nnamely that one has at its disposal two matrices D∈Rn×nandD′∈Rm×mthat represent some relationship\\nbetween the points on which the histograms are deﬁned.'),\n",
              " Document(page_content='A typical scenario is when these matrices are (power\\nof) distance matrices. The Gromov-Wasserstein problem reads\\nGW(( a,D),(b,D′))2def.= min\\nP∈U(a,b)ED,D′(P)def.=∑\\ni,j,i′,j′|Di,i′−D′\\nj,j′|2Pi,jPi′,j′. (1.83)\\nThis is a non-convex problem, which can be recast as a Quadratic Assignment Problem (QAP) [ ?] and is in\\nfull generality NP-hard to solve for arbitrary inputs. It is in fact equivalent to a graph matching problem [ ?]\\nfor a particular cost. One can show that GW satisﬁes the triangular inequality, and in fact it deﬁnes a distance between\\nmetric spaces equipped with a probability distribution (here assumed to be discrete in deﬁnition (1.83))\\nup to isometries preserving the measures. This distance was introduced and studied in details by Memoli\\nin [?].'),\n",
              " Document(page_content='An in-depth mathematical exposition (in particular, its geodesic structure and gradient ﬂows) is given\\nin [?]. See also [ ?] for applications in computer vision. This distance is also tightly connected with the\\nGromov-Hausdorﬀ distance [ ?] between metric spaces, which have been used for shape matching [ ?,?]. Remark 19.Gromov-Wasserstein distance The general setting corresponds to computing couplings between\\nmetric measure spaces ( X,dX,αX) and (Y,dY,αY) where (dX,dY) are distances and ( αX,αY) are measures\\non their respective spaces. One deﬁnes\\nGW((αX,dX),(αY,dY))2def.= min\\nπ∈U(αX,αY)∫\\nX2×Y2|dX(x,x′)−dY(y,y′)|2dπ(x,y)dπ(x′,y′). (1.84)\\nGW deﬁnes a distance between metric measure spaces up to isometries, where one says that ( αX,dX) and\\n(αY,dY) are isometric if there exists ϕ:X→Y such thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′)) =dX(x,x′). Remark 20.Gromov-Wasserstein geodesics The space of metric spaces (up to isometries) endowed with\\nthisGW distance (1.84) has a geodesic structure. [ ?] shows that the geodesic between ( X0,dX0,α0) and\\n(X1,dX1,α1) can be chosen to be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is a solution of (1.84) and for all\\n((x0,x1),(x′\\n0,x′\\n1))∈(X0×X 1)2,\\ndt((x0,x1),(x′\\n0,x′\\n1))def.= (1−t)dX0(x0,x′\\n0) +tdX1(x1,x′\\n1). This formula allows one to deﬁne and analyze gradient ﬂows which minimize functionals involving metric\\nspaces, see [ ?]. It is however diﬃcult to handle numerically, because it involves computations over the product\\nspaceX0×X 1. A heuristic approach is used in [ ?] to deﬁne geodesics and barycenters of metric measure\\nspaces while imposing the cardinality of the involved spaces and making use of the entropic smoothing (1.85)\\ndetailed below. To approximate the computation of GW, and to help convergence of minimization schemes to better\\nminima, one can consider the entropic regularized variant\\nmin\\nP∈U(a,b)ED,D′(P)−εH(P). (1.85)\\n29'),\n",
              " Document(page_content='Figure 1.17: Example of fuzzy correspondences computed by solving GW problem (1.85) with Sinkhorn\\niterations (1.86). Extracted from [ ?].'),\n",
              " Document(page_content='As proposed initially in [ ?,?], and later revisited in [ ?] for applications in graphics, one can use iteratively\\nSinkhorn’s algorithm to progressively compute a stationary point of (1.85). Indeed, successive linearizations\\nof the objective function lead to consider the succession of updates\\nP(ℓ+1) def.= min\\nP∈U(a,b)⟨P,C(ℓ)⟩−εH(P) where (1.86)\\nC(ℓ)def.=∇ED,D′(P(ℓ)) =−D′TP(ℓ)D,\\nwhich can be interpreted as a mirror-descent scheme [ ?]. Each update can thus be solved using Sinkhorn\\niterations (1.51) with cost C(ℓ). Figure (1.17) illustrates the use of this entropic Gromov-Wasserstein to\\ncompute soft maps between domains. 30'),\n",
              " Document(page_content='Bibliography\\n[1] Amir Beck. Introduction to Nonlinear Optimization: Theory, Algorithms, and Applications with MAT-\\nLAB. SIAM, 2014. [2] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization\\nand statistical learning via the alternating direction method of multipliers. Foundations and Trends R⃝\\nin Machine Learning , 3(1):1–122, 2011. [3] Stephen Boyd and Lieven Vandenberghe. Convex optimization . Cambridge university press, 2004. [4] E. Cand` es and D.'),\n",
              " Document(page_content='Donoho. New tight frames of curvelets and optimal representations of objects with\\npiecewise C2singularities. Commun. on Pure and Appl. Math. , 57(2):219–266, 2004. [5] E. J. Cand` es, L. Demanet, D. L. Donoho, and L.'),\n",
              " Document(page_content='Ying. Fast discrete curvelet transforms. SIAM\\nMultiscale Modeling and Simulation , 5:861–899, 2005. [6] A. Chambolle. An algorithm for total variation minimization and applications. J. Math. Imaging Vis. ,\\n20:89–97, 2004. [7] Antonin Chambolle, Vicent Caselles, Daniel Cremers, Matteo Novaga, and Thomas Pock. An intro-\\nduction to total variation for image analysis. Theoretical foundations and numerical methods for sparse\\nrecovery , 9(263-340):227, 2010. [8] Antonin Chambolle and Thomas Pock. An introduction to continuous optimization for imaging. Acta\\nNumerica , 25:161–319, 2016. [9] S.S. Chen, D.L. Donoho, and M.A.'),\n",
              " Document(page_content='Saunders. Atomic decomposition by basis pursuit. SIAM Journal\\non Scientiﬁc Computing , 20(1):33–61, 1999. [10] Philippe G Ciarlet. Introduction ` a l’analyse num´ erique matricielle et ` a l’optimisation. 1982. [11] P. L. Combettes and V. R. Wajs. Signal recovery by proximal forward-backward splitting. SIAM\\nMultiscale Modeling and Simulation , 4(4), 2005. [12] I. Daubechies, M. Defrise, and C. De Mol. An iterative thresholding algorithm for linear inverse problems\\nwith a sparsity constraint. Commun. on Pure and Appl. Math. , 57:1413–1541, 2004. [13] D. Donoho and I.'),\n",
              " Document(page_content='Johnstone. Ideal spatial adaptation via wavelet shrinkage. Biometrika , 81:425–455,\\nDec 1994. [14] Heinz Werner Engl, Martin Hanke, and Andreas Neubauer. Regularization of inverse problems , volume\\n375. Springer Science & Business Media, 1996. [15] M. Figueiredo and R.'),\n",
              " Document(page_content='Nowak. An EM Algorithm for Wavelet-Based Image Restoration. IEEE Trans. Image Proc. , 12(8):906–916, 2003. [16] Simon Foucart and Holger Rauhut. A mathematical introduction to compressive sensing , volume 1. Birkh¨ auser Basel, 2013. 31'),\n",
              " Document(page_content='[17] Stephane Mallat. A wavelet tour of signal processing: the sparse way . Academic press, 2008.'),\n",
              " Document(page_content='[18] D. Mumford and J. Shah. Optimal approximation by piecewise smooth functions and associated varia-\\ntional problems. Commun. on Pure and Appl. Math. , 42:577–685, 1989. [19] Neal Parikh, Stephen Boyd, et al. Proximal algorithms. Foundations and Trends R⃝in Optimization ,\\n1(3):127–239, 2014. [20] Gabriel Peyr´ e. L’alg` ebre discr` ete de la transform´ ee de Fourier . Ellipses, 2004. [21] J. Portilla, V. Strela, M.J.'),\n",
              " Document(page_content='Wainwright, and Simoncelli E.P. Image denoising using scale mixtures of\\nGaussians in the wavelet domain. IEEE Trans. Image Proc. , 12(11):1338–1351, November 2003. [22] L. I. Rudin, S. Osher, and E.'),\n",
              " Document(page_content='Fatemi. Nonlinear total variation based noise removal algorithms. Phys. D, 60(1-4):259–268, 1992. [23] Otmar Scherzer, Markus Grasmair, Harald Grossauer, Markus Haltmeier, Frank Lenzen, and L Sirovich. Variational methods in imaging . Springer, 2009. [24] C. E. Shannon. A mathematical theory of communication. The Bell System Technical Journal ,\\n27(3):379–423, 1948. [25] Jean-Luc Starck, Fionn Murtagh, and Jalal Fadili. Sparse image and signal processing: Wavelets and\\nrelated geometric multiscale analysis . Cambridge university press, 2015. 32')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using text embeddings\n",
        "\n",
        "text_embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "semantic_chunks = text_chunker.semantic_section_chunking_with_TextEmbedding( documents , text_embedding_model_name,  breakpoint_threshold_type = \"percentile\")\n",
        "\n",
        "\n",
        "print(\"\\nsemantic chunking with text embeddings:\")\n",
        "for i, chunk in enumerate(semantic_chunks):\n",
        "    print(f\"Chunk {i+1}: {chunk}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dee259618ffe43d1acf3949149c6e492",
            "6321e86cb6804a16916b633427e6a25e",
            "d9f821ba2aa2430d9962e63488fd61b2",
            "b8e588e83d674ee09908f498121c6374",
            "981d9feed1d74bd8952f4edaff57ec88",
            "e92bc4a6d26b4aacb01edc225626a421",
            "6768b442e5344e43886e9a416bfad8ca",
            "211e36f151ea48a9877a7fdd470540ce",
            "70e17f4b00764257ab8ad6a4869325f0",
            "25ef21bc55e243c6b6721f2e1efbdd35",
            "58bdd3d989774c8a9da647ecc6146886",
            "86c7aaba772a4ec0ac1a3427dc659c02",
            "d7da84b07b4e474dbb620eafab1dbdef",
            "7c9e245124644079a96891b7e497ef33",
            "9a3fa06798064967b39a69ec6c345696",
            "6ff33ed73bb64c5794f12c1d5ecb1d0a",
            "c8afec28431d48ef8d06863083a82595",
            "49a7a126152f47349d804570e51a70ad",
            "f49cd4bc555443b5b3550e9fa4b5d849",
            "02c871c02ce14f61ba29a4ceb972907d",
            "f3b53f8916e3485f96881f487e180725",
            "9628fe2c9b854276b28914e23034ed41",
            "5e20376da74f41c5a95eef582655a634",
            "280ade5062aa47f1a8d0a700ea1c1cba",
            "7acf8c9ca0f64d488ef0c901decc9790",
            "01a2ec5e014c413893a8f8e2b71368ff",
            "4e53628c6f834f4081efc0cb1269c848",
            "0a344ed1057c48a28da77f3003b17f7e",
            "db3b1500b992420f89c55b2204039746",
            "891faf33ee5b4d428db3f53a11063e08",
            "bc8c635f20ae4ce7831fbaa6edc40990",
            "f088389cebd14005b473996e48d0244d",
            "5e80296abab34f56989912e24137582a",
            "5475a06e87544618a330042a2a0a22d8",
            "9f6c56ae5c0b4f4e9454c94e74a2ed2d",
            "f9feda69895a4322af34591b132c7c2f",
            "d8d72c016091433a8ae80d6267bcc4b2",
            "a25bf3284c454535b35708b9277e5525",
            "ad7a62d36c23460fa98502789f381422",
            "cf460b361d9846838a35e0dd1d716cd2",
            "dec4e2eb6953407e947ea3d4731055d5",
            "434cd666947c4ce380387b5666929c8c",
            "e2817add739c4b2c85ec862d3d3c5da1",
            "f2ea564d380e4d028953a157ba33702a",
            "138d475989394f379615556ac017baeb",
            "e319f70791af4f108d8bad78eb85b972",
            "cf8432a417c94f059ef72d1ab1a03f0d",
            "634117d3179d489fa3e4504d3ac1f332",
            "053bce7a21304a2fbb33302a598a7438",
            "598934192e2b4564b73c4349c887a0cf",
            "4a9e6509652c4c7c9dd69327ba3ff00a",
            "fad778dcec9f4c4da3eaa66307e7117f",
            "44ceba2fcbd54692a0867dbd68d25286",
            "dfc5003a2e5e44e0828477e6e35a4255",
            "94282be1b70f4a56835bf474e0647446",
            "43c60008c42d49aea133ef70f28215f0",
            "8f9d5475bb9c4020adec22265d560e58",
            "3a64664a75ec422988eb6c6b4c2d56b8",
            "dde39c2cd84d4be6b1f968a1155b6c11",
            "853d46996b6147b8b04929823aee5bfb",
            "7b5b098316f942e9a91b36b3513ccda6",
            "4c05615ba7994b01a8bd891276f52997",
            "bd7ce91f61e64dfdaf0e09c7ea485967",
            "64243f6d232a4f42840ae6e4bfee680d",
            "0a9396d4671e4214b5424901e0d7539c",
            "867030196ad24fa98f3fbdd5a0da6d86"
          ]
        },
        "id": "VBAe2KsZDeXR",
        "outputId": "240f9829-0e68-47ea-ca1e-2321acd9a0f9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dee259618ffe43d1acf3949149c6e492"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86c7aaba772a4ec0ac1a3427dc659c02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e20376da74f41c5a95eef582655a634"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5475a06e87544618a330042a2a0a22d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "138d475989394f379615556ac017baeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43c60008c42d49aea133ef70f28215f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "semantic chunking with text embeddings:\n",
            "Chunk 1: page_content='Mathematical Foundations of Data Sciences\\nGabriel Peyr´ e\\nCNRS & DMA\\n´Ecole Normale Sup´ erieure\\ngabriel.peyre@ens.fr\\nhttps://mathematical-tours.github.io\\nwww.numerical-tours.com\\nAugust 14, 2019'\n",
            "Chunk 2: page_content='2'\n",
            "Chunk 3: page_content='Chapter 1\\nOptimal Transport\\n1.1 Radon Measures\\nMeasures. We will interchangeably the term histogram or probability vector for any element a∈Σnthat\\nbelongs to the probability simplex\\nΣndef.={\\na∈Rn\\n+;n∑\\ni=1ai= 1}\\n. A discrete measure with weights aand locations x1,...,xn∈X reads\\nα=n∑\\ni=1aiδxi (1.1)\\nwhereδxis the Dirac at position x, intuitively a unit of mass which is inﬁnitely concentrated at location\\nx. Such as measure describes a probability measure if, additionally, a∈Σn, and more generally a positive\\nmeasure if each of the “weights” described in vector ais positive itself. Remark 1 (General measures) .A convenient feature of OT is that it can deal with discrete and continuous\\n“objects” within the same framework. Such objects only need to be modelled as measures. This corresponds\\nto the notion of Radon measures M(X) on the spaceX. The formal deﬁnition of that set requires that Xis\\nequipped with a distance, usually denoted d, because one can only access a measure by “testing” (integrating)\\nit against continuous functions, denoted f∈C(X). Integration of f∈C(X) against a discrete measure αcomputes a sum\\n∫\\nXf(x)dα(x) =n∑\\ni=1aif(xi). More general measures, for instance on X=Rd(whered∈N∗is the dimension), can have a density\\ndα(x) =ρα(x)dxw.r.t. the Lebesgue measure, often denoted ρα=dα\\ndx, which means that\\n∀h∈C(Rd),∫\\nRdh(x)dα(x) =∫\\nRdh(x)ρα(x)dx. An arbitrary measure α∈M (X) (which needs not to have a density nor be a sum of Diracs) is deﬁned by\\nthe fact that it can be integrated agains any continuous function f∈C(X) and obtain∫\\nXf(x)dα(x)∈R. IfXis not compact, one should also impose that fhas compact support or at least as 0 limit at inﬁnity. Measure as thus in some sense “less regular” than functions, but more regular than distributions (which are\\ndual to smooth functions).'\n",
            "Chunk 4: page_content='For instance, the derivative of a Dirac is not a measure. We denote M+(X) the\\nset of all positive measures on X. The set of probability measures is denoted M1\\n+(X), which means that\\nanyα∈M1\\n+(X) is positive, and that α(X) =∫\\nXdα= 1. Figure 1.1 oﬀers a visualization of the diﬀerent\\nclasses of measures, beyond histograms, considered in this work. 3'\n",
            "Chunk 5: page_content='Discreted= 1 Discrete d= 2 Density d= 1 Density d= 2\\nFigure 1.1: Schematic display of discrete distributions α=∑n\\ni=1aiδxi(red corresponds to empirical uniform\\ndistribution ai= 1/n, and blue to arbitrary distributions) and densities d α(x) =ρα(x)dx(in violet), in both\\n1-D and 2-D. Discrete distributions in 1-D are displayed using vertical segments (with length equal to ai)\\nand in 2-D using point clouds (radius equal to ai). Operators on measures. For some continuous map T:X →Y , we deﬁne the pushforward operator\\nT♯:M(X)→M (Y). For discrete measures (1.1), the pushforward operation consists simply in moving the\\npositions of all the points in the support of the measure\\nT♯αdef.=∑\\niaiδT(xi). For more general measures, for instance for those with a density, the notion of push-forward plays a funda-\\nmental to describe spatial modiﬁcations of probability measures. The formal deﬁnition reads as follow. Deﬁnition 1 (Push-forward) .ForT:X → Y , the push forward measure β=T♯α∈ M (Y)of some\\nα∈M (X)reads\\n∀h∈C(Y),∫\\nYh(y)dβ(y) =∫\\nXh(T(x))dα(x). (1.2)\\nEquivalently, for any measurable set B⊂Y, one has\\nβ(B) =α({x∈X;T(x)∈B}). (1.3)\\nNote thatT♯preserves positivity and total mass, so that if α∈M1\\n+(X)thenT♯α∈M1\\n+(Y). Intuitively, a measurable map T:X→Y , can be interpreted as a function “moving” a single point from a\\nmeasurable space to another. The more general extension T♯can now “move” an entire probability measure\\nonXtowards a new probability measure on Y. The operator T♯“pushes forward” each elementary mass of\\na measureαonXby applying the map Tto obtain then an elementary mass in Y, to build on aggregate a\\nnew measure onY) writtenT♯α. Note that such a push-forward T♯:M1\\n+(X)→M1\\n+(Y) is a linear operator\\nbetween measures in the sense that for two measures α1,α2onX,T♯(α1+α2) =T♯α1+T♯α2. Remark 2 (Push-forward for densities) .Explicitly doing the change of variable in formula (1.2) for measures\\nwith densities ( ρα,ρβ) onRd(assumingTis smooth and a bijection) shows that a push-forward acts on\\ndensities linearly as a change of variables in the integration formula, indeed\\nρα(x) =|det(T′(x))|ρβ(T(x)) (1.4)\\nwhereT′(x)∈Rd×dis the Jacobian matrix of T(the matrix formed by taking the gradient of each coordinate\\nofT). This implies, denoting y=T(x)\\n|det(T′(x))|=ρα(x)\\nρβ(y).'\n",
            "Chunk 6: page_content='4'\n",
            "Chunk 7: page_content='=Pi\\x00xiT↵T]↵def.=Pi\\x00T(xi)\\nTT]gdef.=g\\x00TgPush-forward of measures Pull-back of functions\\nFigure 1.2: Comparison of push-forward T♯and pull-back T♯. Remark 3 (Push-forward vs. pull-back) .The push-forward T♯of measures should not be confounded with\\nthe pull-back of function T♯:C(Y)→C(X) which corresponds to the “warping” of functions. It is the linear\\nmap deﬁned, for g∈C(Y) byT♯g=g◦T. Push-forward and pull-back are actually adjoint one from each\\nothers, in the sense that\\n∀(α,g)∈M (X)×C(Y),∫\\nYgd(T♯α) =∫\\nX(T♯g)dα. It is important to realize that even if ( α,β) have densities ( ρα,ρβ),T♯αis not equal to T♯ρβ, because of\\nthe presence of the Jacobian in (1.4). This explains why OT should be used with caution to perform image\\nregistration, because it does not operate as an image warping method. Figure 1.2 illustrate the distinction\\nbetween these push-forward and pull-back operators. Remark 4 (Measures and random variables) .Radon measures can also be viewed as representing the distri-\\nbutions of random variables. A random variable XonXis actually a map X: Ω→X from some abstract\\n(often un-speciﬁed) probabized space (Ω ,P), and its distribution αis the Radon measure X∈M1\\n+(X) such\\nthatP(X∈A) =α(A) =∫\\nAdα(x). Equivalently, it is the push-forward of PbyX,α=X♯P. Applying\\nanother push-forward β=T♯αforT:X →Y , following (1.2), is equivalent to deﬁning another random\\nvariableY=T(X) :ω∈Ω→T(X(ω))∈Y, so thatβis the distribution of Y. Drawing a random sample\\nyfromYis thus simply achieved by computing y=T(x) wherexis drawn from X. Convergence of random variable.'\n",
            "Chunk 8: page_content='Convergence of random variable (in probability, almost sure, in law),\\nconvergence of measures (strong, weak). 1.2 Monge Problem\\nGiven a cost matrix ( Ci,j)i∈JnK,j∈JmK, assuming n=m, the optimal assignment problem seeks for a\\nbijectionσin the set Perm( n) of permutations of nelements solving\\nmin\\nσ∈Perm(n)1\\nnn∑\\ni=1Ci,σ(i). (1.5)\\nOne could naively evaluate the cost function above using all permutations in the set Perm( n). However,\\nthat set has size n!, which is gigantic even for small n. Consider for instance that such a set has more than\\n10100elements [ ?] whennis as small as 70. That problem can therefore only be solved if there exist eﬃcient\\nalgorithms to optimize that cost function over the set of permutations, which will be the subject of §??. 5'\n",
            "Chunk 9: page_content='x1x2y1y2x1x2y1y2x4x5x6x3y3x7Figure 1.3: (left) blue dots from measure αand red dots from measure βare pairwise equidistant. Hence,\\neither matching σ= (1,2) (full line) or σ= (2,1) (dotted line) is optimal. (right) a Monge map can associate\\nthe blue measure αto the red measure β. The weights αiare displayed proportionally to the area of the\\ndisk marked at each location. The mapping here is such that T(x1) =T(x2) =y2,T(x3) =y3, whereas for\\n4⩽i⩽7 we haveT(xi) =y1. Remark 5 (Uniqueness) .Note that the optimal assignment problem may have several optimal solutions. Suppose for instance that n=m= 2 and that the matrix Cis the pairwise distance matrix between the 4\\ncorners of a 2-dimensional square of side length 1, as represented in the left plot in Figure 1.3.'\n",
            "Chunk 10: page_content='In that case\\nonly two assignments exist, and they share the same cost. For discrete measures\\nα=n∑\\ni=1aiδxiandβ=m∑\\nj=1bjδyj (1.6)\\nthe Monge problem [ ?] seeks for a map that associates to each point xia single point yj, and which must\\npush the mass of αtoward the mass of β, which is to say that such a map T:{x1,...,xn}→{y1,...,ym}\\nmust verify that\\n∀j∈JmK,bj=∑\\ni:T(xi)=yjai (1.7)\\nwhich we write in compact form as T♯α=β. This map should minimize some transportation cost, which is\\nparameterized by a function c(x,y) deﬁned for points ( x,y)∈X×Y\\nmin\\nT{∑\\nic(xi,T(xi)) ;T♯α=β}\\n. (1.8)\\nSuch a map between discrete points can be of course encoded, assuming all x’s andy’s are distinct, using\\nindicesσ:JnK→JmKso thatj=σ(i), and the mass conservation is written as\\n∑\\ni∈σ−1(j)ai=bj. In the special case when n=mand all weights are uniform, that is ai=bj= 1/n, then the mass conservation\\nconstraint implies that Tis a bijection, such that T(xi) =yσ(i), and the Monge problem is equivalent to the\\noptimal matching problem (1.5) where the cost matrix is\\nCi,jdef.=c(xi,yj). Whenn̸=m, note that, optimality aside, Monge maps may not even exist between an empirical measure\\nto another. This happens when their weight vectors are not compatible, which is always the case when the\\ntarget measure has more points than the source measure. For instance, the right plot in Figure 1.3 shows\\nan (optimal) Monge map between αandβ, but there is no Monge map from βtoα. 6'\n",
            "Chunk 11: page_content='Monge problem (1.8) is extended to the setting of two arbitrary probability measures ( α,β) on two spaces\\n(X,Y) as ﬁnding a map T:X→Y that minimizes\\nmin\\nT{∫\\nXc(x,T(x))dα(x) ;T♯α=β}\\n(1.9)\\nThe constraint T♯α=βmeans that Tpushes forward the mass of αtoβ, and makes use of the push-forward\\noperator (1.2). 1.3 Kantorovitch Problem\\nThe assignment problem has several limitations in practical settings, also encountered when using the\\nMonge problem. Indeed, because the assignment problem is formulated as a permutation problem, it can only\\nbe used to compare two points clouds of the same size. A direct generalization to discrete measures with non-\\nuniform weights can be carried out using Monge’s formalism of pushforward maps, but that formulation may\\nalso be degenerate it there does not exist feasible solutions satisfying the mass conservation constraint (1.7)\\n(see the end of Remark ??). Additionally, the assignment Problem (1.8) is combinatorial, whereas the feasible\\nset for the Monge Problem (1.9), consisting in all push-forward measures that satisfy the mass conservation\\nconstraint, is non-convex . Both are therefore diﬃcult to solve in their original formulation. Kantorovitch formulation for discrete measures. The key idea of [ ?] is to relax the deterministic na-\\nture of transportation, namely the fact that a source point xican only be assigned to another, or transported\\nto one and one location T(xi) only. Kantorovich proposes instead that the mass at any point xibe potentially\\ndispatched across several locations. Kantorovich moves away from the idea that mass transportation should\\nbe “deterministic” to consider instead a “probabilistic” (or “fuzzy”) transportation, which allows what is\\ncommonly known now as “mass splitting” from a source towards several targets. This ﬂexibility is encoded\\nusing, in place of a permutation σor a mapT, a coupling matrix P∈Rn×m\\n+, where Pi,jdescribes the\\namount of mass ﬂowing from bin i(or pointxi) towards bin j(or pointxj),xitowardsyjin the formalism\\nof discrete measures (1.6). Admissible couplings admit a far simpler characterization than Monge maps:\\nU(a,b)def.={\\nP∈Rn×m\\n+ ;P1m=aand PT1n=b}\\n, (1.10)\\nwhere we used the following matrix-vector notation\\nP1m=\\uf8eb\\n\\uf8ed∑\\njPi,j\\uf8f6\\n\\uf8f8\\ni∈Rnand PT1n=(∑\\niPi,j)\\nj∈Rm. The set of matrices U(a,b) is bounded, deﬁned by n+mequality constraints, and therefore a convex\\npolytope (the convex hull of a ﬁnite set of matrices). Additionally, whereas the Monge formulation (as illustrated in the right plot of Figure 1.3) was intrisically\\nasymmetric, Kantorovich’s relaxed formulation is always symmetric, in the sense that a coupling Pis in\\nU(a,b) if and only if PTis inU(b,a). Kantorovich’s optimal transport problem now reads\\nLC(a,b)def.= min\\nP∈U(a,b)⟨C,P⟩def.=∑\\ni,jCi,jPi,j. (1.11)\\nThis is a linear program (see Chapter ??), and as is usually the case with such programs, its solutions are\\nnot necessarily unique.'\n",
            "Chunk 12: page_content='7'\n",
            "Chunk 13: page_content='↵\\x00\\n↵\\x00Figure 1.4: Comparison of optimal matching and generic couplings. A black segment between xiandyj\\nindicates a non-zero element in the displayed optimal coupling Pi,jsolving (1.11). Left: optimal matching,\\ncorresponding to the setting of Proposition (1) (empirical measures with the same number n=mof points). Right: these two weighted point clouds cannot be matched; instead a Kantorovich coupling can be used to\\nassociate two arbitrary discrete measures. Permutation Matrices as Couplings For a permutation σ∈Perm(n), we write Pσfor the correspond-\\ning permutation matrix,\\n∀(i,j)∈JnK2,(Pσ)i,j={1/n ifj=σi,\\n0 otherwise.(1.12)\\nOne can check that in that case\\n⟨C,Pσ⟩=1\\nnn∑\\ni=1Ci,σi,\\nwhich shows that the assignment problem (1.5) can be recast as a Kantorovich problem (1.11) where the\\ncouplings Pare restricted to be exactly permutation matrices:\\nmin\\nσ∈Perm(n)1\\nnn∑\\ni=1Ci,σ(i)= min\\nσ∈Perm(n)⟨C,Pσ⟩. Next, one can easily check that the set of permutation matrices is strictly included in the so-called Birkhoﬀ\\npolytope U(1n/n,1n,n). Indeed, for any permutation σwe have Pσ1=1nandPσT1=1n, whereas\\n1n1nT/n2is a valid coupling but not a permutation matrix. Therefore, one has naturally that\\nmin\\nσ∈Perm(n)⟨C,Pσ⟩⩽LC(1n/n,1n/n). The following proposition shows that these problems result in fact in the same optimum, namely that\\none can always ﬁnd a permutation matrix that minimizes Kantorovich’s problem (1.11) between two uniform\\nmeasures a=b=1n/n, which shows that the Kantorovich relaxation is tight when considered on assignment\\nproblems. Figure 1.4 shows on the left a 2-D example of optimal matching corresponding to this special\\ncase. Proposition 1 (Kantorovich for matching) .Ifm=nanda=b=1n/n, then there exists an optimal\\nsolution for Problem (1.11) Pσ⋆, which is a permutation matrix associated to an optimal permutation σ⋆∈\\nPerm(n)for Problem (1.5) . Proof.'\n",
            "Chunk 14: page_content='Birkhoﬀ’s theorem states that the set of extremal points of U(1n/n,1n/n) is equal to the set of\\npermutation matrices. A fundamental theorem of linear programming [ ?, Theorem 2.7] states that the\\nminimum of a linear objective in a non-empty polyhedron, if ﬁnite, is reached at an extremal point of the\\npolyhedron. 8'\n",
            "Chunk 15: page_content='⇡\\x00↵\\x00↵\\n⇡\\x00↵\\x00↵\\n⇡\\x00↵\\x00↵\\nDiscrete Semi-discrete Continuous\\nFigure 1.5: Schematic viewed of input measures ( α,β) and couplingsU(α,β) encountered in the three main\\nscenario for Kantorovich OT. Chapter ??is dedicated to the semi-discrete setup. ⇡\\x00↵\\n⇡\\x00↵\\nFigure 1.6: Left: “continuous” coupling πsolving (1.13) between two 1-D measure with density. The\\ncoupling is localized along the graph of the Monge map ( x,T(x)) (displayed in black). Right: “discrete”\\ncouplingTsolving (1.11) between two discrete measures of the form (1.6). The non-zero entries Ti,jare\\ndisplay with a black disk at position ( i,j) with radius proportional to Ti,j. Kantorovitch formulation for arbitrary measures. The deﬁnition of Lcin (??) can be extended to\\narbitrary measures by considering couplings π∈M1\\n+(X×Y ) which are joint distributions over the product\\nspace. The discrete case is a special situation where one imposes this product measure to be of the form\\nπ=∑\\ni,jPi,jδ(xi,yj). In the general case, the mass conservation constraint (1.10) should be rewritten as a\\nmarginal constraint on joint probability distributions\\nU(α,β)def.={\\nπ∈M1\\n+(X×Y ) ;PX♯π=αandPY♯π=β}\\n. (1.13)\\nHerePX♯andPY♯are the push-forward (see Deﬁnition 1) by the projections PX(x,y) =xandPY(x,y) =y. Figure 1.5 shows a schematic visualization of the coupling constraints for diﬀerent class of problem (discrete\\nmeasures and densities). Using (1.3), these marginal constraints are equivalent to imposing that π(A×Y) =\\nα(A) andπ(X×B) =β(B) for setsA⊂X andB⊂Y. The Kantorovich problem (1.11) is then generalized as\\nLc(α,β)def.= min\\nπ∈U(α,β)∫\\nX×Yc(x,y)dπ(x,y). (1.14)\\nThis is an inﬁnite-dimensional linear program over a space of measures.'\n",
            "Chunk 16: page_content='Figure 1.6 shows examples of discrete\\nand continuous optimal coupling solving (1.14). Figure 1.7 shows other examples of optimal 1-D couplings,\\ninvolving discrete and continuous marginals. On compact domain ( X,Y), (1.14) always has a solution, because using the weak-* topology (so called\\nweak topology of measures), the set of measure is compact, and a linear function with a continuous c(x,y)\\n9'\n",
            "Chunk 17: page_content='\\x00↵\\x00↵⇡\\n\\x00↵\\x00↵⇡\\n\\x00↵\\x00↵⇡\\n↵\\x00↵⇡\\x00Figure 1.7: Four simple examples of optimal couplings between 1-D distributions, represented as maps\\nabove (arrows) and couplings below. Inspired by [ ?].'\n",
            "Chunk 18: page_content='is weak-* continuous. And the set of constraint is non empty, taking α⊗β. On non compact domain, needs\\nto impose moment condition on αandβ. Wasserstein distances. An important feature of OT is that it deﬁnes a distance between histograms\\nand probability measures as soon as the cost matrix satisﬁes certain suitable properties. Indeed, OT can be\\nunderstood as a canonical way to lift a ground distance between points to a distance between histogram or\\nmeasures. We ﬁrst consider the case where, using a term ﬁrst introduce by [ ?], the “ground metric” matrix C\\nis ﬁxed, representing substitution costs between bins, and shared across several histograms we would like\\nto compare. The following proposition states that OT provides a meaningful distance between histograms\\nsupported on these bins. Proposition 2. We suppose n=m, and that for some p⩾1,C=Dp= (Dp\\ni,j)i,j∈Rn×nwhere D∈Rn×n\\n+\\nis a distance on JnK,i.e. 1.D∈Rn×n\\n+ is symmetric;\\n2.Di,j= 0if and only if i=j;\\n3.∀(i,j,k )∈JnK3,Di,k⩽Di,j+Dj,k. Then\\nWp(a,b)def.= LDp(a,b)1/p(1.15)\\n(note that Wpdepends on D) deﬁnes the p-Wasserstein distance on Σn,i.e. Wpis symmetric, positive,\\nWp(a,b) = 0 if and only if a=b, and it satisﬁes the triangle inequality\\n∀a,a′,b∈Σn,Wp(a,b)⩽Wp(a,a′) + Wp(a′,b). Proof. Symmetry and deﬁniteness of the distance are easy to prove: since C=Dphas a null diagonal,\\nWp(a,a) = 0, with corresponding optimal transport matrix P⋆= diag( a); by the positivity of all oﬀ-diagonal\\nelements of Dp, Wp(a,b)>0 whenever a̸=b(because in this case, an admissible coupling necessarily has\\na non-zero element outside the diagonal); by symmetry of Dp, Wp(a,b) = 0 is itself a symmetric function. To prove the triangle inequality of Wasserstein distances for arbitrary measures, [ ?, Theorem 7.3] uses the\\ngluing lemma, which stresses the existence of couplings with a prescribed structure. In the discrete setting,\\nthe explicit constuction of this glued coupling is simple.'\n",
            "Chunk 19: page_content='Let a,b,c∈Σn. Let PandQbe two optimal\\nsolutions of the transport problems between aandb, and bandcrespectively. We deﬁne ¯bjdef.=bjifbj>0\\nand set otherwise ¯bj= 1 (or actually any other value). We then deﬁne\\nSdef.=Pdiag(1/¯b)Q∈Rn×n\\n+. 10'\n",
            "Chunk 20: page_content='We remark that S∈U(a,c) because\\nS1n=Pdiag(1/¯b)Q1n=P(b/¯b) =P1Supp( b)=a\\nwhere we denoted 1Supp( b)the indicator of the support of b, and we use the fact that P1Supp( b)=P1=b\\nbecause necessarily Pi,j= 0 forj /∈Supp( b). Similarly one veriﬁes that S⊤1n=c. The triangle inequality follows from\\nWp(a,c) =(\\nmin\\nP∈U(a,c)⟨P,Dp⟩)1/p\\n⩽⟨S,Dp⟩1/p\\n=\\uf8eb\\n\\uf8ed∑\\nikDp\\nik∑\\njPijQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n⩽\\uf8eb\\n\\uf8ed∑\\nijk(Dij+Djk)pPijQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n⩽\\uf8eb\\n\\uf8ed∑\\nijkDp\\nijPijQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n+\\uf8eb\\n\\uf8ed∑\\nijkDp\\njkPijQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n=\\uf8eb\\n\\uf8ed∑\\nijDp\\nijPij∑\\nkQjk\\n¯bj\\uf8f6\\n\\uf8f81/p\\n+\\uf8eb\\n\\uf8ed∑\\njkDp\\njkQjk∑\\niPij\\n¯bj\\uf8f6\\n\\uf8f81/p\\n=\\uf8eb\\n\\uf8ed∑\\nijDp\\nijPij\\uf8f6\\n\\uf8f81/p\\n+\\uf8eb\\n\\uf8ed∑\\njkDp\\njkQjk\\uf8f6\\n\\uf8f81/p\\n= Wp(a,b) + Wp(b,b). The ﬁrst inequality is due to the suboptimality of S, the second is the usual triangle inequality for elements\\ninD, and the third comes from Minkowski’s inequality. Proposition 2 generalizes from histogram to arbitrary measures that need not be discrete.'\n",
            "Chunk 21: page_content='Proposition 3. We assumeX=Y, and that for some p⩾1,c(x,y) =d(x,y)pwheredis a distance on\\nX,i.e. (i)d(x,y) =d(y,x)⩾0;\\n(ii)d(x,y) = 0 if and only if x=y;\\n(ii)∀(x,y,z )∈X3,d(x,z)⩽d(x,y) +d(y,z). Then\\nWp(α,β)def.=Ldp(α,β)1/p(1.16)\\n(note thatWpdepends on d) deﬁnes the p-Wasserstein distance on X,i.e.Wpis symmetric, positive,\\nWp(α,β) = 0 if and only if α=β, and it satisﬁes the triangle inequality\\n∀(α,β,γ )∈M1\\n+(X)3,Wp(α,γ)⩽Wp(α,β) +Wp(β,γ). Proof. The proof follows the same approach as that for Proposition 2 and relies on the existence of a coupling\\nbetween (α,γ) obtained by “guying” optimal couplings between ( α,β) and (β,γ). The Wasserstein distance Wphas many important properties, the most important one being that it is a\\nweak distance, i.e.it allows to compare singular distributions (for instance discrete ones) and to quantify\\nspatial shift between the supports of the distributions. In particular, “classical” distances (or divergences)\\nare not even deﬁned between discrete distributions (the L2norm can only be applied to continuous measures\\nwith a density with respect to a base measure, and the discrete ℓ2norm requires the positions ( xi,yj) to\\nbe ﬁxed to work). In sharp contrast, one has that for any p >0,Wp\\np(δx,δy) =d(x,y). Indeed, it suﬃces\\nto notice thatU(δx,δy) ={δx,y}and therefore the Kantorovich problem having only one feasible solution,\\nWp\\np(δx,δy) is necessarily ( d(x,y)p)1/p=d(x,y). This shows that Wp(δx,δy)→0 ifx→y. This property\\ncorresponds to the fact that Wpis a way to quantify the weak convergence as we now deﬁne. 11'\n",
            "Chunk 22: page_content='Deﬁnition 2 (Weak convergence) .(αk)kconverges weakly to αinM1\\n+(X)(denotedαk⇀α ) if and only if\\nfor any continuous function g∈C(X),∫\\nXgdαk→∫\\nXgdα. This notion of weak convergence corresponds to\\nthe convergence in law of random vectors. This convergence can be shown to be equivalent to Wp(αk,α)→0 [?, Theorem 6.8] (together with a\\nconvergence of the moments up to order pfor unbounded metric spaces). Note that there exists alternative distances which also metrize weak convergence. The simplest one are\\nHilbertian norms, deﬁned as\\n||α||2\\nkdef.=Eα⊗α(k) =∫\\nX×Xk(x,y)dα(x)dα(y)\\nfor a suitable choice of kernel k:X2→R. The most famous of such kernel is the Gaussian one k(x,y) =\\ne−||x−y||2\\n2σ2for some choice of bandwidth σ>0. This convergence should not be confounded with the strong convergence of measures, which is metrized\\nby the TV norm ||α||TVdef.=|α|(X), which is the total mass of the absolute value of the measure. Algorithms Since ( ??)ˆA is a linear program, it is possible to use any classical linear program solver, such\\nas interior point methods or simplex. In practice, the network simplex is an eﬃcient option, and it used\\npivoting rule adapted to the OT constraint set. In the case of the assignment problem, a=b=1n/n, there\\nexists faster combinatorial optimization scheme, the most famous ones being the Hungarian algorithm and\\nthe auction algorithm, which have roughly O(n3) complexity. Section 1.5 details an approximate algorithm,\\nwhich is typically faster, and amenable to parallelisation, but do not compute exactly the solution to the\\nOT problem. 1.4 Duality\\nThe Kantorovich problem (1.11) is a constrained convex minimization problem, and as such, it can be\\nnaturally paired with a so-called dual problem, which is a constrained concave maximization problem. The\\nfollowing fundamental proposition, which is a special case of Fenchel-Rockafellar duality theory, explains the\\nrelationship between the primal and dual problems. Proposition 4. One has\\nLC(a,b) = max\\n(f,g)∈R(a,b)⟨f,a⟩+⟨g,b⟩ (1.17)\\nwhere the set of admissible potentials is\\nR(a,b)def.={(f,g)∈Rn×Rm;∀(i,j)∈JnK×JmK,f⊕g⩽C} (1.18)\\nProof. This result is a direct consequence of the more general result on the strong duality for linear pro-\\ngrams [ ?, p.148,Theo.4.4]. The easier part of that result, namely that the right-hand side of Equation (1.17)\\nis a lower bound on L C(a,b) is discussed in ??. For the sake of completeness, let us derive this dual problem\\nwith the use of Lagrangian duality. The Lagangian associate to (1.11) reads\\nmin\\nP⩾0max\\n(f,g)∈Rn×Rm⟨C,P⟩+⟨a−P1m,f⟩+⟨b−P⊤1n,g⟩. (1.19)\\nFor linear program, one can always exchange the min and the max and get the same value of the linear\\nprogram, and one thus consider\\nmax\\n(f,g)∈Rn×Rm⟨a,f⟩+⟨b,g⟩+ min\\nP⩾0⟨C−f1⊤\\nm−1ng⊤,P⟩. We conclude by remarking that\\nmin\\nP⩾0⟨Q,P⟩={0 if Q⩾0\\n−∞ otherwise\\nso that the constraint reads C−f1⊤\\nm−1ng⊤=C−f⊕g⩾0.'\n",
            "Chunk 23: page_content='12'\n",
            "Chunk 24: page_content='The primal-dual optimality relation for the Lagrangian (1.19) allows to locate the support of the optimal\\ntransport plan\\nSupp( P)⊂{\\n(i,j)∈JnK×JmK;fi+gj=Ci,j}\\n. (1.20)\\nTo extend this primal-dual construction to arbitrary measures, it is important to realize that measures\\nare naturally paired in duality with continuous functions (a measure can only be accessed through integration\\nagainst continuous functions). The duality is formalized in the following proposition, which boils down to\\nProposition 4 when dealing with discrete measures. Proposition 5. One has\\nLc(α,β) = max\\n(f,g)∈R(c)∫\\nXf(x)dα(x) +∫\\nYg(y)dβ(y), (1.21)\\nwhere the set of admissible dual potentials is\\nR(c)def.={(f,g)∈C(X)×C(Y) ;∀(x,y),f(x) +g(y)⩽c(x,y)}. (1.22)\\nHere, (f,g)is a pair of continuous functions, and are often called “Kantorovich potentials”. The discrete case (1.17) corresponds to the dual vectors being samples of the continuous potentials, i.e. (fi,gj) = (f(xi),g(yj)). The primal-dual optimality conditions allow to track the support of optimal plan,\\nand (1.20) is generalized as\\nSupp(π)⊂{(x,y)∈X×Y ;f(x) +g(y) =c(x,y)}. (1.23)\\nNote that in contrast to the primal problem (1.14), showing the existence of solutions to (1.21) is non-\\ntrivial, because the constraint set R(c) is not compact and the function to minimize non-coercive. Using the\\nmachinery of c-transform detailed in Section ??, one can however show that optimal ( f,g) are necessarily\\nLipschitz regular, which enable to replace the constraint by a compact one. Benier’s Theorem and Monge-Amp` ere PDE The following celebrated theorem of [ ?] ensures that in\\nRdforp= 2, if at least one of the two inputs measures has a density, then Kantorovitch and Monge problems\\nare equivalent. Theorem 1 (Brenier) .In the caseX=Y=Rdandc(x,y) =||x−y||2, if at least one of the two inputs\\nmeasures (denoted α) has a density ραwith respect to the Lebesgue measure, then the optimal πin the\\nKantorovich formulation (1.14) is unique, and is supported on the graph (x,T(x))of a “Monge map” T:\\nRd→Rd. This means that π= (Id,T)♯µ,i.e. ∀h∈C(X×Y ),∫\\nX×Yh(x,y)dπ(x,y) =∫\\nXh(x,T(x))dµ(x). (1.24)\\nFurthermore, this map Tis uniquely deﬁned as the gradient of a convex function ϕ,T(x) =∇ϕ(x), where\\nϕis the unique (up to an additive constant) convex function such that (∇ϕ)♯µ=ν. This convex function is\\nrelated to the dual potential fsolving (1.21) asϕ(x) =||x||2\\n2−f(x). Proof.'\n",
            "Chunk 25: page_content='We sketch the main ingredients of the proof, more details can be found for instance in [ ?]. We remark\\nthat∫\\ncdπ=Cα,β−2∫\\n⟨x, y⟩dπ(x,y) where the constant is Cα,β=∫\\n||x||2dα(x) +∫\\n||y||2dβ(y). Instead of\\nsolving (1.14), one can thus consider the following problem\\nmax\\nπ∈U(α,β)∫\\nX×Y⟨x, y⟩dπ(x,y),\\nwhose dual reads\\nmin\\n(ϕ,ψ){∫\\nXϕdα+∫\\nYψdβ;∀(x,y), ϕ (x) +ψ(y)⩾⟨x, y⟩}\\n. (1.25)\\n13'\n",
            "Chunk 26: page_content='The relation between these variables and those of (1.22) is ( ϕ,ψ) = (||·||2\\n2−f,||·||2\\n2−g). One can replace the\\nconstraint by\\n∀y, ψ (y)⩾ϕ∗(y)def.= sup\\nx⟨x, y⟩−ϕ(x). (1.26)\\nHereϕ∗is the Legendre transform of ϕand is a convex function as a supremum of linear forms (see\\nalso ( ??)). Since the objective appearing in (1.27) is linear and the integrating measures positive, one can\\nminimize explicitly with respect to ϕand setψ=ϕ∗in order to consider the unconstraint problem\\nmin\\nϕ∫\\nXϕdα+∫\\nYϕ∗dβ, (1.27)\\nsee also Section ??for a generalization of this idea to generic costs c(x,y). By iterating this argument\\ntwice, one can replace ϕbyϕ∗∗, which is a convex function, and thus impose in (1.27) that ϕis convex. Condition (1.23) shows that an optimal πis supported on{(x,y) ;ϕ(x) +ϕ∗(y) =⟨x, y⟩}which shows that\\nsuch anyis optimal for the minimization (1.26) of the Legendre transform, whose optimality condition reads\\ny∈∂ϕ(x). Sinceϕis convex, it is diﬀerentiable almost everywhere, and since αhas a density, it is also\\ndiﬀerentiable α-almost everywhere. This shows that for each x, the associated yis uniquely deﬁned α-almost\\neverywhere as y=∇ϕ(x), and shows that necessarily π= (Id,∇ϕ)♯α. This results shows that in the setting of W2with non-singular densities, the Monge problem (1.9)\\nand its Kantorovich relaxation (1.14) are equal (the relaxation is tight). This is the continuous analog\\nof Proposition 1 for the assignment case (1), which states that the minimum of the optimal transport\\nproblem is achieved, when the marginals are equal and uniform, at a permutation matrix (a discrete map). Brenier’s theorem, stating that an optimal transport map must be the gradient of a convex function, should\\nbe examined under the light that a convex function is the natural generalization of the notion of increasing\\nfunctions in dimension more than one. Optimal transport can thus plays an important role to deﬁne quantile\\nfunctions in arbitrary dimensions, which in turn is useful for applications to quantile regression problems [ ?]. Note also that this theorem can be extended in many directions.'\n",
            "Chunk 27: page_content='The condition that αhas a density can\\nbe weakened to the condition that it does not give mass to “small sets” having Hausdorﬀ dimension smaller\\nthand−1 (e.g. hypersurfaces). One can also consider costs of the form c(x,y) =h(x−y) wherehis a\\nstrictly convex function. For measures with densities, using (1.4), one obtains that ϕis the unique (up to the addition of a\\nconstant) convex function which solves the following Monge-Amp ˜A¨re-type equation\\ndet(∂2ϕ(x))ρβ(∇ϕ(x)) =ρα(x) (1.28)\\nwhere∂2ϕ(x)∈Rd×dis the hessian of ϕ. The Monge-Amp` ere operator det( ∂2ϕ(x)) can be understood as a\\nnon-linear degenerate Laplacian. In the limit of small displacements, ϕ= Id +εϕ, one indeed recovers the\\nLaplacian ∆ as a linearization since for smooth maps\\ndet(∂2ϕ(x)) = 1 +ε∆ϕ(x) +o(ε). The convexity constraint forces det( ∂2ϕ(x))⩾0 and is necessary for this equation to have a solution.'\n",
            "Chunk 28: page_content='Special cases In general, computing OT distances is numerically involved. We review special favorable\\ncases where the resolution of the OT problem is easy. Remark 6 (Binary Cost Matrix and 1-Norm) .One can easily check that when the cost matrix Cis zero on\\nthe diagonal and 1 elsewhere, namely when C=1n×n−In, the OT distance between aandbis equal to\\nthe 1-norm of their diﬀerence, L C(a,b) =||a−b||1. One can also easily check that this result extends to\\ndiscrete and discrete measures in the case where c(x,y) is 0 ifx=yand 1 when x̸=y. The OT distance\\nbetween two discrete measures αandβis equal to their total variation distance. 14'\n",
            "Chunk 29: page_content='\\x00\\x00↵Figure 1.8: 1-D optimal couplings: each arrow xi→yjindicate a non-zero Pi,jin the optimal coupling. Top: empirical measures with same number of points (optimal matching). Bottom: generic case. This\\ncorresponds to monotone rearrangements, if xi⩽xi′are such that Pi,j̸= 0,Pi′,j′̸= 0, then necessarily\\nyj⩽yj′. Remark 7 (1-D case – Empirical measures) .HereX=R. Assuming α=1\\nn∑n\\ni=1δxiandβ=1\\nn∑n\\nj=1δyj,\\nand assuming (without loss of generality) that the points are ordered, i.e.x1⩽x2⩽...⩽xnand\\ny1⩽y2⩽...⩽yn, then one has the simple formula\\nWp(α,β)p=p∑\\ni=1|xi−yi|p, (1.29)\\ni.e.locally (if one assumes distinct points), Wp(α,β) is theℓpnorm between two vectors of ordered values of\\nαandβ. That statement is only valid locally, in the sense that the order (and those vector representations)\\nmight change whenever some of the values change.'\n",
            "Chunk 30: page_content='That formula is a simple consequence of the more general\\nremark given below. Figure 1.8, top row, illustrates the 1-D transportation map between empirical measures\\nwith the same number of points. The bottom row shows how this monotone map generalizes to arbitrary\\ndiscrete measures. It is possible to leverage this 1-D computation to also compute eﬃciently OT on the\\ncircle, see [ ?]. Note that in the case of concave cost of the distance, for instance when p<1, the behaviour\\nof the optimal transport plan is very diﬀerent, see [ ?], which describes an eﬃcient solver in this case. Remark 8 (1-D case – Generic case) .For a measure αonR, we introduce the cumulative function\\n∀x∈R,Cα(x)def.=∫x\\n−∞dα, (1.30)\\nwhich is a function Cα:R→[0,1], and its pseudo-inverse C−1\\nα: [0,1]→R∪{−∞}\\n∀r∈[0,1],C−1\\nα(r) = min\\nx{x∈R∪{−∞} ;Cα(x)⩾r}. That function is also called the generalized quantile function of α. For anyp⩾1, one has\\nWp(α,β)p=||C−1\\nα−C−1\\nβ||p\\nLp([0,1])=∫1\\n0|C−1\\nα(r)−C−1\\nβ(r)|pdr. (1.31)\\nThis means that through the map α↦→C−1\\nα, the Wasserstein distance is isometric to a linear space equipped\\nwith theLpnorm, or, equivalently, that the Wasserstein distance for measures on the real line is a Hilbertian\\nmetric. This makes the geometry of 1-D optimal transport very simple, but also very diﬀerent from its\\ngeometry in higher dimensions, which is not Hilbertian as discussed in Proposition ??and more generally\\nin§??. Forp= 1, one even has the simpler formula\\nW1(α,β) =||Cα−Cβ||L1(R)=∫\\nR|Cα(x)−Cβ(x)|dx (1.32)\\n=∫\\nR⏐⏐⏐⏐∫x\\n−∞d(α−β)⏐⏐⏐⏐dx. (1.33)\\n15'\n",
            "Chunk 31: page_content='µ ν (tT+ (1−t)Id)♯µ\\n0 0.5 10.5Cµ\\nCν\\n0 0.5 100.51\\nCµ-1\\nCν-1\\n0 0.5 100.51\\nT\\nT-1\\n0 0.5 100.51\\n(Cα,Cβ) (C−1\\nα,C−1\\nβ) ( T,T−1) (1−t)C−1\\nα+tC−1\\nβ\\nFigure 1.9: Computation of OT and displacement interpolation between two 1-D measures, using cumulant\\nfunction as detailed in (1.34). which shows that W1is a norm (see§??for the generalization to arbitrary dimensions). An optimal Monge\\nmapTsuch thatT♯α=βis then deﬁned by\\nT=C−1\\nβ◦Cα. (1.34)\\nFigure 1.9 illustrates the computation of 1-D OT through cumulative functions. It also displays displacement\\ninterpolations, computed as detailed in ( ??), see also Remark ??. For a detailed survey of the properties of\\noptimal transport in 1-D, we refer the reader to [ ?, Chapter 2]. Remark 9 (Distance between Gaussians) .Ifα=N(mα,Σα) andβ=N(mβ,Σβ) are two Gaussians in Rd,\\nthen one can show that the following map\\nT:x↦→mβ+A(x−mα), (1.35)\\nwhere\\nA=Σ−1\\n2α(\\nΣ1\\n2αΣβΣ1\\n2α)1\\n2Σ−1\\n2α=AT,\\nis such that T♯ρα=ρβ. Indeed, one simply has to notice that the change of variables formula (1.4) is satisﬁed\\nsince\\nρβ(T(x)) = det(2πΣβ)−1\\n2exp(−⟨T(x)−mβ,Σ−1\\nβ(T(x)−mβ)⟩)\\n= det(2πΣβ)−1\\n2exp(−⟨x−mα, ATΣ−1\\nβA(x−mα)⟩)\\n= det(2πΣβ)−1\\n2exp(−⟨x−mα,Σ−1\\nα(x−mα)⟩),\\nand sinceTis a linear map we have that\\n|detT′(x)|= detA=(detΣβ\\ndetΣα)1\\n2\\nand we therefore recover ρα=|detT′|ρβmeaningT♯α=β. Notice now that Tis the gradient of the convex\\nfunctionψ:x↦→1\\n2⟨x−mα, A(x−mα)⟩+⟨mβ, x⟩to conclude, using Brenier’s theorem [ ?] (see Remark ??)\\nthatTis optimal. Both that map Tand the corresponding potential ψare illustrated in Figures 1.10 and ??'\n",
            "Chunk 32: page_content='16'\n",
            "Chunk 33: page_content='-4 -2 0 2 4 6-3-2-101234\\nρβραFigure 1.10: Two Gaussians ραandρβ, represented using the contour plots of their densities, with respective\\nmean and variance matrices mα= (−2,0),Σα=1\\n2(\\n1−1\\n2;−1\\n21)\\nandmβ= (3,1),Σβ=(\\n2,1\\n2;1\\n2,1)\\n. The\\narrows originate at random points xtaken on the plane and end at the corresponding mappings of those\\npointsT(x) =mβ+A(x−mα). \\x00m\\nFigure 1.11: Computation of displacement interpolation between two 1-D Gaussians. Denoting Gm,σ(x)def.=\\n1√\\n2πse−(x−m)2\\n2s2the Gaussian density, it thus shows the interpolation G(1−t)m0+tm1,(1−t)σ0+tσ1. With additional calculations involving ﬁrst and second order moments of ρα, we obtain that the transport\\ncost of that map is\\nW2\\n2(α,β) =||mα−mβ||2+B(Σα,Σβ)2(1.36)\\nwhereBis the so-called Bures’ metric [ ?] between positive deﬁnite matrices (see also [ ?,?]),\\nB(Σα,Σβ)2def.= tr(\\nΣα+Σβ−2(Σ1/2\\nαΣβΣ1/2\\nα)1/2)\\n, (1.37)\\nwhere Σ1/2is the matrix square root. One can show that Bis a distance on covariance matrices, and that\\nB2is convex with respect to both its arguments. In the case where Σα= diag(ri)iandΣβ= diag(si)iare\\ndiagonals, the Bures metric is the Hellinger distance\\nB(Σα,Σβ) =||√r−√s||2. For 1-D Gaussians, W2is thus the Euclidean distance on the 2-D plane ( m,√\\nΣ), as illustrated in Figure 1.11. For a detailed treatment of the Wasserstein geometry of Gaussian distributions, we refer to [ ?]. 1.5 Sinkhorn\\nThis section introduces a family of numerical scheme to approximate solutions to Kantorovich formulation\\nof optimal transport and its many generalizations. It operates by adding an entropic regularization penalty to\\nthe original problem.'\n",
            "Chunk 34: page_content='This regularization has several important advantages, but a few stand out particularly:\\nThe minimization of the regularized problen can be solved using a simple alternate minimization scheme;\\nthat scheme translates into iterations that are simple matrix products, making them particularly suited to\\nexecution of GPU; the resulting approximate distance is smooth with respect to input histogram weights\\nand positions of the Diracs. 17'\n",
            "Chunk 35: page_content='c\"P\"Figure 1.12: Impact of εon the optimization of a linear function on the simplex, solving Pε=\\nargminP∈Σ3⟨C,P⟩−εH(P) for a varying ε. Entropic Regularization. The discrete entropy of a coupling matrix is deﬁned as\\nH(P)def.=−∑\\ni,jPi,j(log(Pi,j)−1), (1.38)\\nwith an analogous deﬁnition for vectors, with the convention that H(a) =−∞ if one of the entries ajis\\n0 or negative. The function His 1-strongly concave, because its hessian is ∂2H(P) =−diag(1/Pi,j) and\\nPi,j⩽1. The idea of the entropic regularization of optimal transport is to use −Has a regularizing function\\nto obtain approximate solutions to the original transport problem (1.11):\\nLε\\nC(a,b)def.= min\\nP∈U(a,b)⟨P,C⟩−εH(P). (1.39)\\nSince the objective is a ε-strongly convex function, problem 1.39 has a unique optimal solution. The idea\\nto regularize the optimal transport problem by an entropic term can be traced back to modeling ideas in\\ntransportation theory [ ?]: Actual traﬃc patterns in a network do not agree with those predicted by the\\nsolution of the optimal transport problem. Indeed, the former are more diﬀuse than the latter, which tend\\nto rely on a few routes as a result of the sparsity of optimal couplings to the solution of 1.11. To balance for\\nthat, researchers in transportation proposed a model, called the “gravity” model [ ?], that is able to form a\\nmore “blurred” traﬃc prediction. Figure 1.12 illustrates the eﬀect of the entropy to regularize a linear program over the simples Σ 3(which\\ncan thus be visualized as a triangle in 2-D).'\n",
            "Chunk 36: page_content='Note how the entropy pushes the original LP solution away\\nfrom the boundary of the triangle. The optimal Pεprogressively moves toward an “entropic center” of the\\ntriangle. This is further detailed in the proposition below. The convergence of the solution of that regularized\\nproblem towards an optimal solution of the original linear program has been studied by [ ?]. Proposition 6 (Convergence with ε).The unique solution Pεof(1.39) converges to the optimal solution\\nwith maximal entropy within the set of all optimal solutions of the Kantorovich problem, namely\\nPεε→0−→argmin\\nP{−H(P) ;P∈U(a,b),⟨P,C⟩= LC(a,b)} (1.40)\\nso that in particular\\nLε\\nC(a,b)ε→0−→LC(a,b). One has\\nPεε→∞−→abT= (aibj)i,j.'\n",
            "Chunk 37: page_content='(1.41)\\nProof. We consider a sequence ( εℓ)ℓsuch thatεℓ→0 andεℓ>0. We denote Pℓthe solution of (1.39) for\\nε=εℓ. Since U(a,b) is bounded, we can extract a sequence (that we do not relabel for sake of simplicity)\\nsuch that Pℓ→P⋆. Since U(a,b) is closed, P⋆∈U(a,b). We consider any Psuch that⟨C,P⟩= LC(a,b). By optimality of PandPℓfor their respective optimization problems (for ε= 0 andε=εℓ), one has\\n0⩽⟨C,Pℓ⟩−⟨C,P⟩⩽εℓ(H(Pℓ)−H(P)). (1.42)\\n18'\n",
            "Chunk 38: page_content='⇡\"↵\\x00\\n\"\\x00↵Figure 1.13: Impact of εon coupling between densities and discrete distributions, illustrating Proposition 6. Left: between two 1-D densities. Right: between two 2-D discrete empirical densities with same number\\nn=mof points (only entries of the optimal ( Pi,j)i,jabove a small threshold are displayed as segments\\nbetweenxiandyj). Since His continuous, taking the limit ℓ→+∞in this expression shows that ⟨C,P⋆⟩=⟨C,P⟩so that\\nP⋆is a feasible point of (1.40). Furthermore, dividing by εℓin (1.42) and taking the limit shows that\\nH(P)⩽H(P⋆), which shows that P⋆is a solution of (1.40). Since the solution P⋆\\n0to this program is unique\\nby strict convexity of −H, one has P⋆=P⋆\\n0, and the whole sequence is converging. Formula (1.40) states that for low regularization, the solution converges to the maximum entropy optimal\\ntransport coupling. In sharp contrast, (1.41) shows that for large regularization, the solution converges to the\\ncoupling with maximal entropy between two prescribed marginals a,b, namely the joint probability between\\ntwo independent random variables with prescribed distributions. A reﬁned analysis of this convergence is\\nperformed in [ ?], including a ﬁrst order expansion in ε(resp.'\n",
            "Chunk 39: page_content='1/ε) nearε= 0 (respε= +∞). Figure 1.13\\nshows visually the eﬀect of these two convergence. A key insight is that, as εincreases, the optimal coupling\\nbecomes less and less sparse (in the sense of having entries larger than a prescribed thresholds), which in\\nturn as the eﬀect of both accelerating computational algorithms (as we study in §1.5) but also leading to\\nfaster statistical convergence (as exposed in §??). Deﬁning the Kullback-Leibler divergence between couplings as\\nKL(P|K)def.=∑\\ni,jPi,jlog(Pi,j\\nKi,j)\\n−Pi,j+Ki,j, (1.43)\\nthe unique solution Pεof (1.39) is a projection onto U(a,b) of the Gibbs kernel associated to the cost matrix\\nCas\\nKi,jdef.=e−Ci,j\\nε\\nIndeed one has that using the deﬁnition above\\nPε= ProjKL\\nU(a,b)(K)def.= argmin\\nP∈U(a,b)KL(P|K). (1.44)\\nRemark 10 (General formulation) .One can consider arbitrary measures by replacing the discrete entropy\\nby the relative entropy with respect to the product measure d α⊗dβ(x,y)def.= dα(x)dβ(y), and propose a\\nregularized counterpart to (1.14) using\\nLε\\nc(α,β)def.= min\\nπ∈U(α,β)∫\\nX×Yc(x,y)dπ(x,y) +εKL(π|α⊗β) (1.45)\\nwhere the relative entropy is a generalization of the discrete Kullback-Leibler divergence (1.43)\\nKL(π|ξ)def.=∫\\nX×Ylog(dπ\\ndξ(x,y))\\ndπ(x,y)+\\n∫\\nX×Y(dξ(x,y)−dπ(x,y)),(1.46)\\n19'\n",
            "Chunk 40: page_content='and by convention KL( π|ξ) = +∞ifπdoes not have a densitydπ\\ndξwith respect to ξ. It is important to\\nrealize that the reference measure α⊗βchosen in (1.45) to deﬁne the entropic regularizing term KL( ·|α⊗β)\\nplays no speciﬁc role, only its support matters. Formula (1.45) can be re-factored as a projection problem\\nmin\\nπ∈U(α,β)KL(π|K) (1.47)\\nwhereKis the Gibbs distributions d K(x,y)def.=e−c(x,y)\\nεdµ(x)dν(y). This problem is often referred to as the\\n“static Schr¨ odinger problem” [ ?,?], since it was initially considered by Schr¨ odinger in statistical physics [ ?]. Asε→0, the unique solution to (1.47) converges to the maximum entropy solution to (1.14), see [ ?,?].§?? details an alternate “dynamic” formulation of the Schr¨ odinger problem over the space of paths connecting\\nthe points of two measures. Sinkhorn’s Algorithm The following proposition shows that the solution of (1.39) has a speciﬁc form,\\nwhich can be parameterized using n+mvariables. That parameterization is therefore essentially dual, in\\nthe sense that a coupling PinU(a,b) hasnmvariables but n+mconstraints. Proposition 7. The solution to (1.39) is unique and has the form\\n∀(i,j)∈JnK×JmK,Pi,j=uiKi,jvj (1.48)\\nfor two (unknown) scaling variable (u,v)∈Rn\\n+×Rm\\n+. Proof. Introducing two dual variables f∈Rn,g∈Rmfor each marginal constraint, the Lagrangian of (1.39)\\nreads\\nE(P,f,g) =⟨P,C⟩−εH(P)−⟨f,P1m−a⟩−⟨g,PT1n−b⟩. Considering ﬁrst order conditions, we have\\n∂E(P,f,g)\\n∂Pi,j=Ci,j−εlog(Pi,j)−fi−gj. which results, for an optimal Pcoupling to the regularized problem, in the expression Pi,j=efi/εe−Ci,j/εegj/ε\\nwhich can be rewritten in the form provided in the proposition using non-negative vectors uandv. The factorization of the optimal solution exhibited in Equation (1.48) can be conveniently rewritten in\\nmatrix form as P= diag( u)Kdiag(v).u,vmust therefore satisfy the following non-linear equations which\\ncorrespond to the mass conservation constraints inherent to U(a,b),\\ndiag(u)Kdiag(v)1m=a,and diag( v)K⊤diag(u)1n=b, (1.49)\\nThese two equations can be further simpliﬁed, since diag( v)1mis simply v, and the multiplication of diag( u)\\ntimes Kvis\\nu⊙(Kv) =aand v⊙(KTu) =b (1.50)\\nwhere⊙corresponds to entry-wise multiplication of vectors. That problem is known in the numerical analysis\\ncommunity as the matrix scaling problem (see [ ?] and references therein). An intuitive way to try to solve\\nthese equations is to solve them iteratively, by modifying ﬁrst uso that it satisﬁes the left-hand side of\\nEquation (1.50) and then vto satisfy its right-hand side. These two updates deﬁne Sinkhorn’s algorithm:\\nu(ℓ+1)def.=a\\nKv(ℓ)and v(ℓ+1)def.=b\\nKTu(ℓ+1), (1.51)\\ninitialized with an arbitrary positive vector v(0)=1m. The division operator used above between two\\nvectors is to be understood entry-wise.'\n",
            "Chunk 41: page_content='Note that a diﬀerent initialization will likely lead to a diﬀerent\\n20'\n",
            "Chunk 42: page_content='`⇡(`)\"\\n1000 2000 3000 4000 5000-2-1.5-1-0.50`Figure 1.14: Left: evolution of the coupling πℓ\\nε= diag( U(ℓ))Kdiag(V(ℓ)) computed at iteration ℓof\\nSinkhorn’s iterations, for 1-D densities. Right: impact of εthe convergence rate of Sinkhorn, as measured\\nin term of marginal constraint violation log( ||πℓ\\nε1m−b||1). solution for u,v, since u,vare only deﬁned up to a multiplicative constant (if u,vsatisfy (1.49) then\\nso doλu,v/λfor anyλ > 0). It turns out however that these iterations converge (see Remark 11 for\\na justiﬁcation using iterative projections, and Remark 13 for a strict contraction result) and all result in\\nthe same optimal coupling diag( u)Kdiag(v). Figure 1.14, top row, shows the evolution of the coupling\\ndiag(U(ℓ))Kdiag(V(ℓ)) computed by Sinkhorn iterations. It evolves from the Gibbs kernel Ktowards the\\noptimal coupling solving (1.39) by progressively shifting the mass away from the diagonal. Remark 11 (Relation with iterative projections) .Denoting\\nC1\\nadef.={P;P1m=a}andC2\\nbdef.={\\nP;PT1m=b}\\nthe rows and columns constraints, one has U(a,b) =C1\\na∩C2\\nb. One can use Bregman iterative projections [ ?]\\nP(ℓ+1) def.= ProjKL\\nC1a(P(ℓ)) and P(ℓ+2) def.= ProjKL\\nC2\\nb(P(ℓ+1)). (1.52)\\nSince the setsC1\\naandC2\\nbare aﬃne, these iterations are known to converge to the solution of (1.44), see [ ?]. These iterate are equivalent to Sinkhorn iterations (1.51) since deﬁning\\nP(2ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)),\\none has\\nP(2ℓ+1) def.= diag( u(ℓ+1))Kdiag(v(ℓ))\\nand P(2ℓ+2) def.= diag( u(ℓ+1))Kdiag(v(ℓ+1))\\nIn practice however one should prefer using (1.51) which only requires manipulating scaling vectors and\\nmultiplication against a Gibbs kernel, which can often be accelerated (see below Remarks ??and??). Remark 12 (Hilbert metric) .As initially explained by [ ?], the global convergence analysis of Sinkhorn is\\ngreatly simpliﬁed using Hilbert projective metric on Rn\\n+,∗(positive vectors), deﬁned as\\n∀(u,u′)∈(Rn\\n+,∗)2, dH(u,u′)def.= log max\\ni,i′uiu′\\ni′\\nui′u′\\ni. This can be shows to be a distance on the projective cone Rn\\n+,∗/∼, where u∼u′means that∃s>0,u=su′\\n(the vector are equal up to rescaling, hence the naming “projective”). This means that dHsatisﬁes the\\ntriangular inequality and dH(u,u′) = 0 if and only if u∼u′. This is a projective version of Hilbert’s original\\ndistance on bounded open convex sets [ ?].'\n",
            "Chunk 43: page_content='The projective cone Rn\\n+,∗/∼is a complete metric space for this\\ndistance. It was introduced independently by [ ?] and [ ?] to provide a quantitative proof of Perron-Frobenius\\ntheorem, which, as explained in Remark ??is linked to a local linearization of Sinkhorn’s iterates. They\\nproved the following fundamental theorem, which shows that a positive matrix is a strict contraction on the\\ncone of positive vectors. 21'\n",
            "Chunk 44: page_content='Theorem 2. Let K∈Rn×m\\n+,∗, then for (v,v′)∈(Rm\\n+,∗)2\\ndH(Kv,Kv′)⩽λ(K)dH(v,v′)where\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3λ(K)def.=√\\nη(K)−1√\\nη(K)+1<1\\nη(K)def.= max\\ni,j,k,ℓKi,kKj,ℓ\\nKj,kKi,ℓ. Remark 13 (Global convergence) .The following theorem, proved by [ ?], makes use of this Theorem 2 to\\nshow the linear convergence of Sinkhorn’s iterations. Theorem 3. One has (u(ℓ),v(ℓ))→(u⋆,v⋆)and\\ndH(u(ℓ),u⋆) =O(λ(K)2ℓ), dH(v(ℓ),v⋆) =O(λ(K)2ℓ). (1.53)\\nOne also has\\ndH(u(ℓ),u⋆)⩽dH(P(ℓ)1m,a)\\n1−λ(K)\\ndH(v(ℓ),v⋆)⩽dH(P(ℓ),⊤1n,b)\\n1−λ(K)(1.54)\\nwhere we denoted P(ℓ)def.= diag( u(ℓ))Kdiag(v(ℓ)). Lastly, one has\\n∥log(P(ℓ))−log(P⋆)∥∞⩽dH(u(ℓ),u⋆) +dH(v(ℓ),v⋆) (1.55)\\nwhere P⋆is the unique solution of (1.39) . Proof. One notice that for any ( v,v′)∈(Rm\\n+,∗)2, one has\\ndH(v,v′) =dH(v/v′,1m) =dH(1m/v,1m/v′). This shows that\\ndH(u(ℓ+1),u⋆) =dH(a\\nKv(ℓ),a\\nKv⋆)\\n=dH(Kv(ℓ),Kv⋆)⩽λ(K)dH(v(ℓ),v⋆). where we used Theorem 2. This shows (1.53). One also has, using the triangular inequality\\ndH(u(ℓ),u⋆)⩽dH(u(ℓ+1),u(ℓ)) +dH(u(ℓ+1),u⋆)\\n⩽dH(a\\nKv(ℓ),u(ℓ))\\n+λ(K)dH(u(ℓ),u⋆)\\n=dH(\\na,u(ℓ)⊙(Kv(ℓ)))\\n+λ(K)dH(u(ℓ),u⋆),\\nwhich gives the ﬁrst part of (1.54) since u(ℓ)⊙(Kv(ℓ)) =P(ℓ)1m(the second one being similar). The proof\\nof (1.55) follows from [ ?, Lemma 3]\\nThe bound (1.54) shows that some error measures on the marginal constraints violation, for instance\\n∥P(ℓ)1m−a∥1and∥P(ℓ)T1n−b∥1, are useful stopping criteria to monitor the convergence.'\n",
            "Chunk 45: page_content='Figure 1.14, bottom row, highlights this linear rate on the constraint violation, and shows how this rate\\ndegrades as ε→0. These results are proved in [ ?] and are tightly connected to nonlinear Perron-Frobenius\\nTheory [ ?]. Perron-Frobenius theory corresponds to the linearization of the iterations, see ( ??). This\\nconvergence analysis is extended in [ ?], who shows that each iteration of Sinkhorn increases the permanent\\nof the scaled coupling matrix. 22'\n",
            "Chunk 46: page_content='Regularized Dual and Log-domain Computations The following proposition details the dual problem\\nassociated to (1.39). Proposition 8.'\n",
            "Chunk 47: page_content='One has\\nLε\\nC(a,b) = max\\nf∈Rn,g∈Rm⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩. (1.56)\\nThe optimal (f,g)are linked to scalings (u,v)appearing in (1.48) through\\n(u,v) = (ef/ε,eg/ε). (1.57)\\nProof. We start from the end of the proof of Proposition 7, which links the optimal primal solution P\\nand dual multipliers fandgfor the marginal constraints as Pi,j=efi/εe−Ci,j/εegj/ε. Substituting in the\\nLagrangianE(P,f,g) of Equation (1.5) the optimal Pas a function of fandg, we obtain that the Lagrange\\ndual function equals\\nf,g↦→⟨ef/ε,(K⊙C)eg/ε⟩−εH(diag(ef/ε)Kdiag(eg/ε)). (1.58)\\nThe entropy of Pscaled byε, namelyε⟨P,logP−1n×m⟩can be stated explicitly as a function of f,g,C\\n⟨diag(ef/ε)Kdiag(eg/ε),f1mT+1ngT−C−ε1n×m⟩\\n=−⟨ef/ε,(K⊙C)eg/ε⟩+⟨f,a⟩+⟨g,b⟩−ε⟨ef/ε,Keg/ε⟩\\ntherefore, the ﬁrst term in (1.58) cancels out with the ﬁrst term in the entropy above. The remaining times\\nare those displayed in (1.56). Remark 14.Dual for generic measures For generic (non-necessarily discrete) input measures ( α,β), the dual\\nproblem (1.56) reads\\nsup\\nf,g∈C(X)×C(Y)∫\\nXf(x)dα(x) +∫\\nYg(x)dβ(x)−ε∫\\nX×Ye−c(x,y)+f(x)+g(y)\\nε dα(x)dβ(y)\\nThis corresponds to a smoothing of the constraint R(c) appearing in the original problem (1.21), which\\nis retrieved in the limit ε→0. Proving existence ( i.e. the sup is actually a max) of these Kantorovich\\npotentials ( f,g) in the case of entropic transport is less easy than for classical OT (because one cannot\\nusec-transform and potentials are not automatically Lipschitz). Proof of existence can be done using the\\nconvergence of Sinkhorn iterations, see [ ?] for more details. Remark 15 (Sinkhorn as a Block Coordinate Ascent on the Dual Problem) .A simple approach to solve the\\nunconstrained maximization problem (1.56) is to use an exact block coordinate ascent strategy, namely to\\nupdate alternatively fandgto cancel their gradients with respect to the objective of (1.56). Indeed, one\\ncan easily notice that, writing Q(f,g) for the objective of (1.56) that\\n∇|fQ(f,g) =a−ef/ε⊙(\\nKeg/ε)\\n, (1.59)\\n∇|gQ(f,g) =b−eg/ε⊙(\\nKTef/ε)\\n. (1.60)\\nBlock coordinate ascent can therefore be implemented in a closed form by applying successively the following\\nupdates, starting from any arbitrary g(0), forl⩾0,\\nf(ℓ+1)=εloga−εlog(\\nKeg(ℓ)/ε)\\n, (1.61)\\ng(ℓ+1)=εlogb−εlog(\\nKTef(ℓ+1)/ε)\\n. (1.62)\\nSuch iterations are mathematically equivalent to the Sinkhorn iterations (1.51) when considering the primal-\\ndual relations highlighted in (1.57). Indeed, we recover that at any iteration\\n(f(ℓ),g(ℓ)) =ε(log(u(ℓ)),log(v(ℓ))). 23'\n",
            "Chunk 48: page_content='Remark 16 (Soft-min rewriting) .Iterations (1.61) and (1.62) can be given an alternative interpretation,\\nusing the following notation. Given a vector zof real numbers we write min εzfor the soft-minimum of its\\ncoordinates, namely\\nminεz=−εlog∑\\nie−zi/ε. Note that min ε(z) converges to min zfor any vector zasε→0. Indeed, min εcan be interpreted as a\\ndiﬀerentiable approximation of the min function. Using these notations, Equations (1.61) and (1.62) can be\\nrewritten\\n(f(ℓ+1))i= minε(Cij−g(ℓ)\\nj)j+εlogai, (1.63)\\n(g(ℓ+1))j= minε(Cij−f(ℓ)\\ni)i+εlogbj. (1.64)\\nHere the term min ε(Cij−g(ℓ)\\nj)jdenotes the soft-minimum of all values of the j-th column of matrix\\n(C−1n(g(ℓ))⊤). To simplify notations, we introduce an operator that takes a matrix as input and outputs\\nnow a column vector of the soft-minimum values of its columns or rows. Namely, for any matrix A∈Rn×m,\\nwe deﬁne\\nMinrow\\nε(A)def.=(\\nminε(Ai,j)j)\\ni∈Rn,\\nMincol\\nε(A)def.=(\\nminε(Ai,j)i)\\nj∈Rm. Note that these operations are equivalent to the entropic c-transform introduced in §??(see in particu-\\nlar (??)). Using these notations, Sinkhorn’s iterates read\\nf(ℓ+1)= Minrow\\nε(C−1ng(ℓ)T) +εloga, (1.65)\\ng(ℓ+1)= Mincol\\nε(C−f(ℓ)1mT) +εlogb. (1.66)\\nNote that as ε→0, minεconverges to min, but the iterations do not converge anymore in the limit ε= 0,\\nbecause alternate minimization does not converge for constrained problems (which is the case for the un-\\nregularized dual (1.17)). Remark 17 (Log-domain Sinkhorn) .While mathematically equivalent to the Sinkhorn updates (1.51), itera-\\ntions (1.63) and (1.64) suggest to use the log-sum-exp stabilization trick to avoid underﬂow for small values\\nofε. Writing z = min z, that trick suggests to evaluate min εzas\\nminεz= z−εlog∑\\nie−(zi−z)/ε. (1.67)\\nInstead of substracting z to stabilize the log domain iterations as in (1.67), one can actually substract the\\npreviously computed scalings. This leads to the following stabilized iteration\\nf(ℓ+1)= Minrow\\nε(S(f(ℓ),g(ℓ)))−f(ℓ)+εlog(a) (1.68)\\ng(ℓ+1)= Mincol\\nε(S(f(ℓ+1),g(ℓ)))−g(ℓ)+εlog(b), (1.69)\\nwhere we deﬁned\\nS(f,g) =(\\nCi,j−fi−gj)\\ni,j. In contrast to the original iterations (1.51), these log-domain iterations (1.68) and (1.69) are stable for\\narbitraryε >0, because the quantity S(f,g) stays bounded during the iterations. The downside is that it\\nrequiresnmcomputations of exp at each step. Computing a Minrow\\nεor Mincol\\nεis typically substantially\\nslower than matrix multiplications, and requires computing line by line soft-minima of matrices S. There is\\ntherefore no eﬃcient way to parallelize the application of Sinkhorn maps for several marginals simultaneously. In Euclidean domain of small dimension, it is possible to develop eﬃcient multiscale solvers with a decaying\\nεstrategy to signiﬁcantly speed up the computation using sparse grids [ ?].'\n",
            "Chunk 49: page_content='24'\n",
            "Chunk 50: page_content='1.6 Extensions\\nWasserstein Barycenters. Given input histogram {bs}S\\ns=1, wherebs∈Σns, and weights λ∈ΣS, a\\nWasserstein barycenter is computed by minimizing\\nmin\\na∈ΣnS∑\\ns=1λsLCs(a,bs) (1.70)\\nwhere the cost matrices Cs∈Rn×nsneed to be speciﬁed. A typical setup is “Eulerian”, so that all the\\nbarycenters are deﬁned on the same grid, ns=n,Cs=C=Dpis set to be a distance matrix, so that one\\nsolves\\nmin\\na∈ΣnS∑\\ns=1λsWp\\np(a,bs). This barycenter problem (1.70) was originally introduced by [ ?] following earlier ideas of [ ?]. They proved\\nin particular uniqueness of the barycenter for c(x,y) =||x−y||2overX=Rd, if one of the input measure\\nhas a density with respect to the Lebesgue measure (and more generally under the same hypothesis as the\\none guaranteeing the existence of a Monge map, see Remark ??). The barycenter problem for histograms (1.70) is in fact a linear program, since one can look for the S\\ncouplings ( Ps)sbetween each input and the barycenter itself\\nmin\\na∈Σn,(Ps∈Rn×ns)s{S∑\\ns=1λs⟨Ps,Cs⟩;∀s,P⊤\\ns1ns=a,P⊤\\ns1n=bs}\\n. Although this problem is an LP, its scale forbids the use generic solvers for medium scale problems. One\\ncan therefore resort to using ﬁrst order methods such as subgradient descent on the dual [ ?]. Remark 18.Barycenter of arbitrary measures Given a set of input measure ( βs)sdeﬁned on some space X,\\nthe barycenter problem becomes\\nmin\\nα∈M1\\n+(X)S∑\\ns=1λsLc(α,βs). (1.71)\\nIn the case where X=Rdandc(x,y) =||x−y||2, [?] shows that if one of the input measures has a density,\\nthen this barycenter is unique. Problem (1.71) can be viewed as a generalization of the problem of computing\\nbarycenters of points ( xs)S\\ns=1∈XSto arbitrary measures. Indeed, if βs=δxsis a single Dirac mass, then a\\nsolution to (1.71) is δx⋆wherex⋆is a Fr´ echet mean solving ( ??). Note that for c(x,y) =||x−y||2, the mean\\nof the barycenter α⋆is necessarily the barycenter of the mean, i.e. ∫\\nXxdα⋆(x) =∑\\nsλs∫\\nXxdαs(x),\\nand the support of α⋆is located in the convex hull of the supports of the ( αs)s.'\n",
            "Chunk 51: page_content='The consistency of the\\napproximation of the inﬁnite dimensional optimization (1.71) when approximating the input distribution\\nusing discrete ones (and thus solving (1.70) in place) is studied in [ ?]. Let us also note that it is possible to\\nre-cast (1.71) as a multi-marginal OT problem, see Remark ??. One can use entropic smoothing and approximate the solution of (1.70) using\\nmin\\na∈ΣnS∑\\ns=1λsLε\\nCs(a,bs) (1.72)\\nfor someε > 0. This is a smooth convex minimization problem, which can be tackled using gradient\\ndescent [ ?]. An alternative is to use descent method (typically quasi-Newton) on the semi-dual [ ?], which is\\n25'\n",
            "Chunk 52: page_content='useful to integrate additional regularizations on the barycenter (e.g. to impose some smoothness). A simple\\nbut eﬀective approach, as remarked in [ ?] is to rewrite (1.72) as a (weighted) KL projection problem\\nmin\\n(Ps)s{∑\\nsλsKL(Ps|Ks) ;∀s,PsT1m=bs,P111=...=PS1S}\\n(1.73)\\nwhere we denoted Ksdef.=e−Cs/ε. Here, the barycenter ais implicitly encoded in the row marginals of all\\nthe couplings Ps∈Rn×nsasa=P111=...=PS1S. As detailed in [ ?], one can generalize Sinkhorn to\\nthis problem, which also corresponds to iterative projection.'\n",
            "Chunk 53: page_content='This can also be seen as a special case of the\\ngeneralized Sinkhorn detailed in §??. The optimal couplings ( Ps)ssolving (1.73) are computed in scaling\\nform as\\nPs= diag( us)Kdiag(vs), (1.74)\\nand the scalings are sequentially updated as\\n∀s∈J1,SK,v(ℓ+1)\\nsdef.=bs\\nKT\\nsu(ℓ)\\ns, (1.75)\\n∀s∈J1,SK,u(ℓ+1)\\nsdef.=a(ℓ+1)\\nKsv(ℓ+1)\\ns, (1.76)\\nwhere a(ℓ+1)def.=∏\\ns(Ksv(ℓ+1)\\ns)λs. (1.77)\\nAn alternative way to derive these iterations is to perform alternate minimization on the variables of a dual\\nproblem, which detailed in the following proposition. Proposition 9. The optimal (us,vs)appearing in (1.74) can be written as (us,vs) = (efs/ε,egs/ε)where\\n(fs,gs)sare the solutions of the following program (whose value matches the one of (1.72) )\\nmax\\n(fs,gs)s{∑\\nsλs(\\n⟨gs,bs⟩−ε⟨Ksegs/ε, efs/ε⟩)\\n;∑\\nsλsfs= 0}\\n. (1.78)\\nProof. Introducing Lagrange multipliers in (1.73) leads to\\nmin\\n(Ps)s,amax\\n(fs,gs)s∑\\nsλs(\\nεKL(Ps|Ks) +⟨a−Ps1m,fs⟩\\n+⟨bs−PsT1m,gs⟩)\\n. Strong duality holds, so that one can exchange the min and the max, and gets\\nmax\\n(fs,gs)s∑\\nsλs(\\n⟨gs,bs⟩+ min\\nPsεKL(Ps|Ks)−⟨Ps,fs⊕gs⟩)\\n+ min\\na⟨∑\\nsλsfs,a⟩. The explicit minimization on agives the constraint∑\\nsλsfs= 0 together with\\nmax\\n(fs,gs)s∑\\nsλs⟨gs,bs⟩−εKL∗(fs⊕gs\\nε|Ks)\\nwhere KL∗(·|Ks) is the Legendre transform ( ??) of the function KL∗(·|Ks). This Legendre transform reads\\nKL∗(U|K) =∑\\ni,jKi,j(eUi,j−1), (1.79)\\n26'\n",
            "Chunk 54: page_content='Figure 1.15: Barycenters between 4 input 3-D shapes using entropic regularization (1.72). The weights\\n(λs)sare bilinear with respect to the four corners of the square. Shapes are represented as measures that\\nare uniform within the boundaries of the shape and null outside.'\n",
            "Chunk 55: page_content='which shows the desired formula. To show (1.79), since this function is separable, one needs to compute\\n∀(u,k)∈R2\\n+,KL∗(u|k)def.= max\\nrur−(rlog(r/k)−r+k)\\nwhose optimality condition reads u= log(r/k), i.e.r=keu, hence the result. Minimizing (1.78) with respect to each gs, while keeping all the other variable ﬁxed, is obtained in closed\\nform by (1.75). Minimizing (1.78) with respect to all the ( fs)srequires to solve for ausing (1.77) and leads\\nto the expression (1.76). Figures ??and??show applications to 2-D and 3-D shapes interpolation. Figure ??shows a computation\\nof barycenters on a surface, where the ground cost is the square of the geodesic distance. For this ﬁgure,\\nthe computations are performed using the geodesic in heat approximation detailed in Remark ??. We refer\\nto [?] for more details and other applications to computer graphics and imaging sciences. Wasserstein Loss. In statistics, text processing or imaging, one must usually compare a probability\\ndistribution βarising from measurements to a model, namely a parameterized family of distributions {αθ,θ∈\\nΘ}where Θ is a subset of an Euclidean space. Such a comparison is done through a “loss” or a “ﬁdelity”\\nterm, which, in this section, is the Wasserstein distance. In the simplest scenario, the computation of a\\nsuitable parameter θis obtained by minimizing directly\\nmin\\nθ∈ΘE(θ)def.=Lc(αθ,β). (1.80)\\nOf course, one can consider more complicated problems: for instance, the barycenter problem described\\nin§??consists in a sum of such terms. However, most of these more advanced problems can be usually\\nsolved by adapting tools deﬁned for basic case: either using the chain rule to compute explicitly derivatives,\\nor using automatic diﬀerentiation. The Wasserstein distance between two histograms or two densities is convex with respect to these inputs,\\nas shown by (1.17) and (1.21) respectively. Therefore, when the parameter θis itself a histogram, namely Θ =\\nΣnandαθ=θ, or more generally when θdescribesKweights in the simplex, Θ = Σ K, andαθ=∑K\\ni=1θiαi\\nis a convex combination of known atoms α1,...,αKin ΣN, Problem (1.80) remains convex (the ﬁrst case\\ncorresponds to the barycenter problem, the second to one iteration of the dictionary learning problem with\\na Wasserstein loss [ ?]). However, for more general parameterizations θ↦→αθ, Problem (1.80) is in general\\nnot convex. 27'\n",
            "Chunk 56: page_content='g✓XZ⇣xz\\x00↵✓Figure 1.16: Schematic display of the density ﬁtting problem 1.81. A practical problem of paramount importance in statistic and machine learning is density ﬁtting. Given\\nsome discrete samples ( xi)n\\ni=1⊂X from some unknown distribution, the goal is to ﬁt a parametric model\\nθ↦→αθ∈M (X) to the observed empirical input measure β\\nmin\\nθ∈ΘL(αθ,β) where β=1\\nn∑\\niδxi, (1.81)\\nwhereLis some “loss” function between a discrete and a “continuous” (arbitrary) distribution (see Fig-\\nure 1.16). In the case where αθas a densify ρθdef.=ραθwith respect to the Lebesgue measure (or any other ﬁxed\\nreference measure), the maximum likelihood estimator (MLE) is obtained by solving\\nmin\\nθLMLE(αθ,β)def.=−∑\\nilog(ρθ(xi)). This corresponds to using an empirical counterpart of a Kullback-Leibler loss since, assuming the xiare i.i.d. samples of some ¯β, then\\nLMLE(α,β)n→+∞−→ KL(α|¯β)\\nThis MLE approach is known to lead to optimal estimation procedures in many cases (see for instance [ ?]). However, it fails to work when estimating singular distributions, typically when the αθdoes not has a density\\n(so thatLMLE(αθ,β) = +∞) or when ( xi)iare samples from some singular ¯β(so that the αθshould share\\nthe same support as βfor KL(α|¯β) to be ﬁnite, but this support is usually unknown). Another issue is that\\nin several cases of practical interest, the density ρθis inaccessible (or too hard to compute). A typical setup where both problems (singular and unknown densities) occur is for so-called generative\\nmodels, where the parametric measure is written as a push-forward of a ﬁxed reference measure ζ∈M (Z)\\nαθ=hθ,♯ζwherehθ:Z→X\\nwhere the push-forward operator is introduced in Deﬁnition 1. The space Zis usually low-dimensional, so\\nthat the support of αθis localized along a low-dimensional “manifold” and the resulting density is highly\\nsingular (it does not have a density with respect to Lebesgue measure). Furthermore, computing this density\\nis usually intractable, while generating i.i.d. samples from αθis achieved by computing xi=hθ(zi) where\\n(zi)iare i.i.d. samples from ζ. In order to cope with such diﬃcult scenario, one has to use weak metrics in place of the MLE functional\\nLMLE, which needs to be written in dual form as\\nL(α,β)def.= max\\n(f,g)∈C(X)2{∫\\nXf(x)dα(x) +∫\\nXg(x)dβ(x) ; (f,g)∈R}\\n. (1.82)\\nDual norms exposed in §??correspond to imposing R={(f,−f) ;f∈B}, while optimal transport (1.21)\\nsetsR=R(c) as deﬁned in (1.22).'\n",
            "Chunk 57: page_content='28'\n",
            "Chunk 58: page_content='For a ﬁxed θ, evaluating the energy to be minimized in (1.81) using such a loss function corresponds to\\nsolving a semi-discrete optimal transport, which is the focus of Chapter ??. Minimizing the energy with\\nrespect toθis much more involved, and is typically highly non-convex. The class of estimators obtained using L=Lc, often called “Minimum Kantorovitch Estimators” (MKE),\\nwas initially introduced in [ ?], see also [ ?].'\n",
            "Chunk 59: page_content='Gromov-Wasserstein. Optimal transport needs a ground cost Cto compare histograms ( a,b), it can\\nthus not be used if the histograms are not deﬁned on the same underlying space, or if one cannot pre-register\\nthese spaces to deﬁne a ground cost. To address this issue, one can instead only assume a weaker assumption,\\nnamely that one has at its disposal two matrices D∈Rn×nandD′∈Rm×mthat represent some relationship\\nbetween the points on which the histograms are deﬁned.'\n",
            "Chunk 60: page_content='A typical scenario is when these matrices are (power\\nof) distance matrices. The Gromov-Wasserstein problem reads\\nGW(( a,D),(b,D′))2def.= min\\nP∈U(a,b)ED,D′(P)def.=∑\\ni,j,i′,j′|Di,i′−D′\\nj,j′|2Pi,jPi′,j′. (1.83)\\nThis is a non-convex problem, which can be recast as a Quadratic Assignment Problem (QAP) [ ?] and is in\\nfull generality NP-hard to solve for arbitrary inputs. It is in fact equivalent to a graph matching problem [ ?]\\nfor a particular cost. One can show that GW satisﬁes the triangular inequality, and in fact it deﬁnes a distance between\\nmetric spaces equipped with a probability distribution (here assumed to be discrete in deﬁnition (1.83))\\nup to isometries preserving the measures. This distance was introduced and studied in details by Memoli\\nin [?]. An in-depth mathematical exposition (in particular, its geodesic structure and gradient ﬂows) is given\\nin [?]. See also [ ?] for applications in computer vision. This distance is also tightly connected with the\\nGromov-Hausdorﬀ distance [ ?] between metric spaces, which have been used for shape matching [ ?,?]. Remark 19.Gromov-Wasserstein distance The general setting corresponds to computing couplings between\\nmetric measure spaces ( X,dX,αX) and (Y,dY,αY) where (dX,dY) are distances and ( αX,αY) are measures\\non their respective spaces. One deﬁnes\\nGW((αX,dX),(αY,dY))2def.= min\\nπ∈U(αX,αY)∫\\nX2×Y2|dX(x,x′)−dY(y,y′)|2dπ(x,y)dπ(x′,y′). (1.84)\\nGW deﬁnes a distance between metric measure spaces up to isometries, where one says that ( αX,dX) and\\n(αY,dY) are isometric if there exists ϕ:X→Y such thatϕ♯αX=αYanddY(ϕ(x),ϕ(x′)) =dX(x,x′). Remark 20.Gromov-Wasserstein geodesics The space of metric spaces (up to isometries) endowed with\\nthisGW distance (1.84) has a geodesic structure. [ ?] shows that the geodesic between ( X0,dX0,α0) and\\n(X1,dX1,α1) can be chosen to be t∈[0,1]↦→(X0×X 1,dt,π⋆) whereπ⋆is a solution of (1.84) and for all\\n((x0,x1),(x′\\n0,x′\\n1))∈(X0×X 1)2,\\ndt((x0,x1),(x′\\n0,x′\\n1))def.= (1−t)dX0(x0,x′\\n0) +tdX1(x1,x′\\n1). This formula allows one to deﬁne and analyze gradient ﬂows which minimize functionals involving metric\\nspaces, see [ ?]. It is however diﬃcult to handle numerically, because it involves computations over the product\\nspaceX0×X 1. A heuristic approach is used in [ ?] to deﬁne geodesics and barycenters of metric measure\\nspaces while imposing the cardinality of the involved spaces and making use of the entropic smoothing (1.85)\\ndetailed below. To approximate the computation of GW, and to help convergence of minimization schemes to better\\nminima, one can consider the entropic regularized variant\\nmin\\nP∈U(a,b)ED,D′(P)−εH(P). (1.85)\\n29'\n",
            "Chunk 61: page_content='Figure 1.17: Example of fuzzy correspondences computed by solving GW problem (1.85) with Sinkhorn\\niterations (1.86). Extracted from [ ?]. As proposed initially in [ ?,?], and later revisited in [ ?] for applications in graphics, one can use iteratively\\nSinkhorn’s algorithm to progressively compute a stationary point of (1.85). Indeed, successive linearizations\\nof the objective function lead to consider the succession of updates\\nP(ℓ+1) def.= min\\nP∈U(a,b)⟨P,C(ℓ)⟩−εH(P) where (1.86)\\nC(ℓ)def.=∇ED,D′(P(ℓ)) =−D′TP(ℓ)D,\\nwhich can be interpreted as a mirror-descent scheme [ ?].'\n",
            "Chunk 62: page_content='Each update can thus be solved using Sinkhorn\\niterations (1.51) with cost C(ℓ). Figure (1.17) illustrates the use of this entropic Gromov-Wasserstein to\\ncompute soft maps between domains. 30'\n",
            "Chunk 63: page_content='Bibliography\\n[1] Amir Beck. Introduction to Nonlinear Optimization: Theory, Algorithms, and Applications with MAT-\\nLAB. SIAM, 2014. [2] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization\\nand statistical learning via the alternating direction method of multipliers. Foundations and Trends R⃝\\nin Machine Learning , 3(1):1–122, 2011. [3] Stephen Boyd and Lieven Vandenberghe. Convex optimization . Cambridge university press, 2004. [4] E. Cand` es and D. Donoho. New tight frames of curvelets and optimal representations of objects with\\npiecewise C2singularities. Commun. on Pure and Appl. Math. , 57(2):219–266, 2004. [5] E. J. Cand` es, L. Demanet, D. L. Donoho, and L. Ying. Fast discrete curvelet transforms. SIAM\\nMultiscale Modeling and Simulation , 5:861–899, 2005. [6] A. Chambolle. An algorithm for total variation minimization and applications. J.'\n",
            "Chunk 64: page_content='Math. Imaging Vis. ,\\n20:89–97, 2004. [7] Antonin Chambolle, Vicent Caselles, Daniel Cremers, Matteo Novaga, and Thomas Pock. An intro-\\nduction to total variation for image analysis. Theoretical foundations and numerical methods for sparse\\nrecovery , 9(263-340):227, 2010. [8] Antonin Chambolle and Thomas Pock. An introduction to continuous optimization for imaging. Acta\\nNumerica , 25:161–319, 2016. [9] S.S. Chen, D.L. Donoho, and M.A. Saunders. Atomic decomposition by basis pursuit. SIAM Journal\\non Scientiﬁc Computing , 20(1):33–61, 1999. [10] Philippe G Ciarlet. Introduction ` a l’analyse num´ erique matricielle et ` a l’optimisation. 1982. [11] P. L. Combettes and V. R.'\n",
            "Chunk 65: page_content='Wajs. Signal recovery by proximal forward-backward splitting. SIAM\\nMultiscale Modeling and Simulation , 4(4), 2005. [12] I. Daubechies, M. Defrise, and C. De Mol. An iterative thresholding algorithm for linear inverse problems\\nwith a sparsity constraint. Commun. on Pure and Appl. Math. , 57:1413–1541, 2004. [13] D. Donoho and I. Johnstone. Ideal spatial adaptation via wavelet shrinkage. Biometrika , 81:425–455,\\nDec 1994. [14] Heinz Werner Engl, Martin Hanke, and Andreas Neubauer. Regularization of inverse problems , volume\\n375. Springer Science & Business Media, 1996. [15] M.'\n",
            "Chunk 66: page_content='Figueiredo and R.'\n",
            "Chunk 67: page_content='Nowak. An EM Algorithm for Wavelet-Based Image Restoration. IEEE Trans. Image Proc. , 12(8):906–916, 2003. [16] Simon Foucart and Holger Rauhut. A mathematical introduction to compressive sensing , volume 1. Birkh¨ auser Basel, 2013.'\n",
            "Chunk 68: page_content='31'\n",
            "Chunk 69: page_content='[17] Stephane Mallat. A wavelet tour of signal processing: the sparse way . Academic press, 2008. [18] D. Mumford and J. Shah. Optimal approximation by piecewise smooth functions and associated varia-\\ntional problems. Commun. on Pure and Appl. Math. , 42:577–685, 1989. [19] Neal Parikh, Stephen Boyd, et al. Proximal algorithms. Foundations and Trends R⃝in Optimization ,\\n1(3):127–239, 2014. [20] Gabriel Peyr´ e. L’alg` ebre discr` ete de la transform´ ee de Fourier . Ellipses, 2004. [21] J. Portilla, V. Strela, M.J. Wainwright, and Simoncelli E.P. Image denoising using scale mixtures of\\nGaussians in the wavelet domain. IEEE Trans. Image Proc. , 12(11):1338–1351, November 2003. [22] L. I. Rudin, S. Osher, and E.'\n",
            "Chunk 70: page_content='Fatemi. Nonlinear total variation based noise removal algorithms. Phys. D, 60(1-4):259–268, 1992. [23] Otmar Scherzer, Markus Grasmair, Harald Grossauer, Markus Haltmeier, Frank Lenzen, and L Sirovich. Variational methods in imaging . Springer, 2009.'\n",
            "Chunk 71: page_content='[24] C. E. Shannon. A mathematical theory of communication. The Bell System Technical Journal ,\\n27(3):379–423, 1948. [25] Jean-Luc Starck, Fionn Murtagh, and Jalal Fadili. Sparse image and signal processing: Wavelets and\\nrelated geometric multiscale analysis . Cambridge university press, 2015.'\n",
            "Chunk 72: page_content='32'\n"
          ]
        }
      ]
    }
  ]
}