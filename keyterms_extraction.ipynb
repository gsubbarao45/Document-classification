{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SURIe1UDpLCu"
      },
      "outputs": [],
      "source": [
        "#!pip install openai langchain langchain_community\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uG7Azba0ppsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain import OpenAI\n",
        "# from langchain.chains import LLMChain\n",
        "# from langchain.prompts import PromptTemplate\n",
        "\n",
        "# # Initialize the model\n",
        "\n",
        "\n",
        "# model = OpenAI(model_name=\"gpt-35-turbo\", temperature=0.5)\n",
        "\n",
        "# # Define a prompt template for extracting key terms\n",
        "# prompt_template = PromptTemplate(input_variables=[\"text\"], template=\"\"\"\n",
        "# Extract the key terms from the following text:\n",
        "# {text}\n",
        "# \"\"\")\n",
        "\n",
        "# # Create a chain for extracting terms\n",
        "# chain = LLMChain(llm=model, prompt=prompt_template)\n",
        "\n",
        "# def extract_key_terms(text):\n",
        "#     result = chain.run({\"text\": text})\n",
        "#     return result.strip().split(\", \")\n",
        "\n",
        "\n",
        "# text = \" something ......\"\n",
        "\n",
        "# # Extract key terms\n",
        "# key_terms = extract_key_terms(text)\n",
        "# print(key_terms)\n"
      ],
      "metadata": {
        "id": "c1k1giNHpll5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v6GIPm3mqs91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4rcL6TvDqtA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "# from langchain.llms import AzureOpenAI\n",
        "# from langchain.chains import LLMChain\n",
        "# from langchain.prompts import PromptTemplate\n",
        "\n",
        "# # Replace with your Azure OpenAI endpoint and API key\n",
        "# openai.api_type = \"azure\"\n",
        "# openai.api_base = \"https://<your-resource-name>.openai.azure.com/\"\n",
        "# openai.api_version = \"2023-05-15\"\n",
        "# openai.api_key = \"<your-api-key>\"\n",
        "\n",
        "# # Initialize the model\n",
        "# model = AzureOpenAI(\n",
        "#     openai_api_base=openai.api_base,\n",
        "#     openai_api_key=openai.api_key,\n",
        "#     model_name=\"gpt-35-turbo\",\n",
        "#     openai_api_version=openai.api_version,\n",
        "#     temperature=0.5\n",
        "# )\n",
        "\n",
        "# # Define a prompt template for extracting key terms\n",
        "# prompt_template = PromptTemplate(input_variables=[\"text\"], template=\"\"\"\n",
        "# Extract the key terms from the following text:\n",
        "# {text}\n",
        "# \"\"\")\n",
        "\n",
        "# # Create a chain for extracting terms\n",
        "# chain = LLMChain(llm=model, prompt=prompt_template)\n",
        "\n",
        "# def extract_key_terms(text):\n",
        "#     result = chain.run({\"text\": text})\n",
        "#     return result.strip().split(\", \")  # Assuming the model returns a comma-separated list of key terms\n",
        "\n",
        "# # Example text\n",
        "# text = \"Azure OpenAI Service provides access to OpenAI's powerful language models, including GPT-3.5-turbo.\"\n",
        "\n",
        "# # Extract key terms\n",
        "# key_terms = extract_key_terms(text)\n",
        "# print(key_terms)\n"
      ],
      "metadata": {
        "id": "2TBZ8lg8qtbA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ke1qR_oCr14-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZM-a39JRr172"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import openai\n",
        "\n",
        "# # Set up OpenAI API key\n",
        "# openai.api_key = \"apikey\"\n",
        "# # Define input text\n",
        "# text =  \"something\"\n",
        "\n",
        "\n",
        "\n",
        "# # Pass preprocessed text through OpenAI GPT for contextual analysis\n",
        "# contextual_embeddings = openai.Completion.create(engine= \"text-davinci-002\", prompt=text, max_tokens=50)\n",
        "\n",
        "# # Combine RAKE scores with contextual embeddings to rank keywords\n",
        "# # Select top-ranked keywords as final extracted keywords\n",
        "# final_keywords = [keyword for keyword  in contextual_embeddings.choices[0].text]\n",
        "\n",
        "# # Print final extracted keywords\n",
        "# print(\"Extracted Keywords:\")\n",
        "# for keyword in final_keywords:\n",
        "#     print(keyword)"
      ],
      "metadata": {
        "id": "9G5Hq9lRr1_F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RK9NwbbW0ZUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nDXtqcLc0ZYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "\n",
        "\n",
        "# try:\n",
        "#     response = openai.Completion.create(\n",
        "#         engine=\"gpt-35-turbo\",\n",
        "#         prompt=\"Say hello!\",\n",
        "#         max_tokens=5\n",
        "#     )\n",
        "#     print(response.choices[0].text.strip())\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "tgRetusl0Zcb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8KbCtd1IDvbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iAzuDWBKDvel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pnPjFLkDvhN",
        "outputId": "597b0e8d-7274-40aa-ca1a-1463a604f387"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch huggingface_hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3BJu6TLDvkB",
        "outputId": "f4ed8d5e-6d84-416e-f110-2eeacbdca409"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  torch\n",
        "\n",
        "from transformers import pipeline\n",
        "import re\n",
        "\n",
        "# Load the QA pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased\")\n",
        "\n",
        "def extract_key_terms_from_definition(definition):\n",
        "    # Construct the context and question\n",
        "    context = definition\n",
        "    question = \"What are the key terms in this definition?\"\n",
        "\n",
        "    # Query the model\n",
        "    result = qa_pipeline(question=question, context=context)\n",
        "    return result['answer']\n",
        "\n",
        "def process_text_and_extract_key_terms(text):\n",
        "    pattern = r'\"([^\"]+)\" (.+?)(?=(?:\\n\\n|$))'\n",
        "    matches = re.findall(pattern, text, re.DOTALL)\n",
        "\n",
        "    key_terms_dict = {}\n",
        "    for keyword, definition in matches:\n",
        "        key_terms_dict[keyword] = extract_key_terms_from_definition(definition)\n",
        "\n",
        "    return key_terms_dict\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"\n",
        "Understanding banking terms is essential for anyone navigating the financial landscape, whether you're managing personal finances or running a business. These terms form the foundation of everyday banking activities, from managing accounts and savings to understanding loans and interest rates. Below, you'll find definitions for some common banking terms, which will help you gain a better grasp of how banking works and enable you to make more informed financial decisions.\n",
        "\n",
        "\"Account Balance\" The amount of money available in a bank account at any given time.\n",
        "\n",
        "\"Annual Percentage Rate (APR)\" The yearly interest rate charged on borrowed money or earned through an investment, including any fees or additional costs.\n",
        "\n",
        "\"Automated Teller Machine (ATM)\" A machine that allows bank customers to perform financial transactions, such as withdrawals, deposits, and transfers, without needing a human teller.\n",
        "\n",
        "\"Certificate of Deposit (CD)\" A savings account that holds a fixed amount of money for a fixed period of time, with a fixed interest rate, typically offering higher interest rates than regular savings accounts.\n",
        "\n",
        "\"Collateral\" An asset or property that a borrower offers to a lender to secure a loan. If the borrower defaults, the lender has the right to seize the collateral.\n",
        "\n",
        "\"Credit Score\" A numerical representation of a person's creditworthiness, based on their credit history, which lenders use to assess the risk of lending money.\n",
        "\"\"\"\n",
        "\n",
        "# Extract key terms\n",
        "key_terms_dict = process_text_and_extract_key_terms(text)\n",
        "print(key_terms_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJCF0yzIEN4i",
        "outputId": "2c4633e7-6913-468f-bbd1-9e34d480c579"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Account Balance': 'money available in a bank account at any given time', 'Annual Percentage Rate (APR)': 'through an investment', 'Automated Teller Machine (ATM)': 'withdrawals, deposits, and', 'Certificate of Deposit (CD)': 'money for a fixed period', 'Collateral': 'borrower defaults', 'Credit Score': 'creditworthiness, based on their credit history'}\n"
          ]
        }
      ]
    }
  ]
}