
import json

# The given string response
response = """ "paragraph_1": "31 55075046_36 65777438_1 (b) The Management Fee lu de any related profits)
paragraph_3": "and similar fees paid on behalf of the Fund, includ ing such expenses

paragraph_4": u al to (i) the Limited Partner's total Capital Contributions in respect of Realized """

# Splitting the response into lines
lines = response.strip().split('\n')

# Initialize an empty dictionary to hold the JSON data
json_data = {}

# Iterate over each line and process it
for line in lines:
    # Splitting the key and value
    if ': ' in line:
        key, value = line.split(': ', 1)
        # Removing any leading or trailing quotes and whitespace from key and value
        key = key.strip().strip('"')
        value = value.strip().strip('"')
        # Assigning the key-value pair to the dictionary
        json_data[key] = value

# Convert the dictionary to a JSON string
json_response = json.dumps(json_data, indent=4)

# Printing the JSON response
print(json_response)









import json

# Define the input string
input_string = """
(b) The Management Fee lu de any related profits)
" paragraph_3": "and similar fees paid on behalf of the Fund, includ ing such expenses
"paragraph_4": u al to (i) the Limited Partner's total Capital Contributions in respect of Realized
"""

# Clean and prepare the input string
input_string = input_string.strip()

# Create a dictionary to hold the key-value pairs
data = {}

# Split the input string by lines
lines = input_string.split('\n')

# Process the first line which doesn't have a key
data["Paragraph_1"] = lines[0].strip()

# Process the remaining lines to extract key-value pairs
for line in lines[1:]:
    key_value = line.split(':', 1)  # Split based on the first occurrence of ':'
    if len(key_value) == 2:
        key = key_value[0].strip().strip('" ')  # Remove leading/trailing spaces and quotes
        value = key_value[1].strip().strip('" ')  # Remove leading/trailing spaces and quotes
        data[key] = value

# Define the output JSON file path
json_file_path = "snippets.json"

# Write the dictionary to a JSON file
with open(json_file_path, 'w') as json_file:
    json.dump(data, json_file, indent=4)

print(f"JSON file '{json_file_path}' has been created successfully.")







import json

# Define the input string
input_string = """
(b) The Management Fee lu de any related profits)
" paragraph_3": "and similar fees paid on behalf of the Fund, includ ing such expenses
"paragraph_4": u al to (i) the Limited Partner's total Capital Contributions in respect of Realized
"""

# Clean and prepare the input string
input_string = input_string.strip()

# Create a dictionary to hold the key-value pairs
data = {}

# Manually parse the string to extract key-value pairs
lines = input_string.split('\n')

# First line which doesn't have a key
data["Paragraph_1"] = lines[0].strip()

# Process the rest of the lines
for line in lines[1:]:
    key_value = line.split(':', 1)  # Split based on the first occurrence of ':'
    if len(key_value) == 2:
        key = key_value[0].strip().strip('" ')
        value = key_value[1].strip().strip('" ')
        data[key] = value

# Define the output JSON file path
json_file_path = "snippets.json"

# Write the dictionary to a JSON file
with open(json_file_path, 'w') as json_file:
    json.dump(data, json_file, indent=4)

print(f"JSON file '{json_file_path}' has been created successfully.")





import json

# Define the input string
input_string = """
(b) The Management Fee lu de any related profits)

" paragraph_3": "and similar fees paid on behalf of the Fund, includ ing such expenses

"paragraph_4": u al to (i) the Limited Partner's total Capital Contributions in respect of Realized
"""

# Split the input string by lines
lines = input_string.strip().split('\n')

# Initialize an empty dictionary to hold the key-value pairs
data = {}

# Process each line to extract key-value pairs
for line in lines:
    # Split the line into key and value based on the first occurrence of ':'
    key_value = line.split(':', 1)
    if len(key_value) == 2:
        key = key_value[0].strip().strip('" ')  # Remove leading/trailing spaces and quotes
        value = key_value[1].strip().strip('" ')  # Remove leading/trailing spaces and quotes
        data[key] = value

# Define the output JSON file path
json_file_path = "snippets.json"

# Write the dictionary to a JSON file
with open(json_file_path, 'w') as json_file:
    json.dump(data, json_file, indent=4)

print(f"JSON file '{json_file_path}' has been created successfully.")








import re
import json

# Noisy text containing embedded JSON-like structure
text = '''
json\n{\n

"paragraph_1": the Fund the capital subscription set (a)\n

"paragraph_2": any right to pa Related Firm) from the conduct ofthat of (and then only to the extent contemplated by this Agreement).

"paragraph_3": The Limited Partners acknowledge and 10.7.2. Fund),

any Portfolio Direct 35 55075046_36 65777438_1"\n}\n```'

# Regular expression to extract the JSON-like content
pattern = r'\{(?:[^{}]|[\n])*?\}'

# Extracting the JSON-like content
match = re.search(pattern, text)

if match:
    json_like_content = match.group()
    # Clean up the JSON-like content
    json_like_content = json_like_content.replace('json', '').replace('```', '').strip()
    
    # Attempt to parse as JSON object
    try:
        # Correct the format of the JSON-like content
        cleaned_content = re.sub(r'[\n\r]+', '', json_like_content)
        cleaned_content = re.sub(r'\s*([a-zA-Z0-9_]+)\s*:', r'"\1":', cleaned_content)
        
        # Load as JSON object
        json_data = json.loads(cleaned_content)
        print(json_data)
        
        # Write to a JSON file
        with open('output.json', 'w') as f:
            json.dump(json_data, f, indent=4)
        
        print("JSON file 'output.json' has been created successfully.")
    
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON: {e}")
    
else:
    print("No JSON-like structure found in the text.")









s

import re
import json

# Noisy text containing embedded JSON-like structure
text = '''
json\n{\n

"paragraph_1": the Fund the capital subscription set (a)\n

"paragraph_2": any right to pa Related Firm) from the conduct ofthat of (and then only to the extent contemplated by this Agreement).

"paragraph_3": The Limited Partners acknowledge and 10.7.2. Fund),

any Portfolio Direct 35 55075046_36 65777438_1"\n}\n```'

# Regular expression to extract the JSON-like content
pattern = r'\{(?:[^{}]|[\n])*?\}'

# Extracting the JSON-like content
match = re.search(pattern, text)

if match:
    json_like_content = match.group()
    # Clean up the JSON-like content
    json_like_content = json_like_content.replace('json', '').replace('```', '').strip()
    
    # Attempt to parse as JSON object
    try:
        # Correct the format of the JSON-like content
        # Remove newlines and ensure proper quoting of keys
        cleaned_content = re.sub(r'[\n\r]+', '', json_like_content)
        cleaned_content = re.sub(r'(?<!\\)"', r'\\"', cleaned_content)
        
        # Add double quotes around keys
        cleaned_content = re.sub(r'([^\s:]+)', r'"\1"', cleaned_content)
        
        # Load as JSON object
        json_data = json.loads(cleaned_content)
        print(json_data)
        
        # Write to a JSON file
        with open('output.json', 'w') as f:
            json.dump(json_data, f, indent=4)
        
        print("JSON file 'output.json' has been created successfully.")
    
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON: {e}")
    
else:
    print("No JSON-like structure found in the text.")




import re
import json

# Noisy text containing embedded JSON-like structure
text = '''
json\n{\n

"paragraph_1": the Fund the capital subscription set (a)\n

"paragraph_2": any right to pa Related Firm) from the conduct ofthat of (and then only to the extent contemplated by this Agreement).

"paragraph_3": The Limited Partners acknowledge and 10.7.2. Fund),

any Portfolio Direct 35 55075046_36 65777438_1"\n}\n```'

# Regular expression to extract the JSON-like content
pattern = r'\{(?:[^{}]|[\n])*?\}'

# Extracting the JSON-like content
match = re.search(pattern, text)

if match:
    json_like_content = match.group()
    # Clean up the JSON-like content
    json_like_content = json_like_content.replace('json', '').replace('```', '').strip()
    
    # Attempt to load as JSON object
    try:
        # Correcting the JSON-like content format
        json_like_content = re.sub(r'\n+', ' ', json_like_content)  # Replace multiple newlines with a single space
        json_like_content = json_like_content.replace('\\"', '"')  # Replace escaped double quotes
        
        # Ensure the structure is valid JSON by wrapping it with curly braces
        json_data = json.loads('{' + json_like_content + '}')
        print(json_data)
        
        # Write to a JSON file
        with open('output.json', 'w') as f:
            json.dump(json_data, f, indent=4)
        
        print("JSON file 'output.json' has been created successfully.")
    
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON: {e}")
    
else:
    print("No JSON-like structure found in the text.")








import re
import json

# Noisy text containing embedded JSON-like structure
text = '''
json\n{\n

"paragraph_1": the Fund the capital subscription set (a)\n

"paragraph_2": any right to pa Related Firm) from the conduct ofthat of (and then only to the extent contemplated by this Agreement).

"paragraph_3": The Limited Partners acknowledge and 10.7.2. Fund),

any Portfolio Direct 35 55075046_36 65777438_1"\n}\n```'

# Regular expression to extract the JSON-like content
pattern = r'\{(?:[^{}]|[\n])*?\}'

# Extracting the JSON-like content
match = re.search(pattern, text)

if match:
    json_like_content = match.group()
    # Clean up the JSON-like content
    json_like_content = json_like_content.replace('json', '').replace('```', '').strip()
    
    # Attempt to load as JSON object
    try:
        # Correcting the JSON-like content format
        json_like_content = json_like_content.replace('\n', ' ').replace('\\"', '"')
        
        json_data = json.loads(json_like_content)
        print(json_data)
        
        # Write to a JSON file
        with open('output.json', 'w') as f:
            json.dump(json_data, f, indent=4)
        
        print("JSON file 'output.json' has been created successfully.")
    
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON: {e}")
    
else:
    print("No JSON-like structure found in the text.")


import re
import json

# Noisy text containing embedded JSON-like structure
text = '''
json\n{\n

"paragraph_1": the Fund the capital subscription set (a)\n

"paragraph_2": any right to pa Related Firm) from the conduct ofthat of (and then only to the extent contemplated by this Agreement).

"paragraph_3": The Limited Partners acknowledge and 10.7.2. Fund),

any Portfolio Direct 35 55075046_36 65777438_1"\n}\n```'

# Regular expression to extract the JSON-like content
pattern = r'\{(?:[^{}]|(?R))*\}'

# Extracting the JSON-like content
match = re.search(pattern, text, re.DOTALL)

if match:
    json_like_content = match.group()
    # Clean up the JSON-like content
    json_like_content = re.sub(r'\\n', '\n', json_like_content)
    json_like_content = json_like_content.replace('json', '').replace('```', '').strip()
    
    # Load as JSON object
    try:
        json_data = json.loads(json_like_content)
        print(json_data)
        
        # Write to a JSON file
        with open('output.json', 'w') as f:
            json.dump(json_data, f, indent=4)
        
        print("JSON file 'output.json' has been created successfully.")
    
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON: {e}")
    
else:
    print("No JSON-like structure found in the text.")












_prompt_template = """
Objective: Extract distinct paragraphs related to the provided question from the document.

Scope: Only consider the main body of the document. Exclude the Table of Contents, headers, and footers.

Steps:
1. Read through the entire document, starting from the first section in the given text after the Table of Contents and ending before any appendices or endnotes.
2. Identify and count the distinct paragraphs where the content is relevant to the question: "{question}".
3. Filter and extract these paragraphs, ensuring they match the context of the question.
4. Provide the filtered content in the following JSON format:
{
    "FilteredContent": [
        {
            "Paragraph": "Relevant paragraph extracted from the document"
        }
    ]
}

The question is: {question}

The text to analyze is:
{paragraphs}
"""










_prompt_template = """
Objective: Extract and filter relevant content related to the management fee calculation based on the provided question using the given text.

Scope: Only consider the main body of the document. Exclude the Table of Contents, headers, and footers.

Steps:
1. Read through the entire document, starting from the first section in the given text after the Table of Contents and ending before any appendices or endnotes.
2. Identify the relevant sections that address the question: "{question}".
3. Filter and extract the content from these sections based on the question, ensuring clarity and relevance.
4. For each relevant section, provide the paragraph content and its corresponding page number.
5. Return the response in the following JSON format:
{
    "FilteredContent": [
        {
            "PageNumber": "Page number where the content is found",
            "Paragraph": "Relevant paragraph extracted from the document"
        }
    ]
}

The question is: {question}

The text to analyze is:
{paragraphs}
"""



import os
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

def extract_filtered_content(pdf_text, _prompt_template, question):
    # Initialize the AzureChatOpenAI model
    llm = AzureChatOpenAI(temperature=0, deployment_name=os.environ["DEPLOYMENT_NAME"])
    
    # Create the prompt template
    prompt_template = ChatPromptTemplate(
        messages=[HumanMessagePromptTemplate.from_template(_prompt_template)],
        input_variables=["paragraphs", "question"]
    )
    
    # Initialize the LLMChain with the model and prompt template
    llm_chain = LLMChain(
        llm=llm,
        prompt=prompt_template
    )
    
    # Predict the output using the given paragraphs and question
    output = llm_chain.predict(paragraphs=pdf_text, question=question)
    
    return output

# Example usage
pdf_text = """Your PDF text here. This should be a string containing the text extracted from your PDF document."""
question = "Can you explain the structure, calculation, and reduction of the Management Fee for each Limited Partner and Series?"

result = extract_filtered_content(pdf_text, _prompt_template, question)
print("Final Result:", result)










_prompt_template = """
Objective: Extract and filter relevant content based on the provided question using the given text.

Scope: Only consider the main body of the document. Exclude the Table of Contents, headers, and footers.

Steps:
1. Read through the entire document, starting from the first section in {paragraphs} after the Table of Contents and ending before any appendices or endnotes.
2. Identify the relevant sections that address the question: "{question}".
3. Filter and extract the content from these sections based on the question, ensuring clarity and relevance.
4. Return the response in the following JSON format:
{
    "FilteredContent": [
        {
            "Section": "<Section Name or Number>",
            "Content": "<Relevant content extracted from the document>"
        }
    ]
}

The question is: {question}
"""
import os
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

def extract_filtered_content(pdf_text, _prompt_template, question):
    # Initialize the AzureChatOpenAI model
    llm = AzureChatOpenAI(temperature=0, deployment_name=os.environ["DEPLOYMENT_NAME"])
    
    # Create the prompt template
    prompt_template = ChatPromptTemplate(
        messages=[HumanMessagePromptTemplate.from_template(_prompt_template)],
        input_variables=["paragraphs", "question"]
    )
    
    # Initialize the LLMChain with the model and prompt template
    llm_chain = LLMChain(
        llm=llm,
        prompt=prompt_template
    )
    
    # Predict the output using the given paragraphs and question
    output = llm_chain.predict(paragraphs=pdf_text, question=question)
    
    return output

# Example usage
pdf_text = """Your PDF text here. This should be a string containing the text extracted from your PDF document."""
question = "Can you explain the structure, calculation, and reduction of the Management Fee for each Limited Partner and Series?"

result = extract_filtered_content(pdf_text, _prompt_template, question)
print("Final Result:", result)















import os
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

def extract_filtered_content(pdf_text, _prompt_template, question):
    # Initialize the AzureChatOpenAI model
    llm = AzureChatOpenAI(temperature=0, deployment_name=os.environ["DEPLOYMENT_NAME"])
    
    # Create the prompt template
    prompt_template = ChatPromptTemplate(
        messages=[HumanMessagePromptTemplate.from_template(_prompt_template)],
        input_variables=["paragraphs", "question"]
    )
    
    # Initialize the LLMChain with the model and prompt template
    llm_chain = LLMChain(
        llm=llm,
        prompt=prompt_template
    )
    
    # Predict the output using the given paragraphs and question
    output = llm_chain.predict(paragraphs=pdf_text, question=question)
    
    return output

# Example usage
pdf_text = """Your PDF text here. This should be a string containing the text extracted from your PDF document."""
_prompt_template = """
Objective: Extract and filter relevant content based on the provided question using the given text.

Scope: Only consider the main body of the document. Exclude the Table of Contents, headers, and footers.

Steps:
1. Read through the entire document, starting from the first section in {paragraphs} after the Table of Contents and ending before any appendices or endnotes.
2. Identify the relevant sections that address the question: "{question}".
3. Filter and extract the content from these sections based on the question, ensuring clarity and relevance.
4. Return the response in the following JSON format:
{
    "FilteredContent": [
        {
            "Section": "Section Name or Number",
            "Content": "Relevant content extracted from the document"
        },
        ...
    ]
}

The question is: {question}
"""
question = "Can you explain the structure, calculation, and reduction of the Management Fee for each Limited Partner and Series?"

result = extract_filtered_content(pdf_text, _prompt_template, question)
print("Final Result:", result)









import json
import re

def save_as_json(self, split_text, file_path, heading):
    # Initialize an empty list to hold the chunks
    chunks = []
    
    for i, text_chunk in enumerate(split_text):
        # Clean the text chunk from unwanted characters
        text_chunk = re.sub(r'[\x80-\x1F]+', '', str(text_chunk))
        
        # Create a dictionary with the chunk details
        chunk_data = {
            'heading': f'{heading} - Chunk {i + 1}',
            'text': text_chunk
        }
        
        # Append the chunk data to the chunks list
        chunks.append(chunk_data)
    
    # Create a dictionary to hold the overall structure
    data = {
        'document_heading': heading,
        'chunks': chunks
    }
    
    # Save the data to a JSON file
    with open(file_path, 'w', encoding='utf-8') as json_file:
        json.dump(data, json_file, ensure_ascii=False, indent=4)
    
    print("Output saved as JSON successfully")

# Example usage
# Assuming `split_text` is a list of text chunks and `heading` is a string
# save_as_json(split_text, 'output.json', 'Document Heading')


absl-py==2.1.0
anyio==4.3.0
argon2-cffi==23.1.0
argon2-cffi-bindings==21.2.0
arrow==1.3.0
asttokens==2.4.1
astunparse==1.6.3
async-lru==2.0.4
attrs==23.2.0
Babel==2.14.0
beautifulsoup4==4.12.3
bleach==6.1.0
certifi==2024.2.2
cffi==1.16.0
charset-normalizer==3.3.2
colorama==0.4.6
comm==0.2.2
debugpy==1.8.1
decorator==5.1.1
defusedxml==0.7.1
executing==2.0.1
fastjsonschema==2.19.1
filelock==3.13.4
flatbuffers==24.3.25
fqdn==1.5.1
fsspec==2024.3.1
gast==0.5.4
google-pasta==0.2.0
grpcio==1.62.2
h11==0.14.0
h5py==3.11.0
httpcore==1.0.5
httpx==0.27.0
huggingface-hub==0.22.2
idna==3.7
ipykernel==6.29.4
ipython==8.23.0
ipython-genutils==0.2.0
isoduration==20.11.0
jedi==0.19.1
Jinja2==3.1.3
json5==0.9.25
jsonpointer==2.4
jsonschema==4.21.1
jsonschema-specifications==2023.12.1
jupyter-events==0.10.0
jupyter-lsp==2.2.5
jupyter_client==8.6.1
jupyter_core==5.7.2
jupyter_server==2.14.0
jupyter_server_terminals==0.5.3
jupyterlab==4.1.6
jupyterlab_pygments==0.3.0
jupyterlab_server==2.27.0
keras==3.3.2
libclang==18.1.1
Markdown==3.6
markdown-it-py==3.0.0
MarkupSafe==2.1.5
matplotlib-inline==0.1.7
mdurl==0.1.2
mistune==3.0.2
ml-dtypes==0.3.2
mpmath==1.3.0
namex==0.0.8
nbclient==0.10.0
nbconvert==7.16.3
nbformat==5.10.4
nest-asyncio==1.6.0
networkx==3.3
notebook==6.1.4
notebook_shim==0.2.4
numpy==1.26.4
opt-einsum==3.3.0
optree==0.11.0
overrides==7.7.0
packaging==24.0
pandas==2.2.2
pandocfilters==1.5.1
parso==0.8.4
platformdirs==4.2.0
prometheus_client==0.20.0
prompt-toolkit==3.0.43
protobuf==4.25.3
psutil==5.9.8
pure-eval==0.2.2
pycparser==2.22
Pygments==2.17.2
PyPDF2==3.0.1
python-dateutil==2.9.0.post0
python-json-logger==2.0.7
pytz==2024.1
pywin32==306
pywinpty==2.0.13
PyYAML==6.0.1
pyzmq==26.0.2
referencing==0.34.0
regex==2024.4.16
requests==2.31.0
rfc3339-validator==0.1.4
rfc3986-validator==0.1.1
rich==13.7.1
rpds-py==0.18.0
safetensors==0.4.3
Send2Trash==1.8.3
six==1.16.0
sniffio==1.3.1
soupsieve==2.5
stack-data==0.6.3
sympy==1.12
tensorboard==2.16.2
tensorboard-data-server==0.7.2
tensorflow==2.16.1
tensorflow-intel==2.16.1
tensorflow-io-gcs-filesystem==0.31.0
termcolor==2.4.0
terminado==0.18.1
tf_keras==2.16.0
tinycss2==1.2.1
tokenizers==0.19.1
torch==2.2.2
tornado==6.4
tqdm==4.66.2
traitlets==5.14.3
transformers==4.40.0
types-python-dateutil==2.9.0.20240316
typing_extensions==4.11.0
tzdata==2024.1
uri-template==1.3.0
urllib3==2.2.1
wcwidth==0.2.13
webcolors==1.13
webencodings==0.5.1
websocket-client==1.7.0
Werkzeug==3.0.2
wrapt==1.16.0
