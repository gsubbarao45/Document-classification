{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8fcbedc294f43b380383938d484cb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71e1eef8ba164b3d8f31c92d12520255",
              "IPY_MODEL_741908e9022341edad91062e0ec31018",
              "IPY_MODEL_09e54e129eb44101b5c4861f4700f48c"
            ],
            "layout": "IPY_MODEL_66f5bf97d72843eb93ca21915539dbf3"
          }
        },
        "71e1eef8ba164b3d8f31c92d12520255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274fd7d7220d41a4bc92498aa5748237",
            "placeholder": "​",
            "style": "IPY_MODEL_0a607ed401aa40e7882d9a000671c81f",
            "value": "Map:   0%"
          }
        },
        "741908e9022341edad91062e0ec31018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b114e819dcf444a1b28a0facdb415952",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a00db594d1e42409e34a4a86323d819",
            "value": 0
          }
        },
        "09e54e129eb44101b5c4861f4700f48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9c49df3b7044f25a05a67301539b6d8",
            "placeholder": "​",
            "style": "IPY_MODEL_a0138727cd434495b117e88f9aae5a31",
            "value": " 0/1 [00:00&lt;?, ? examples/s]"
          }
        },
        "66f5bf97d72843eb93ca21915539dbf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "274fd7d7220d41a4bc92498aa5748237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a607ed401aa40e7882d9a000671c81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b114e819dcf444a1b28a0facdb415952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a00db594d1e42409e34a4a86323d819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9c49df3b7044f25a05a67301539b6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0138727cd434495b117e88f9aae5a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Vvu51XnR8Tfb"
      },
      "outputs": [],
      "source": [
        "#!pip install pdf2image\n",
        "#!sudo apt-get install poppler-utils\n",
        "#!pip install datasets\n",
        "#!pip install pytesseract\n",
        "#!apt install tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['CV', 'invoive']\n",
        "labels = ['CV', 'invoive']\n",
        "idx2label = {v: k for v, k in enumerate(labels)}\n",
        "label2idx = {k: v for v, k in enumerate(labels)}\n",
        "label2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjGw2_xo8Z44",
        "outputId": "ba534dae-e5b9-42af-fb35-0c8a410b2e8b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CV': 0, 'invoive': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmmjHgIpGd1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LayoutLMTokenizer\n",
        "import torch\n",
        "model_path = '/content/drive/MyDrive/dataset/saved_model/'\n",
        "tokenizer = LayoutLMTokenizer.from_pretrained('/content/drive/MyDrive/dataset/saved_model/')\n",
        "\n",
        "def encode_example(example, max_seq_length=512, pad_token_box=[0, 0, 0, 0]):\n",
        "  words = example['words']\n",
        "  normalized_word_boxes = example['bbox']\n",
        "\n",
        "  assert len(words) == len(normalized_word_boxes)\n",
        "\n",
        "  token_boxes = []\n",
        "  for word, box in zip(words, normalized_word_boxes):\n",
        "      word_tokens = tokenizer.tokenize(word)\n",
        "      token_boxes.extend([box] * len(word_tokens))\n",
        "\n",
        "  # Truncation of token_boxes\n",
        "  special_tokens_count = 2\n",
        "  if len(token_boxes) > max_seq_length - special_tokens_count:\n",
        "      token_boxes = token_boxes[: (max_seq_length - special_tokens_count)]\n",
        "\n",
        "  # add bounding boxes of cls + sep tokens\n",
        "  token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
        "\n",
        "  encoding = tokenizer(' '.join(words), padding='max_length', truncation=True)\n",
        "  # Padding of token_boxes up the bounding boxes to the sequence length.\n",
        "  input_ids = tokenizer(' '.join(words), truncation=True)[\"input_ids\"]\n",
        "  padding_length = max_seq_length - len(input_ids)\n",
        "  token_boxes += [pad_token_box] * padding_length\n",
        "  encoding['bbox'] = token_boxes\n",
        "  encoding['label'] = label2idx[example['label']]\n",
        "\n",
        "  assert len(encoding['input_ids']) == max_seq_length\n",
        "  assert len(encoding['attention_mask']) == max_seq_length\n",
        "  assert len(encoding['token_type_ids']) == max_seq_length\n",
        "  assert len(encoding['bbox']) == max_seq_length\n",
        "\n",
        "  return encoding"
      ],
      "metadata": {
        "id": "LobgtyMNDbTD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Features, Sequence, ClassLabel, Value, Array2D\n",
        "# we need to define the features ourselves as the bbox of LayoutLM are an extra feature\n",
        "features = Features({\n",
        "    'input_ids': Sequence(feature=Value(dtype='int64')),\n",
        "    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
        "    'attention_mask': Sequence(Value(dtype='int64')),\n",
        "    'token_type_ids': Sequence(Value(dtype='int64')),\n",
        "    'label': ClassLabel(names=['CV', 'Invoice','Bon','memo']),\n",
        "    'image_path': Value(dtype='string'),\n",
        "    'words': Sequence(feature=Value(dtype='string')),\n",
        "})\n",
        "\n",
        "\n",
        "encoded_test_dataset = updated_test_dataset.map(lambda example: encode_example(example),\n",
        "                                      features=features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "c8fcbedc294f43b380383938d484cb49",
            "71e1eef8ba164b3d8f31c92d12520255",
            "741908e9022341edad91062e0ec31018",
            "09e54e129eb44101b5c4861f4700f48c",
            "66f5bf97d72843eb93ca21915539dbf3",
            "274fd7d7220d41a4bc92498aa5748237",
            "0a607ed401aa40e7882d9a000671c81f",
            "b114e819dcf444a1b28a0facdb415952",
            "4a00db594d1e42409e34a4a86323d819",
            "f9c49df3b7044f25a05a67301539b6d8",
            "a0138727cd434495b117e88f9aae5a31"
          ]
        },
        "id": "XZ8fuJR3C-y_",
        "outputId": "ae0fdae8-f54c-4ef7-9954-ab8863b87241"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8fcbedc294f43b380383938d484cb49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a486e23ee714>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m encoded_test_dataset = updated_test_dataset.map(lambda example: encode_example(example),\n\u001b[0m\u001b[1;32m     15\u001b[0m                                       features=features)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         }\n\u001b[1;32m    566\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3154\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3155\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3156\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3157\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3515\u001b[0m                     \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3516\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshard_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3517\u001b[0;31m                         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_function_on_filtered_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3518\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3519\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3414\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3415\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3416\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3417\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3418\u001b[0m                 processed_inputs = {\n",
            "\u001b[0;32m<ipython-input-46-a486e23ee714>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m encoded_test_dataset = updated_test_dataset.map(lambda example: encode_example(example),\n\u001b[0m\u001b[1;32m     15\u001b[0m                                       features=features)\n",
            "\u001b[0;32m<ipython-input-42-410ca834f1b9>\u001b[0m in \u001b[0;36mencode_example\u001b[0;34m(example, max_seq_length, pad_token_box)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mtoken_boxes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpad_token_box\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpadding_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3z7H5TqEjIT",
        "outputId": "e86c0d03-8090-407b-9b39-4452b90c81a1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image_path', 'label', 'words', 'bbox'],\n",
              "    num_rows: 1\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsL5JU7hFJBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LayoutLMForSequenceClassification, LayoutLMTokenizer\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "model_path = '/content/drive/MyDrive/dataset/saved_model/'\n",
        "model = LayoutLMForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = LayoutLMTokenizer.from_pretrained(model_path)\n"
      ],
      "metadata": {
        "id": "sBR4haIrFJD9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the model onto the device\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-VIKkKkFNFB",
        "outputId": "f5955a90-ba6f-41ed-fd9c-c6619b10df00"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LayoutLMForSequenceClassification(\n",
              "  (layoutlm): LayoutLMModel(\n",
              "    (embeddings): LayoutLMEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (x_position_embeddings): Embedding(1024, 768)\n",
              "      (y_position_embeddings): Embedding(1024, 768)\n",
              "      (h_position_embeddings): Embedding(1024, 768)\n",
              "      (w_position_embeddings): Embedding(1024, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): LayoutLMEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x LayoutLMLayer(\n",
              "          (attention): LayoutLMAttention(\n",
              "            (self): LayoutLMSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): LayoutLMPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-H1Oaiz7FmCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "def preprocess_new_pdf_images(pdf_path):\n",
        "    # Convert PDF to images\n",
        "    images = convert_from_path(pdf_path)\n",
        "\n",
        "    # Initialize a list to store preprocessed examples\n",
        "    preprocessed_examples = []\n",
        "\n",
        "    # Perform OCR on each image and create examples\n",
        "    for i, image in enumerate(images):\n",
        "        # Perform OCR to extract text\n",
        "        text = pytesseract.image_to_string(image)\n",
        "\n",
        "        # Extract bounding boxes and words using OCR data frame\n",
        "        ocr_df = pytesseract.image_to_data(image, output_type='data.frame')\n",
        "        ocr_df = ocr_df.dropna().reset_index(drop=True)\n",
        "        words = list(ocr_df.text)\n",
        "        coordinates = ocr_df[['left', 'top', 'width', 'height']]\n",
        "        actual_boxes = []\n",
        "        for _, row in coordinates.iterrows():\n",
        "            x, y, w, h = tuple(row)\n",
        "            actual_box = [x, y, x + w, y + h]\n",
        "            actual_boxes.append(actual_box)\n",
        "\n",
        "        # Normalize bounding boxes\n",
        "        width, height = image.size\n",
        "        normalized_boxes = []\n",
        "        for box in actual_boxes:\n",
        "            normalized_box = normalize_box(box, width, height)\n",
        "            normalized_boxes.append(normalized_box)\n",
        "\n",
        "        # Create example dictionary\n",
        "        example = {\n",
        "            'image_path': pdf_path,  # Store the path to the PDF image\n",
        "            'words': words,\n",
        "            'bbox': normalized_boxes\n",
        "        }\n",
        "\n",
        "        preprocessed_examples.append(example)\n",
        "\n",
        "    return preprocessed_examples\n",
        "\n",
        "# Normalize bounding boxes\n",
        "def normalize_box(box, width, height):\n",
        "    return [\n",
        "        int(1000 * (box[0] / width)),\n",
        "        int(1000 * (box[1] / height)),\n",
        "        int(1000 * (box[2] / width)),\n",
        "        int(1000 * (box[3] / height)),\n",
        "    ]\n",
        "\n",
        "# Example usage:\n",
        "pdf_path = \"/content/drive/MyDrive/input/OD124156933233239000.pdf\"\n",
        "preprocessed_data = preprocess_new_pdf_images(pdf_path)\n",
        "print(preprocessed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb07ES7CFmR0",
        "outputId": "8cfc6e12-1a22-4d48-eadf-fb36a610ef53"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'image_path': '/content/drive/MyDrive/input/OD124156933233239000.pdf', 'words': ['Tax', 'Invoice', 'Sold', 'By:', 'Shreyash', 'Retail', 'Private', 'Limited', ',', 'Ship-from', 'Address:', 'Sy', 'no', '18/2,18/3,18/4', '19/1,19/2,19/3,20/1,20/2,20/3,21/2,22/2,23/2,23/3,23/4', 'Taverekere', 'venkatapura,', 'hosakote', 'taluk,', 'nadagudi', 'hobli,bangalore', '562122,', 'Bangalore,', 'KARNATAKA,', 'India', '-', '562122,', 'IN-KA', 'GSTIN', '-', '29AAXCS0655F1ZU', 'FSSAI', 'License', 'No', '-', '13321999000230', 'iin', ' ', ' ', ' ', 'Order', 'ID:', '0D124156933233239000', 'Bil|', 'To', 'Order', 'Date:', '13-02-2022', 'Invoice', 'Date:', '13-02-2022', 'Anumula', 'Brahma', 'Chary', 'H.', 'No:136,', 'Marigudem,', 'abbayipalem,', 'korivi', 'road,', 'maripeda', 'bunglow.', 'Ship', 'To', 'Anumula', 'Brahma', 'Chary', 'H.', 'No:136,', 'Marigudem,', 'abbayipalem,', 'korivi', 'road,', 'maripeda', 'bunglow.', '*Keep', 'this', 'invoice', 'and', 'manufacturer', 'box', 'for', ' ', ' ', ' ', ' ', 'PAN:', 'aaxcs0655f', 'Mahabubabad', 'District', '506315', 'Mahabubabad', 'District', '506315', 'warranty', 'purposes.', '.', 'Telangana', 'Telangana', 'GIN:', 'U52399DL201', '6PTC299716', 'Phone:', 'xxxXxxXxXXxX', 'Phone:', 'xxxxxxxXxxx', 'Total', 'items:', '1', 'Product', 'Title', 'Qty', 'Gross', 'Discount', '=', 'Taxable', 'IGST%', '‘Total', '=', 'Amount', '&', 'Value', '%', 'Headphones', 'boAt', 'Airdopes', '402', '1', '1499.00', '0.00', '1270.34', '228.66', '1499.00', 'FSN:', 'ACCFSDGSYTH8XV7A_', 'Bluetooth', 'Headset', 'HSN/SAC:', '85176290', 'Warranty:', '1', 'Year', 'Warranty', 'IGST:', '18.0', '%', 'Total', '1', '1499.00', '0.00', '1270.34', '228.66', '1499.00', 'Grand', 'Total', '=', '1499.00', 'Shreyash', 'Retail', 'Private', 'Limited', 'Authorized', 'Signatory', ' ', 'Flipkart', 'Thank', 'You!', 'for', 'shopping', 'with', 'us', 'Returns', 'Policy:', 'At', 'Flipkart', 'we', 'try', 'to', 'deliver', 'perfectly', 'each', 'and', 'every', 'time.', 'But', 'in', 'the', 'off-chance', 'that', 'you', 'need', 'to', 'return', 'the', 'item,', 'please', 'do', 'so', 'with', 'the', 'original', 'Brand', 'box/price', 'tag,', 'original', 'packing', 'and', 'invoice', 'without', 'which', 'it', 'will', 'be', 'really', 'difficult', 'for', 'us', 'to', 'act', 'on', 'your', 'request.', 'Please', 'help', 'us', 'in', 'helping', 'you.', 'Terms', 'and', 'conditions', 'apply.', 'The', 'goods', 'sold', 'as', 'are', 'intended', 'for', 'end', 'user', 'consumption', 'and', 'not', 'for', 're-sale.', 'Regd.', 'office:', 'Shreyash', 'Retail', 'Private', 'Limited', ',', '2nd', 'Floor,', 'Plot', 'No.', '82,', 'Okhla', 'Industrial', 'Estate,', 'Phase-III', 'New', 'Delhi,', 'South', 'Delhi,', 'NEW', 'DELHI,', 'DELHI', '-', '110020', 'Contact', 'Flipkart:', '1800', '208', '9898', '||', 'www.fli', 'kart.com/helpcentre', ' ', '  ', ' ', 'E.', '&O.', 'page', '1', 'of', '1'], 'bbox': [[434, 14, 467, 25], [473, 14, 537, 25], [19, 31, 48, 39], [53, 31, 73, 41], [78, 31, 140, 41], [146, 31, 183, 39], [189, 31, 235, 39], [241, 31, 290, 39], [295, 38, 297, 40], [19, 46, 72, 54], [75, 46, 123, 52], [125, 47, 136, 54], [140, 48, 151, 52], [154, 47, 222, 53], [226, 47, 485, 53], [489, 46, 541, 52], [545, 46, 606, 54], [609, 46, 650, 52], [655, 46, 679, 53], [19, 61, 62, 68], [66, 61, 141, 68], [145, 61, 182, 68], [186, 61, 238, 68], [241, 61, 310, 68], [313, 61, 338, 67], [341, 64, 345, 65], [348, 61, 385, 68], [389, 61, 420, 67], [19, 74, 62, 82], [67, 78, 70, 79], [75, 74, 208, 82], [19, 89, 59, 97], [65, 89, 116, 97], [121, 89, 139, 97], [143, 93, 147, 94], [152, 89, 269, 97], [697, 102, 715, 113], [704, 32, 785, 97], [715, 97, 952, 113], [9, 126, 962, 130], [19, 138, 56, 146], [61, 138, 78, 146], [83, 138, 258, 146], [277, 141, 296, 150], [301, 142, 318, 150], [19, 159, 56, 167], [61, 159, 95, 167], [101, 159, 175, 167], [19, 180, 67, 188], [72, 180, 106, 188], [111, 180, 186, 188], [275, 156, 336, 164], [341, 156, 392, 164], [397, 156, 436, 166], [277, 171, 289, 178], [295, 171, 345, 179], [350, 170, 428, 180], [433, 170, 520, 180], [277, 184, 310, 192], [316, 184, 348, 194], [353, 184, 415, 194], [421, 184, 479, 194], [537, 141, 567, 152], [571, 142, 588, 150], [537, 156, 597, 164], [603, 156, 654, 164], [659, 156, 698, 166], [538, 171, 551, 178], [557, 171, 606, 179], [612, 170, 690, 180], [695, 170, 782, 180], [538, 184, 572, 192], [578, 184, 609, 194], [615, 184, 676, 194], [682, 184, 741, 194], [812, 172, 842, 180], [846, 172, 865, 178], [868, 172, 905, 178], [908, 172, 928, 178], [817, 186, 888, 193], [890, 186, 909, 193], [913, 186, 928, 193], [9, 268, 962, 273], [9, 305, 962, 309], [189, 391, 961, 395], [9, 423, 962, 427], [19, 201, 53, 209], [58, 201, 136, 209], [277, 198, 371, 206], [377, 199, 423, 206], [428, 199, 478, 206], [538, 198, 633, 206], [638, 199, 685, 206], [690, 199, 739, 206], [823, 197, 874, 211], [878, 197, 928, 211], [44, 224, 47, 226], [276, 211, 345, 225], [537, 213, 606, 223], [19, 222, 47, 230], [52, 222, 144, 230], [148, 222, 234, 230], [277, 227, 321, 235], [326, 230, 400, 235], [538, 227, 583, 235], [588, 230, 661, 235], [9, 259, 42, 267], [48, 259, 87, 267], [93, 259, 98, 267], [15, 276, 67, 289], [187, 276, 225, 289], [474, 276, 496, 289], [535, 276, 574, 289], [612, 278, 670, 286], [675, 278, 682, 286], [727, 276, 780, 289], [821, 278, 865, 286], [893, 277, 927, 286], [932, 278, 940, 286], [522, 292, 575, 300], [580, 292, 587, 300], [728, 292, 767, 300], [771, 292, 778, 300], [15, 318, 88, 332], [195, 320, 229, 329], [234, 320, 301, 331], [307, 320, 335, 329], [482, 321, 486, 328], [528, 321, 581, 328], [633, 321, 660, 328], [727, 321, 781, 328], [820, 321, 865, 328], [890, 321, 943, 328], [15, 336, 41, 342], [45, 336, 179, 342], [195, 335, 266, 344], [272, 335, 334, 344], [15, 349, 82, 358], [87, 349, 154, 357], [194, 351, 243, 359], [248, 351, 251, 357], [257, 351, 280, 357], [283, 351, 330, 359], [195, 365, 223, 371], [227, 365, 249, 371], [252, 365, 260, 371], [301, 404, 342, 418], [467, 406, 471, 413], [528, 406, 582, 413], [632, 406, 661, 413], [727, 406, 781, 413], [819, 406, 866, 413], [889, 406, 944, 413], [705, 448, 756, 459], [764, 448, 807, 459], [867, 448, 876, 459], [883, 448, 956, 459], [750, 473, 810, 483], [816, 473, 851, 481], [857, 474, 903, 481], [908, 473, 956, 481], [771, 566, 843, 574], [848, 566, 911, 576], [9, 579, 962, 583], [848, 795, 912, 807], [857, 813, 901, 822], [905, 813, 935, 822], [859, 823, 869, 829], [872, 824, 906, 829], [909, 824, 924, 828], [928, 825, 935, 828], [24, 851, 76, 859], [81, 851, 125, 861], [128, 853, 139, 859], [142, 853, 181, 861], [184, 855, 197, 859], [200, 854, 213, 861], [216, 854, 225, 859], [228, 853, 261, 859], [263, 853, 305, 861], [308, 853, 329, 859], [333, 853, 350, 859], [354, 855, 379, 861], [382, 853, 404, 859], [408, 853, 425, 859], [428, 853, 436, 859], [440, 853, 454, 859], [457, 853, 506, 861], [510, 853, 528, 859], [530, 855, 548, 861], [551, 853, 573, 859], [577, 854, 585, 859], [589, 854, 617, 859], [621, 853, 635, 859], [638, 853, 660, 860], [664, 853, 694, 861], [698, 853, 709, 859], [712, 855, 722, 859], [726, 853, 745, 859], [749, 853, 762, 859], [767, 851, 816, 861], [822, 851, 860, 859], [866, 851, 929, 861], [23, 867, 48, 877], [53, 867, 103, 877], [108, 867, 160, 877], [165, 867, 189, 875], [195, 867, 242, 875], [246, 869, 281, 875], [284, 869, 312, 875], [316, 869, 321, 875], [325, 869, 342, 875], [346, 869, 356, 875], [359, 869, 387, 876], [390, 869, 427, 876], [429, 869, 443, 876], [447, 871, 456, 875], [460, 870, 468, 875], [472, 870, 486, 875], [489, 871, 500, 875], [502, 871, 525, 876], [528, 870, 565, 876], [569, 869, 600, 875], [603, 869, 623, 876], [627, 871, 636, 875], [640, 869, 648, 875], [652, 869, 687, 876], [689, 871, 709, 876], [714, 869, 742, 875], [745, 869, 763, 875], [766, 869, 814, 875], [818, 869, 846, 876], [24, 890, 41, 896], [44, 890, 71, 897], [75, 890, 94, 896], [98, 892, 108, 896], [111, 892, 127, 896], [130, 890, 170, 896], [173, 890, 187, 897], [190, 890, 207, 896], [210, 892, 230, 896], [234, 890, 293, 897], [297, 890, 313, 896], [317, 891, 332, 896], [335, 890, 349, 897], [352, 890, 386, 896], [23, 911, 49, 919], [54, 911, 82, 919], [87, 911, 135, 919], [139, 911, 168, 917], [171, 911, 207, 917], [210, 911, 254, 918], [248, 907, 256, 921], [257, 911, 275, 917], [278, 911, 307, 918], [310, 911, 330, 917], [333, 911, 349, 917], [353, 911, 367, 918], [371, 911, 399, 917], [402, 911, 448, 917], [451, 911, 483, 918], [487, 911, 532, 917], [534, 911, 555, 917], [558, 911, 586, 918], [591, 911, 617, 917], [620, 911, 649, 918], [652, 911, 678, 917], [680, 911, 717, 918], [721, 911, 756, 917], [759, 915, 762, 915], [766, 911, 800, 917], [19, 929, 71, 936], [76, 928, 128, 936], [134, 929, 165, 936], [171, 929, 195, 936], [200, 929, 232, 936], [238, 929, 243, 938], [248, 928, 298, 936], [308, 928, 444, 937], [91, 930, 98, 938], [298, 930, 306, 938], [41, 939, 955, 941], [795, 943, 806, 951], [811, 943, 838, 951], [878, 945, 909, 953], [915, 943, 919, 951], [927, 943, 940, 951], [944, 939, 952, 951]]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_example(example, max_seq_length=512, pad_token_box=[0, 0, 0, 0]):\n",
        "    words = example['words']\n",
        "    normalized_word_boxes = example['bbox']\n",
        "\n",
        "    assert len(words) == len(normalized_word_boxes)\n",
        "\n",
        "    token_boxes = []\n",
        "    for word, box in zip(words, normalized_word_boxes):\n",
        "        word_tokens = tokenizer.tokenize(word)\n",
        "        token_boxes.extend([box] * len(word_tokens))\n",
        "\n",
        "    # Truncation of token_boxes\n",
        "    special_tokens_count = 2\n",
        "    if len(token_boxes) > max_seq_length - special_tokens_count:\n",
        "        token_boxes = token_boxes[: (max_seq_length - special_tokens_count)]\n",
        "\n",
        "    # add bounding boxes of cls + sep tokens\n",
        "    token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
        "\n",
        "    encoding = tokenizer(' '.join(words), padding='max_length', truncation=True)\n",
        "    # Padding of token_boxes up the bounding boxes to the sequence length.\n",
        "    input_ids = tokenizer(' '.join(words), truncation=True)[\"input_ids\"]\n",
        "    padding_length = max_seq_length - len(input_ids)\n",
        "    token_boxes += [pad_token_box] * padding_length\n",
        "    encoding['bbox'] = token_boxes\n",
        "\n",
        "    # Check if 'label' key exists in example dictionary\n",
        "    if 'label' in example:\n",
        "        encoding['label'] = label2idx[example['label']]\n",
        "\n",
        "    assert len(encoding['input_ids']) == max_seq_length\n",
        "    assert len(encoding['attention_mask']) == max_seq_length\n",
        "    assert len(encoding['token_type_ids']) == max_seq_length\n",
        "    assert len(encoding['bbox']) == max_seq_length\n",
        "\n",
        "    return encoding\n"
      ],
      "metadata": {
        "id": "hMqB_7TrGLoQ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the examples using the tokenizer\n",
        "encoded_examples = []\n",
        "for example in preprocessed_data:\n",
        "    encoded_example = encode_example(example)  # Assuming you have encode_example function defined\n",
        "    encoded_examples.append(encoded_example)\n",
        "\n",
        "# Convert the encoded examples to PyTorch tensors\n",
        "input_ids = torch.tensor([example['input_ids'] for example in encoded_examples], dtype=torch.long).to(device)\n",
        "bbox = torch.tensor([example['bbox'] for example in encoded_examples], dtype=torch.long).to(device)\n",
        "attention_mask = torch.tensor([example['attention_mask'] for example in encoded_examples], dtype=torch.long).to(device)\n",
        "token_type_ids = torch.tensor([example['token_type_ids'] for example in encoded_examples], dtype=torch.long).to(device)\n",
        "\n",
        "# Run inference using the loaded model\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "\n",
        "# Decode the predictions\n",
        "predicted_labels = [idx2label[prediction] for prediction in predictions]\n",
        "\n",
        "# Print the predicted labels\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X8Yk4UcF5Qk",
        "outputId": "b1a6165b-cbcd-4665-eaba-c9f98573497d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: ['invoive']\n"
          ]
        }
      ]
    }
  ]
}